{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:26:11.961537Z",
     "start_time": "2019-01-20T09:26:11.957717Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:26:14.567897Z",
     "start_time": "2019-01-20T09:26:13.730804Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import gc\n",
    "import itertools\n",
    "from contextlib import redirect_stdout\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:26:15.807929Z",
     "start_time": "2019-01-20T09:26:14.570447Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, TensorBoard\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, Input\n",
    "from keras.layers.recurrent import SimpleRNN, GRU, LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D, Convolution1D, Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:26:17.679053Z",
     "start_time": "2019-01-20T09:26:15.810459Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:04:09.411218Z",
     "start_time": "2019-01-20T09:04:09.407292Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:04:09.421426Z",
     "start_time": "2019-01-20T09:04:09.414039Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:04:09.431164Z",
     "start_time": "2019-01-20T09:04:09.424112Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.data import Data\n",
    "\n",
    "# load preprocessing functions\n",
    "from deepvideoclassification.pretrained_CNNs import load_pretrained_model, load_pretrained_model_preprocessor, precompute_CNN_features\n",
    "# load preprocessing constants\n",
    "from deepvideoclassification.pretrained_CNNs import pretrained_model_len_features, pretrained_model_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:04:09.510506Z",
     "start_time": "2019-01-20T09:04:09.504301Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture class (contains keras model object and train/evaluate method, writes training results to /models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:04:09.694847Z",
     "start_time": "2019-01-20T09:04:09.513731Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Architecture(object):\n",
    "    \n",
    "    def __init__(self, model_id, architecture, sequence_length, \n",
    "                frame_size = None, \n",
    "                pretrained_model_name = None, pooling = None,\n",
    "                sequence_model = None, sequence_model_layers = None,\n",
    "                layer_1_size = 0, layer_2_size = 0, layer_3_size = 0, \n",
    "                dropout = 0, convolution_kernel_size = 3, \n",
    "                model_weights_path = None, \n",
    "                batch_size = 32, \n",
    "                verbose = False):\n",
    "        \"\"\"\n",
    "        Model object constructor. Contains Keras model object and training/evaluation methods. Writes model results to /models/_id_ folder\n",
    "        \n",
    "        Architecture can be one of: \n",
    "        image_MLP_frozen, image_MLP_trainable, video_MLP_concat, video_LRCNN_frozen, video_LRCNN_trainable, C3D, C3Dsmall\n",
    "        \n",
    "        :model_id: integer identifier for this model e.g. 1337\n",
    "        \n",
    "        :architecture: architecture of model in [image_MLP_frozen, image_MLP_trainable, video_MLP_concat, video_LRCNN_frozen, video_LRCNN_trainable, C3D, C3Dsmall]\n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        \n",
    "        :frame_size: size that frames are resized to (different models / architectures accept different input sizes - will be inferred if pretrained_model_name is given since they have fixed sizes)\n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN or if fitting more non-dense layers on top of pretrained model base)\n",
    "        \n",
    "        :sequence_model: sequence model in [LSTM, SimpleRNN, GRU, Convolution1D]\n",
    "        :sequence_model_layers: default to 1, can be stacked 2 or 3 (but less than 4) layer sequence model (assume always stacking the same sequence model, not mixing LSTM and GRU, for example)\n",
    "        \n",
    "        :layer_1_size: number of neurons in layer 1\n",
    "        :layer_2_size: number of neurons in layer 2\n",
    "        :layer_3_size: number of neurons in layer 3 \n",
    "        \n",
    "        :dropout: amount of dropout to add (same applied throughout model - good default is 0.2) \n",
    "        \n",
    "        :convolution_kernel_size: size of 1-D convolutional kernel for 1-d conv sequence models (good default is 3)\n",
    "        \n",
    "        :model_weights_path: path to .h5 weights file to be loaded for pretrained CNN in LRCNN-trainable \n",
    "        \n",
    "        :batch_size: batch size used to fit model (default to 32)\n",
    "        \n",
    "        :verbose: whether to log progress updates\n",
    "        \"\"\"\n",
    "    \n",
    "        # required params\n",
    "        self.model_id = model_id\n",
    "        \n",
    "        # create path based on model id\n",
    "        self.path_model = pwd + 'models/' + str(model_id) + '/'\n",
    "        if not os.path.exists(self.path_model):\n",
    "            os.makedirs(self.path_model)\n",
    "        else:\n",
    "            if not os.path.exists(self.path_model + 'results.json'):\n",
    "                logging.info(\"Model folder exists but no results found - potential error in previous model training\")\n",
    "        \n",
    "        self.architecture = architecture\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # model architecture params\n",
    "        self.frame_size = frame_size\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.sequence_model = sequence_model\n",
    "        self.sequence_model_layers = sequence_model_layers\n",
    "        #\n",
    "        self.layer_1_size = layer_1_size\n",
    "        self.layer_2_size = layer_2_size\n",
    "        self.layer_3_size = layer_3_size\n",
    "        #\n",
    "        self.dropout = dropout\n",
    "        #\n",
    "        self.convolution_kernel_size = convolution_kernel_size\n",
    "        #\n",
    "        self.model_weights_path = model_weights_path\n",
    "        #\n",
    "        self.batch_size = batch_size\n",
    "        #\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # fix case sensitivity\n",
    "        if type(self.architecture) == str:\n",
    "            self.architecture = self.architecture.lower()\n",
    "        if type(self.pretrained_model_name) == str:\n",
    "            self.pretrained_model_name = self.pretrained_model_name.lower()\n",
    "        if type(self.pooling) == str:\n",
    "            self.pooling = self.pooling.lower()\n",
    "        \n",
    "        # read num features from pretrained model\n",
    "        if pretrained_model_name is not None:\n",
    "            self.num_features = pretrained_model_len_features[pretrained_model_name]\n",
    "            self.frame_size = pretrained_model_sizes[pretrained_model_name]\n",
    "        \n",
    "        # check one of pretrained model and frame size is specified\n",
    "        assert (self.pretrained_model_name is not None or self.frame_size is not None), \"Must specify one of pretrained_model_name or frame_size\"\n",
    "            \n",
    "            \n",
    "        # init model and data objects for this architecture\n",
    "        self.model = None\n",
    "        self.data = None\n",
    "        \n",
    "        \n",
    "        #############################################################\n",
    "        ### Build model architecture and init appropriate data object\n",
    "        #############################################################\n",
    "        \n",
    "        if architecture == \"image_MLP_frozen\":\n",
    "            \n",
    "            ####################\n",
    "            ### image_MLP_frozen\n",
    "            ####################\n",
    "            # image classification (single frame)\n",
    "            # train MLP on top of weights extracted from pretrained CNN with no fine-tuning\n",
    "            \n",
    "            # check inputs\n",
    "            assert self.sequence_length == 1, \"image_MLP_frozen requires sequence length of 1\"\n",
    "            assert self.pretrained_model_name is not None, \"image_MLP_frozen requires a pretrained_model_name input\" \n",
    "            assert self.pooling is not None, \"image_MLP_frozen requires a pooling input\" \n",
    "            \n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = 1, \n",
    "                                return_CNN_features = True, \n",
    "                                pretrained_model_name= self.pretrained_model_name,\n",
    "                                pooling = self.pooling)\n",
    "            \n",
    "            # init model\n",
    "            model = Sequential()\n",
    "\n",
    "            # 1st layer group\n",
    "            if self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_1_size, activation='relu', input_shape=(self.num_features,)))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "                \n",
    "            # 2nd layer group\n",
    "            if self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_2_size, activation='relu'))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # 3rd layer group\n",
    "            if self.layer_3_size > 0 and self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_3_size, activation='relu'))\n",
    "                if dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # classifier layer\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax'))\n",
    "            \n",
    "\n",
    "        elif architecture == \"image_MLP_trainable\":\n",
    "            \n",
    "            #######################\n",
    "            ### image_MLP_trainable\n",
    "            #######################\n",
    "            # image classification (single frame)\n",
    "            # fine-tune pretrained CNN with MLP on top\n",
    "            #\n",
    "            # start off freezing base CNN layers then will unfreeze \n",
    "            # after each training round\n",
    "            #\n",
    "            # we will ultimately want to compare our best fine-tuned \n",
    "            # CNN as a feature extractor vs fixed ImageNet pretrained CNN features\n",
    "            \n",
    "            # check inputs\n",
    "            assert self.sequence_length == 1, \"image_MLP_trainable requires sequence length of 1\"\n",
    "            assert self.pretrained_model_name is not None, \"image_MLP_trainable requires a pretrained_model_name input\" \n",
    "            assert self.pooling is not None, \"image_MLP_trainable requires a pooling input\" \n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = 1, \n",
    "                                return_CNN_features = False, \n",
    "                                pretrained_model_name = self.pretrained_model_name,\n",
    "                                pooling = self.pooling,\n",
    "                                return_generator = True,\n",
    "                                batch_size = self.batch_size)\n",
    "            \n",
    "            # create the base pre-trained model\n",
    "            model_base = load_pretrained_model(self.pretrained_model_name, pooling=self.pooling)\n",
    "            \n",
    "\n",
    "            # freeze base model layers (will unfreeze after train top)\n",
    "            for l in model_base.layers:\n",
    "                l.trainable=False\n",
    "\n",
    "            # use Keras functional API\n",
    "            model_top = model_base.output\n",
    "\n",
    "            # note layer names are there so we can exclude those layers \n",
    "            # when setting base model layers to trainable\n",
    "\n",
    "            # 1st layer group\n",
    "            if self.layer_1_size > 0:\n",
    "                model_top = Dense(self.layer_1_size, activation=\"relu\", name='top_a')(model_top)\n",
    "                if self.dropout > 0:\n",
    "                    model_top = Dropout(self.dropout, name='top_b')(model_top)\n",
    "\n",
    "            # 2nd layer group\n",
    "            if self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model_top = Dense(self.layer_2_size, activation=\"relu\", name='top_c')(model_top)\n",
    "                if self.dropout > 0:\n",
    "                    model_top = Dropout(self.dropout, name='top_d')(model_top)\n",
    "\n",
    "            # 3rd layer group\n",
    "            if self.layer_3_size > 0 and self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model_top = Dense(self.layer_3_size, activation=\"relu\", name='top_e')(model_top)\n",
    "                if self.dropout > 0:\n",
    "                    model_top = Dropout(self.dropout, name='top_f')(model_top)\n",
    "\n",
    "            # classifier layer\n",
    "            model_predictions = Dense(self.data.num_classes, activation=\"softmax\", name='top_g')(model_top)\n",
    "\n",
    "            # combine base and top models into single model object\n",
    "            model = Model(inputs=model_base.input, outputs=model_predictions)\n",
    "                \n",
    "        elif architecture == \"video_MLP_concat\":\n",
    "\n",
    "            ####################\n",
    "            ### video_MLP_concat\n",
    "            ####################\n",
    "            \n",
    "            # concatenate all frames in sequence and train MLP on top of concatenated frame input\n",
    "            \n",
    "            assert self.sequence_length > 1, \"video_MLP_concat requires sequence length > 1\"\n",
    "            assert self.pretrained_model_name is not None, \"video_MLP_concat requires a pretrained_model_name input\"\n",
    "            assert self.pooling is not None, \"video_MLP_concat requires a pooling input\"\n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = self.sequence_length, \n",
    "                                return_CNN_features = True, \n",
    "                                pretrained_model_name=self.pretrained_model_name,\n",
    "                                pooling = self.pooling)\n",
    "\n",
    "            # init model\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Flatten(input_shape=(self.sequence_length, self.num_features)))\n",
    "\n",
    "            # 1st layer group\n",
    "            if self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_1_size, activation='relu', input_shape=(self.num_features,)))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # 2nd layer group\n",
    "            if self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_2_size, activation='relu'))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # 3rd layer group\n",
    "            if self.layer_3_size > 0 and self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_3_size, activation='relu'))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # classifier layer\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax'))\n",
    "            \n",
    "        elif architecture == \"video_LRCNN_frozen\":\n",
    "\n",
    "            ######################\n",
    "            ### video_LRCNN_frozen\n",
    "            ######################\n",
    "            \n",
    "            # Implement:\n",
    "            # “Long-Term Recurrent Convolutional Networks for Visual Recognition and Description.”\n",
    "            # Donahue, Jeff, Lisa Anne Hendricks, Marcus Rohrbach, Subhashini Venugopalan, \n",
    "            # Sergio Guadarrama, Kate Saenko, and Trevor Darrell.  \n",
    "            # Proceedings of the IEEE Computer Society Conference on Computer Vision and \n",
    "            # Pattern Recognition, 2015, 2625–34.\n",
    "            #\n",
    "            # Essentially they extract features with fine-tuned CNN then fit recurrent models on top\n",
    "            # in the paper they only use LSTM but we will also try RNN, GRU and 1-D CNN\n",
    "            # \n",
    "            # note: no fine-tuning of CNN in this frozen LRCNN architecture\n",
    "            # \n",
    "            # implementation inspired by:\n",
    "            # https://github.com/sagarvegad/Video-Classification-CNN-and-LSTM-/blob/master/train_CNN_RNN.py\n",
    "\n",
    "            \n",
    "            # check inputs\n",
    "            assert self.sequence_length > 1, \"video_LRCNN_frozen requires sequence length > 1\"\n",
    "            assert self.layer_1_size > 0, \"video_LRCNN_frozen requires a layer_1_size > 0\" \n",
    "            assert self.pretrained_model_name is not None, \"video_LRCNN_frozen requires a pretrained_model_name input\" \n",
    "            assert self.pooling is not None, \"video_LRCNN_frozen requires a pooling input\" \n",
    "            assert self.sequence_model_layers is not None, \"video_LRCNN_frozen requires sequence_model_layers >= 1\" \n",
    "            assert self.sequence_model_layers >= 1, \"video_LRCNN_frozen requires sequence_model_layers >= 1\" \n",
    "            assert self.sequence_model_layers < 4, \"video_LRCNN_frozen requires sequence_model_layers <= 3\" \n",
    "            assert self.sequence_model is not None, \"video_LRCNN_frozen requires a sequence_model\" \n",
    "            if self.sequence_model == 'Convolution1D':\n",
    "                assert self.convolution_kernel_size > 0, \"Convolution1D sequence model requires convolution_kernel_size parameter > 0\"\n",
    "                assert self.convolution_kernel_size < self.sequence_length, \"convolution_kernel_size must be less than sequence_length\"\n",
    "\n",
    "                \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = self.sequence_length, \n",
    "                                return_CNN_features = True, \n",
    "                                pretrained_model_name = self.pretrained_model_name,\n",
    "                                pooling = self.pooling)\n",
    "            \n",
    "                \n",
    "            # set whether to return sequences for stacked sequence models\n",
    "            return_sequences_1, return_sequences_2 = False, False\n",
    "            if sequence_model_layers > 1 and layer_2_size > 0:\n",
    "                return_sequences_1 = True\n",
    "            if sequence_model_layers >= 2 and layer_3_size > 0 and layer_2_size > 0:\n",
    "                return_sequences_2 = True\n",
    "            \n",
    "            # init model\n",
    "            model = Sequential()\n",
    "\n",
    "            # layer 1 (sequence layer)\n",
    "            if sequence_model == \"LSTM\":\n",
    "                model.add(LSTM(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout, \n",
    "                               input_shape=(self.sequence_length, self.num_features)))\n",
    "            elif sequence_model == \"SimpleRNN\":\n",
    "                model.add(SimpleRNN(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout, \n",
    "                               input_shape=(self.sequence_length, self.num_features)))\n",
    "            elif sequence_model == \"GRU\":\n",
    "                model.add(GRU(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout, \n",
    "                               input_shape=(self.sequence_length, self.num_features)))\n",
    "            elif sequence_model == \"Convolution1D\":\n",
    "                model.add(Convolution1D(self.layer_1_size, kernel_size = self.convolution_kernel_size, padding = 'valid', \n",
    "                               input_shape=(self.sequence_length, self.num_features)))\n",
    "                if layer_2_size == 0 or sequence_model_layers == 1:\n",
    "                    model.add(Flatten())\n",
    "            else:\n",
    "                raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]')    \n",
    "\n",
    "            # layer 2 (sequential or dense)\n",
    "            if layer_2_size > 0:\n",
    "                if return_sequences_1 == False:\n",
    "                    model.add(Dense(self.layer_2_size, activation='relu'))\n",
    "                    model.add(Dropout(self.dropout))\n",
    "                else:\n",
    "                    if sequence_model == \"LSTM\":\n",
    "                        model.add(LSTM(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout))\n",
    "                    elif sequence_model == \"SimpleRNN\":\n",
    "                        model.add(SimpleRNN(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout))\n",
    "                    elif sequence_model == \"GRU\":\n",
    "                        model.add(GRU(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout))\n",
    "                    elif sequence_model == \"Convolution1D\":\n",
    "                        model.add(Convolution1D(self.layer_2_size, kernel_size = self.convolution_kernel_size, padding = 'valid'))\n",
    "                    else:\n",
    "                        raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]') \n",
    "\n",
    "            # layer 3 (sequential or dense)\n",
    "            if layer_3_size > 0:\n",
    "                if sequence_model_layers < 3:\n",
    "                    if sequence_model_layers == 2:\n",
    "                        model.add(Flatten())\n",
    "                    model.add(Dense(self.layer_3_size, activation='relu'))\n",
    "                    model.add(Dropout(self.dropout))\n",
    "                else:\n",
    "                    if sequence_model == \"LSTM\":\n",
    "                        model.add(LSTM(self.layer_3_size, return_sequences=False, dropout=self.dropout))\n",
    "                        model.add(Flatten())\n",
    "                    elif sequence_model == \"SimpleRNN\":\n",
    "                        model.add(SimpleRNN(self.layer_3_size, return_sequences=False, dropout=self.dropout))\n",
    "                        model.add(Flatten())\n",
    "                    elif sequence_model == \"GRU\":\n",
    "                        model.add(GRU(self.layer_3_size, return_sequences=False, dropout=self.dropout))\n",
    "                        model.add(Flatten())\n",
    "                    elif sequence_model == \"Convolution1D\":\n",
    "                        model.add(Convolution1D(self.layer_3_size, kernel_size = self.convolution_kernel_size, padding = 'valid'))\n",
    "                        model.add(Flatten())\n",
    "                    else:\n",
    "                        raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]') \n",
    "            else:\n",
    "                if return_sequences_2 == True: \n",
    "                    model.add(Flatten())\n",
    "\n",
    "            # classifier layer\n",
    "            if self.dropout > 0:\n",
    "                model.add(Dropout(self.dropout))\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax'))\n",
    "\n",
    "        elif architecture == \"video_LRCNN_trainable\":\n",
    "            \n",
    "            #########################\n",
    "            ### video_LRCNN_trainable\n",
    "            #########################\n",
    "            \n",
    "            # Same as above:\n",
    "            # “Long-Term Recurrent Convolutional Networks for Visual Recognition and Description.”\n",
    "            # Donahue, Jeff, Lisa Anne Hendricks, Marcus Rohrbach, Subhashini Venugopalan, \n",
    "            # Sergio Guadarrama, Kate Saenko, and Trevor Darrell.  \n",
    "            # Proceedings of the IEEE Computer Society Conference on Computer Vision and \n",
    "            # Pattern Recognition, 2015, 2625–34.\n",
    "            #\n",
    "            # But with fine-tuning of the CNNs that are input into the recurrent models\n",
    "            # \n",
    "            # note: will take long because not precomputing the CNN part so re-computed \n",
    "            # on each training pass\n",
    "\n",
    "            # implementation inspired by https://stackoverflow.com/questions/49535488/lstm-on-top-of-a-pre-trained-cnn\n",
    "            \n",
    "            # check inputs\n",
    "            assert self.sequence_length > 1, \"video_LRCNN_trainable requires sequence length > 1\"\n",
    "            assert self.layer_1_size > 0, \"video_LRCNN_trainable requires a layer_1_size > 0\" \n",
    "            assert self.pretrained_model_name is not None, \"video_LRCNN_trainable requires a pretrained_model_name input\" \n",
    "            assert self.pooling is not None, \"video_LRCNN_trainable requires a pooling input\" \n",
    "            assert self.sequence_model_layers >= 1, \"video_LRCNN_trainable requires sequence_model_layers >= 1\" \n",
    "            assert self.sequence_model_layers < 4, \"video_LRCNN_trainable requires sequence_model_layers <= 3\" \n",
    "            assert self.sequence_model is not None, \"video_LRCNN_trainable requires a sequence_model\" \n",
    "            if self.sequence_model == 'Convolution1D':\n",
    "                assert self.convolution_kernel_size > 0, \"Convolution1D sequence model requires convolution_kernel_size parameter > 0\"\n",
    "                assert self.convolution_kernel_size < self.sequence_length, \"convolution_kernel_size must be less than sequence_length\"\n",
    "                \n",
    "                \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = self.sequence_length, \n",
    "                                return_CNN_features = False, \n",
    "                                return_generator=True,\n",
    "                                pretrained_model_name = self.pretrained_model_name,\n",
    "                                pooling = self.pooling,\n",
    "                                batch_size=self.batch_size)\n",
    "            \n",
    "                \n",
    "            # set whether to return sequences for stacked sequence models\n",
    "            return_sequences_1, return_sequences_2 = False, False\n",
    "            if sequence_model_layers > 1 and layer_2_size > 0:\n",
    "                return_sequences_1 = True\n",
    "            if sequence_model_layers >= 2 and layer_3_size > 0 and layer_2_size > 0:\n",
    "                return_sequences_2 = True\n",
    "\n",
    "            # load pretrained model weights - will train from there\n",
    "            model_cnn = load_pretrained_model(self.pretrained_model_name, pooling=self.pooling)\n",
    "\n",
    "            # optionally load weights for pretrained architecture\n",
    "            # (will likely be better to first train CNN then load weights in LRCNN vs. use pretrained ImageNet CNN)\n",
    "            if self.model_weights_path is not None:\n",
    "                model_base.load_weights(self.model_weights_path)\n",
    "            \n",
    "            # freeze model_cnn layers but make final 3 layers of pretrained CNN trainable\n",
    "            for i, l in enumerate(model_cnn.layers):\n",
    "                if i < len(model_cnn.layers)-3:\n",
    "                    l.trainable = False\n",
    "                else:\n",
    "                    l.trainable = True\n",
    "\n",
    "            # sequential component on top of CNN\n",
    "            frames = Input(shape=(self.sequence_length, self.frame_size[0], self.frame_size[1], 3))\n",
    "            x = TimeDistributed(model_cnn)(frames)\n",
    "            x = TimeDistributed(Flatten())(x)\n",
    "            \n",
    "\n",
    "            # layer 1 (sequence layer)\n",
    "            if sequence_model == \"LSTM\":\n",
    "                x = LSTM(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout)(x)\n",
    "            elif sequence_model == \"SimpleRNN\":\n",
    "                x = SimpleRNN(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout)(x)\n",
    "            elif sequence_model == \"GRU\":\n",
    "                x = GRU(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout)(x)\n",
    "            elif sequence_model == \"Convolution1D\":\n",
    "                x = Convolution1D(self.layer_1_size, kernel_size = self.convolution_kernel_size, padding = 'valid')(x)\n",
    "                if layer_2_size == 0 or sequence_model_layers == 1:\n",
    "                    x = Flatten()(x)\n",
    "            else:\n",
    "                raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]')    \n",
    "\n",
    "            # layer 2 (sequential or dense)\n",
    "            if layer_2_size > 0:\n",
    "                if return_sequences_1 == False:\n",
    "                    x = Dense(self.layer_2_size, activation='relu')(x)\n",
    "                    x = Dropout(self.dropout)(x)\n",
    "                else:\n",
    "                    if sequence_model == \"LSTM\":\n",
    "                        x = LSTM(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout)(x)\n",
    "                    elif sequence_model == \"SimpleRNN\":\n",
    "                        x = SimpleRNN(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout)(x)\n",
    "                    elif sequence_model == \"GRU\":\n",
    "                        x = GRU(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout)(x)\n",
    "                    elif sequence_model == \"Convolution1D\":\n",
    "                        x = Convolution1D(self.layer_2_size, kernel_size = self.convolution_kernel_size, padding = 'valid')(x)\n",
    "                    else:\n",
    "                        raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]') \n",
    "\n",
    "            # layer 3 (sequential or dense)\n",
    "            if layer_3_size > 0:\n",
    "                if sequence_model_layers < 3:\n",
    "                    if sequence_model_layers == 2:\n",
    "                        x = Flatten()(x)\n",
    "                    x = Dense(self.layer_3_size, activation='relu')(x)\n",
    "                    x = Dropout(self.dropout)(x)\n",
    "                else:\n",
    "                    if sequence_model == \"LSTM\":\n",
    "                        x = LSTM(self.layer_3_size, return_sequences=False, dropout=self.dropout)(x)\n",
    "                        x = Flatten()(x)\n",
    "                    elif sequence_model == \"SimpleRNN\":\n",
    "                        x = SimpleRNN(self.layer_3_size, return_sequences=False, dropout=self.dropout)(x)\n",
    "                        x = Flatten()(x)\n",
    "                    elif sequence_model == \"GRU\":\n",
    "                        x = GRU(self.layer_3_size, return_sequences=False, dropout=self.dropout)(x)\n",
    "                        x = Flatten()(x)\n",
    "                    elif sequence_model == \"Convolution1D\":\n",
    "                        x = Convolution1D(self.layer_3_size, kernel_size = self.convolution_kernel_size, padding = 'valid')(x)\n",
    "                        x = Flatten()(x)\n",
    "                    else:\n",
    "                        raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]') \n",
    "            else:\n",
    "                if return_sequences_2 == True: \n",
    "                    x = Flatten()(x)\n",
    "\n",
    "            # classifier layer\n",
    "            if self.dropout > 0:\n",
    "                x = Dropout(self.dropout)(x)\n",
    "            out = Dense(self.data.num_classes, activation='softmax')(x)\n",
    "                        \n",
    "\n",
    "            # join cnn frame model and LSTM top\n",
    "            model = Model(inputs=frames, outputs=out)\n",
    "         \n",
    "        elif architecture == \"C3D\":\n",
    "            \n",
    "            #########\n",
    "            ### C3D\n",
    "            #########\n",
    "            \n",
    "            # Implement:\n",
    "            # Learning Spatiotemporal Features with 3D Convolutional Networks\n",
    "            # Tran et al 2015\n",
    "            # https://arxiv.org/abs/1412.0767\n",
    "            #\n",
    "            # Implementation inspired by https://gist.github.com/albertomontesg/d8b21a179c1e6cca0480ebdf292c34d2\n",
    "            \n",
    "            assert self.sequence_length == 16, \"C3D requires sequence length 16\"\n",
    "            assert self.frame_size == (112,112), \"C3D requires frame size 112x112\"\n",
    "            assert self.layer_1_size == 0, \"C3D does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.layer_2_size == 0, \"C3D does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.layer_3_size == 0, \"C3D does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.dropout == 0, \"C3D does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.sequence_model == None, \"C3D does not accept a sequence_model parameter\"\n",
    "            assert self.sequence_model_layers == None, \"C3D does not accept a sequence_model_layers parameter\"\n",
    "            assert self.pretrained_model_name == None, \"C3D does not accept a pretrained_model_name parameter\"            \n",
    "            assert self.pooling == None, \"C3D does not accept a pooling parameter\"                            \n",
    "            \n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = 16, \n",
    "                                return_CNN_features = False, \n",
    "                                return_generator = True,\n",
    "                                frame_size = (112,112),\n",
    "                                batch_size=self.batch_size,\n",
    "                                verbose = False)\n",
    "            \n",
    "            # C3D\n",
    "            model = Sequential()\n",
    "            # 1st layer group\n",
    "            model.add(Conv3D(64, (3, 3, 3), activation='relu', padding='same', name='conv1', input_shape=(16, 112, 112, 3)))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), padding='valid', name='pool1'))\n",
    "            # 2nd layer group\n",
    "            model.add(Conv3D(128, (3, 3, 3), activation='relu',padding='same', name='conv2'))\n",
    "            model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),padding='valid', name='pool2'))\n",
    "            # 3rd layer group\n",
    "            model.add(Conv3D(256, (3, 3, 3), activation='relu',padding='same', name='conv3a'))\n",
    "            model.add(Conv3D(256, (3, 3, 3), activation='relu',padding='same', name='conv3b'))\n",
    "            model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='pool3'))\n",
    "            # 4th layer group\n",
    "            model.add(Conv3D(512, (3, 3, 3), activation='relu',padding='same', name='conv4a'))\n",
    "            model.add(Conv3D(512, (3, 3, 3), activation='relu',padding='same', name='conv4b'))\n",
    "            model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),padding='valid', name='pool4'))\n",
    "            # 5th layer group\n",
    "            model.add(Conv3D(512, (3, 3, 3), activation='relu',padding='same', name='conv5a'))\n",
    "            model.add(Conv3D(512, (3, 3, 3), activation='relu',padding='same', name='conv5b'))\n",
    "            model.add(ZeroPadding3D(padding=(0, 1, 1)))\n",
    "            model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),padding='valid', name='pool5'))\n",
    "            model.add(Flatten())\n",
    "            # FC layers group\n",
    "            model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "            model.add(Dropout(.5))\n",
    "            model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "            model.add(Dropout(.5))\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax', name='fc8'))\n",
    "            \n",
    "        elif architecture == \"C3Dsmall\":\n",
    "            \n",
    "            #########################\n",
    "            ### C3D - small variation\n",
    "            #########################\n",
    "            \n",
    "            # Custom small version of C3D from paper:\n",
    "            # Learning Spatiotemporal Features with 3D Convolutional Networks\n",
    "            # Tran et al 2015\n",
    "            # https://arxiv.org/abs/1412.0767\n",
    "            #\n",
    "            # Implementation inspired by https://gist.github.com/albertomontesg/d8b21a179c1e6cca0480ebdf292c34d2\n",
    "            \n",
    "            assert self.sequence_length == 16, \"C3Dsmall requires sequence length 16\"\n",
    "            assert self.frame_size == (112,112), \"C3Dsmall requires frame size 112x112\"\n",
    "            assert self.layer_1_size == 0, \"C3Dsmall does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.layer_2_size == 0, \"C3Dsmall does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.layer_3_size == 0, \"C3Dsmall does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.dropout == 0, \"C3Dsmall does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.sequence_model == None, \"C3Dsmall does not accept a sequence_model parameter\"\n",
    "            assert self.sequence_model_layers == None, \"C3Dsmall does not accept a sequence_model_layers parameter\"\n",
    "            assert self.pretrained_model_name == None, \"C3Dsmall does not accept a pretrained_model_name parameter\"            \n",
    "            assert self.pooling == None, \"C3Dsmall does not accept a pooling parameter\"      \n",
    "            \n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = 16, \n",
    "                                return_CNN_features = False, \n",
    "                                return_generator = True,\n",
    "                                frame_size = (112,112),\n",
    "                                batch_size=self.batch_size,\n",
    "                                verbose = False)\n",
    "            \n",
    "            # C3Dsmall\n",
    "            model = Sequential()\n",
    "            # 1st layer group\n",
    "            model.add(Conv3D(32, (3,3,3), activation='relu', input_shape=(data.sequence_length, 112, 112, 3)))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "            # 2nd layer group\n",
    "            model.add(Conv3D(64, (3,3,3), activation='relu'))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "            # 3rd layer group\n",
    "            model.add(Conv3D(128, (3,3,3), activation='relu'))\n",
    "            model.add(Conv3D(128, (3,3,3), activation='relu'))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "            # 4th layer group\n",
    "            model.add(Conv3D(256, (2,2,2), activation='relu'))\n",
    "            model.add(Conv3D(256, (2,2,2), activation='relu'))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "            # FC layers group\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(256))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(128))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax'))\n",
    "            \n",
    "        else:\n",
    "            raise NameError('Invalid architecture - must be one of [image_MLP_frozen, image_MLP_trainable, video_MLP_concat, video_LRCNN_frozen, video_LRCNN_trainable, C3D, C3Dsmall]')    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ###############\n",
    "        ### Finish init\n",
    "        ###############\n",
    "        \n",
    "        # set class model to constructed model\n",
    "        self.model = model\n",
    "        \n",
    "        # load weights of model if they exist\n",
    "        if os.path.exists(self.path_model + 'model.h5'):\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading saved model weights\")\n",
    "            model.load_weights(self.path_model + 'model.h5')            \n",
    "        \n",
    "        # save model summary to model folder\n",
    "        with open(self.path_model + 'model_summary.txt', 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                self.model.summary()\n",
    "        \n",
    "        # save architecture params to model folder\n",
    "        params = self.__dict__.copy()\n",
    "        params['data_shape'] = str(self.data)\n",
    "        del params['model']\n",
    "        del params['data']\n",
    "        with open(self.path_model + 'params.json', 'w') as fp:\n",
    "            json.dump(params, fp, indent=4, sort_keys=True)\n",
    "    \n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Run several rounds of fitting to train model, reducing learning rate after each round\n",
    "        \n",
    "        Progress and model parameters will be saved to the model's path e.g. /models/1/\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # init results with architecture params\n",
    "        results = self.__dict__.copy()\n",
    "        results['data_total_rows_train'] = self.data.total_rows_train\n",
    "        results['data_total_rows_valid'] = self.data.total_rows_valid\n",
    "        results['data_total_rows_test'] = self.data.total_rows_test\n",
    "        del results['model']\n",
    "        del results['data']\n",
    "        results['model_param_count'] = self.model.count_params()\n",
    "        \n",
    "        \n",
    "        ###############\n",
    "        ### Train model\n",
    "        ###############\n",
    "        \n",
    "        # start training timer\n",
    "        start = datetime.datetime.now()\n",
    "        results['fit_dt_train_start'] = start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        # do first round of fitting\n",
    "        history1, stopped_epoch1 = self.fit(learning_rate = 0.001)\n",
    "        \n",
    "        # load best model weights so far\n",
    "        self.model.load_weights(self.path_model + 'model.h5')\n",
    "        \n",
    "        # reduce learning rate and fit some more\n",
    "        history2, stopped_epoch2 = self.fit(learning_rate = 0.0001)\n",
    "        \n",
    "        # load best model weights so far\n",
    "        self.model.load_weights(self.path_model + 'model.h5')\n",
    "        \n",
    "        # reduce learning rate and fit some more\n",
    "        history3, stopped_epoch3 = self.fit(learning_rate = 0.00001)\n",
    "        \n",
    "        # end time training\n",
    "        end = datetime.datetime.now()    \n",
    "        results['fit_dt_train_end']  = end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        results['fit_dt_train_duration_seconds']  = str((end - start).total_seconds()).split(\".\")[0]\n",
    "        \n",
    "        \n",
    "        #################\n",
    "        ### build results\n",
    "        #################\n",
    "        # combine fit histories into big dataframe and write to model folder\n",
    "        # only keep history until accuracy declined (where early stopping made checkpoint)\n",
    "\n",
    "        # parse history dicts to dataframes\n",
    "        history1 = pd.DataFrame(history1.history).head(stopped_epoch1)\n",
    "        history1['fit_round'] = 1\n",
    "        history2 = pd.DataFrame(history2.history).head(stopped_epoch2)\n",
    "        history2['fit_round'] = 2\n",
    "        history3 = pd.DataFrame(history3.history).head(stopped_epoch3)\n",
    "        history3['fit_round'] = 3\n",
    "        \n",
    "        # combine and save csv\n",
    "        fit_history = pd.concat([history1, history2, history3], axis=0)\n",
    "        fit_history = fit_history.reset_index(drop=True)\n",
    "        fit_history['epoch'] = fit_history.index+1\n",
    "        fit_history.to_csv(self.path_model + 'fit_history.csv')\n",
    "        self.fit_history = fit_history\n",
    "        \n",
    "        results['fit_stopped_epoch1'] = stopped_epoch1\n",
    "        results['fit_stopped_epoch2'] = stopped_epoch2\n",
    "        results['fit_stopped_epoch3'] = stopped_epoch3\n",
    "        \n",
    "        # add 3 = 1 for each training round because stopped_epoch is 0 indexed\n",
    "        results['fit_num_epochs'] = stopped_epoch1 + stopped_epoch2 + stopped_epoch3 + 3\n",
    "        results['fit_val_acc'] = list(fit_history.tail(1)['val_acc'])[0]\n",
    "        results['fit_train_acc'] = list(fit_history.tail(1)['acc'])[0]\n",
    "        results['fit_val_loss'] = list(fit_history.tail(1)['val_loss'])[0]\n",
    "        results['fit_train_loss'] = list(fit_history.tail(1)['loss'])[0]\n",
    "\n",
    "        #######################\n",
    "        ### Predict on test set\n",
    "        #######################\n",
    "        \n",
    "        # start test timer\n",
    "        start = datetime.datetime.now()\n",
    "        results['fit_dt_test_start'] = start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        y_pred = None\n",
    "        y_test = None\n",
    "        if self.data.return_generator:\n",
    "            # predict on test set via generator\n",
    "            y_pred = self.model.predict_generator(self.data.generator_test,verbose=self.verbose)\n",
    "            \n",
    "            # save predicted clas probabilities\n",
    "            np.save(self.path_model + 'test_predictions', y_pred)\n",
    "            \n",
    "            # take argmax to get predicted class\n",
    "            y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "            # get truth labels from generator\n",
    "            y_test = []\n",
    "            for _, label in self.data.generator_test:\n",
    "                y_test.extend(label)\n",
    "            y_test = np.argmax(np.array(y_test), axis = 1)\n",
    "            \n",
    "        else:\n",
    "            # predict on test data loaded into memory\n",
    "            y_pred = self.model.predict(self.data.x_test, verbose=self.verbose)\n",
    "            \n",
    "            # save predicted clas probabilities\n",
    "            np.save(self.path_model + 'test_predictions', y_pred)\n",
    "            \n",
    "            # take argmax to get predicted class\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "            # get truth labels from memory\n",
    "            y_test = np.argmax(self.data.y_test,axis=1)\n",
    "        \n",
    "        # end time testing\n",
    "        end = datetime.datetime.now()    \n",
    "        results['fit_dt_test_end']  = end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        results['fit_dt_test_duration_seconds']  = str((end - start).total_seconds()).split(\".\")[0]\n",
    "        \n",
    "        ############################\n",
    "        ### Compute confusion matrix\n",
    "        ############################\n",
    "        \n",
    "        # Compute and store confusion matrix\n",
    "        cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        pd.DataFrame(cnf_matrix).to_csv(self.path_model + \"confusion_matrix.csv\")\n",
    "\n",
    "        # get clas names from label map for plot\n",
    "        class_names = list(self.data.label_map.values())\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')\n",
    "        plt.savefig(self.path_model + 'confusion_matrix.png', bbox_inches='tight')\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix')\n",
    "        plt.savefig(self.path_model + 'confusion_matrix_normalized.png', bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "        ##########################\n",
    "        ### Compute raw error rate\n",
    "        ##########################\n",
    "        \n",
    "        # build dataframe and calculate test error (assuming we classify using majority rule, not ROC cutoff approach)\n",
    "        pdf = pd.DataFrame(y_pred, columns = ['pred'])\n",
    "        pdf['prediction'] = pdf['pred'].apply(lambda x: self.data.label_map[str(x)])\n",
    "\n",
    "        truth = pd.DataFrame(y_test, columns = ['truth'])\n",
    "        truth['label'] = truth['truth'].apply(lambda x: self.data.label_map[str(x)])\n",
    "        truth = truth[['label']]\n",
    "\n",
    "        pdf = pd.concat([pdf, truth], axis=1)\n",
    "        pdf['error'] = (pdf['prediction'] != pdf['label']).astype(int)\n",
    "        test_acc = 1 - pdf['error'].mean()\n",
    "        \n",
    "        results['fit_test_acc'] = test_acc\n",
    "        \n",
    "        if self.verbose:\n",
    "            logger.info(str(results))\n",
    "            logger.info(\"model {} test acc: {}\".format(self.model_id, test_acc))\n",
    "        \n",
    "        \n",
    "        ##################\n",
    "        ### Output results\n",
    "        ##################\n",
    "        self.results = results\n",
    "        with open(self.path_model + 'results.json', 'w') as fp:\n",
    "            json.dump(results, fp, indent=4, sort_keys=True)\n",
    "\n",
    "        \n",
    "    def fit(self, learning_rate = 0.001, epochs = 30, patience=5):\n",
    "        \"\"\"\n",
    "        Compile and fit model for *epochs* rounds of training, dividing learning rate by 10 after each round\n",
    "\n",
    "        Fitting will stop if val_acc does not improve for at least patience epochs\n",
    "\n",
    "        Only the best weights will be kept\n",
    "\n",
    "        The model is saved to /models/*model_id*/\n",
    "\n",
    "        Good practice is to decrease the learning rate by a factor of 10 after each plateau and train some more \n",
    "        (after first re-loading best weights from previous training round)...\n",
    "\n",
    "        for example (not exact example because this fit method has been refactored into the architecture object but the principle remains):\n",
    "            fit_history = fit(model_id, model, data, learning_rate = 0.001, epochs = 30)\n",
    "            model.load_weights(path_model + \"model.h5\")\n",
    "            model = fit(model, 5)\n",
    "            fit_history = train(model_id, model, data, learning_rate = 0.0001, epochs = 30)\n",
    "\n",
    "        :learning_rate: learning rate parameter for Adam optimizer (default is 0.001)\n",
    "\n",
    "        :epochs: number of training epochs per fit round (subject to patience)\n",
    "        :batch_size: number of samples in each batch\n",
    "        :patience: how many epochs without val_acc improvement before stopping fit round\n",
    "        :verbose: print progress\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # create optimizer with given learning rate \n",
    "        opt = Adam(lr = learning_rate)\n",
    "\n",
    "        # compile model\n",
    "        self.model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # setup training callbacks\n",
    "        callback_stopper = EarlyStopping(monitor='val_acc', patience=patience, verbose=0)\n",
    "        callback_csvlogger = CSVLogger(self.path_model + 'training.log')\n",
    "        callback_checkpointer = ModelCheckpoint(self.path_model +  'model.h5', monitor='val_acc', save_best_only=True, verbose=verbose)\n",
    "        callbacks = [callback_stopper, callback_checkpointer, callback_csvlogger]\n",
    "\n",
    "        # fit model\n",
    "        if self.data.return_generator == True:\n",
    "            # train using generator\n",
    "            history = self.model.fit_generator(generator=self.data.generator_train,\n",
    "                validation_data=self.data.generator_valid,\n",
    "                use_multiprocessing=True,\n",
    "                workers=CPU_COUNT,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                shuffle=True,\n",
    "                verbose=self.verbose)\n",
    "        else:\n",
    "            # train using full dataset\n",
    "            history = self.model.fit(self.data.x_train, self.data.y_train, \n",
    "                validation_data=(self.data.x_valid, self.data.y_valid),\n",
    "                batch_size=self.batch_size,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                shuffle=True,\n",
    "                verbose=self.verbose)\n",
    "\n",
    "        # get number of epochs actually trained (might have early stopped)\n",
    "        epochs_trained = callback_stopper.stopped_epoch\n",
    "        \n",
    "        if epochs_trained == 0:\n",
    "            # trained but didn't stop early\n",
    "            if len(history.history) > 0:\n",
    "                epochs_trained = epochs\n",
    "        else:\n",
    "            # subtract patience from stop point to get actual peak epoch for this fitting round\n",
    "            epochs_trained -= patience \n",
    "        \n",
    "        # return fit history and the epoch that the early stopper completed on\n",
    "        return history, epochs_trained\n",
    "        \n",
    "        \n",
    "    def make_last_layers_trainable(self, num_layers):\n",
    "        \"\"\"\n",
    "        Set the last *num_layers* non-trainable layers to trainable  \n",
    "\n",
    "        NB to be used with model_base and assumes name = \"top_xxx\" added to each top layer to know \n",
    "        to ignore that layer when looping through layers from top backwards\n",
    "\n",
    "        :num_layers: number of layers from end of model (that are currently not trainable) to be set as trainable\n",
    "        \"\"\"\n",
    "\n",
    "        # get index of last non-trainable layer\n",
    "        # (the layers we added on top of model_base are already trainable=True)\n",
    "        # ...\n",
    "        # need to find last layer of base model and set that (and previous num_layers)\n",
    "        # to trainable=True via this method\n",
    "\n",
    "        # find last non-trainable layer index\n",
    "        idx_not_trainable = 0\n",
    "        for i, l in enumerate(self.model.layers):\n",
    "            if \"top\" not in l.name:\n",
    "                idx_not_trainable = i\n",
    "\n",
    "        # set last non-trainable layer and num_layers prior to trainable=True\n",
    "        for i in reversed(range(idx_not_trainable-num_layers+1, idx_not_trainable+1)):\n",
    "            self.model.layers[i].trainable = True\n",
    "        \n",
    "        if self.verbose:\n",
    "            logging.info(\"last {} layers of CNN set to trainable\".format(num_layers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
