{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T01:26:53.570790Z",
     "start_time": "2019-01-20T01:26:53.567196Z"
    }
   },
   "outputs": [],
   "source": [
    "### TODO\n",
    "# * fit_models create_architectures_list (append mode)\n",
    "# * fit_models worker if experiment id last digit in os environment var\n",
    "\n",
    "# * collect garbage between fitting models\n",
    "\n",
    "# * refactor custom_model_name and model_weights_path to instead use trained model id\n",
    "\n",
    "# * delete cached sequences after each experiment\n",
    "\n",
    "# train c3d and c3dsmall separately\n",
    "# save model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:47.230896Z",
     "start_time": "2019-01-20T08:20:47.228002Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:47.441062Z",
     "start_time": "2019-01-20T08:20:47.437797Z"
    }
   },
   "outputs": [],
   "source": [
    "# to get number of CPUs to parallelize fit generator batch loading\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:47.660753Z",
     "start_time": "2019-01-20T08:20:47.658076Z"
    }
   },
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:48.645651Z",
     "start_time": "2019-01-20T08:20:48.172485Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:49.890765Z",
     "start_time": "2019-01-20T08:20:48.648204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, TensorBoard\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, Input\n",
    "from keras.layers.recurrent import SimpleRNN, GRU, LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D, Convolution1D, Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.491195Z",
     "start_time": "2019-01-20T08:20:49.893318Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.497194Z",
     "start_time": "2019-01-20T08:20:50.493943Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.505323Z",
     "start_time": "2019-01-20T08:20:50.499806Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.512505Z",
     "start_time": "2019-01-20T08:20:50.507700Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.518882Z",
     "start_time": "2019-01-20T08:20:50.514812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 08:20:50,516 [MainThread  ] [INFO ]  WORKER ID=1\n"
     ]
    }
   ],
   "source": [
    "# get worker id for this instance\n",
    "WORKERID = None\n",
    "try:\n",
    "    WORKERID = int(os.environ['WORKERID'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "logging.info(\"WORKER ID={}\".format(WORKERID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained_CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.525152Z",
     "start_time": "2019-01-20T08:20:50.521743Z"
    }
   },
   "outputs": [],
   "source": [
    "# pretrained model shapes\n",
    "pretrained_model_len_features = {}\n",
    "#\n",
    "pretrained_model_len_features['vgg16'] = 512\n",
    "#\n",
    "\n",
    "pretrained_model_len_features['mobilenetv2_1.00_224'] = 1280\n",
    "#\n",
    "pretrained_model_len_features['inception_resnet_v2'] = 1536\n",
    "#\n",
    "pretrained_model_len_features['resnet50'] = 2048\n",
    "pretrained_model_len_features['xception'] = 2048\n",
    "pretrained_model_len_features['inception_v3'] = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.530813Z",
     "start_time": "2019-01-20T08:20:50.527620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Notice the output features of the models group (roughly) into 3 buckets: 512, 1280 (with 1536), and 2048... \n",
    "# we'll do a grid search for 1 model in each bucket then run the best model in the grid for all other models in that bucket\n",
    "pretrained_model_names_bucketed_subset = ['vgg16', 'inception_resnet_v2', 'resnet50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.537000Z",
     "start_time": "2019-01-20T08:20:50.533433Z"
    }
   },
   "outputs": [],
   "source": [
    "# pretrained model shapes\n",
    "pretrained_model_sizes = {}\n",
    "#\n",
    "pretrained_model_sizes['vgg16'] = (224,224)\n",
    "pretrained_model_sizes['resnet50'] = (224,224)\n",
    "pretrained_model_sizes['mobilenetv2_1.00_224'] = (224,224)\n",
    "#\n",
    "pretrained_model_sizes['xception'] = (299,299)\n",
    "pretrained_model_sizes['inception_v3'] = (299,299)\n",
    "pretrained_model_sizes['inception_resnet_v2'] = (299,299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.542483Z",
     "start_time": "2019-01-20T08:20:50.539344Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_names = [\"inception_resnet_v2\", \"inception_v3\", \"mobilenetv2_1.00_224\", \"resnet50\", \"vgg16\", \"xception\"]\n",
    "poolings = ['max','avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.553453Z",
     "start_time": "2019-01-20T08:20:50.545298Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_model(pretrained_model_name, pooling, model_weights_path = None):\n",
    "    \"\"\" Load pretrained model with given pooling applied\n",
    "    \n",
    "    Args:\n",
    "        pretrained_model: name of pretrained model [\"Xception\", \"VGG16\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNetV2\"]\n",
    "        pooling: pooling strategy for final pretrained model layer [\"max\",\"avg\"]\n",
    "        :model_weights_path: path to custom model weights if we want to load CNN model we've fine-tuned to produce features (e.g. for LRCNN)\n",
    "    \n",
    "    Returns:\n",
    "        Pretrained model object (excluding dense softmax 1000 ImageNet classes layer)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize output\n",
    "    model = None\n",
    "    \n",
    "    pretrained_model_name = pretrained_model_name.lower()\n",
    "    \n",
    "    ###########################\n",
    "    ### import pretrained model\n",
    "    ###########################\n",
    "    if pretrained_model_name == \"xception\":   \n",
    "        from keras.applications.xception import Xception\n",
    "        model = Xception(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"vgg16\":   \n",
    "        from keras.applications.vgg16 import VGG16\n",
    "        model = VGG16(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"resnet50\":   \n",
    "        from keras.applications.resnet50 import ResNet50\n",
    "        model = ResNet50(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"inception_v3\":   \n",
    "        from keras.applications.inception_v3 import InceptionV3\n",
    "        model = InceptionV3(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"inception_resnet_v2\":   \n",
    "        from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "        model = InceptionResNetV2(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"mobilenetv2_1.00_224\":   \n",
    "        from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "        model = MobileNetV2(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    else:\n",
    "        raise NameError('Invalid pretrained model name - must be one of [\"Xception\", \"VGG16\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNetV2\"]')\n",
    "    \n",
    "    if model_weights_path is not None:\n",
    "        if os.path.exists(model_weights_path):\n",
    "            model.load_weights(model_weights_path)\n",
    "        else:\n",
    "            raise NameError('pretrained model weights not found')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.561035Z",
     "start_time": "2019-01-20T08:20:50.555939Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_model_preprocessor(pretrained_model_name):\n",
    "    \"\"\"\n",
    "    Return preprocessing function for a given pretrained model\n",
    "    \"\"\"\n",
    "\n",
    "    preprocess_input = None\n",
    "\n",
    "    pretrained_model_name = pretrained_model_name.lower()\n",
    "        \n",
    "    if pretrained_model_name == \"xception\":   \n",
    "        from keras.applications.xception import preprocess_input\n",
    "    elif pretrained_model_name == \"vgg16\":   \n",
    "        from keras.applications.vgg16 import preprocess_input\n",
    "    elif pretrained_model_name == \"resnet50\":   \n",
    "        from keras.applications.resnet50 import preprocess_input\n",
    "    elif pretrained_model_name == \"inception_v3\":   \n",
    "        from keras.applications.inception_v3 import preprocess_input\n",
    "    elif pretrained_model_name == \"inception_resnet_v2\":   \n",
    "        from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "    elif pretrained_model_name == \"mobilenetv2_1.00_224\":   \n",
    "        from keras.applications.mobilenet_v2 import preprocess_input\n",
    "    else:\n",
    "        raise NameError('Invalid pretrained model name - must be one of [\"Xception\", \"VGG16\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNetV2\"]')\n",
    "        \n",
    "    return preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.574615Z",
     "start_time": "2019-01-20T08:20:50.563838Z"
    }
   },
   "outputs": [],
   "source": [
    "def precompute_CNN_features(pretrained_model_name, pooling, model_weights_path = None, custom_model_name = None):\n",
    "    \"\"\" \n",
    "    Save pretrained features array computed over all frames of each video \n",
    "    using given pretrained model and pooling method\n",
    "    \n",
    "    :pretrained_model_name: pretrained model object loaded using `load_pretrained_model`\n",
    "    :pooling: pooling method used with pretrained model\n",
    "    :model_weights_path: path to custom model weights if we want to load CNN model we've fine-tuned to produce features (e.g. for LRCNN)\n",
    "    :custom_model_name: custom output name to append to pretrained model name\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    assert (pretrained_model_name is not None or custom_model_name is not None), \"need to specify a pretrained_model_name in ['Xception', 'VGG16', 'ResNet50', 'InceptionV3', 'InceptionResNetV2', 'MobileNetV2'] or a custom_model_name\"\n",
    "    \n",
    "    pretrained_model_name = pretrained_model_name.lower()\n",
    "    \n",
    "    # setup path to save features\n",
    "    path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "    \n",
    "    # store in custom directory if custom model name given (for when loading weights from fine-tuned CNN and precomputing features from that model)\n",
    "    if custom_model_name is not None and model_weights_path is not None:\n",
    "        path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "    \n",
    "    if not os.path.exists(path_features):\n",
    "        \n",
    "        os.makedirs(path_features)\n",
    "        \n",
    "        # load pretrained model\n",
    "        pretrained_model = load_pretrained_model(pretrained_model_name, pooling, model_weights_path)\n",
    "\n",
    "        # load preprocessing function\n",
    "        preprocess_input = load_pretrained_model_preprocessor(pretrained_model_name)\n",
    "\n",
    "        # lookup pretrained model input shape\n",
    "        model_input_size = pretrained_model_sizes[pretrained_model_name]\n",
    "        \n",
    "        # precompute features for each video using pretrained model\n",
    "        from deepvideoclassification.data import get_video_paths\n",
    "        path_videos = get_video_paths()\n",
    "\n",
    "        for c, path_video in enumerate(path_videos):\n",
    "\n",
    "            if verbose:\n",
    "                logging.info(\"Computing pretrained model features for video {}/{} using pretrained model: {}, pooling: {}\".format(c+1,len(path_videos),pretrained_model_name, pooling))\n",
    "\n",
    "            # get video name from video path\n",
    "            video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "            # build output path\n",
    "            path_output = path_features + video_name\n",
    "\n",
    "            try:\n",
    "                if not os.path.exists(path_output + '.npy'):\n",
    "\n",
    "                    path_frames = path_data + video_name + \"/\"\n",
    "\n",
    "                    # initialize features list\n",
    "                    features = []\n",
    "\n",
    "                    frame_paths = os.listdir(path_frames)\n",
    "                    frame_paths = [path_frames + f for f in frame_paths if f != '.DS_Store']\n",
    "\n",
    "                    # sort paths in sequence (they were created with incrementing filenames through time)\n",
    "                    frame_paths.sort()\n",
    "\n",
    "                    # load each frame in vid and get features\n",
    "                    for j, frame_path in enumerate(frame_paths):\n",
    "\n",
    "                        # load image & preprocess\n",
    "                        image = cv2.imread(frame_path, cv2.COLOR_BGR2RGB)\n",
    "                        img = cv2.resize(image, model_input_size, interpolation=cv2.INTER_AREA)\n",
    "                        img = img_to_array(img)\n",
    "                        img = np.expand_dims(img, axis=0)\n",
    "                        img = preprocess_input(img)\n",
    "\n",
    "                        # get features from pretrained model\n",
    "                        feature = pretrained_model.predict(img).ravel()\n",
    "                        features.append(feature)\n",
    "\n",
    "                    # convert to arrays\n",
    "                    features = np.array(features)\n",
    "\n",
    "                    np.save(path_output, features)\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        logger.info(\"Features already cached: {}\".format(path_output))\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(\"Error precomputing features {} / {},{}\".format(video_namepretrained_model_name, pooling))\n",
    "                logging.fatal(e, exc_info=True)\n",
    "                \n",
    "    else:\n",
    "        if verbose:\n",
    "            logger.info(\"Features already cached: {}\".format(path_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:50.589262Z",
     "start_time": "2019-01-20T08:20:50.577016Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture class (contains keras model object and train/evaluate method, writes training results to /models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:51.803457Z",
     "start_time": "2019-01-20T08:20:51.615708Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Architecture(object):\n",
    "    \n",
    "    def __init__(self, model_id, architecture, sequence_length, \n",
    "                frame_size = None, \n",
    "                pretrained_model_name = None, pooling = None,\n",
    "                sequence_model = None, sequence_model_layers = None,\n",
    "                layer_1_size = 0, layer_2_size = 0, layer_3_size = 0, \n",
    "                dropout = 0, convolution_kernel_size = 3, \n",
    "                model_weights_path = None, \n",
    "                batch_size = 32, \n",
    "                verbose = False):\n",
    "        \"\"\"\n",
    "        Model object constructor. Contains Keras model object and training/evaluation methods. Writes model results to /models/_id_ folder\n",
    "        \n",
    "        Architecture can be one of: \n",
    "        image_MLP_frozen, image_MLP_trainable, video_MLP_concat, video_LRCNN_frozen, video_LRCNN_trainable, C3D, C3Dsmall\n",
    "        \n",
    "        :model_id: integer identifier for this model e.g. 1337\n",
    "        \n",
    "        :architecture: architecture of model in [image_MLP_frozen, image_MLP_trainable, video_MLP_concat, video_LRCNN_frozen, video_LRCNN_trainable, C3D, C3Dsmall]\n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        \n",
    "        :frame_size: size that frames are resized to (different models / architectures accept different input sizes - will be inferred if pretrained_model_name is given since they have fixed sizes)\n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN or if fitting more non-dense layers on top of pretrained model base)\n",
    "        \n",
    "        :sequence_model: sequence model in [LSTM, SimpleRNN, GRU, Convolution1D]\n",
    "        :sequence_model_layers: default to 1, can be stacked 2 or 3 (but less than 4) layer sequence model (assume always stacking the same sequence model, not mixing LSTM and GRU, for example)\n",
    "        \n",
    "        :layer_1_size: number of neurons in layer 1\n",
    "        :layer_2_size: number of neurons in layer 2\n",
    "        :layer_3_size: number of neurons in layer 3 \n",
    "        \n",
    "        :dropout: amount of dropout to add (same applied throughout model - good default is 0.2) \n",
    "        \n",
    "        :convolution_kernel_size: size of 1-D convolutional kernel for 1-d conv sequence models (good default is 3)\n",
    "        \n",
    "        :model_weights_path: path to .h5 weights file to be loaded for pretrained CNN in LRCNN-trainable \n",
    "        \n",
    "        :batch_size: batch size used to fit model (default to 32)\n",
    "        \n",
    "        :verbose: whether to log progress updates\n",
    "        \"\"\"\n",
    "    \n",
    "        # required params\n",
    "        self.model_id = model_id\n",
    "        \n",
    "        # create path based on model id\n",
    "        self.path_model = pwd + 'models/' + str(model_id) + '/'\n",
    "        if not os.path.exists(self.path_model):\n",
    "            os.makedirs(self.path_model)\n",
    "        else:\n",
    "            if not os.path.exists(self.path_model + 'results.json'):\n",
    "                logging.info(\"Model folder exists but no results found - potential error in previous model training\")\n",
    "        \n",
    "        self.architecture = architecture\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # model architecture params\n",
    "        self.frame_size = frame_size\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.sequence_model = sequence_model\n",
    "        self.sequence_model_layers = sequence_model_layers\n",
    "        #\n",
    "        self.layer_1_size = layer_1_size\n",
    "        self.layer_2_size = layer_2_size\n",
    "        self.layer_3_size = layer_3_size\n",
    "        #\n",
    "        self.dropout = dropout\n",
    "        #\n",
    "        self.convolution_kernel_size = convolution_kernel_size\n",
    "        #\n",
    "        self.model_weights_path = model_weights_path\n",
    "        #\n",
    "        self.batch_size = batch_size\n",
    "        #\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # fix case sensitivity\n",
    "        if type(self.architecture) == str:\n",
    "            self.architecture = self.architecture.lower()\n",
    "        if type(self.pretrained_model_name) == str:\n",
    "            self.pretrained_model_name = self.pretrained_model_name.lower()\n",
    "        if type(self.pooling) == str:\n",
    "            self.pooling = self.pooling.lower()\n",
    "        \n",
    "        # read num features from pretrained model\n",
    "        if pretrained_model_name is not None:\n",
    "            self.num_features = pretrained_model_len_features[pretrained_model_name]\n",
    "            self.frame_size = pretrained_model_sizes[pretrained_model_name]\n",
    "        \n",
    "        # check one of pretrained model and frame size is specified\n",
    "        assert (self.pretrained_model_name is not None or self.frame_size is not None), \"Must specify one of pretrained_model_name or frame_size\"\n",
    "            \n",
    "            \n",
    "        # init model and data objects for this architecture\n",
    "        self.model = None\n",
    "        self.data = None\n",
    "        \n",
    "        \n",
    "        #############################################################\n",
    "        ### Build model architecture and init appropriate data object\n",
    "        #############################################################\n",
    "        \n",
    "        if architecture == \"image_MLP_frozen\":\n",
    "            \n",
    "            ####################\n",
    "            ### image_MLP_frozen\n",
    "            ####################\n",
    "            # image classification (single frame)\n",
    "            # train MLP on top of weights extracted from pretrained CNN with no fine-tuning\n",
    "            \n",
    "            # check inputs\n",
    "            assert self.sequence_length == 1, \"image_MLP_frozen requires sequence length of 1\"\n",
    "            assert self.pretrained_model_name is not None, \"image_MLP_frozen requires a pretrained_model_name input\" \n",
    "            assert self.pooling is not None, \"image_MLP_frozen requires a pooling input\" \n",
    "            \n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = 1, \n",
    "                                return_CNN_features = True, \n",
    "                                pretrained_model_name= self.pretrained_model_name,\n",
    "                                pooling = self.pooling)\n",
    "            \n",
    "            # init model\n",
    "            model = Sequential()\n",
    "\n",
    "            # 1st layer group\n",
    "            if self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_1_size, activation='relu', input_shape=(self.num_features,)))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "                \n",
    "            # 2nd layer group\n",
    "            if self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_2_size, activation='relu'))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # 3rd layer group\n",
    "            if self.layer_3_size > 0 and self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_3_size, activation='relu'))\n",
    "                if dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # classifier layer\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax'))\n",
    "            \n",
    "\n",
    "        elif architecture == \"image_MLP_trainable\":\n",
    "            \n",
    "            #######################\n",
    "            ### image_MLP_trainable\n",
    "            #######################\n",
    "            # image classification (single frame)\n",
    "            # fine-tune pretrained CNN with MLP on top\n",
    "            #\n",
    "            # start off freezing base CNN layers then will unfreeze \n",
    "            # after each training round\n",
    "            #\n",
    "            # we will ultimately want to compare our best fine-tuned \n",
    "            # CNN as a feature extractor vs fixed ImageNet pretrained CNN features\n",
    "            \n",
    "            # check inputs\n",
    "            assert self.sequence_length == 1, \"image_MLP_trainable requires sequence length of 1\"\n",
    "            assert self.pretrained_model_name is not None, \"image_MLP_trainable requires a pretrained_model_name input\" \n",
    "            assert self.pooling is not None, \"image_MLP_trainable requires a pooling input\" \n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = 1, \n",
    "                                return_CNN_features = False, \n",
    "                                pretrained_model_name = self.pretrained_model_name,\n",
    "                                pooling = self.pooling,\n",
    "                                return_generator = True,\n",
    "                                batch_size = self.batch_size)\n",
    "            \n",
    "            # create the base pre-trained model\n",
    "            model_base = load_pretrained_model(self.pretrained_model_name, pooling=self.pooling)\n",
    "            \n",
    "\n",
    "            # freeze base model layers (will unfreeze after train top)\n",
    "            for l in model_base.layers:\n",
    "                l.trainable=False\n",
    "\n",
    "            # use Keras functional API\n",
    "            model_top = model_base.output\n",
    "\n",
    "            # note layer names are there so we can exclude those layers \n",
    "            # when setting base model layers to trainable\n",
    "\n",
    "            # 1st layer group\n",
    "            if self.layer_1_size > 0:\n",
    "                model_top = Dense(self.layer_1_size, activation=\"relu\", name='top_a')(model_top)\n",
    "                if self.dropout > 0:\n",
    "                    model_top = Dropout(self.dropout, name='top_b')(model_top)\n",
    "\n",
    "            # 2nd layer group\n",
    "            if self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model_top = Dense(self.layer_2_size, activation=\"relu\", name='top_c')(model_top)\n",
    "                if self.dropout > 0:\n",
    "                    model_top = Dropout(self.dropout, name='top_d')(model_top)\n",
    "\n",
    "            # 3rd layer group\n",
    "            if self.layer_3_size > 0 and self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model_top = Dense(self.layer_3_size, activation=\"relu\", name='top_e')(model_top)\n",
    "                if self.dropout > 0:\n",
    "                    model_top = Dropout(self.dropout, name='top_f')(model_top)\n",
    "\n",
    "            # classifier layer\n",
    "            model_predictions = Dense(self.data.num_classes, activation=\"softmax\", name='top_g')(model_top)\n",
    "\n",
    "            # combine base and top models into single model object\n",
    "            model = Model(inputs=model_base.input, outputs=model_predictions)\n",
    "                \n",
    "        elif architecture == \"video_MLP_concat\":\n",
    "\n",
    "            ####################\n",
    "            ### video_MLP_concat\n",
    "            ####################\n",
    "            \n",
    "            # concatenate all frames in sequence and train MLP on top of concatenated frame input\n",
    "            \n",
    "            assert self.sequence_length > 1, \"video_MLP_concat requires sequence length > 1\"\n",
    "            assert self.pretrained_model_name is not None, \"video_MLP_concat requires a pretrained_model_name input\"\n",
    "            assert self.pooling is not None, \"video_MLP_concat requires a pooling input\"\n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = self.sequence_length, \n",
    "                                return_CNN_features = True, \n",
    "                                pretrained_model_name=self.pretrained_model_name,\n",
    "                                pooling = self.pooling)\n",
    "\n",
    "            # init model\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Flatten(input_shape=(self.sequence_length, self.num_features)))\n",
    "\n",
    "            # 1st layer group\n",
    "            if self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_1_size, activation='relu', input_shape=(self.num_features,)))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # 2nd layer group\n",
    "            if self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_2_size, activation='relu'))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # 3rd layer group\n",
    "            if self.layer_3_size > 0 and self.layer_2_size > 0 and self.layer_1_size > 0:\n",
    "                model.add(Dense(self.layer_3_size, activation='relu'))\n",
    "                if self.dropout > 0:\n",
    "                    model.add(Dropout(self.dropout))\n",
    "\n",
    "            # classifier layer\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax'))\n",
    "            \n",
    "        elif architecture == \"video_LRCNN_frozen\":\n",
    "\n",
    "            ######################\n",
    "            ### video_LRCNN_frozen\n",
    "            ######################\n",
    "            \n",
    "            # Implement:\n",
    "            # “Long-Term Recurrent Convolutional Networks for Visual Recognition and Description.”\n",
    "            # Donahue, Jeff, Lisa Anne Hendricks, Marcus Rohrbach, Subhashini Venugopalan, \n",
    "            # Sergio Guadarrama, Kate Saenko, and Trevor Darrell.  \n",
    "            # Proceedings of the IEEE Computer Society Conference on Computer Vision and \n",
    "            # Pattern Recognition, 2015, 2625–34.\n",
    "            #\n",
    "            # Essentially they extract features with fine-tuned CNN then fit recurrent models on top\n",
    "            # in the paper they only use LSTM but we will also try RNN, GRU and 1-D CNN\n",
    "            # \n",
    "            # note: no fine-tuning of CNN in this frozen LRCNN architecture\n",
    "            # \n",
    "            # implementation inspired by:\n",
    "            # https://github.com/sagarvegad/Video-Classification-CNN-and-LSTM-/blob/master/train_CNN_RNN.py\n",
    "\n",
    "            \n",
    "            # check inputs\n",
    "            assert self.sequence_length > 1, \"video_LRCNN_frozen requires sequence length > 1\"\n",
    "            assert self.layer_1_size > 0, \"video_LRCNN_frozen requires a layer_1_size > 0\" \n",
    "            assert self.pretrained_model_name is not None, \"video_LRCNN_frozen requires a pretrained_model_name input\" \n",
    "            assert self.pooling is not None, \"video_LRCNN_frozen requires a pooling input\" \n",
    "            assert self.sequence_model_layers is not None, \"video_LRCNN_frozen requires sequence_model_layers >= 1\" \n",
    "            assert self.sequence_model_layers >= 1, \"video_LRCNN_frozen requires sequence_model_layers >= 1\" \n",
    "            assert self.sequence_model_layers < 4, \"video_LRCNN_frozen requires sequence_model_layers <= 3\" \n",
    "            assert self.sequence_model is not None, \"video_LRCNN_frozen requires a sequence_model\" \n",
    "            if self.sequence_model == 'Convolution1D':\n",
    "                assert self.convolution_kernel_size > 0, \"Convolution1D sequence model requires convolution_kernel_size parameter > 0\"\n",
    "                assert self.convolution_kernel_size < self.sequence_length, \"convolution_kernel_size must be less than sequence_length\"\n",
    "\n",
    "                \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = self.sequence_length, \n",
    "                                return_CNN_features = True, \n",
    "                                pretrained_model_name = self.pretrained_model_name,\n",
    "                                pooling = self.pooling)\n",
    "            \n",
    "                \n",
    "            # set whether to return sequences for stacked sequence models\n",
    "            return_sequences_1, return_sequences_2 = False, False\n",
    "            if sequence_model_layers > 1 and layer_2_size > 0:\n",
    "                return_sequences_1 = True\n",
    "            if sequence_model_layers >= 2 and layer_3_size > 0 and layer_2_size > 0:\n",
    "                return_sequences_2 = True\n",
    "            \n",
    "            # init model\n",
    "            model = Sequential()\n",
    "\n",
    "            # layer 1 (sequence layer)\n",
    "            if sequence_model == \"LSTM\":\n",
    "                model.add(LSTM(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout, \n",
    "                               input_shape=(self.sequence_length, self.num_features)))\n",
    "            elif sequence_model == \"SimpleRNN\":\n",
    "                model.add(SimpleRNN(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout, \n",
    "                               input_shape=(self.sequence_length, self.num_features)))\n",
    "            elif sequence_model == \"GRU\":\n",
    "                model.add(GRU(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout, \n",
    "                               input_shape=(self.sequence_length, self.num_features)))\n",
    "            elif sequence_model == \"Convolution1D\":\n",
    "                model.add(Convolution1D(self.layer_1_size, kernel_size = self.convolution_kernel_size, padding = 'valid', \n",
    "                               input_shape=(self.sequence_length, self.num_features)))\n",
    "                if layer_2_size == 0 or sequence_model_layers == 1:\n",
    "                    model.add(Flatten())\n",
    "            else:\n",
    "                raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]')    \n",
    "\n",
    "            # layer 2 (sequential or dense)\n",
    "            if layer_2_size > 0:\n",
    "                if return_sequences_1 == False:\n",
    "                    model.add(Dense(self.layer_2_size, activation='relu'))\n",
    "                    model.add(Dropout(self.dropout))\n",
    "                else:\n",
    "                    if sequence_model == \"LSTM\":\n",
    "                        model.add(LSTM(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout))\n",
    "                    elif sequence_model == \"SimpleRNN\":\n",
    "                        model.add(SimpleRNN(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout))\n",
    "                    elif sequence_model == \"GRU\":\n",
    "                        model.add(GRU(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout))\n",
    "                    elif sequence_model == \"Convolution1D\":\n",
    "                        model.add(Convolution1D(self.layer_2_size, kernel_size = self.convolution_kernel_size, padding = 'valid'))\n",
    "                    else:\n",
    "                        raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]') \n",
    "\n",
    "            # layer 3 (sequential or dense)\n",
    "            if layer_3_size > 0:\n",
    "                if sequence_model_layers < 3:\n",
    "                    if sequence_model_layers == 2:\n",
    "                        model.add(Flatten())\n",
    "                    model.add(Dense(self.layer_3_size, activation='relu'))\n",
    "                    model.add(Dropout(self.dropout))\n",
    "                else:\n",
    "                    if sequence_model == \"LSTM\":\n",
    "                        model.add(LSTM(self.layer_3_size, return_sequences=False, dropout=self.dropout))\n",
    "                        model.add(Flatten())\n",
    "                    elif sequence_model == \"SimpleRNN\":\n",
    "                        model.add(SimpleRNN(self.layer_3_size, return_sequences=False, dropout=self.dropout))\n",
    "                        model.add(Flatten())\n",
    "                    elif sequence_model == \"GRU\":\n",
    "                        model.add(GRU(self.layer_3_size, return_sequences=False, dropout=self.dropout))\n",
    "                        model.add(Flatten())\n",
    "                    elif sequence_model == \"Convolution1D\":\n",
    "                        model.add(Convolution1D(self.layer_3_size, kernel_size = self.convolution_kernel_size, padding = 'valid'))\n",
    "                        model.add(Flatten())\n",
    "                    else:\n",
    "                        raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]') \n",
    "            else:\n",
    "                if return_sequences_2 == True: \n",
    "                    model.add(Flatten())\n",
    "\n",
    "            # classifier layer\n",
    "            if self.dropout > 0:\n",
    "                model.add(Dropout(self.dropout))\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax'))\n",
    "\n",
    "        elif architecture == \"video_LRCNN_trainable\":\n",
    "            \n",
    "            #########################\n",
    "            ### video_LRCNN_trainable\n",
    "            #########################\n",
    "            \n",
    "            # Same as above:\n",
    "            # “Long-Term Recurrent Convolutional Networks for Visual Recognition and Description.”\n",
    "            # Donahue, Jeff, Lisa Anne Hendricks, Marcus Rohrbach, Subhashini Venugopalan, \n",
    "            # Sergio Guadarrama, Kate Saenko, and Trevor Darrell.  \n",
    "            # Proceedings of the IEEE Computer Society Conference on Computer Vision and \n",
    "            # Pattern Recognition, 2015, 2625–34.\n",
    "            #\n",
    "            # But with fine-tuning of the CNNs that are input into the recurrent models\n",
    "            # \n",
    "            # note: will take long because not precomputing the CNN part so re-computed \n",
    "            # on each training pass\n",
    "\n",
    "            # implementation inspired by https://stackoverflow.com/questions/49535488/lstm-on-top-of-a-pre-trained-cnn\n",
    "            \n",
    "            # check inputs\n",
    "            assert self.sequence_length > 1, \"video_LRCNN_trainable requires sequence length > 1\"\n",
    "            assert self.layer_1_size > 0, \"video_LRCNN_trainable requires a layer_1_size > 0\" \n",
    "            assert self.pretrained_model_name is not None, \"video_LRCNN_trainable requires a pretrained_model_name input\" \n",
    "            assert self.pooling is not None, \"video_LRCNN_trainable requires a pooling input\" \n",
    "            assert self.sequence_model_layers >= 1, \"video_LRCNN_trainable requires sequence_model_layers >= 1\" \n",
    "            assert self.sequence_model_layers < 4, \"video_LRCNN_trainable requires sequence_model_layers <= 3\" \n",
    "            assert self.sequence_model is not None, \"video_LRCNN_trainable requires a sequence_model\" \n",
    "            if self.sequence_model == 'Convolution1D':\n",
    "                assert self.convolution_kernel_size > 0, \"Convolution1D sequence model requires convolution_kernel_size parameter > 0\"\n",
    "                assert self.convolution_kernel_size < self.sequence_length, \"convolution_kernel_size must be less than sequence_length\"\n",
    "                \n",
    "                \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = self.sequence_length, \n",
    "                                return_CNN_features = False, \n",
    "                                return_generator=True,\n",
    "                                pretrained_model_name = self.pretrained_model_name,\n",
    "                                pooling = self.pooling,\n",
    "                                batch_size=self.batch_size)\n",
    "            \n",
    "                \n",
    "            # set whether to return sequences for stacked sequence models\n",
    "            return_sequences_1, return_sequences_2 = False, False\n",
    "            if sequence_model_layers > 1 and layer_2_size > 0:\n",
    "                return_sequences_1 = True\n",
    "            if sequence_model_layers >= 2 and layer_3_size > 0 and layer_2_size > 0:\n",
    "                return_sequences_2 = True\n",
    "\n",
    "            # load pretrained model weights - will train from there\n",
    "            model_cnn = load_pretrained_model(self.pretrained_model_name, pooling=self.pooling)\n",
    "\n",
    "            # optionally load weights for pretrained architecture\n",
    "            # (will likely be better to first train CNN then load weights in LRCNN vs. use pretrained ImageNet CNN)\n",
    "            if self.model_weights_path is not None:\n",
    "                model_base.load_weights(self.model_weights_path)\n",
    "            \n",
    "            # freeze model_cnn layers but make final 3 layers of pretrained CNN trainable\n",
    "            for i, l in enumerate(model_cnn.layers):\n",
    "                if i < len(model_cnn.layers)-3:\n",
    "                    l.trainable = False\n",
    "                else:\n",
    "                    l.trainable = True\n",
    "\n",
    "            # sequential component on top of CNN\n",
    "            frames = Input(shape=(self.sequence_length, self.frame_size[0], self.frame_size[1], 3))\n",
    "            x = TimeDistributed(model_cnn)(frames)\n",
    "            x = TimeDistributed(Flatten())(x)\n",
    "            \n",
    "\n",
    "            # layer 1 (sequence layer)\n",
    "            if sequence_model == \"LSTM\":\n",
    "                x = LSTM(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout)(x)\n",
    "            elif sequence_model == \"SimpleRNN\":\n",
    "                x = SimpleRNN(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout)(x)\n",
    "            elif sequence_model == \"GRU\":\n",
    "                x = GRU(self.layer_1_size, return_sequences=return_sequences_1, dropout=self.dropout)(x)\n",
    "            elif sequence_model == \"Convolution1D\":\n",
    "                x = Convolution1D(self.layer_1_size, kernel_size = self.convolution_kernel_size, padding = 'valid')(x)\n",
    "                if layer_2_size == 0 or sequence_model_layers == 1:\n",
    "                    x = Flatten()(x)\n",
    "            else:\n",
    "                raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]')    \n",
    "\n",
    "            # layer 2 (sequential or dense)\n",
    "            if layer_2_size > 0:\n",
    "                if return_sequences_1 == False:\n",
    "                    x = Dense(self.layer_2_size, activation='relu')(x)\n",
    "                    x = Dropout(self.dropout)(x)\n",
    "                else:\n",
    "                    if sequence_model == \"LSTM\":\n",
    "                        x = LSTM(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout)(x)\n",
    "                    elif sequence_model == \"SimpleRNN\":\n",
    "                        x = SimpleRNN(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout)(x)\n",
    "                    elif sequence_model == \"GRU\":\n",
    "                        x = GRU(self.layer_2_size, return_sequences=return_sequences_2, dropout=self.dropout)(x)\n",
    "                    elif sequence_model == \"Convolution1D\":\n",
    "                        x = Convolution1D(self.layer_2_size, kernel_size = self.convolution_kernel_size, padding = 'valid')(x)\n",
    "                    else:\n",
    "                        raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]') \n",
    "\n",
    "            # layer 3 (sequential or dense)\n",
    "            if layer_3_size > 0:\n",
    "                if sequence_model_layers < 3:\n",
    "                    if sequence_model_layers == 2:\n",
    "                        x = Flatten()(x)\n",
    "                    x = Dense(self.layer_3_size, activation='relu')(x)\n",
    "                    x = Dropout(self.dropout)(x)\n",
    "                else:\n",
    "                    if sequence_model == \"LSTM\":\n",
    "                        x = LSTM(self.layer_3_size, return_sequences=False, dropout=self.dropout)(x)\n",
    "                        x = Flatten()(x)\n",
    "                    elif sequence_model == \"SimpleRNN\":\n",
    "                        x = SimpleRNN(self.layer_3_size, return_sequences=False, dropout=self.dropout)(x)\n",
    "                        x = Flatten()(x)\n",
    "                    elif sequence_model == \"GRU\":\n",
    "                        x = GRU(self.layer_3_size, return_sequences=False, dropout=self.dropout)(x)\n",
    "                        x = Flatten()(x)\n",
    "                    elif sequence_model == \"Convolution1D\":\n",
    "                        x = Convolution1D(self.layer_3_size, kernel_size = self.convolution_kernel_size, padding = 'valid')(x)\n",
    "                        x = Flatten()(x)\n",
    "                    else:\n",
    "                        raise NameError('Invalid sequence_model - must be one of [LSTM, SimpleRNN, GRU, Convolution1D]') \n",
    "            else:\n",
    "                if return_sequences_2 == True: \n",
    "                    x = Flatten()(x)\n",
    "\n",
    "            # classifier layer\n",
    "            if self.dropout > 0:\n",
    "                x = Dropout(self.dropout)(x)\n",
    "            out = Dense(self.data.num_classes, activation='softmax')(x)\n",
    "                        \n",
    "\n",
    "            # join cnn frame model and LSTM top\n",
    "            model = Model(inputs=frames, outputs=out)\n",
    "         \n",
    "        elif architecture == \"C3D\":\n",
    "            \n",
    "            #########\n",
    "            ### C3D\n",
    "            #########\n",
    "            \n",
    "            # Implement:\n",
    "            # Learning Spatiotemporal Features with 3D Convolutional Networks\n",
    "            # Tran et al 2015\n",
    "            # https://arxiv.org/abs/1412.0767\n",
    "            #\n",
    "            # Implementation inspired by https://gist.github.com/albertomontesg/d8b21a179c1e6cca0480ebdf292c34d2\n",
    "            \n",
    "            assert self.sequence_length == 16, \"C3D requires sequence length 16\"\n",
    "            assert self.frame_size == (112,112), \"C3D requires frame size 112x112\"\n",
    "            assert self.layer_1_size == 0, \"C3D does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.layer_2_size == 0, \"C3D does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.layer_3_size == 0, \"C3D does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.dropout == 0, \"C3D does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.sequence_model == None, \"C3D does not accept a sequence_model parameter\"\n",
    "            assert self.sequence_model_layers == None, \"C3D does not accept a sequence_model_layers parameter\"\n",
    "            assert self.pretrained_model_name == None, \"C3D does not accept a pretrained_model_name parameter\"            \n",
    "            assert self.pooling == None, \"C3D does not accept a pooling parameter\"                            \n",
    "            \n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = 16, \n",
    "                                return_CNN_features = False, \n",
    "                                return_generator = True,\n",
    "                                frame_size = (112,112),\n",
    "                                batch_size=self.batch_size,\n",
    "                                verbose = False)\n",
    "            \n",
    "            # C3D\n",
    "            model = Sequential()\n",
    "            # 1st layer group\n",
    "            model.add(Conv3D(64, (3, 3, 3), activation='relu', padding='same', name='conv1', input_shape=(16, 112, 112, 3)))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), padding='valid', name='pool1'))\n",
    "            # 2nd layer group\n",
    "            model.add(Conv3D(128, (3, 3, 3), activation='relu',padding='same', name='conv2'))\n",
    "            model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),padding='valid', name='pool2'))\n",
    "            # 3rd layer group\n",
    "            model.add(Conv3D(256, (3, 3, 3), activation='relu',padding='same', name='conv3a'))\n",
    "            model.add(Conv3D(256, (3, 3, 3), activation='relu',padding='same', name='conv3b'))\n",
    "            model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='pool3'))\n",
    "            # 4th layer group\n",
    "            model.add(Conv3D(512, (3, 3, 3), activation='relu',padding='same', name='conv4a'))\n",
    "            model.add(Conv3D(512, (3, 3, 3), activation='relu',padding='same', name='conv4b'))\n",
    "            model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),padding='valid', name='pool4'))\n",
    "            # 5th layer group\n",
    "            model.add(Conv3D(512, (3, 3, 3), activation='relu',padding='same', name='conv5a'))\n",
    "            model.add(Conv3D(512, (3, 3, 3), activation='relu',padding='same', name='conv5b'))\n",
    "            model.add(ZeroPadding3D(padding=(0, 1, 1)))\n",
    "            model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),padding='valid', name='pool5'))\n",
    "            model.add(Flatten())\n",
    "            # FC layers group\n",
    "            model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "            model.add(Dropout(.5))\n",
    "            model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "            model.add(Dropout(.5))\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax', name='fc8'))\n",
    "            \n",
    "        elif architecture == \"C3Dsmall\":\n",
    "            \n",
    "            #########################\n",
    "            ### C3D - small variation\n",
    "            #########################\n",
    "            \n",
    "            # Custom small version of C3D from paper:\n",
    "            # Learning Spatiotemporal Features with 3D Convolutional Networks\n",
    "            # Tran et al 2015\n",
    "            # https://arxiv.org/abs/1412.0767\n",
    "            #\n",
    "            # Implementation inspired by https://gist.github.com/albertomontesg/d8b21a179c1e6cca0480ebdf292c34d2\n",
    "            \n",
    "            assert self.sequence_length == 16, \"C3Dsmall requires sequence length 16\"\n",
    "            assert self.frame_size == (112,112), \"C3Dsmall requires frame size 112x112\"\n",
    "            assert self.layer_1_size == 0, \"C3Dsmall does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.layer_2_size == 0, \"C3Dsmall does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.layer_3_size == 0, \"C3Dsmall does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.dropout == 0, \"C3Dsmall does not accept layer size inputs since it's a predefined architecture\"\n",
    "            assert self.sequence_model == None, \"C3Dsmall does not accept a sequence_model parameter\"\n",
    "            assert self.sequence_model_layers == None, \"C3Dsmall does not accept a sequence_model_layers parameter\"\n",
    "            assert self.pretrained_model_name == None, \"C3Dsmall does not accept a pretrained_model_name parameter\"            \n",
    "            assert self.pooling == None, \"C3Dsmall does not accept a pooling parameter\"      \n",
    "            \n",
    "            \n",
    "            ### create data object for this architecture\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading data\")\n",
    "            self.data = Data(sequence_length = 16, \n",
    "                                return_CNN_features = False, \n",
    "                                return_generator = True,\n",
    "                                frame_size = (112,112),\n",
    "                                batch_size=self.batch_size,\n",
    "                                verbose = False)\n",
    "            \n",
    "            # C3Dsmall\n",
    "            model = Sequential()\n",
    "            # 1st layer group\n",
    "            model.add(Conv3D(32, (3,3,3), activation='relu', input_shape=(data.sequence_length, 112, 112, 3)))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "            # 2nd layer group\n",
    "            model.add(Conv3D(64, (3,3,3), activation='relu'))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "            # 3rd layer group\n",
    "            model.add(Conv3D(128, (3,3,3), activation='relu'))\n",
    "            model.add(Conv3D(128, (3,3,3), activation='relu'))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "            # 4th layer group\n",
    "            model.add(Conv3D(256, (2,2,2), activation='relu'))\n",
    "            model.add(Conv3D(256, (2,2,2), activation='relu'))\n",
    "            model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "            # FC layers group\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(256))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(128))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(self.data.num_classes, activation='softmax'))\n",
    "            \n",
    "        else:\n",
    "            raise NameError('Invalid architecture - must be one of [image_MLP_frozen, image_MLP_trainable, video_MLP_concat, video_LRCNN_frozen, video_LRCNN_trainable, C3D, C3Dsmall]')    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ###############\n",
    "        ### Finish init\n",
    "        ###############\n",
    "        \n",
    "        # set class model to constructed model\n",
    "        self.model = model\n",
    "        \n",
    "        # load weights of model if they exist\n",
    "        if os.path.exists(self.path_model + 'model.h5'):\n",
    "            if self.verbose:\n",
    "                logging.info(\"Loading saved model weights\")\n",
    "            model.load_weights(self.path_model + 'model.h5')            \n",
    "        \n",
    "        # save model summary to model folder\n",
    "        with open(self.path_model + 'model_summary.txt', 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                self.model.summary()\n",
    "        \n",
    "        # save architecture params to model folder\n",
    "        params = self.__dict__.copy()\n",
    "        params['data_shape'] = str(self.data)\n",
    "        del params['model']\n",
    "        del params['data']\n",
    "        with open(self.path_model + 'params.json', 'w') as fp:\n",
    "            json.dump(params, fp, indent=4, sort_keys=True)\n",
    "    \n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Run several rounds of fitting to train model, reducing learning rate after each round\n",
    "        \n",
    "        Progress and model parameters will be saved to the model's path e.g. /models/1/\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # init results with architecture params\n",
    "        results = self.__dict__.copy()\n",
    "        results['data_total_rows_train'] = self.data.total_rows_train\n",
    "        results['data_total_rows_valid'] = self.data.total_rows_valid\n",
    "        results['data_total_rows_test'] = self.data.total_rows_test\n",
    "        del results['model']\n",
    "        del results['data']\n",
    "        results['model_param_count'] = self.model.count_params()\n",
    "        \n",
    "        \n",
    "        ###############\n",
    "        ### Train model\n",
    "        ###############\n",
    "        \n",
    "        # start training timer\n",
    "        start = datetime.datetime.now()\n",
    "        results['fit_dt_train_start'] = start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        # do first round of fitting\n",
    "        history1, stopped_epoch1 = self.fit(learning_rate = 0.001)\n",
    "        \n",
    "        # load best model weights so far\n",
    "        self.model.load_weights(self.path_model + 'model.h5')\n",
    "        \n",
    "        # reduce learning rate and fit some more\n",
    "        history2, stopped_epoch2 = self.fit(learning_rate = 0.0001)\n",
    "        \n",
    "        # load best model weights so far\n",
    "        self.model.load_weights(self.path_model + 'model.h5')\n",
    "        \n",
    "        # reduce learning rate and fit some more\n",
    "        history3, stopped_epoch3 = self.fit(learning_rate = 0.00001)\n",
    "        \n",
    "        # end time training\n",
    "        end = datetime.datetime.now()    \n",
    "        results['fit_dt_train_end']  = end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        results['fit_dt_train_duration_seconds']  = str((end - start).total_seconds()).split(\".\")[0]\n",
    "        \n",
    "        \n",
    "        #################\n",
    "        ### build results\n",
    "        #################\n",
    "        # combine fit histories into big dataframe and write to model folder\n",
    "        # only keep history until accuracy declined (where early stopping made checkpoint)\n",
    "\n",
    "        # parse history dicts to dataframes\n",
    "        history1 = pd.DataFrame(history1.history).head(stopped_epoch1)\n",
    "        history1['fit_round'] = 1\n",
    "        history2 = pd.DataFrame(history2.history).head(stopped_epoch2)\n",
    "        history2['fit_round'] = 2\n",
    "        history3 = pd.DataFrame(history3.history).head(stopped_epoch3)\n",
    "        history3['fit_round'] = 3\n",
    "        \n",
    "        # combine and save csv\n",
    "        fit_history = pd.concat([history1, history2, history3], axis=0)\n",
    "        fit_history = fit_history.reset_index(drop=True)\n",
    "        fit_history['epoch'] = fit_history.index+1\n",
    "        fit_history.to_csv(self.path_model + 'fit_history.csv')\n",
    "        self.fit_history = fit_history\n",
    "        \n",
    "        results['fit_stopped_epoch1'] = stopped_epoch1\n",
    "        results['fit_stopped_epoch2'] = stopped_epoch2\n",
    "        results['fit_stopped_epoch3'] = stopped_epoch3\n",
    "        \n",
    "        # add 3 = 1 for each training round because stopped_epoch is 0 indexed\n",
    "        results['fit_num_epochs'] = stopped_epoch1 + stopped_epoch2 + stopped_epoch3 + 3\n",
    "        results['fit_val_acc'] = list(fit_history.tail(1)['val_acc'])[0]\n",
    "        results['fit_train_acc'] = list(fit_history.tail(1)['acc'])[0]\n",
    "        results['fit_val_loss'] = list(fit_history.tail(1)['val_loss'])[0]\n",
    "        results['fit_train_loss'] = list(fit_history.tail(1)['loss'])[0]\n",
    "\n",
    "        #######################\n",
    "        ### Predict on test set\n",
    "        #######################\n",
    "        \n",
    "        # start test timer\n",
    "        start = datetime.datetime.now()\n",
    "        results['fit_dt_test_start'] = start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        y_pred = None\n",
    "        y_test = None\n",
    "        if self.data.return_generator:\n",
    "            # predict on test set via generator\n",
    "            y_pred = self.model.predict_generator(self.data.generator_test,verbose=self.verbose)\n",
    "            \n",
    "            # save predicted clas probabilities\n",
    "            np.save(self.path_model + 'test_predictions', y_pred)\n",
    "            \n",
    "            # take argmax to get predicted class\n",
    "            y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "            # get truth labels from generator\n",
    "            y_test = []\n",
    "            for _, label in self.data.generator_test:\n",
    "                y_test.extend(label)\n",
    "            y_test = np.argmax(np.array(y_test), axis = 1)\n",
    "            \n",
    "        else:\n",
    "            # predict on test data loaded into memory\n",
    "            y_pred = self.model.predict(self.data.x_test, verbose=self.verbose)\n",
    "            \n",
    "            # save predicted clas probabilities\n",
    "            np.save(self.path_model + 'test_predictions', y_pred)\n",
    "            \n",
    "            # take argmax to get predicted class\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "            # get truth labels from memory\n",
    "            y_test = np.argmax(self.data.y_test,axis=1)\n",
    "        \n",
    "        # end time testing\n",
    "        end = datetime.datetime.now()    \n",
    "        results['fit_dt_test_end']  = end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        results['fit_dt_test_duration_seconds']  = str((end - start).total_seconds()).split(\".\")[0]\n",
    "        \n",
    "        ############################\n",
    "        ### Compute confusion matrix\n",
    "        ############################\n",
    "        \n",
    "        # Compute and store confusion matrix\n",
    "        cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        pd.DataFrame(cnf_matrix).to_csv(self.path_model + \"confusion_matrix.csv\")\n",
    "\n",
    "        # get clas names from label map for plot\n",
    "        class_names = list(self.data.label_map.values())\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')\n",
    "        plt.savefig(self.path_model + 'confusion_matrix.png', bbox_inches='tight')\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix')\n",
    "        plt.savefig(self.path_model + 'confusion_matrix_normalized.png', bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "        ##########################\n",
    "        ### Compute raw error rate\n",
    "        ##########################\n",
    "        \n",
    "        # build dataframe and calculate test error (assuming we classify using majority rule, not ROC cutoff approach)\n",
    "        pdf = pd.DataFrame(y_pred, columns = ['pred'])\n",
    "        pdf['prediction'] = pdf['pred'].apply(lambda x: self.data.label_map[str(x)])\n",
    "\n",
    "        truth = pd.DataFrame(y_test, columns = ['truth'])\n",
    "        truth['label'] = truth['truth'].apply(lambda x: self.data.label_map[str(x)])\n",
    "        truth = truth[['label']]\n",
    "\n",
    "        pdf = pd.concat([pdf, truth], axis=1)\n",
    "        pdf['error'] = (pdf['prediction'] != pdf['label']).astype(int)\n",
    "        test_acc = 1 - pdf['error'].mean()\n",
    "        \n",
    "        results['fit_test_acc'] = test_acc\n",
    "        \n",
    "        if self.verbose:\n",
    "            logger.info(str(results))\n",
    "            logger.info(\"model {} test acc: {}\".format(self.model_id, test_acc))\n",
    "        \n",
    "        \n",
    "        ##################\n",
    "        ### Output results\n",
    "        ##################\n",
    "        self.results = results\n",
    "        with open(self.path_model + 'results.json', 'w') as fp:\n",
    "            json.dump(results, fp, indent=4, sort_keys=True)\n",
    "\n",
    "        \n",
    "    def fit(self, learning_rate = 0.001, epochs = 30, patience=5):\n",
    "        \"\"\"\n",
    "        Compile and fit model for *epochs* rounds of training, dividing learning rate by 10 after each round\n",
    "\n",
    "        Fitting will stop if val_acc does not improve for at least patience epochs\n",
    "\n",
    "        Only the best weights will be kept\n",
    "\n",
    "        The model is saved to /models/*model_id*/\n",
    "\n",
    "        Good practice is to decrease the learning rate by a factor of 10 after each plateau and train some more \n",
    "        (after first re-loading best weights from previous training round)...\n",
    "\n",
    "        for example (not exact example because this fit method has been refactored into the architecture object but the principle remains):\n",
    "            fit_history = fit(model_id, model, data, learning_rate = 0.001, epochs = 30)\n",
    "            model.load_weights(path_model + \"model.h5\")\n",
    "            model = fit(model, 5)\n",
    "            fit_history = train(model_id, model, data, learning_rate = 0.0001, epochs = 30)\n",
    "\n",
    "        :learning_rate: learning rate parameter for Adam optimizer (default is 0.001)\n",
    "\n",
    "        :epochs: number of training epochs per fit round (subject to patience)\n",
    "        :batch_size: number of samples in each batch\n",
    "        :patience: how many epochs without val_acc improvement before stopping fit round\n",
    "        :verbose: print progress\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # get number of processors for multiprocessing fit generators\n",
    "        num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "        # create optimizer with given learning rate \n",
    "        opt = Adam(lr = learning_rate)\n",
    "\n",
    "        # compile model\n",
    "        self.model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # setup training callbacks\n",
    "        callback_stopper = EarlyStopping(monitor='val_acc', patience=patience, verbose=0)\n",
    "        callback_csvlogger = CSVLogger(self.path_model + 'training.log')\n",
    "        callback_checkpointer = ModelCheckpoint(self.path_model +  'model.h5', monitor='val_acc', save_best_only=True, verbose=verbose)\n",
    "        callbacks = [callback_stopper, callback_checkpointer, callback_csvlogger]\n",
    "\n",
    "        # fit model\n",
    "        if self.data.return_generator == True:\n",
    "            # train using generator\n",
    "            history = self.model.fit_generator(generator=self.data.generator_train,\n",
    "                validation_data=self.data.generator_valid,\n",
    "                use_multiprocessing=True,\n",
    "                workers=num_workers,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                shuffle=True,\n",
    "                verbose=self.verbose)\n",
    "        else:\n",
    "            # train using full dataset\n",
    "            history = self.model.fit(self.data.x_train, self.data.y_train, \n",
    "                validation_data=(self.data.x_valid, self.data.y_valid),\n",
    "                batch_size=self.batch_size,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                shuffle=True,\n",
    "                verbose=self.verbose)\n",
    "\n",
    "        # get number of epochs actually trained (might have early stopped)\n",
    "        epochs_trained = callback_stopper.stopped_epoch\n",
    "        \n",
    "        if epochs_trained == 0:\n",
    "            # trained but didn't stop early\n",
    "            if len(history.history) > 0:\n",
    "                epochs_trained = epochs\n",
    "        else:\n",
    "            # subtract patience from stop point to get actual peak epoch for this fitting round\n",
    "            epochs_trained -= patience \n",
    "        \n",
    "        # return fit history and the epoch that the early stopper completed on\n",
    "        return history, epochs_trained\n",
    "        \n",
    "        \n",
    "    def make_last_layers_trainable(self, num_layers):\n",
    "        \"\"\"\n",
    "        Set the last *num_layers* non-trainable layers to trainable  \n",
    "\n",
    "        NB to be used with model_base and assumes name = \"top_xxx\" added to each top layer to know \n",
    "        to ignore that layer when looping through layers from top backwards\n",
    "\n",
    "        :num_layers: number of layers from end of model (that are currently not trainable) to be set as trainable\n",
    "        \"\"\"\n",
    "\n",
    "        # get index of last non-trainable layer\n",
    "        # (the layers we added on top of model_base are already trainable=True)\n",
    "        # ...\n",
    "        # need to find last layer of base model and set that (and previous num_layers)\n",
    "        # to trainable=True via this method\n",
    "\n",
    "        # find last non-trainable layer index\n",
    "        idx_not_trainable = 0\n",
    "        for i, l in enumerate(self.model.layers):\n",
    "            if \"top\" not in l.name:\n",
    "                idx_not_trainable = i\n",
    "\n",
    "        # set last non-trainable layer and num_layers prior to trainable=True\n",
    "        for i in reversed(range(idx_not_trainable-num_layers+1, idx_not_trainable+1)):\n",
    "            self.model.layers[i].trainable = True\n",
    "        \n",
    "        if self.verbose:\n",
    "            logging.info(\"last {} layers of CNN set to trainable\".format(num_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create experiments lists and run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* batch 1 = run frozen MLPs and LRCNNs and all concats\n",
    "\n",
    "* batch 2 = run trainable MLP and LRCNN on best performing frozen variants\n",
    "\n",
    "* batch 3 = run trainable but initializing with best CNN weights\n",
    "\n",
    "* batch 4 = run C3D models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T08:20:54.886575Z",
     "start_time": "2019-01-20T08:20:54.882930Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_batch_name = 'experiment_batch_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T01:53:30.306637Z",
     "start_time": "2019-01-20T01:53:30.303473Z"
    }
   },
   "outputs": [],
   "source": [
    "# init list of experiments\n",
    "experiments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T01:53:30.738359Z",
     "start_time": "2019-01-20T01:53:30.734259Z"
    }
   },
   "outputs": [],
   "source": [
    "pooling = 'max'\n",
    "layer_sizes = [512, 256, 128, 0]\n",
    "dropouts = [0.2]\n",
    "sequence_lengths = [1,3,5,10,20]\n",
    "sequence_models = [\"LSTM\", \"SimpleRNN\", \"GRU\", \"Convolution1D\"]\n",
    "sequence_model_layer_counts = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T01:53:31.833613Z",
     "start_time": "2019-01-20T01:53:31.827491Z"
    }
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### image_MLP_frozen \n",
    "####################\n",
    "\n",
    "for pretrained_model_name in pretrained_model_names:\n",
    "    for layer_1_size in layer_sizes:\n",
    "        for layer_2_size in layer_sizes:\n",
    "            for layer_3_size in layer_sizes:\n",
    "                for dropout in dropouts:\n",
    "\n",
    "                    # build experiment parameters\n",
    "                    experiment = {}\n",
    "                    \n",
    "                    experiment['architecture'] = 'image_MLP_frozen'\n",
    "                    experiment['sequence_length'] = 1\n",
    "                    experiment['pretrained_model_name'] = pretrained_model_name\n",
    "                    experiment['layer_1_size'] = layer_1_size\n",
    "                    experiment['layer_2_size'] = layer_2_size\n",
    "                    experiment['layer_3_size'] = layer_3_size\n",
    "                    experiment['dropout'] = dropout\n",
    "                    experiment['pooling'] = 'max' # outperforms avg across all parameters\n",
    "                    \n",
    "                    # add to list of experiments\n",
    "                    experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T01:53:32.453442Z",
     "start_time": "2019-01-20T01:53:32.446036Z"
    }
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### video_MLP_concat\n",
    "####################\n",
    "\n",
    "for sequence_length in sequence_lengths:\n",
    "    for pretrained_model_name in pretrained_model_names:\n",
    "        for layer_1_size in layer_sizes:\n",
    "            for layer_2_size in layer_sizes:\n",
    "                for layer_3_size in layer_sizes:\n",
    "                    for dropout in dropouts:\n",
    "\n",
    "                        # build experiment parameters\n",
    "                        experiment = {}\n",
    "\n",
    "                        experiment['architecture'] = 'video_MLP_concat'\n",
    "                        experiment['pretrained_model_name'] = pretrained_model_name\n",
    "                        experiment['layer_1_size'] = layer_1_size\n",
    "                        experiment['layer_2_size'] = layer_2_size\n",
    "                        experiment['layer_3_size'] = layer_3_size\n",
    "                        experiment['dropout'] = dropout\n",
    "                        experiment['pooling'] = 'max' # outperforms avg across all parameters\n",
    "\n",
    "                        # add to list of experiments\n",
    "                        experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T01:53:32.943940Z",
     "start_time": "2019-01-20T01:53:32.914420Z"
    }
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### video_LRCNN_frozen\n",
    "######################\n",
    "\n",
    "for sequence_length in sequence_lengths:\n",
    "    for pretrained_model_name in pretrained_model_names:\n",
    "        for layer_1_size in layer_sizes:\n",
    "            for layer_2_size in layer_sizes:\n",
    "                for layer_3_size in layer_sizes:\n",
    "                    for dropout in dropouts:\n",
    "                        for sequence_model in sequence_models:\n",
    "                            for sequence_model_layers in sequence_model_layer_counts:\n",
    "\n",
    "                                # build experiment parameters\n",
    "                                experiment = {}\n",
    "\n",
    "                                experiment['architecture'] = 'video_LRCNN_frozen'\n",
    "                                experiment['pretrained_model_name'] = pretrained_model_name\n",
    "                                experiment['layer_1_size'] = layer_1_size\n",
    "                                experiment['layer_2_size'] = layer_2_size\n",
    "                                experiment['layer_3_size'] = layer_3_size\n",
    "                                experiment['dropout'] = dropout\n",
    "                                experiment['pooling'] = 'max' # outperforms avg across all parameters\n",
    "                                experiment['sequence_model'] = sequence_model\n",
    "                                experiment['sequence_model_layers'] = sequence_model_layers\n",
    "\n",
    "                                # add to list of experiments\n",
    "                                experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T01:53:34.403935Z",
     "start_time": "2019-01-20T01:53:34.336552Z"
    }
   },
   "outputs": [],
   "source": [
    "########################\n",
    "### convert to dataframe\n",
    "########################\n",
    "\n",
    "experiments = pd.DataFrame(experiments)\n",
    "experiments['model_id'] = experiments.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T01:53:38.895151Z",
     "start_time": "2019-01-20T01:53:38.649758Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments.to_csv(pwd + \"experiments/\" + experiment_batch_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-20T01:54:17.546Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 01:54:17,780 [MainThread  ] [INFO ]  Begin experiment for model_id=0\n",
      "2019-01-20 01:54:17,781 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 0, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 01:54:18,737 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 01:54:18,738 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1948 - acc: 0.9241 - val_loss: 0.1766 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92044, saving model to /mnt/seals/models/0/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1574 - acc: 0.9363 - val_loss: 0.2080 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92044\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1517 - acc: 0.9388 - val_loss: 0.2166 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92044\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1492 - acc: 0.9402 - val_loss: 0.2014 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92044\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1444 - acc: 0.9425 - val_loss: 0.1981 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92044\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 239us/step - loss: 0.1435 - acc: 0.9428 - val_loss: 0.1812 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92044 to 0.92381, saving model to /mnt/seals/models/0/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1409 - acc: 0.9438 - val_loss: 0.1923 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92381\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1389 - acc: 0.9451 - val_loss: 0.1934 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92381\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1371 - acc: 0.9456 - val_loss: 0.2098 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92381\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1361 - acc: 0.9458 - val_loss: 0.1782 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92381 to 0.92708, saving model to /mnt/seals/models/0/model.h5\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1347 - acc: 0.9468 - val_loss: 0.2086 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92708\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1344 - acc: 0.9465 - val_loss: 0.1856 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92708\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1319 - acc: 0.9478 - val_loss: 0.1868 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92708\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1356 - acc: 0.9456 - val_loss: 0.2265 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92708\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1357 - acc: 0.9448 - val_loss: 0.2046 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92708\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1207 - acc: 0.9521 - val_loss: 0.1798 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92171, saving model to /mnt/seals/models/0/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1183 - acc: 0.9526 - val_loss: 0.1871 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92171\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1166 - acc: 0.9528 - val_loss: 0.1707 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92171 to 0.92750, saving model to /mnt/seals/models/0/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1160 - acc: 0.9533 - val_loss: 0.1792 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92750\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1152 - acc: 0.9536 - val_loss: 0.1803 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92750\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1146 - acc: 0.9539 - val_loss: 0.1762 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92750\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1140 - acc: 0.9541 - val_loss: 0.1793 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92750\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1136 - acc: 0.9543 - val_loss: 0.1813 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92750\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1151 - acc: 0.9535 - val_loss: 0.1756 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92456, saving model to /mnt/seals/models/0/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1143 - acc: 0.9542 - val_loss: 0.1750 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92456\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1147 - acc: 0.9540 - val_loss: 0.1749 - val_acc: 0.9255\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92456 to 0.92548, saving model to /mnt/seals/models/0/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1144 - acc: 0.9541 - val_loss: 0.1753 - val_acc: 0.9248\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92548\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1144 - acc: 0.9536 - val_loss: 0.1748 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92548\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1140 - acc: 0.9541 - val_loss: 0.1769 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92548\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1143 - acc: 0.9540 - val_loss: 0.1728 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.92548 to 0.92648, saving model to /mnt/seals/models/0/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1140 - acc: 0.9540 - val_loss: 0.1760 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92648\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1142 - acc: 0.9541 - val_loss: 0.1734 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92648\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1137 - acc: 0.9542 - val_loss: 0.1753 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92648\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1134 - acc: 0.9542 - val_loss: 0.1753 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92648\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1131 - acc: 0.9543 - val_loss: 0.1774 - val_acc: 0.9230\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92648\n",
      "3139/3139 [==============================] - 0s 132us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:02:55,993 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 01:54:19', 'fit_val_loss': 0.1769447398378962, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 9, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 2, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '513', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 02:02:54', 'fit_train_loss': 0.11396418052761166, 'dropout': 0.2, 'fit_stopped_epoch3': 6, 'path_model': '/mnt/seals/models/0/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 02:02:54', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 20, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 02:02:53', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 1315847, 'fit_test_acc': 0.5530423701815865, 'layer_2_size': 512, 'fit_train_acc': 0.9541349446401522, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9235171222330032, 'pooling': 'max', 'model_id': 0, 'fit_dt_test_duration_seconds': '0'}\n",
      "2019-01-20 02:02:55,994 [MainThread  ] [INFO ]  model 0 test acc: 0.5530423701815865\n",
      "2019-01-20 02:02:55,996 [MainThread  ] [INFO ]  Begin experiment for model_id=1\n",
      "2019-01-20 02:02:55,998 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 1, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:02:56,931 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 02:02:56,932 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1899 - acc: 0.9245 - val_loss: 0.1997 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90729, saving model to /mnt/seals/models/1/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1651 - acc: 0.9342 - val_loss: 0.2142 - val_acc: 0.8985\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90729\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1603 - acc: 0.9357 - val_loss: 0.1941 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90729 to 0.91751, saving model to /mnt/seals/models/1/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1494 - acc: 0.9409 - val_loss: 0.2097 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91751\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1446 - acc: 0.9431 - val_loss: 0.2569 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91751\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1422 - acc: 0.9442 - val_loss: 0.1790 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91751 to 0.92145, saving model to /mnt/seals/models/1/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1394 - acc: 0.9452 - val_loss: 0.1907 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92145\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1381 - acc: 0.9460 - val_loss: 0.2006 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92145\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1372 - acc: 0.9466 - val_loss: 0.2055 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92145\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1345 - acc: 0.9478 - val_loss: 0.1924 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92145\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1338 - acc: 0.9480 - val_loss: 0.1771 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92145 to 0.92786, saving model to /mnt/seals/models/1/model.h5\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1333 - acc: 0.9483 - val_loss: 0.1865 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92786\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1318 - acc: 0.9490 - val_loss: 0.2073 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92786\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1337 - acc: 0.9477 - val_loss: 0.2880 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92786\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1328 - acc: 0.9479 - val_loss: 0.2079 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92786\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1339 - acc: 0.9475 - val_loss: 0.1924 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92786\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1189 - acc: 0.9535 - val_loss: 0.1847 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91470, saving model to /mnt/seals/models/1/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1159 - acc: 0.9545 - val_loss: 0.1921 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91470\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1149 - acc: 0.9548 - val_loss: 0.1787 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91470 to 0.92087, saving model to /mnt/seals/models/1/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1139 - acc: 0.9553 - val_loss: 0.1905 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92087\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1126 - acc: 0.9557 - val_loss: 0.1836 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92087\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1127 - acc: 0.9555 - val_loss: 0.1830 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92087\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1117 - acc: 0.9562 - val_loss: 0.2006 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92087\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1116 - acc: 0.9562 - val_loss: 0.1905 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92087\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1127 - acc: 0.9554 - val_loss: 0.1862 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91497, saving model to /mnt/seals/models/1/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1127 - acc: 0.9557 - val_loss: 0.1843 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91497 to 0.91648, saving model to /mnt/seals/models/1/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1131 - acc: 0.9556 - val_loss: 0.1849 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91648\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1129 - acc: 0.9556 - val_loss: 0.1851 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91648 to 0.91650, saving model to /mnt/seals/models/1/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1126 - acc: 0.9556 - val_loss: 0.1871 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91650\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1119 - acc: 0.9560 - val_loss: 0.1876 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91650\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1119 - acc: 0.9561 - val_loss: 0.1895 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91650\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1118 - acc: 0.9564 - val_loss: 0.1884 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91650\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1115 - acc: 0.9562 - val_loss: 0.1892 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91650\n",
      "3139/3139 [==============================] - 0s 155us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:10:58,128 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 02:02:57', 'fit_val_loss': 0.18491422959099388, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 10, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 2, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '477', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 02:10:56', 'fit_train_loss': 0.11308398356372784, 'dropout': 0.2, 'fit_stopped_epoch3': 3, 'path_model': '/mnt/seals/models/1/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 02:10:56', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 18, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 02:10:55', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 1182727, 'fit_test_acc': 0.5441223319528512, 'layer_2_size': 512, 'fit_train_acc': 0.955575373875382, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9159912920354905, 'pooling': 'max', 'model_id': 1, 'fit_dt_test_duration_seconds': '0'}\n",
      "2019-01-20 02:10:58,130 [MainThread  ] [INFO ]  model 1 test acc: 0.5441223319528512\n",
      "2019-01-20 02:10:58,132 [MainThread  ] [INFO ]  Begin experiment for model_id=2\n",
      "2019-01-20 02:10:58,133 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 2, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:10:59,074 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 02:10:59,075 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 256us/step - loss: 0.1972 - acc: 0.9235 - val_loss: 0.2449 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89626, saving model to /mnt/seals/models/2/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1610 - acc: 0.9355 - val_loss: 0.1958 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89626 to 0.90098, saving model to /mnt/seals/models/2/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1516 - acc: 0.9391 - val_loss: 0.1912 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90098 to 0.90953, saving model to /mnt/seals/models/2/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1490 - acc: 0.9400 - val_loss: 0.1843 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90953 to 0.91933, saving model to /mnt/seals/models/2/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1458 - acc: 0.9415 - val_loss: 0.1905 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91933\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1413 - acc: 0.9435 - val_loss: 0.2170 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91933\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1394 - acc: 0.9440 - val_loss: 0.2121 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91933\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1375 - acc: 0.9456 - val_loss: 0.2334 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91933\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1343 - acc: 0.9467 - val_loss: 0.2088 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91933\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 256us/step - loss: 0.1343 - acc: 0.9455 - val_loss: 0.1857 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91730, saving model to /mnt/seals/models/2/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1296 - acc: 0.9471 - val_loss: 0.1936 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91730\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1278 - acc: 0.9482 - val_loss: 0.1934 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91730\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1257 - acc: 0.9487 - val_loss: 0.1981 - val_acc: 0.9090\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91730\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1243 - acc: 0.9496 - val_loss: 0.1911 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91730\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1231 - acc: 0.9499 - val_loss: 0.2070 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91730\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 256us/step - loss: 0.1288 - acc: 0.9473 - val_loss: 0.1897 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91405, saving model to /mnt/seals/models/2/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1286 - acc: 0.9474 - val_loss: 0.1922 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91405\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1280 - acc: 0.9480 - val_loss: 0.1904 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91405\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1281 - acc: 0.9477 - val_loss: 0.1890 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91405 to 0.91443, saving model to /mnt/seals/models/2/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1273 - acc: 0.9478 - val_loss: 0.1886 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91443 to 0.91526, saving model to /mnt/seals/models/2/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1275 - acc: 0.9478 - val_loss: 0.1875 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91526 to 0.91599, saving model to /mnt/seals/models/2/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1271 - acc: 0.9481 - val_loss: 0.1921 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91599\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1267 - acc: 0.9481 - val_loss: 0.1901 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91599\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1268 - acc: 0.9484 - val_loss: 0.1937 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91599\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1263 - acc: 0.9481 - val_loss: 0.1937 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91599\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1266 - acc: 0.9481 - val_loss: 0.1927 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91599\n",
      "3139/3139 [==============================] - 1s 169us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:17:23,087 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 02:10:59', 'fit_val_loss': 0.18862147443461003, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 3, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 0, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '380', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 02:17:21', 'fit_train_loss': 0.12727368095230382, 'dropout': 0.2, 'fit_stopped_epoch3': 5, 'path_model': '/mnt/seals/models/2/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 02:17:21', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 11, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 02:17:20', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 1116167, 'fit_test_acc': 0.5517680790060528, 'layer_2_size': 512, 'fit_train_acc': 0.9478286456990553, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9152565216483023, 'pooling': 'max', 'model_id': 2, 'fit_dt_test_duration_seconds': '0'}\n",
      "2019-01-20 02:17:23,088 [MainThread  ] [INFO ]  model 2 test acc: 0.5517680790060528\n",
      "2019-01-20 02:17:23,090 [MainThread  ] [INFO ]  Begin experiment for model_id=3\n",
      "2019-01-20 02:17:23,092 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 3, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:17:24,032 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 02:17:24,033 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.2024 - acc: 0.9231 - val_loss: 0.1947 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90639, saving model to /mnt/seals/models/3/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1680 - acc: 0.9327 - val_loss: 0.2128 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90639\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1550 - acc: 0.9384 - val_loss: 0.1772 - val_acc: 0.9313\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90639 to 0.93131, saving model to /mnt/seals/models/3/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1511 - acc: 0.9400 - val_loss: 0.1910 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93131\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1468 - acc: 0.9413 - val_loss: 0.1902 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93131\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1445 - acc: 0.9420 - val_loss: 0.2113 - val_acc: 0.9026\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93131\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1399 - acc: 0.9436 - val_loss: 0.1885 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93131\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1420 - acc: 0.9422 - val_loss: 0.1722 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93131\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1354 - acc: 0.9454 - val_loss: 0.1824 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91797, saving model to /mnt/seals/models/3/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1310 - acc: 0.9471 - val_loss: 0.1759 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91797 to 0.92637, saving model to /mnt/seals/models/3/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1284 - acc: 0.9484 - val_loss: 0.1816 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92637\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1257 - acc: 0.9493 - val_loss: 0.1812 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92637\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1239 - acc: 0.9499 - val_loss: 0.1846 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92637\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1223 - acc: 0.9506 - val_loss: 0.1809 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92637\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1206 - acc: 0.9511 - val_loss: 0.1791 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92637\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1275 - acc: 0.9484 - val_loss: 0.1842 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91739, saving model to /mnt/seals/models/3/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 218us/step - loss: 0.1270 - acc: 0.9487 - val_loss: 0.1831 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91739 to 0.91791, saving model to /mnt/seals/models/3/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1266 - acc: 0.9488 - val_loss: 0.1812 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91791 to 0.91824, saving model to /mnt/seals/models/3/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1263 - acc: 0.9491 - val_loss: 0.1806 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91824 to 0.91880, saving model to /mnt/seals/models/3/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1261 - acc: 0.9489 - val_loss: 0.1791 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91880 to 0.92116, saving model to /mnt/seals/models/3/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1254 - acc: 0.9496 - val_loss: 0.1821 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92116\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1248 - acc: 0.9496 - val_loss: 0.1806 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92116\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1248 - acc: 0.9493 - val_loss: 0.1797 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92116\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1242 - acc: 0.9497 - val_loss: 0.1807 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92116\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1251 - acc: 0.9496 - val_loss: 0.1804 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92116\n",
      "3139/3139 [==============================] - 1s 184us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:23:00,928 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 02:17:24', 'fit_val_loss': 0.1805889705693038, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 2, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 1, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '333', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 02:22:59', 'fit_train_loss': 0.12628185420794139, 'dropout': 0.2, 'fit_stopped_epoch3': 4, 'path_model': '/mnt/seals/models/3/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 02:22:58', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 10, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 02:22:57', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 1053191, 'fit_test_acc': 0.547945205479452, 'layer_2_size': 512, 'fit_train_acc': 0.9491488436902122, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9187967754956196, 'pooling': 'max', 'model_id': 3, 'fit_dt_test_duration_seconds': '0'}\n",
      "2019-01-20 02:23:00,930 [MainThread  ] [INFO ]  model 3 test acc: 0.547945205479452\n",
      "2019-01-20 02:23:00,933 [MainThread  ] [INFO ]  Begin experiment for model_id=4\n",
      "2019-01-20 02:23:00,934 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 4, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:23:01,870 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 02:23:01,871 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1879 - acc: 0.9252 - val_loss: 0.2304 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89664, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1592 - acc: 0.9355 - val_loss: 0.2090 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89664 to 0.90521, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1532 - acc: 0.9388 - val_loss: 0.1955 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90521 to 0.91176, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1463 - acc: 0.9421 - val_loss: 0.1966 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91176 to 0.91684, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1434 - acc: 0.9431 - val_loss: 0.2224 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91684\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1501 - acc: 0.9412 - val_loss: 0.1824 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91684 to 0.91978, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1463 - acc: 0.9432 - val_loss: 0.2202 - val_acc: 0.8937\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91978\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1434 - acc: 0.9446 - val_loss: 0.1959 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91978\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1424 - acc: 0.9447 - val_loss: 0.1823 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91978\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1397 - acc: 0.9457 - val_loss: 0.2100 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91978\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1380 - acc: 0.9464 - val_loss: 0.1888 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91978\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1340 - acc: 0.9481 - val_loss: 0.1816 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92018, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1306 - acc: 0.9494 - val_loss: 0.1817 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92018\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1286 - acc: 0.9503 - val_loss: 0.1813 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92018\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1275 - acc: 0.9507 - val_loss: 0.1735 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92018 to 0.92347, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1260 - acc: 0.9507 - val_loss: 0.1790 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92347\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1259 - acc: 0.9510 - val_loss: 0.1871 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92347\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1239 - acc: 0.9517 - val_loss: 0.1801 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92347\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1237 - acc: 0.9518 - val_loss: 0.1805 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92347\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1218 - acc: 0.9527 - val_loss: 0.1805 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92347\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1248 - acc: 0.9516 - val_loss: 0.1843 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91566, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1246 - acc: 0.9519 - val_loss: 0.1821 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91566 to 0.91704, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1247 - acc: 0.9515 - val_loss: 0.1823 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91704\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1247 - acc: 0.9517 - val_loss: 0.1827 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91704 to 0.91722, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1241 - acc: 0.9519 - val_loss: 0.1818 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91722 to 0.91857, saving model to /mnt/seals/models/4/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1244 - acc: 0.9515 - val_loss: 0.1839 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91857\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1238 - acc: 0.9518 - val_loss: 0.1824 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91857\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1239 - acc: 0.9519 - val_loss: 0.1834 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91857\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 239us/step - loss: 0.1238 - acc: 0.9520 - val_loss: 0.1814 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91857\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1238 - acc: 0.9518 - val_loss: 0.1819 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91857\n",
      "3139/3139 [==============================] - 1s 210us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:30:22,752 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 02:23:02', 'fit_val_loss': 0.18265184336469656, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 5, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 3, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '436', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 02:30:21', 'fit_train_loss': 0.12470627705766645, 'dropout': 0.2, 'fit_stopped_epoch3': 4, 'path_model': '/mnt/seals/models/4/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 02:30:20', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 15, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 02:30:19', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 1053447, 'fit_test_acc': 0.5504937878305193, 'layer_2_size': 256, 'fit_train_acc': 0.9517067249309883, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.917215908257444, 'pooling': 'max', 'model_id': 4, 'fit_dt_test_duration_seconds': '0'}\n",
      "2019-01-20 02:30:22,754 [MainThread  ] [INFO ]  model 4 test acc: 0.5504937878305193\n",
      "2019-01-20 02:30:22,756 [MainThread  ] [INFO ]  Begin experiment for model_id=5\n",
      "2019-01-20 02:30:22,757 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 5, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:30:23,697 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 02:30:23,698 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1958 - acc: 0.9232 - val_loss: 0.2424 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89455, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1602 - acc: 0.9355 - val_loss: 0.2059 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89455 to 0.90813, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1513 - acc: 0.9392 - val_loss: 0.1945 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90813 to 0.91127, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1479 - acc: 0.9414 - val_loss: 0.1997 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91127\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1425 - acc: 0.9438 - val_loss: 0.2398 - val_acc: 0.8912\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91127\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1401 - acc: 0.9447 - val_loss: 0.1831 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91127 to 0.91884, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1375 - acc: 0.9457 - val_loss: 0.1959 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91884\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1356 - acc: 0.9467 - val_loss: 0.1956 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91884\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1347 - acc: 0.9468 - val_loss: 0.1953 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91884 to 0.92439, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1357 - acc: 0.9461 - val_loss: 0.2080 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92439\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1404 - acc: 0.9449 - val_loss: 0.1876 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92439\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1387 - acc: 0.9454 - val_loss: 0.2139 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92439\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1362 - acc: 0.9465 - val_loss: 0.2446 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92439\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1366 - acc: 0.9460 - val_loss: 0.2134 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92439\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1192 - acc: 0.9525 - val_loss: 0.2005 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91196, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1165 - acc: 0.9537 - val_loss: 0.1966 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91196 to 0.91232, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1159 - acc: 0.9536 - val_loss: 0.1882 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91232 to 0.91675, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1141 - acc: 0.9543 - val_loss: 0.1954 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91675\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1133 - acc: 0.9546 - val_loss: 0.1892 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91675\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1128 - acc: 0.9548 - val_loss: 0.1907 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91675 to 0.91831, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1122 - acc: 0.9550 - val_loss: 0.1912 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91831\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1110 - acc: 0.9553 - val_loss: 0.1864 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91831 to 0.91940, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1109 - acc: 0.9554 - val_loss: 0.1950 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91940\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1109 - acc: 0.9555 - val_loss: 0.1880 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91940\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1101 - acc: 0.9558 - val_loss: 0.1910 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91940\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1096 - acc: 0.9560 - val_loss: 0.1953 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.91940\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1090 - acc: 0.9561 - val_loss: 0.1933 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.91940\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1099 - acc: 0.9559 - val_loss: 0.1924 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91612, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1102 - acc: 0.9556 - val_loss: 0.1933 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91612 to 0.91628, saving model to /mnt/seals/models/5/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1095 - acc: 0.9560 - val_loss: 0.1959 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91628\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1096 - acc: 0.9558 - val_loss: 0.1949 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91628\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1093 - acc: 0.9559 - val_loss: 0.1953 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91628\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1086 - acc: 0.9562 - val_loss: 0.1968 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91628\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1097 - acc: 0.9558 - val_loss: 0.1921 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91628\n",
      "3139/3139 [==============================] - 1s 230us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:38:43,933 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 02:30:24', 'fit_val_loss': 0.19241663557186983, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 8, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 7, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '495', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 02:38:42', 'fit_train_loss': 0.10992905340958073, 'dropout': 0.2, 'fit_stopped_epoch3': 1, 'path_model': '/mnt/seals/models/5/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 02:38:41', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 19, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 02:38:40', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 985863, 'fit_test_acc': 0.570882446639057, 'layer_2_size': 256, 'fit_train_acc': 0.9559172101161826, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9161248855162737, 'pooling': 'max', 'model_id': 5, 'fit_dt_test_duration_seconds': '0'}\n",
      "2019-01-20 02:38:43,934 [MainThread  ] [INFO ]  model 5 test acc: 0.570882446639057\n",
      "2019-01-20 02:38:43,937 [MainThread  ] [INFO ]  Begin experiment for model_id=6\n",
      "2019-01-20 02:38:43,938 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 6, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:38:44,892 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 02:38:44,893 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1926 - acc: 0.9236 - val_loss: 0.2669 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88604, saving model to /mnt/seals/models/6/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1584 - acc: 0.9368 - val_loss: 0.1845 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88604 to 0.91577, saving model to /mnt/seals/models/6/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 239us/step - loss: 0.1497 - acc: 0.9406 - val_loss: 0.2021 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91577\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1456 - acc: 0.9420 - val_loss: 0.2115 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91577\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1413 - acc: 0.9437 - val_loss: 0.2126 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91577\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1379 - acc: 0.9446 - val_loss: 0.2369 - val_acc: 0.9063\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91577\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1374 - acc: 0.9451 - val_loss: 0.2008 - val_acc: 0.9059\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91577\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1353 - acc: 0.9454 - val_loss: 0.1867 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91624, saving model to /mnt/seals/models/6/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1304 - acc: 0.9475 - val_loss: 0.1846 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91624 to 0.91724, saving model to /mnt/seals/models/6/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1279 - acc: 0.9483 - val_loss: 0.1974 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91724\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1252 - acc: 0.9496 - val_loss: 0.1920 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91724\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1236 - acc: 0.9501 - val_loss: 0.1857 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91724\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1220 - acc: 0.9509 - val_loss: 0.1762 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91724 to 0.91802, saving model to /mnt/seals/models/6/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1202 - acc: 0.9518 - val_loss: 0.1849 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91802\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1191 - acc: 0.9517 - val_loss: 0.1785 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91802 to 0.92156, saving model to /mnt/seals/models/6/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1175 - acc: 0.9528 - val_loss: 0.1911 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92156\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1165 - acc: 0.9531 - val_loss: 0.1885 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92156\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1145 - acc: 0.9541 - val_loss: 0.1916 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92156\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1139 - acc: 0.9541 - val_loss: 0.1902 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92156\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1125 - acc: 0.9545 - val_loss: 0.1892 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92156\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 273us/step - loss: 0.1154 - acc: 0.9537 - val_loss: 0.1865 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91559, saving model to /mnt/seals/models/6/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1152 - acc: 0.9539 - val_loss: 0.1850 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91559 to 0.91615, saving model to /mnt/seals/models/6/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1152 - acc: 0.9536 - val_loss: 0.1865 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91615\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1146 - acc: 0.9541 - val_loss: 0.1864 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91615\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1143 - acc: 0.9544 - val_loss: 0.1850 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91615\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1149 - acc: 0.9538 - val_loss: 0.1864 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91615\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1141 - acc: 0.9539 - val_loss: 0.1860 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91615\n",
      "3139/3139 [==============================] - 1s 269us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:45:30,087 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 02:38:45', 'fit_val_loss': 0.18648501253336147, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 1, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 7, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '400', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 02:45:28', 'fit_train_loss': 0.11540492048747512, 'dropout': 0.2, 'fit_stopped_epoch3': 1, 'path_model': '/mnt/seals/models/6/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 02:45:27', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 12, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 02:45:26', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 952071, 'fit_test_acc': 0.5562280981204205, 'layer_2_size': 256, 'fit_train_acc': 0.9537035229428502, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9155905068366604, 'pooling': 'max', 'model_id': 6, 'fit_dt_test_duration_seconds': '0'}\n",
      "2019-01-20 02:45:30,089 [MainThread  ] [INFO ]  model 6 test acc: 0.5562280981204205\n",
      "2019-01-20 02:45:30,091 [MainThread  ] [INFO ]  Begin experiment for model_id=7\n",
      "2019-01-20 02:45:30,092 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 7, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:45:31,044 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 02:45:31,045 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.2107 - acc: 0.9245 - val_loss: 0.1989 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91152, saving model to /mnt/seals/models/7/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 219us/step - loss: 0.1568 - acc: 0.9368 - val_loss: 0.2171 - val_acc: 0.8985\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91152\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1479 - acc: 0.9403 - val_loss: 0.2109 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91152\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1453 - acc: 0.9416 - val_loss: 0.2137 - val_acc: 0.9002\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91152\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1407 - acc: 0.9436 - val_loss: 0.1797 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91152 to 0.92663, saving model to /mnt/seals/models/7/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1366 - acc: 0.9454 - val_loss: 0.1872 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92663\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1357 - acc: 0.9458 - val_loss: 0.1981 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92663\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1330 - acc: 0.9473 - val_loss: 0.1946 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92663\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1314 - acc: 0.9477 - val_loss: 0.1827 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92663\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1291 - acc: 0.9487 - val_loss: 0.1980 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92663\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1254 - acc: 0.9497 - val_loss: 0.1967 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91430, saving model to /mnt/seals/models/7/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1219 - acc: 0.9514 - val_loss: 0.1932 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91430 to 0.91557, saving model to /mnt/seals/models/7/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1203 - acc: 0.9520 - val_loss: 0.1994 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91557\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1198 - acc: 0.9519 - val_loss: 0.1916 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91557 to 0.91630, saving model to /mnt/seals/models/7/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 219us/step - loss: 0.1188 - acc: 0.9524 - val_loss: 0.1884 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91630 to 0.91766, saving model to /mnt/seals/models/7/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1177 - acc: 0.9529 - val_loss: 0.2024 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91766\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1171 - acc: 0.9530 - val_loss: 0.1943 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91766\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1156 - acc: 0.9538 - val_loss: 0.1999 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91766\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1151 - acc: 0.9537 - val_loss: 0.1939 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91766\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 219us/step - loss: 0.1138 - acc: 0.9545 - val_loss: 0.2022 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91766\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1163 - acc: 0.9535 - val_loss: 0.1915 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91499, saving model to /mnt/seals/models/7/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1163 - acc: 0.9534 - val_loss: 0.1937 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91499\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1158 - acc: 0.9534 - val_loss: 0.1925 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91499\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1158 - acc: 0.9536 - val_loss: 0.1910 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91499\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1152 - acc: 0.9536 - val_loss: 0.1917 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91499\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1152 - acc: 0.9538 - val_loss: 0.1912 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91499 to 0.91555, saving model to /mnt/seals/models/7/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1148 - acc: 0.9540 - val_loss: 0.1924 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91555\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1145 - acc: 0.9540 - val_loss: 0.1927 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91555\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1146 - acc: 0.9541 - val_loss: 0.1955 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91555\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1145 - acc: 0.9543 - val_loss: 0.1940 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91555\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1142 - acc: 0.9544 - val_loss: 0.1927 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91555\n",
      "3139/3139 [==============================] - 1s 280us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:52:33,225 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 02:45:31', 'fit_val_loss': 0.1916699182437245, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 4, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 4, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '417', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 02:52:31', 'fit_train_loss': 0.11524396230978255, 'dropout': 0.2, 'fit_stopped_epoch3': 5, 'path_model': '/mnt/seals/models/7/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 02:52:30', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 16, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 02:52:29', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 920071, 'fit_test_acc': 0.5587766804714878, 'layer_2_size': 256, 'fit_train_acc': 0.9536469432842078, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.914922533041224, 'pooling': 'max', 'model_id': 7, 'fit_dt_test_duration_seconds': '0'}\n",
      "2019-01-20 02:52:33,226 [MainThread  ] [INFO ]  model 7 test acc: 0.5587766804714878\n",
      "2019-01-20 02:52:33,229 [MainThread  ] [INFO ]  Begin experiment for model_id=8\n",
      "2019-01-20 02:52:33,231 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 8, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 02:52:34,188 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 02:52:34,189 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 279us/step - loss: 0.1906 - acc: 0.9238 - val_loss: 0.1891 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92779, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1577 - acc: 0.9363 - val_loss: 0.1955 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92779\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1475 - acc: 0.9405 - val_loss: 0.2076 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92779\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1434 - acc: 0.9424 - val_loss: 0.2098 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92779\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1413 - acc: 0.9432 - val_loss: 0.1733 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92779\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1389 - acc: 0.9446 - val_loss: 0.1786 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92779\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 276us/step - loss: 0.1418 - acc: 0.9424 - val_loss: 0.2085 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90183, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1348 - acc: 0.9453 - val_loss: 0.2056 - val_acc: 0.8996\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90183\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1308 - acc: 0.9469 - val_loss: 0.1913 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90183 to 0.91550, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1271 - acc: 0.9487 - val_loss: 0.1877 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91550\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1241 - acc: 0.9496 - val_loss: 0.1860 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91550\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1213 - acc: 0.9507 - val_loss: 0.1960 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91550\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1196 - acc: 0.9520 - val_loss: 0.1852 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91550 to 0.91742, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1166 - acc: 0.9528 - val_loss: 0.2115 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91742\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1154 - acc: 0.9533 - val_loss: 0.1803 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91742 to 0.91786, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1131 - acc: 0.9543 - val_loss: 0.2001 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91786\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1115 - acc: 0.9548 - val_loss: 0.1954 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91786\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1099 - acc: 0.9555 - val_loss: 0.1866 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.91786 to 0.91906, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1092 - acc: 0.9559 - val_loss: 0.1838 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.91906 to 0.92029, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1070 - acc: 0.9569 - val_loss: 0.2007 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92029\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1064 - acc: 0.9569 - val_loss: 0.1976 - val_acc: 0.9110\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92029\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1050 - acc: 0.9573 - val_loss: 0.1808 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.92029 to 0.92082, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1038 - acc: 0.9584 - val_loss: 0.2018 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92082\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1025 - acc: 0.9585 - val_loss: 0.1878 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.92082 to 0.92109, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 19/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1018 - acc: 0.9588 - val_loss: 0.1835 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92109\n",
      "Epoch 20/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1007 - acc: 0.9592 - val_loss: 0.1979 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92109\n",
      "Epoch 21/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.0995 - acc: 0.9597 - val_loss: 0.1936 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92109\n",
      "Epoch 22/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.0987 - acc: 0.9600 - val_loss: 0.2046 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.92109\n",
      "Epoch 23/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.0976 - acc: 0.9604 - val_loss: 0.2020 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.92109\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 276us/step - loss: 0.0973 - acc: 0.9607 - val_loss: 0.1946 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91695, saving model to /mnt/seals/models/8/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.0970 - acc: 0.9605 - val_loss: 0.1994 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91695\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.0969 - acc: 0.9607 - val_loss: 0.1966 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91695\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.0962 - acc: 0.9611 - val_loss: 0.1950 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91695\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.0960 - acc: 0.9610 - val_loss: 0.1929 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91695\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.0958 - acc: 0.9613 - val_loss: 0.1973 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91695\n",
      "3139/3139 [==============================] - 1s 303us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:01:25,573 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 02:52:34', 'fit_val_loss': 0.20183700036972835, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 0, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 17, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '527', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 03:01:24', 'fit_train_loss': 0.10377433994402536, 'dropout': 0.2, 'fit_stopped_epoch3': 0, 'path_model': '/mnt/seals/models/8/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 03:01:23', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 20, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 03:01:22', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 922247, 'fit_test_acc': 0.5425294679834343, 'layer_2_size': 128, 'fit_train_acc': 0.958411439154796, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9119166520765595, 'pooling': 'max', 'model_id': 8, 'fit_dt_test_duration_seconds': '0'}\n",
      "2019-01-20 03:01:25,575 [MainThread  ] [INFO ]  model 8 test acc: 0.5425294679834343\n",
      "2019-01-20 03:01:25,577 [MainThread  ] [INFO ]  Begin experiment for model_id=9\n",
      "2019-01-20 03:01:25,578 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 9, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:01:26,523 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 03:01:26,524 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 281us/step - loss: 0.1928 - acc: 0.9233 - val_loss: 0.1722 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92621, saving model to /mnt/seals/models/9/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1567 - acc: 0.9374 - val_loss: 0.2102 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92621\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1507 - acc: 0.9398 - val_loss: 0.2078 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92621\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1432 - acc: 0.9430 - val_loss: 0.1853 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92621\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1400 - acc: 0.9443 - val_loss: 0.1987 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92621\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1372 - acc: 0.9454 - val_loss: 0.2121 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92621\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 284us/step - loss: 0.1459 - acc: 0.9410 - val_loss: 0.1943 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91074, saving model to /mnt/seals/models/9/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1389 - acc: 0.9438 - val_loss: 0.1900 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91074 to 0.91425, saving model to /mnt/seals/models/9/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1347 - acc: 0.9458 - val_loss: 0.2002 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91425\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1302 - acc: 0.9475 - val_loss: 0.2177 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91425\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1276 - acc: 0.9487 - val_loss: 0.1968 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91425\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1242 - acc: 0.9500 - val_loss: 0.2030 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91425\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1218 - acc: 0.9511 - val_loss: 0.1993 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91425\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 288us/step - loss: 0.1344 - acc: 0.9456 - val_loss: 0.1951 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90891, saving model to /mnt/seals/models/9/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1332 - acc: 0.9462 - val_loss: 0.1966 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90891\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1328 - acc: 0.9466 - val_loss: 0.1925 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90891 to 0.91227, saving model to /mnt/seals/models/9/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1320 - acc: 0.9468 - val_loss: 0.1963 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91227\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1317 - acc: 0.9466 - val_loss: 0.1933 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91227\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1315 - acc: 0.9471 - val_loss: 0.2010 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91227\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1306 - acc: 0.9473 - val_loss: 0.1970 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91227\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1299 - acc: 0.9479 - val_loss: 0.2010 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91227\n",
      "3139/3139 [==============================] - 1s 347us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:06:54,715 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 03:01:27', 'fit_val_loss': 0.19658612825924024, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 0, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 1, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '323', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 03:06:53', 'fit_train_loss': 0.13316366597667023, 'dropout': 0.2, 'fit_stopped_epoch3': 2, 'path_model': '/mnt/seals/models/9/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 03:06:52', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 6, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 03:06:51', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 887431, 'fit_test_acc': 0.5543166613571201, 'layer_2_size': 128, 'fit_train_acc': 0.946194901699213, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9073967047760314, 'pooling': 'max', 'model_id': 9, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 03:06:54,716 [MainThread  ] [INFO ]  model 9 test acc: 0.5543166613571201\n",
      "2019-01-20 03:06:54,719 [MainThread  ] [INFO ]  Begin experiment for model_id=10\n",
      "2019-01-20 03:06:54,720 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 10, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:06:55,656 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 03:06:55,657 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 287us/step - loss: 0.1961 - acc: 0.9223 - val_loss: 0.1897 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91091, saving model to /mnt/seals/models/10/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1588 - acc: 0.9357 - val_loss: 0.1945 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91091 to 0.91539, saving model to /mnt/seals/models/10/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1508 - acc: 0.9393 - val_loss: 0.2078 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91539\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1438 - acc: 0.9423 - val_loss: 0.2149 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91539\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1388 - acc: 0.9443 - val_loss: 0.2192 - val_acc: 0.9063\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91539\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1382 - acc: 0.9444 - val_loss: 0.2153 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91539\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1353 - acc: 0.9459 - val_loss: 0.2189 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91539\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 290us/step - loss: 0.1377 - acc: 0.9440 - val_loss: 0.1956 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91352, saving model to /mnt/seals/models/10/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1330 - acc: 0.9457 - val_loss: 0.1871 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91352 to 0.91619, saving model to /mnt/seals/models/10/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1309 - acc: 0.9465 - val_loss: 0.1942 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91619\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1283 - acc: 0.9476 - val_loss: 0.1978 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91619\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1271 - acc: 0.9481 - val_loss: 0.1870 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91619 to 0.92120, saving model to /mnt/seals/models/10/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1255 - acc: 0.9488 - val_loss: 0.1960 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92120\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1240 - acc: 0.9492 - val_loss: 0.1978 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92120\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1225 - acc: 0.9501 - val_loss: 0.1915 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92120\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1209 - acc: 0.9501 - val_loss: 0.1968 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92120\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1202 - acc: 0.9506 - val_loss: 0.1996 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92120\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 287us/step - loss: 0.1244 - acc: 0.9492 - val_loss: 0.1919 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91501, saving model to /mnt/seals/models/10/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1241 - acc: 0.9492 - val_loss: 0.1968 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91501\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1238 - acc: 0.9492 - val_loss: 0.1924 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91501 to 0.91575, saving model to /mnt/seals/models/10/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1229 - acc: 0.9496 - val_loss: 0.1921 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91575 to 0.91739, saving model to /mnt/seals/models/10/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1233 - acc: 0.9497 - val_loss: 0.1960 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91739\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1228 - acc: 0.9498 - val_loss: 0.1943 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91739\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1227 - acc: 0.9497 - val_loss: 0.1920 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91739\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1224 - acc: 0.9501 - val_loss: 0.1917 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91739\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1220 - acc: 0.9499 - val_loss: 0.1951 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91739\n",
      "3139/3139 [==============================] - 1s 359us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py:513: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "2019-01-20 03:13:41,044 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 03:06:56', 'fit_val_loss': 0.1924319550803772, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 1, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 4, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '400', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 03:13:39', 'fit_train_loss': 0.12375078941131422, 'dropout': 0.2, 'fit_stopped_epoch3': 3, 'path_model': '/mnt/seals/models/10/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 03:13:38', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 11, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 03:13:36', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 870023, 'fit_test_acc': 0.5657852819369226, 'layer_2_size': 128, 'fit_train_acc': 0.9491747745661491, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9157463674830677, 'pooling': 'max', 'model_id': 10, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 03:13:41,045 [MainThread  ] [INFO ]  model 10 test acc: 0.5657852819369226\n",
      "2019-01-20 03:13:41,047 [MainThread  ] [INFO ]  Begin experiment for model_id=11\n",
      "2019-01-20 03:13:41,048 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 11, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:13:41,993 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 03:13:41,994 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.2071 - acc: 0.9233 - val_loss: 0.1995 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90537, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1548 - acc: 0.9369 - val_loss: 0.1882 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90537 to 0.90931, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 220us/step - loss: 0.1452 - acc: 0.9413 - val_loss: 0.2572 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90931\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1405 - acc: 0.9436 - val_loss: 0.2143 - val_acc: 0.9013\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90931\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1360 - acc: 0.9452 - val_loss: 0.1955 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90931 to 0.91216, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1325 - acc: 0.9467 - val_loss: 0.1823 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91216\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 221us/step - loss: 0.1303 - acc: 0.9471 - val_loss: 0.2003 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91216\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1274 - acc: 0.9487 - val_loss: 0.1879 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91216 to 0.91238, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1257 - acc: 0.9494 - val_loss: 0.1951 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91238 to 0.92223, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 220us/step - loss: 0.1235 - acc: 0.9504 - val_loss: 0.1896 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92223\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1223 - acc: 0.9508 - val_loss: 0.1753 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92223 to 0.92937, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1201 - acc: 0.9515 - val_loss: 0.1835 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92937\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1201 - acc: 0.9516 - val_loss: 0.2091 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92937\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 13s 220us/step - loss: 0.1183 - acc: 0.9520 - val_loss: 0.1859 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92937\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1158 - acc: 0.9532 - val_loss: 0.1866 - val_acc: 0.9255\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92937\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1172 - acc: 0.9528 - val_loss: 0.2331 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92937\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1080 - acc: 0.9563 - val_loss: 0.1965 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91849, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1059 - acc: 0.9566 - val_loss: 0.1983 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91849\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 221us/step - loss: 0.1046 - acc: 0.9573 - val_loss: 0.1972 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91849\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1035 - acc: 0.9579 - val_loss: 0.2014 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91849\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1030 - acc: 0.9578 - val_loss: 0.2008 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91849\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 221us/step - loss: 0.1023 - acc: 0.9583 - val_loss: 0.1923 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91849 to 0.92372, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1019 - acc: 0.9585 - val_loss: 0.1971 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92372\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1014 - acc: 0.9585 - val_loss: 0.2003 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92372\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1005 - acc: 0.9590 - val_loss: 0.1949 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92372\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1005 - acc: 0.9590 - val_loss: 0.1854 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92372\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.0998 - acc: 0.9589 - val_loss: 0.1952 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92372\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1006 - acc: 0.9589 - val_loss: 0.1963 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91766, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1010 - acc: 0.9586 - val_loss: 0.1933 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91766 to 0.91882, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1001 - acc: 0.9590 - val_loss: 0.1977 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91882\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1005 - acc: 0.9586 - val_loss: 0.1972 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91882\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1004 - acc: 0.9590 - val_loss: 0.1969 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91882\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.0997 - acc: 0.9590 - val_loss: 0.1949 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91882 to 0.91889, saving model to /mnt/seals/models/11/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1000 - acc: 0.9589 - val_loss: 0.1975 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91889\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.0999 - acc: 0.9592 - val_loss: 0.1983 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91889\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.0999 - acc: 0.9591 - val_loss: 0.1968 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91889\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.0992 - acc: 0.9592 - val_loss: 0.1972 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91889\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 221us/step - loss: 0.0995 - acc: 0.9590 - val_loss: 0.1976 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91889\n",
      "3139/3139 [==============================] - 1s 381us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:22:36,661 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 03:13:42', 'fit_val_loss': 0.1968536339421522, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 10, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 5, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '529', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 03:22:35', 'fit_train_loss': 0.10041678049880026, 'dropout': 0.2, 'fit_stopped_epoch3': 5, 'path_model': '/mnt/seals/models/11/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 03:22:33', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 23, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 03:22:32', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 853511, 'fit_test_acc': 0.5584581076776043, 'layer_2_size': 128, 'fit_train_acc': 0.9589819534551975, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9177725526162811, 'pooling': 'max', 'model_id': 11, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 03:22:36,662 [MainThread  ] [INFO ]  model 11 test acc: 0.5584581076776043\n",
      "2019-01-20 03:22:36,665 [MainThread  ] [INFO ]  Begin experiment for model_id=12\n",
      "2019-01-20 03:22:36,666 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 12, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:22:37,607 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 03:22:37,609 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.2635 - acc: 0.9245 - val_loss: 0.2365 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89450, saving model to /mnt/seals/models/12/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1512 - acc: 0.9383 - val_loss: 0.2178 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89450 to 0.90488, saving model to /mnt/seals/models/12/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1444 - acc: 0.9408 - val_loss: 0.1818 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90488 to 0.92590, saving model to /mnt/seals/models/12/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 200us/step - loss: 0.1381 - acc: 0.9437 - val_loss: 0.2129 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92590\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1320 - acc: 0.9463 - val_loss: 0.1934 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92590\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.1299 - acc: 0.9474 - val_loss: 0.1942 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92590\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 12s 197us/step - loss: 0.1281 - acc: 0.9478 - val_loss: 0.2221 - val_acc: 0.8981\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92590\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1251 - acc: 0.9492 - val_loss: 0.2169 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92590\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1247 - acc: 0.9493 - val_loss: 0.1887 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91846, saving model to /mnt/seals/models/12/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1215 - acc: 0.9509 - val_loss: 0.1907 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91846\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.1194 - acc: 0.9517 - val_loss: 0.1913 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91846\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 200us/step - loss: 0.1180 - acc: 0.9522 - val_loss: 0.1979 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91846\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1164 - acc: 0.9526 - val_loss: 0.1946 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91846\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 198us/step - loss: 0.1155 - acc: 0.9532 - val_loss: 0.2101 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91846\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1206 - acc: 0.9509 - val_loss: 0.2007 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91238, saving model to /mnt/seals/models/12/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1203 - acc: 0.9512 - val_loss: 0.2011 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91238\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1205 - acc: 0.9509 - val_loss: 0.2050 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91238\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 200us/step - loss: 0.1198 - acc: 0.9514 - val_loss: 0.1988 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91238 to 0.91307, saving model to /mnt/seals/models/12/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1195 - acc: 0.9519 - val_loss: 0.1997 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91307\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1190 - acc: 0.9516 - val_loss: 0.1957 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91307 to 0.91499, saving model to /mnt/seals/models/12/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1192 - acc: 0.9516 - val_loss: 0.1963 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91499\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 12s 198us/step - loss: 0.1191 - acc: 0.9513 - val_loss: 0.2007 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91499\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1182 - acc: 0.9520 - val_loss: 0.1974 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91499\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1181 - acc: 0.9518 - val_loss: 0.2016 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91499\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 12s 200us/step - loss: 0.1177 - acc: 0.9521 - val_loss: 0.1976 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91499\n",
      "3139/3139 [==============================] - 1s 376us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:28:00,867 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 03:22:38', 'fit_val_loss': 0.19970816626513094, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 2, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 0, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '318', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 03:27:59', 'fit_train_loss': 0.11950804909838543, 'dropout': 0.2, 'fit_stopped_epoch3': 5, 'path_model': '/mnt/seals/models/12/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 03:27:58', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 10, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 03:27:57', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 790535, 'fit_test_acc': 0.5737496017840076, 'layer_2_size': 0, 'fit_train_acc': 0.951850531790629, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9116494673445932, 'pooling': 'max', 'model_id': 12, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 03:28:00,868 [MainThread  ] [INFO ]  model 12 test acc: 0.5737496017840076\n",
      "2019-01-20 03:28:00,870 [MainThread  ] [INFO ]  Begin experiment for model_id=13\n",
      "2019-01-20 03:28:00,872 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 13, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:28:01,813 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 03:28:01,814 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.2628 - acc: 0.9229 - val_loss: 0.2169 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89353, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1507 - acc: 0.9383 - val_loss: 0.2242 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89353 to 0.89758, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 198us/step - loss: 0.1432 - acc: 0.9420 - val_loss: 0.2310 - val_acc: 0.8981\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89758 to 0.89811, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1357 - acc: 0.9451 - val_loss: 0.1940 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89811 to 0.90686, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 198us/step - loss: 0.1342 - acc: 0.9456 - val_loss: 0.2224 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90686 to 0.90942, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1300 - acc: 0.9473 - val_loss: 0.2410 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90942\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1274 - acc: 0.9482 - val_loss: 0.1916 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.90942 to 0.93051, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1256 - acc: 0.9490 - val_loss: 0.2367 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93051\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1235 - acc: 0.9500 - val_loss: 0.2281 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93051\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.1214 - acc: 0.9506 - val_loss: 0.1885 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93051\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1203 - acc: 0.9505 - val_loss: 0.2196 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93051\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 12s 200us/step - loss: 0.1184 - acc: 0.9515 - val_loss: 0.2001 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93051\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1127 - acc: 0.9544 - val_loss: 0.2059 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91230, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1106 - acc: 0.9552 - val_loss: 0.2099 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91230 to 0.91566, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 200us/step - loss: 0.1092 - acc: 0.9554 - val_loss: 0.1937 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91566 to 0.91911, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 198us/step - loss: 0.1086 - acc: 0.9558 - val_loss: 0.2047 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91911\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 200us/step - loss: 0.1079 - acc: 0.9561 - val_loss: 0.1975 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91911 to 0.92191, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 198us/step - loss: 0.1065 - acc: 0.9563 - val_loss: 0.2003 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92191\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 12s 200us/step - loss: 0.1063 - acc: 0.9566 - val_loss: 0.2085 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92191\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1057 - acc: 0.9565 - val_loss: 0.2068 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92191\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1052 - acc: 0.9569 - val_loss: 0.2192 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92191\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 12s 197us/step - loss: 0.1043 - acc: 0.9571 - val_loss: 0.2032 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92191\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1055 - acc: 0.9570 - val_loss: 0.1970 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92058, saving model to /mnt/seals/models/13/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1057 - acc: 0.9565 - val_loss: 0.1996 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92058\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.1050 - acc: 0.9571 - val_loss: 0.2020 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92058\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1052 - acc: 0.9569 - val_loss: 0.2032 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92058\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1051 - acc: 0.9572 - val_loss: 0.2004 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92058\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1051 - acc: 0.9569 - val_loss: 0.2019 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92058\n",
      "3139/3139 [==============================] - 1s 417us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:34:02,541 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 03:28:02', 'fit_val_loss': 0.2047024453964614, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 6, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 4, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '355', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 03:34:01', 'fit_train_loss': 0.10864803174220644, 'dropout': 0.2, 'fit_stopped_epoch3': 0, 'path_model': '/mnt/seals/models/13/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 03:33:59', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 13, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 03:33:58', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 790535, 'fit_test_acc': 0.5641924179675055, 'layer_2_size': 0, 'fit_train_acc': 0.9557545431496682, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9165479343133675, 'pooling': 'max', 'model_id': 13, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 03:34:02,542 [MainThread  ] [INFO ]  model 13 test acc: 0.5641924179675055\n",
      "2019-01-20 03:34:02,544 [MainThread  ] [INFO ]  Begin experiment for model_id=14\n",
      "2019-01-20 03:34:02,546 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 14, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:34:03,484 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 03:34:03,486 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.2216 - acc: 0.9280 - val_loss: 0.2049 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89969, saving model to /mnt/seals/models/14/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 199us/step - loss: 0.1502 - acc: 0.9386 - val_loss: 0.1824 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89969 to 0.92634, saving model to /mnt/seals/models/14/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.1429 - acc: 0.9421 - val_loss: 0.2039 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92634\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1375 - acc: 0.9442 - val_loss: 0.1673 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92634 to 0.93231, saving model to /mnt/seals/models/14/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1316 - acc: 0.9471 - val_loss: 0.2132 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93231\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1294 - acc: 0.9477 - val_loss: 0.2377 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93231\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.1260 - acc: 0.9493 - val_loss: 0.2513 - val_acc: 0.9027\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93231\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.1232 - acc: 0.9504 - val_loss: 0.2128 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93231\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1220 - acc: 0.9506 - val_loss: 0.2149 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93231\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1208 - acc: 0.9511 - val_loss: 0.1906 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91653, saving model to /mnt/seals/models/14/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1175 - acc: 0.9523 - val_loss: 0.2215 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91653\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.1163 - acc: 0.9530 - val_loss: 0.1936 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91653\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1146 - acc: 0.9534 - val_loss: 0.2026 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91653\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.1129 - acc: 0.9542 - val_loss: 0.2085 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91653\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1121 - acc: 0.9544 - val_loss: 0.1958 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91653\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1169 - acc: 0.9527 - val_loss: 0.1925 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91546, saving model to /mnt/seals/models/14/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1167 - acc: 0.9531 - val_loss: 0.2001 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91546\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1162 - acc: 0.9529 - val_loss: 0.1931 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91546\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1155 - acc: 0.9531 - val_loss: 0.1950 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91546\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 200us/step - loss: 0.1157 - acc: 0.9534 - val_loss: 0.1979 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91546\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1155 - acc: 0.9533 - val_loss: 0.1939 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91546\n",
      "3139/3139 [==============================] - 1s 445us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:38:41,422 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 03:34:04', 'fit_val_loss': 0.20392142210220757, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 3, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 0, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '273', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 03:38:39', 'fit_train_loss': 0.1429001824853434, 'dropout': 0.2, 'fit_stopped_epoch3': 0, 'path_model': '/mnt/seals/models/14/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 03:38:38', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 6, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 03:38:37', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 790535, 'fit_test_acc': 0.5543166613571201, 'layer_2_size': 0, 'fit_train_acc': 0.9420692869034735, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9148780033178163, 'pooling': 'max', 'model_id': 14, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 03:38:41,424 [MainThread  ] [INFO ]  model 14 test acc: 0.5543166613571201\n",
      "2019-01-20 03:38:41,427 [MainThread  ] [INFO ]  Begin experiment for model_id=15\n",
      "2019-01-20 03:38:41,428 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 15, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 512, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:38:42,364 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 03:38:42,366 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 16s 256us/step - loss: 0.2036 - acc: 0.9290 - val_loss: 0.2531 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88787, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1485 - acc: 0.9395 - val_loss: 0.2240 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88787 to 0.90032, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.1400 - acc: 0.9434 - val_loss: 0.2032 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90032 to 0.90871, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.1356 - acc: 0.9447 - val_loss: 0.1979 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90871 to 0.91412, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.1310 - acc: 0.9465 - val_loss: 0.1869 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91412 to 0.91849, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1271 - acc: 0.9485 - val_loss: 0.1923 - val_acc: 0.9230\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91849 to 0.92301, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1245 - acc: 0.9488 - val_loss: 0.2039 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92301\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1226 - acc: 0.9497 - val_loss: 0.1856 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92301\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.1217 - acc: 0.9505 - val_loss: 0.1872 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92301 to 0.92621, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.1204 - acc: 0.9508 - val_loss: 0.2065 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92621\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.1180 - acc: 0.9519 - val_loss: 0.2172 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92621\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.1161 - acc: 0.9522 - val_loss: 0.2034 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92621\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.1159 - acc: 0.9528 - val_loss: 0.1944 - val_acc: 0.9269\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92621 to 0.92688, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.1138 - acc: 0.9536 - val_loss: 0.2200 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92688\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 12s 201us/step - loss: 0.1140 - acc: 0.9531 - val_loss: 0.2085 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92688\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.1112 - acc: 0.9543 - val_loss: 0.1978 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92688\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.1125 - acc: 0.9540 - val_loss: 0.2336 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92688\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 12s 202us/step - loss: 0.1101 - acc: 0.9549 - val_loss: 0.2098 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92688\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1023 - acc: 0.9582 - val_loss: 0.2267 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91361, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.1010 - acc: 0.9591 - val_loss: 0.2054 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91361 to 0.91857, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.0999 - acc: 0.9590 - val_loss: 0.2212 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91857\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.0994 - acc: 0.9595 - val_loss: 0.2209 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91857\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.0989 - acc: 0.9597 - val_loss: 0.2270 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91857\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.0990 - acc: 0.9597 - val_loss: 0.2107 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91857\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.0982 - acc: 0.9595 - val_loss: 0.2182 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91857\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.0989 - acc: 0.9596 - val_loss: 0.2174 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91568, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.0985 - acc: 0.9598 - val_loss: 0.2147 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91568 to 0.91673, saving model to /mnt/seals/models/15/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.0984 - acc: 0.9599 - val_loss: 0.2190 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91673\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.0984 - acc: 0.9599 - val_loss: 0.2182 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91673\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.0984 - acc: 0.9599 - val_loss: 0.2161 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91673\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.0982 - acc: 0.9597 - val_loss: 0.2200 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91673\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.0982 - acc: 0.9598 - val_loss: 0.2200 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91673\n",
      "3139/3139 [==============================] - 1s 421us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:45:39,715 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 03:38:43', 'fit_val_loss': 0.21741741728455646, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 12, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 1, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '411', 'layer_1_size': 512, 'fit_dt_test_end': '2019-01-20 03:45:38', 'fit_train_loss': 0.09888196758361438, 'dropout': 0.2, 'fit_stopped_epoch3': 1, 'path_model': '/mnt/seals/models/15/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 03:45:36', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 17, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 03:45:35', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 790535, 'fit_test_acc': 0.5606881172347882, 'layer_2_size': 0, 'fit_train_acc': 0.9596491251064295, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9156795725263562, 'pooling': 'max', 'model_id': 15, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 03:45:39,716 [MainThread  ] [INFO ]  model 15 test acc: 0.5606881172347882\n",
      "2019-01-20 03:45:39,718 [MainThread  ] [INFO ]  Begin experiment for model_id=16\n",
      "2019-01-20 03:45:39,719 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 16, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:45:40,663 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 03:45:40,664 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 301us/step - loss: 0.1917 - acc: 0.9228 - val_loss: 0.1836 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91430, saving model to /mnt/seals/models/16/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1637 - acc: 0.9332 - val_loss: 0.1962 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91430 to 0.91564, saving model to /mnt/seals/models/16/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1550 - acc: 0.9364 - val_loss: 0.1808 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91564 to 0.92786, saving model to /mnt/seals/models/16/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1522 - acc: 0.9380 - val_loss: 0.1911 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92786\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1532 - acc: 0.9372 - val_loss: 0.2160 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92786\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1516 - acc: 0.9382 - val_loss: 0.2123 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92786\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1506 - acc: 0.9389 - val_loss: 0.2040 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92786\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1478 - acc: 0.9402 - val_loss: 0.2458 - val_acc: 0.8939\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92786\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 299us/step - loss: 0.1366 - acc: 0.9440 - val_loss: 0.1848 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91895, saving model to /mnt/seals/models/16/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1330 - acc: 0.9453 - val_loss: 0.1834 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91895\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1313 - acc: 0.9462 - val_loss: 0.1889 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91895\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1288 - acc: 0.9469 - val_loss: 0.1817 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91895 to 0.91924, saving model to /mnt/seals/models/16/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1280 - acc: 0.9474 - val_loss: 0.1896 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91924\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1262 - acc: 0.9481 - val_loss: 0.1743 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91924 to 0.92786, saving model to /mnt/seals/models/16/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1250 - acc: 0.9486 - val_loss: 0.1809 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92786\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1237 - acc: 0.9493 - val_loss: 0.1817 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92786\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1223 - acc: 0.9501 - val_loss: 0.1852 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92786\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1218 - acc: 0.9504 - val_loss: 0.1835 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92786\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1209 - acc: 0.9504 - val_loss: 0.1882 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92786\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 304us/step - loss: 0.1241 - acc: 0.9488 - val_loss: 0.1829 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92060, saving model to /mnt/seals/models/16/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1224 - acc: 0.9496 - val_loss: 0.1850 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92060\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1230 - acc: 0.9495 - val_loss: 0.1849 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92060\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 239us/step - loss: 0.1229 - acc: 0.9495 - val_loss: 0.1812 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92060 to 0.92252, saving model to /mnt/seals/models/16/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1225 - acc: 0.9500 - val_loss: 0.1808 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92252\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1227 - acc: 0.9496 - val_loss: 0.1823 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92252\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1224 - acc: 0.9497 - val_loss: 0.1809 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92252\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1225 - acc: 0.9493 - val_loss: 0.1840 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92252\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1224 - acc: 0.9497 - val_loss: 0.1826 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92252\n",
      "3139/3139 [==============================] - 1s 474us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:52:58,931 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 03:45:41', 'fit_val_loss': 0.18492643367917164, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 2, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 5, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '432', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 03:52:57', 'fit_train_loss': 0.1229865025063581, 'dropout': 0.2, 'fit_stopped_epoch3': 3, 'path_model': '/mnt/seals/models/16/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 03:52:55', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 13, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 03:52:53', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 791303, 'fit_test_acc': 0.5686524370818732, 'layer_2_size': 512, 'fit_train_acc': 0.9495425450449122, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.919709674140759, 'pooling': 'max', 'model_id': 16, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 03:52:58,932 [MainThread  ] [INFO ]  model 16 test acc: 0.5686524370818732\n",
      "2019-01-20 03:52:58,934 [MainThread  ] [INFO ]  Begin experiment for model_id=17\n",
      "2019-01-20 03:52:58,935 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 17, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 03:52:59,855 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 03:52:59,856 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 304us/step - loss: 0.1896 - acc: 0.9246 - val_loss: 0.1835 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92182, saving model to /mnt/seals/models/17/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1628 - acc: 0.9342 - val_loss: 0.2126 - val_acc: 0.9059\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92182\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1542 - acc: 0.9374 - val_loss: 0.2066 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92182\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1485 - acc: 0.9403 - val_loss: 0.2424 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92182\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1517 - acc: 0.9378 - val_loss: 0.1912 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92182 to 0.92626, saving model to /mnt/seals/models/17/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1500 - acc: 0.9382 - val_loss: 0.2213 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92626\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1518 - acc: 0.9381 - val_loss: 0.2045 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92626\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1533 - acc: 0.9377 - val_loss: 0.1858 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92626 to 0.92648, saving model to /mnt/seals/models/17/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1519 - acc: 0.9381 - val_loss: 0.1909 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92648\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1500 - acc: 0.9389 - val_loss: 0.2385 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92648\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1538 - acc: 0.9370 - val_loss: 0.1889 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92648\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1550 - acc: 0.9372 - val_loss: 0.2186 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92648\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1573 - acc: 0.9349 - val_loss: 0.1919 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92648\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 297us/step - loss: 0.1385 - acc: 0.9431 - val_loss: 0.1984 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91512, saving model to /mnt/seals/models/17/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1372 - acc: 0.9442 - val_loss: 0.1883 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91512 to 0.91922, saving model to /mnt/seals/models/17/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1358 - acc: 0.9450 - val_loss: 0.1935 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91922 to 0.91924, saving model to /mnt/seals/models/17/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1348 - acc: 0.9454 - val_loss: 0.1882 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91924 to 0.92200, saving model to /mnt/seals/models/17/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1336 - acc: 0.9459 - val_loss: 0.1854 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92200 to 0.92392, saving model to /mnt/seals/models/17/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1338 - acc: 0.9458 - val_loss: 0.1938 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92392\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1331 - acc: 0.9461 - val_loss: 0.2032 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92392\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1316 - acc: 0.9470 - val_loss: 0.1891 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92392\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1313 - acc: 0.9471 - val_loss: 0.1914 - val_acc: 0.9066\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92392\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 239us/step - loss: 0.1309 - acc: 0.9470 - val_loss: 0.2000 - val_acc: 0.8985\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92392\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 301us/step - loss: 0.1327 - acc: 0.9465 - val_loss: 0.1864 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92162, saving model to /mnt/seals/models/17/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 239us/step - loss: 0.1322 - acc: 0.9466 - val_loss: 0.1919 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92162\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1323 - acc: 0.9465 - val_loss: 0.1894 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92162\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1319 - acc: 0.9466 - val_loss: 0.1890 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92162\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1317 - acc: 0.9470 - val_loss: 0.1915 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92162\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1311 - acc: 0.9472 - val_loss: 0.1902 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92162\n",
      "3139/3139 [==============================] - 2s 484us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:00:26,913 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 03:53:00', 'fit_val_loss': 0.18817600176815974, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 7, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 4, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '441', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 04:00:25', 'fit_train_loss': 0.13484584492386073, 'dropout': 0.2, 'fit_stopped_epoch3': 0, 'path_model': '/mnt/seals/models/17/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 04:00:23', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 14, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 04:00:22', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 658183, 'fit_test_acc': 0.5587766804714878, 'layer_2_size': 512, 'fit_train_acc': 0.9454098554620066, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.922003049951539, 'pooling': 'max', 'model_id': 17, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 04:00:26,915 [MainThread  ] [INFO ]  model 17 test acc: 0.5587766804714878\n",
      "2019-01-20 04:00:26,916 [MainThread  ] [INFO ]  Begin experiment for model_id=18\n",
      "2019-01-20 04:00:26,918 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 18, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:00:27,866 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 04:00:27,868 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 301us/step - loss: 0.1923 - acc: 0.9235 - val_loss: 0.1964 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92011, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1648 - acc: 0.9345 - val_loss: 0.1908 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92011\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 239us/step - loss: 0.1540 - acc: 0.9389 - val_loss: 0.1852 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92011 to 0.92439, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1486 - acc: 0.9405 - val_loss: 0.1961 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92439\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1505 - acc: 0.9411 - val_loss: 0.2003 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92439\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1460 - acc: 0.9429 - val_loss: 0.1814 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92439 to 0.92494, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1431 - acc: 0.9436 - val_loss: 0.1810 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92494\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1407 - acc: 0.9449 - val_loss: 0.1931 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92494\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1397 - acc: 0.9456 - val_loss: 0.2160 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92494\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1466 - acc: 0.9425 - val_loss: 0.2135 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92494\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1490 - acc: 0.9417 - val_loss: 0.1917 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92494\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 301us/step - loss: 0.1313 - acc: 0.9485 - val_loss: 0.1864 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91599, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1287 - acc: 0.9495 - val_loss: 0.1847 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91599 to 0.91724, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1265 - acc: 0.9504 - val_loss: 0.1815 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91724\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1257 - acc: 0.9509 - val_loss: 0.1766 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91724 to 0.92080, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1242 - acc: 0.9509 - val_loss: 0.1783 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92080\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1238 - acc: 0.9512 - val_loss: 0.1858 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92080\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1232 - acc: 0.9517 - val_loss: 0.1896 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92080\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1231 - acc: 0.9517 - val_loss: 0.1891 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92080\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1216 - acc: 0.9521 - val_loss: 0.1728 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92080 to 0.92323, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1208 - acc: 0.9523 - val_loss: 0.1778 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92323\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1209 - acc: 0.9528 - val_loss: 0.1733 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92323 to 0.92385, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 239us/step - loss: 0.1195 - acc: 0.9533 - val_loss: 0.1839 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92385\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1192 - acc: 0.9531 - val_loss: 0.1736 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92385 to 0.92401, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1189 - acc: 0.9532 - val_loss: 0.1716 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.92401 to 0.92537, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1184 - acc: 0.9534 - val_loss: 0.1743 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92537\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 15s 239us/step - loss: 0.1182 - acc: 0.9535 - val_loss: 0.1793 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92537\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1176 - acc: 0.9539 - val_loss: 0.1882 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92537\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1170 - acc: 0.9541 - val_loss: 0.1758 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92537\n",
      "Epoch 19/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1158 - acc: 0.9544 - val_loss: 0.1901 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92537\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 310us/step - loss: 0.1172 - acc: 0.9539 - val_loss: 0.1773 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92140, saving model to /mnt/seals/models/18/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1169 - acc: 0.9541 - val_loss: 0.1776 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92140\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1165 - acc: 0.9543 - val_loss: 0.1780 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92140\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1168 - acc: 0.9541 - val_loss: 0.1822 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92140\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1163 - acc: 0.9543 - val_loss: 0.1784 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92140\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1163 - acc: 0.9545 - val_loss: 0.1810 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92140\n",
      "3139/3139 [==============================] - 2s 547us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:09:39,405 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 04:00:28', 'fit_val_loss': 0.1735967793072251, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 5, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 13, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '546', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 04:09:37', 'fit_train_loss': 0.11918269151560058, 'dropout': 0.2, 'fit_stopped_epoch3': 0, 'path_model': '/mnt/seals/models/18/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 04:09:36', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 21, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 04:09:34', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 591623, 'fit_test_acc': 0.5702453010512902, 'layer_2_size': 512, 'fit_train_acc': 0.9530552113807869, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9240069658381683, 'pooling': 'max', 'model_id': 18, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 04:09:39,407 [MainThread  ] [INFO ]  model 18 test acc: 0.5702453010512902\n",
      "2019-01-20 04:09:39,410 [MainThread  ] [INFO ]  Begin experiment for model_id=19\n",
      "2019-01-20 04:09:39,412 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 19, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:09:40,356 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 04:09:40,357 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 278us/step - loss: 0.1930 - acc: 0.9232 - val_loss: 0.2177 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89495, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 220us/step - loss: 0.1638 - acc: 0.9340 - val_loss: 0.2365 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89495 to 0.89682, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1548 - acc: 0.9372 - val_loss: 0.1983 - val_acc: 0.9101\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89682 to 0.91011, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1489 - acc: 0.9396 - val_loss: 0.1817 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91011 to 0.92093, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1448 - acc: 0.9417 - val_loss: 0.1921 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92093\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1420 - acc: 0.9431 - val_loss: 0.1912 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92093\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1407 - acc: 0.9433 - val_loss: 0.1801 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.92093 to 0.92234, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1393 - acc: 0.9441 - val_loss: 0.1759 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92234\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1371 - acc: 0.9449 - val_loss: 0.1628 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92234 to 0.93414, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1353 - acc: 0.9459 - val_loss: 0.1872 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93414\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1337 - acc: 0.9468 - val_loss: 0.1699 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93414\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1317 - acc: 0.9475 - val_loss: 0.1804 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93414\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1310 - acc: 0.9480 - val_loss: 0.1744 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93414\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1315 - acc: 0.9478 - val_loss: 0.1880 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93414\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 282us/step - loss: 0.1228 - acc: 0.9508 - val_loss: 0.1738 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92505, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1211 - acc: 0.9514 - val_loss: 0.1822 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92505\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1195 - acc: 0.9520 - val_loss: 0.1783 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92505\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 217us/step - loss: 0.1195 - acc: 0.9519 - val_loss: 0.1919 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92505\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 218us/step - loss: 0.1188 - acc: 0.9523 - val_loss: 0.1779 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92505\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1180 - acc: 0.9525 - val_loss: 0.1680 - val_acc: 0.9299\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92505 to 0.92993, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1172 - acc: 0.9528 - val_loss: 0.1760 - val_acc: 0.9255\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92993\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1174 - acc: 0.9529 - val_loss: 0.1748 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92993\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1162 - acc: 0.9533 - val_loss: 0.1766 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92993\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1162 - acc: 0.9534 - val_loss: 0.1849 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92993\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1158 - acc: 0.9536 - val_loss: 0.1811 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92993\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 17s 280us/step - loss: 0.1165 - acc: 0.9533 - val_loss: 0.1775 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92383, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1158 - acc: 0.9533 - val_loss: 0.1766 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92383 to 0.92508, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 218us/step - loss: 0.1163 - acc: 0.9531 - val_loss: 0.1748 - val_acc: 0.9258\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92508 to 0.92581, saving model to /mnt/seals/models/19/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 218us/step - loss: 0.1163 - acc: 0.9531 - val_loss: 0.1784 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92581\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1158 - acc: 0.9537 - val_loss: 0.1778 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92581\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1163 - acc: 0.9533 - val_loss: 0.1783 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92581\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1157 - acc: 0.9535 - val_loss: 0.1769 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92581\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 216us/step - loss: 0.1162 - acc: 0.9533 - val_loss: 0.1776 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92581\n",
      "3139/3139 [==============================] - 2s 543us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:17:17,455 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 04:09:41', 'fit_val_loss': 0.17660148939735573, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 8, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 5, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '450', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 04:17:15', 'fit_train_loss': 0.11580210327679154, 'dropout': 0.2, 'fit_stopped_epoch3': 2, 'path_model': '/mnt/seals/models/19/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 04:17:14', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 18, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 04:17:11', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 528647, 'fit_test_acc': 0.5578209620898376, 'layer_2_size': 512, 'fit_train_acc': 0.9533074642169247, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9250757196300344, 'pooling': 'max', 'model_id': 19, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 04:17:17,456 [MainThread  ] [INFO ]  model 19 test acc: 0.5578209620898376\n",
      "2019-01-20 04:17:17,458 [MainThread  ] [INFO ]  Begin experiment for model_id=20\n",
      "2019-01-20 04:17:17,459 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 20, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:17:18,414 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 04:17:18,415 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 306us/step - loss: 0.1909 - acc: 0.9244 - val_loss: 0.2048 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90735, saving model to /mnt/seals/models/20/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1609 - acc: 0.9353 - val_loss: 0.1721 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90735 to 0.92875, saving model to /mnt/seals/models/20/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1554 - acc: 0.9379 - val_loss: 0.1926 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92875\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1525 - acc: 0.9394 - val_loss: 0.1988 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92875\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1476 - acc: 0.9413 - val_loss: 0.2013 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92875\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1461 - acc: 0.9420 - val_loss: 0.2541 - val_acc: 0.8961\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92875\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1510 - acc: 0.9393 - val_loss: 0.1978 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92875\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 314us/step - loss: 0.1387 - acc: 0.9435 - val_loss: 0.1914 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91107, saving model to /mnt/seals/models/20/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1341 - acc: 0.9455 - val_loss: 0.1940 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91107\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1318 - acc: 0.9461 - val_loss: 0.1923 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91107\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1301 - acc: 0.9471 - val_loss: 0.1904 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91107 to 0.91227, saving model to /mnt/seals/models/20/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1279 - acc: 0.9481 - val_loss: 0.1799 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91227 to 0.91490, saving model to /mnt/seals/models/20/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1263 - acc: 0.9482 - val_loss: 0.1905 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91490\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1248 - acc: 0.9494 - val_loss: 0.1953 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91490\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1235 - acc: 0.9498 - val_loss: 0.1944 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91490\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1228 - acc: 0.9501 - val_loss: 0.1906 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91490\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1217 - acc: 0.9505 - val_loss: 0.1972 - val_acc: 0.9033\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91490\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 314us/step - loss: 0.1249 - acc: 0.9492 - val_loss: 0.1900 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90998, saving model to /mnt/seals/models/20/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 240us/step - loss: 0.1243 - acc: 0.9492 - val_loss: 0.1916 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90998\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1241 - acc: 0.9492 - val_loss: 0.1897 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90998\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1242 - acc: 0.9496 - val_loss: 0.1899 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90998 to 0.91022, saving model to /mnt/seals/models/20/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1238 - acc: 0.9495 - val_loss: 0.1898 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91022\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1242 - acc: 0.9496 - val_loss: 0.1880 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91022 to 0.91261, saving model to /mnt/seals/models/20/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1232 - acc: 0.9496 - val_loss: 0.1882 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91261\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1233 - acc: 0.9497 - val_loss: 0.1902 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91261\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1231 - acc: 0.9499 - val_loss: 0.1901 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91261\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1230 - acc: 0.9499 - val_loss: 0.1910 - val_acc: 0.9090\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91261\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1230 - acc: 0.9498 - val_loss: 0.1906 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91261\n",
      "3139/3139 [==============================] - 2s 611us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:24:39,602 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 04:17:19', 'fit_val_loss': 0.1898267289572523, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 1, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 4, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '434', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 04:24:38', 'fit_train_loss': 0.12378564199781703, 'dropout': 0.2, 'fit_stopped_epoch3': 5, 'path_model': '/mnt/seals/models/20/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 04:24:36', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 13, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 04:24:33', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 594439, 'fit_test_acc': 0.5587766804714878, 'layer_2_size': 256, 'fit_train_acc': 0.9495118971248447, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9093115610672055, 'pooling': 'max', 'model_id': 20, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 04:24:39,604 [MainThread  ] [INFO ]  model 20 test acc: 0.5587766804714878\n",
      "2019-01-20 04:24:39,606 [MainThread  ] [INFO ]  Begin experiment for model_id=21\n",
      "2019-01-20 04:24:39,607 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 21, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:24:40,551 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 04:24:40,552 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 318us/step - loss: 0.1916 - acc: 0.9232 - val_loss: 0.1903 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91944, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1613 - acc: 0.9349 - val_loss: 0.2170 - val_acc: 0.9021\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91944\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1531 - acc: 0.9385 - val_loss: 0.2002 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91944\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1494 - acc: 0.9402 - val_loss: 0.1707 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91944 to 0.93156, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1460 - acc: 0.9413 - val_loss: 0.1737 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93156\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1415 - acc: 0.9436 - val_loss: 0.1918 - val_acc: 0.9255\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93156\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1417 - acc: 0.9434 - val_loss: 0.1908 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93156\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1392 - acc: 0.9442 - val_loss: 0.2167 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93156\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1385 - acc: 0.9445 - val_loss: 0.1787 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93156\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 315us/step - loss: 0.1303 - acc: 0.9470 - val_loss: 0.2067 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90938, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1270 - acc: 0.9482 - val_loss: 0.1948 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90938 to 0.91530, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1254 - acc: 0.9489 - val_loss: 0.2077 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91530\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1243 - acc: 0.9493 - val_loss: 0.2067 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91530\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1236 - acc: 0.9499 - val_loss: 0.1935 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91530 to 0.91586, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1227 - acc: 0.9501 - val_loss: 0.1957 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91586 to 0.91846, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1213 - acc: 0.9507 - val_loss: 0.1938 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91846\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1203 - acc: 0.9512 - val_loss: 0.2003 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91846\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1198 - acc: 0.9511 - val_loss: 0.2120 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91846\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1190 - acc: 0.9515 - val_loss: 0.2029 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91846\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1181 - acc: 0.9519 - val_loss: 0.1953 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91846\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 324us/step - loss: 0.1206 - acc: 0.9508 - val_loss: 0.1976 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91515, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1201 - acc: 0.9510 - val_loss: 0.1981 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91515\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1199 - acc: 0.9513 - val_loss: 0.1977 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91515\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1194 - acc: 0.9514 - val_loss: 0.1967 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91515 to 0.91579, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1198 - acc: 0.9513 - val_loss: 0.1971 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91579\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1193 - acc: 0.9514 - val_loss: 0.1972 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91579 to 0.91584, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1192 - acc: 0.9515 - val_loss: 0.1987 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91584\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1187 - acc: 0.9516 - val_loss: 0.1944 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91584 to 0.91699, saving model to /mnt/seals/models/21/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1191 - acc: 0.9516 - val_loss: 0.2016 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91699\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1190 - acc: 0.9513 - val_loss: 0.1996 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91699\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1186 - acc: 0.9515 - val_loss: 0.1977 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91699\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1187 - acc: 0.9518 - val_loss: 0.1987 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.91699\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1182 - acc: 0.9518 - val_loss: 0.2003 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.91699\n",
      "3139/3139 [==============================] - 2s 621us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:33:18,984 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 04:24:41', 'fit_val_loss': 0.19866444129599004, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 3, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 5, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '511', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 04:33:17', 'fit_train_loss': 0.11924768954587754, 'dropout': 0.2, 'fit_stopped_epoch3': 7, 'path_model': '/mnt/seals/models/21/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 04:33:15', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 18, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 04:33:13', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 526855, 'fit_test_acc': 0.5737496017840076, 'layer_2_size': 256, 'fit_train_acc': 0.951511052976137, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9149670654401517, 'pooling': 'max', 'model_id': 21, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 04:33:18,985 [MainThread  ] [INFO ]  model 21 test acc: 0.5737496017840076\n",
      "2019-01-20 04:33:18,988 [MainThread  ] [INFO ]  Begin experiment for model_id=22\n",
      "2019-01-20 04:33:18,989 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 22, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:33:19,933 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 04:33:19,935 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 322us/step - loss: 0.1924 - acc: 0.9234 - val_loss: 0.2017 - val_acc: 0.9019\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90187, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1633 - acc: 0.9349 - val_loss: 0.2164 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90187 to 0.90501, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1543 - acc: 0.9385 - val_loss: 0.2054 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90501 to 0.91040, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1495 - acc: 0.9403 - val_loss: 0.1917 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91040 to 0.91822, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1474 - acc: 0.9414 - val_loss: 0.2186 - val_acc: 0.8986\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91822\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1425 - acc: 0.9432 - val_loss: 0.2025 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91822\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1407 - acc: 0.9441 - val_loss: 0.1857 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91822 to 0.92024, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1386 - acc: 0.9444 - val_loss: 0.2008 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92024\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1383 - acc: 0.9447 - val_loss: 0.1836 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92024 to 0.92419, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1358 - acc: 0.9457 - val_loss: 0.2089 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92419\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1342 - acc: 0.9463 - val_loss: 0.1933 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92419\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1368 - acc: 0.9462 - val_loss: 0.2091 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92419\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1465 - acc: 0.9411 - val_loss: 0.1986 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92419\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1456 - acc: 0.9412 - val_loss: 0.1798 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92419\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 323us/step - loss: 0.1257 - acc: 0.9494 - val_loss: 0.1939 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91860, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1228 - acc: 0.9505 - val_loss: 0.1893 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91860 to 0.91933, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1217 - acc: 0.9509 - val_loss: 0.1966 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91933 to 0.91964, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1207 - acc: 0.9514 - val_loss: 0.1923 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91964\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1210 - acc: 0.9510 - val_loss: 0.1962 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91964\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1206 - acc: 0.9511 - val_loss: 0.1989 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91964\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1191 - acc: 0.9520 - val_loss: 0.2043 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91964\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1191 - acc: 0.9517 - val_loss: 0.2103 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91964\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 324us/step - loss: 0.1202 - acc: 0.9514 - val_loss: 0.1951 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91875, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1201 - acc: 0.9515 - val_loss: 0.1979 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91875\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1200 - acc: 0.9517 - val_loss: 0.1943 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91875\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1201 - acc: 0.9513 - val_loss: 0.1957 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91875 to 0.91915, saving model to /mnt/seals/models/22/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1195 - acc: 0.9519 - val_loss: 0.1963 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91915\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1192 - acc: 0.9520 - val_loss: 0.1964 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91915\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1195 - acc: 0.9515 - val_loss: 0.1962 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91915\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1198 - acc: 0.9515 - val_loss: 0.1999 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91915\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1195 - acc: 0.9518 - val_loss: 0.1982 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91915\n",
      "3139/3139 [==============================] - 2s 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:41:34,292 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 04:33:20', 'fit_val_loss': 0.19427855349984252, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 8, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 2, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '487', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 04:41:32', 'fit_train_loss': 0.11997986927411874, 'dropout': 0.2, 'fit_stopped_epoch3': 3, 'path_model': '/mnt/seals/models/22/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 04:41:30', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 16, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 04:41:28', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 493063, 'fit_test_acc': 0.5836253583943931, 'layer_2_size': 256, 'fit_train_acc': 0.9517161558775555, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9186186487240684, 'pooling': 'max', 'model_id': 22, 'fit_dt_test_duration_seconds': '1'}\n",
      "2019-01-20 04:41:34,294 [MainThread  ] [INFO ]  model 22 test acc: 0.5836253583943931\n",
      "2019-01-20 04:41:34,296 [MainThread  ] [INFO ]  Begin experiment for model_id=23\n",
      "2019-01-20 04:41:34,297 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 23, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:41:35,248 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 04:41:35,249 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 304us/step - loss: 0.2003 - acc: 0.9225 - val_loss: 0.2196 - val_acc: 0.8865\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88647, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 221us/step - loss: 0.1629 - acc: 0.9333 - val_loss: 0.2012 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88647 to 0.89831, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 221us/step - loss: 0.1557 - acc: 0.9354 - val_loss: 0.2090 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89831 to 0.90357, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1498 - acc: 0.9382 - val_loss: 0.1861 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90357 to 0.91697, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 221us/step - loss: 0.1452 - acc: 0.9406 - val_loss: 0.1857 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91697\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1398 - acc: 0.9428 - val_loss: 0.2190 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91697\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1397 - acc: 0.9429 - val_loss: 0.1823 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91697 to 0.92209, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1397 - acc: 0.9435 - val_loss: 0.2023 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92209\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 220us/step - loss: 0.1376 - acc: 0.9442 - val_loss: 0.2007 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92209\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1328 - acc: 0.9464 - val_loss: 0.2046 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92209\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1326 - acc: 0.9466 - val_loss: 0.1744 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92209 to 0.92499, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1312 - acc: 0.9472 - val_loss: 0.2245 - val_acc: 0.9024\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92499\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1304 - acc: 0.9477 - val_loss: 0.1906 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92499\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1284 - acc: 0.9484 - val_loss: 0.2035 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92499\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1283 - acc: 0.9487 - val_loss: 0.2013 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92499\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 13s 222us/step - loss: 0.1279 - acc: 0.9486 - val_loss: 0.2134 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92499\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 303us/step - loss: 0.1189 - acc: 0.9518 - val_loss: 0.1841 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92372, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 223us/step - loss: 0.1172 - acc: 0.9527 - val_loss: 0.1915 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92372\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1152 - acc: 0.9535 - val_loss: 0.1983 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92372\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1154 - acc: 0.9534 - val_loss: 0.1855 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92372\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 221us/step - loss: 0.1143 - acc: 0.9542 - val_loss: 0.2006 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92372\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 223us/step - loss: 0.1141 - acc: 0.9538 - val_loss: 0.1898 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92372\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 305us/step - loss: 0.1163 - acc: 0.9532 - val_loss: 0.1905 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92176, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1163 - acc: 0.9530 - val_loss: 0.1898 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92176 to 0.92178, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1155 - acc: 0.9532 - val_loss: 0.1909 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92178\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1158 - acc: 0.9533 - val_loss: 0.1898 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92178 to 0.92314, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1156 - acc: 0.9536 - val_loss: 0.1876 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92314 to 0.92390, saving model to /mnt/seals/models/23/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1151 - acc: 0.9534 - val_loss: 0.1877 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92390\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1150 - acc: 0.9535 - val_loss: 0.1894 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92390\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1150 - acc: 0.9536 - val_loss: 0.1895 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92390\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1152 - acc: 0.9535 - val_loss: 0.1904 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92390\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1142 - acc: 0.9537 - val_loss: 0.1905 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92390\n",
      "3139/3139 [==============================] - 2s 646us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:49:21,745 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 04:41:36', 'fit_val_loss': 0.1897575831101125, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 10, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 0, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '460', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 04:49:20', 'fit_train_loss': 0.11575464574499296, 'dropout': 0.2, 'fit_stopped_epoch3': 4, 'path_model': '/mnt/seals/models/23/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 04:49:18', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 17, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 04:49:16', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 461063, 'fit_test_acc': 0.5829882128066264, 'layer_2_size': 256, 'fit_train_acc': 0.9532862474608051, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9231385997405968, 'pooling': 'max', 'model_id': 23, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 04:49:21,747 [MainThread  ] [INFO ]  model 23 test acc: 0.5829882128066264\n",
      "2019-01-20 04:49:21,749 [MainThread  ] [INFO ]  Begin experiment for model_id=24\n",
      "2019-01-20 04:49:21,750 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 24, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:49:22,697 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 04:49:22,698 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 330us/step - loss: 0.1897 - acc: 0.9232 - val_loss: 0.1885 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91392, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1596 - acc: 0.9349 - val_loss: 0.1878 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91392 to 0.92779, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1509 - acc: 0.9388 - val_loss: 0.1970 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92779\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1462 - acc: 0.9410 - val_loss: 0.2095 - val_acc: 0.8999\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92779\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1430 - acc: 0.9427 - val_loss: 0.2356 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92779\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1427 - acc: 0.9426 - val_loss: 0.1924 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92779\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1405 - acc: 0.9440 - val_loss: 0.1879 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92779\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 335us/step - loss: 0.1372 - acc: 0.9441 - val_loss: 0.2053 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90223, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1326 - acc: 0.9458 - val_loss: 0.2000 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90223 to 0.90773, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1298 - acc: 0.9473 - val_loss: 0.1938 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90773 to 0.90784, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1279 - acc: 0.9481 - val_loss: 0.2039 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90784\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1254 - acc: 0.9492 - val_loss: 0.1958 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90784 to 0.91147, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1238 - acc: 0.9498 - val_loss: 0.1841 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91147 to 0.91728, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1222 - acc: 0.9508 - val_loss: 0.1978 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91728\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1216 - acc: 0.9511 - val_loss: 0.1883 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91728\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1199 - acc: 0.9514 - val_loss: 0.1860 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91728 to 0.91902, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1190 - acc: 0.9517 - val_loss: 0.1893 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91902\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1173 - acc: 0.9525 - val_loss: 0.1942 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91902\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1165 - acc: 0.9531 - val_loss: 0.1872 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.91902\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1155 - acc: 0.9532 - val_loss: 0.1999 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.91902\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1143 - acc: 0.9539 - val_loss: 0.1870 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.91902\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 331us/step - loss: 0.1167 - acc: 0.9533 - val_loss: 0.1867 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91849, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1162 - acc: 0.9531 - val_loss: 0.1902 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91849\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1165 - acc: 0.9529 - val_loss: 0.1894 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91849\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1160 - acc: 0.9533 - val_loss: 0.1863 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91849 to 0.91882, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1159 - acc: 0.9532 - val_loss: 0.1879 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91882\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1159 - acc: 0.9533 - val_loss: 0.1840 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91882 to 0.92085, saving model to /mnt/seals/models/24/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1159 - acc: 0.9534 - val_loss: 0.1920 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92085\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1153 - acc: 0.9535 - val_loss: 0.1877 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92085\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1151 - acc: 0.9535 - val_loss: 0.1865 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92085\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1149 - acc: 0.9536 - val_loss: 0.1854 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92085\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1147 - acc: 0.9536 - val_loss: 0.1869 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92085\n",
      "3139/3139 [==============================] - 2s 690us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:58:00,193 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 04:49:23', 'fit_val_loss': 0.18792134913571754, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 1, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 8, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '510', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 04:57:58', 'fit_train_loss': 0.1159369017247249, 'dropout': 0.2, 'fit_stopped_epoch3': 5, 'path_model': '/mnt/seals/models/24/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 04:57:56', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 17, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 04:57:53', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 496007, 'fit_test_acc': 0.5759796113411915, 'layer_2_size': 128, 'fit_train_acc': 0.953182516428402, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9179952076248398, 'pooling': 'max', 'model_id': 24, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 04:58:00,194 [MainThread  ] [INFO ]  model 24 test acc: 0.5759796113411915\n",
      "2019-01-20 04:58:00,196 [MainThread  ] [INFO ]  Begin experiment for model_id=25\n",
      "2019-01-20 04:58:00,197 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 25, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:58:01,132 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 04:58:01,133 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 338us/step - loss: 0.1902 - acc: 0.9240 - val_loss: 0.2340 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88789, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1648 - acc: 0.9328 - val_loss: 0.2167 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88789 to 0.90308, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1529 - acc: 0.9386 - val_loss: 0.2064 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90308 to 0.90911, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1466 - acc: 0.9409 - val_loss: 0.1817 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90911 to 0.91833, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1420 - acc: 0.9427 - val_loss: 0.2073 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91833\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1443 - acc: 0.9417 - val_loss: 0.2120 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91833\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1408 - acc: 0.9437 - val_loss: 0.1949 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91833\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1407 - acc: 0.9437 - val_loss: 0.1874 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91833 to 0.92407, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1390 - acc: 0.9442 - val_loss: 0.1895 - val_acc: 0.9258\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92407 to 0.92581, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1411 - acc: 0.9434 - val_loss: 0.2069 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92581\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1442 - acc: 0.9422 - val_loss: 0.1957 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92581\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1443 - acc: 0.9425 - val_loss: 0.2224 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92581\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1401 - acc: 0.9440 - val_loss: 0.1845 - val_acc: 0.9248\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92581\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1384 - acc: 0.9449 - val_loss: 0.1844 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92581\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 338us/step - loss: 0.1242 - acc: 0.9500 - val_loss: 0.1893 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91775, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1221 - acc: 0.9502 - val_loss: 0.1775 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91775 to 0.92541, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1189 - acc: 0.9517 - val_loss: 0.1917 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92541\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1174 - acc: 0.9517 - val_loss: 0.1844 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92541\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1170 - acc: 0.9523 - val_loss: 0.1823 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92541\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1161 - acc: 0.9528 - val_loss: 0.1849 - val_acc: 0.9195\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92541\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1154 - acc: 0.9530 - val_loss: 0.1862 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92541\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 21s 341us/step - loss: 0.1185 - acc: 0.9520 - val_loss: 0.1855 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91969, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1179 - acc: 0.9522 - val_loss: 0.1856 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91969\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1179 - acc: 0.9520 - val_loss: 0.1863 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91969\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1172 - acc: 0.9525 - val_loss: 0.1839 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91969 to 0.91987, saving model to /mnt/seals/models/25/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1168 - acc: 0.9524 - val_loss: 0.1848 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91987\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1169 - acc: 0.9523 - val_loss: 0.1878 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91987\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1165 - acc: 0.9523 - val_loss: 0.1851 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91987\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1170 - acc: 0.9521 - val_loss: 0.1872 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91987\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1168 - acc: 0.9526 - val_loss: 0.1863 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91987\n",
      "3139/3139 [==============================] - 2s 699us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:06:13,311 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 04:58:01', 'fit_val_loss': 0.18625410711230186, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 8, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 1, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '484', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 05:06:11', 'fit_train_loss': 0.1178723910997535, 'dropout': 0.2, 'fit_stopped_epoch3': 3, 'path_model': '/mnt/seals/models/25/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 05:06:09', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 15, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 05:06:06', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 461191, 'fit_test_acc': 0.5813953488372092, 'layer_2_size': 128, 'fit_train_acc': 0.9520037694650312, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9186631845417166, 'pooling': 'max', 'model_id': 25, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 05:06:13,312 [MainThread  ] [INFO ]  model 25 test acc: 0.5813953488372092\n",
      "2019-01-20 05:06:13,314 [MainThread  ] [INFO ]  Begin experiment for model_id=26\n",
      "2019-01-20 05:06:13,316 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 26, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:06:14,244 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 05:06:14,245 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 21s 340us/step - loss: 0.1975 - acc: 0.9206 - val_loss: 0.2090 - val_acc: 0.8981\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89807, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1657 - acc: 0.9318 - val_loss: 0.2092 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89807 to 0.90165, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1585 - acc: 0.9344 - val_loss: 0.2033 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90165 to 0.90795, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1517 - acc: 0.9375 - val_loss: 0.2299 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90795\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1492 - acc: 0.9392 - val_loss: 0.2030 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90795 to 0.90951, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1449 - acc: 0.9410 - val_loss: 0.2003 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90951\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1452 - acc: 0.9401 - val_loss: 0.1813 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.90951 to 0.91695, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1440 - acc: 0.9412 - val_loss: 0.1958 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91695\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1393 - acc: 0.9432 - val_loss: 0.1781 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91695 to 0.92169, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1385 - acc: 0.9434 - val_loss: 0.1907 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92169\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1384 - acc: 0.9438 - val_loss: 0.1847 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92169 to 0.92338, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1394 - acc: 0.9432 - val_loss: 0.1857 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.92338 to 0.92349, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1361 - acc: 0.9450 - val_loss: 0.1828 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92349\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1405 - acc: 0.9426 - val_loss: 0.2008 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92349\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1370 - acc: 0.9444 - val_loss: 0.2059 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92349\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1390 - acc: 0.9429 - val_loss: 0.2001 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92349\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1383 - acc: 0.9434 - val_loss: 0.1948 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92349\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 21s 345us/step - loss: 0.1236 - acc: 0.9490 - val_loss: 0.1893 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91586, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1220 - acc: 0.9495 - val_loss: 0.1921 - val_acc: 0.9110\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91586\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1210 - acc: 0.9503 - val_loss: 0.1842 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91586 to 0.91655, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1199 - acc: 0.9508 - val_loss: 0.1829 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91655 to 0.91706, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1198 - acc: 0.9508 - val_loss: 0.1918 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91706\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1197 - acc: 0.9509 - val_loss: 0.1898 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91706\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1191 - acc: 0.9511 - val_loss: 0.1895 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91706\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1183 - acc: 0.9515 - val_loss: 0.1908 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91706\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1181 - acc: 0.9512 - val_loss: 0.1896 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91706 to 0.91808, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1176 - acc: 0.9515 - val_loss: 0.1902 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91808\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1172 - acc: 0.9518 - val_loss: 0.1919 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91808\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1174 - acc: 0.9517 - val_loss: 0.1836 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.91808 to 0.92269, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1166 - acc: 0.9523 - val_loss: 0.1849 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92269\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1165 - acc: 0.9521 - val_loss: 0.1867 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92269\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1161 - acc: 0.9520 - val_loss: 0.1881 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92269\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1156 - acc: 0.9526 - val_loss: 0.1841 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92269\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1148 - acc: 0.9523 - val_loss: 0.1841 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92269\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 21s 343us/step - loss: 0.1152 - acc: 0.9526 - val_loss: 0.1908 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91608, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1153 - acc: 0.9523 - val_loss: 0.1919 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91608\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1157 - acc: 0.9522 - val_loss: 0.1927 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91608\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 256us/step - loss: 0.1155 - acc: 0.9525 - val_loss: 0.1907 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91608 to 0.91646, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1151 - acc: 0.9526 - val_loss: 0.1890 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91646 to 0.91717, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1145 - acc: 0.9528 - val_loss: 0.1870 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91717 to 0.91913, saving model to /mnt/seals/models/26/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1152 - acc: 0.9525 - val_loss: 0.1909 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91913\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1156 - acc: 0.9523 - val_loss: 0.1901 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91913\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1152 - acc: 0.9525 - val_loss: 0.1908 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91913\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1151 - acc: 0.9527 - val_loss: 0.1910 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91913\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1147 - acc: 0.9530 - val_loss: 0.1914 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91913\n",
      "3139/3139 [==============================] - 2s 727us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:18:18,572 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 05:06:14', 'fit_val_loss': 0.18900290826460964, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 11, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 11, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '716', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 05:18:17', 'fit_train_loss': 0.1150639800535487, 'dropout': 0.2, 'fit_stopped_epoch3': 5, 'path_model': '/mnt/seals/models/26/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 05:18:14', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 30, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 05:18:11', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 443783, 'fit_test_acc': 0.5625995539980886, 'layer_2_size': 128, 'fit_train_acc': 0.9525719252974668, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.917171373480276, 'pooling': 'max', 'model_id': 26, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 05:18:18,574 [MainThread  ] [INFO ]  model 26 test acc: 0.5625995539980886\n",
      "2019-01-20 05:18:18,576 [MainThread  ] [INFO ]  Begin experiment for model_id=27\n",
      "2019-01-20 05:18:18,578 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 27, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:18:19,530 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 05:18:19,532 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 321us/step - loss: 0.1945 - acc: 0.9241 - val_loss: 0.2875 - val_acc: 0.8904\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89036, saving model to /mnt/seals/models/27/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1601 - acc: 0.9354 - val_loss: 0.2301 - val_acc: 0.8951\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89036 to 0.89511, saving model to /mnt/seals/models/27/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1501 - acc: 0.9391 - val_loss: 0.1843 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89511 to 0.91385, saving model to /mnt/seals/models/27/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1481 - acc: 0.9398 - val_loss: 0.1988 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91385\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1468 - acc: 0.9400 - val_loss: 0.1831 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91385 to 0.92009, saving model to /mnt/seals/models/27/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1408 - acc: 0.9431 - val_loss: 0.2007 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92009\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1398 - acc: 0.9436 - val_loss: 0.1930 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92009\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1399 - acc: 0.9431 - val_loss: 0.1873 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92009 to 0.92024, saving model to /mnt/seals/models/27/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1368 - acc: 0.9452 - val_loss: 0.2054 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92024\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1349 - acc: 0.9457 - val_loss: 0.1951 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92024\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1336 - acc: 0.9467 - val_loss: 0.1988 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92024\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1421 - acc: 0.9415 - val_loss: 0.2024 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92024\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1456 - acc: 0.9388 - val_loss: 0.2143 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92024\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 325us/step - loss: 0.1257 - acc: 0.9490 - val_loss: 0.1908 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91517, saving model to /mnt/seals/models/27/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1232 - acc: 0.9503 - val_loss: 0.1787 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91517 to 0.92370, saving model to /mnt/seals/models/27/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1219 - acc: 0.9506 - val_loss: 0.1866 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92370\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1216 - acc: 0.9510 - val_loss: 0.1858 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92370\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1209 - acc: 0.9517 - val_loss: 0.1929 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92370\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1199 - acc: 0.9518 - val_loss: 0.1857 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92370\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1197 - acc: 0.9518 - val_loss: 0.1847 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92370\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 20s 326us/step - loss: 0.1210 - acc: 0.9511 - val_loss: 0.1840 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91911, saving model to /mnt/seals/models/27/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1208 - acc: 0.9513 - val_loss: 0.1859 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91911\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1208 - acc: 0.9513 - val_loss: 0.1856 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91911\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1206 - acc: 0.9514 - val_loss: 0.1849 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91911\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1204 - acc: 0.9518 - val_loss: 0.1831 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91911 to 0.92060, saving model to /mnt/seals/models/27/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1202 - acc: 0.9516 - val_loss: 0.1864 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92060\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1199 - acc: 0.9517 - val_loss: 0.1872 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92060\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1201 - acc: 0.9514 - val_loss: 0.1846 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92060\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1203 - acc: 0.9515 - val_loss: 0.1862 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92060\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1200 - acc: 0.9518 - val_loss: 0.1845 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92060\n",
      "3139/3139 [==============================] - 2s 751us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:25:57,748 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 05:18:20', 'fit_val_loss': 0.184927174686791, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 7, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 1, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '450', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 05:25:56', 'fit_train_loss': 0.12060159623693223, 'dropout': 0.2, 'fit_stopped_epoch3': 4, 'path_model': '/mnt/seals/models/27/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 05:25:53', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 15, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 05:25:50', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 427271, 'fit_test_acc': 0.5543166613571201, 'layer_2_size': 128, 'fit_train_acc': 0.9514356134142311, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.919108497828914, 'pooling': 'max', 'model_id': 27, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 05:25:57,750 [MainThread  ] [INFO ]  model 27 test acc: 0.5543166613571201\n",
      "2019-01-20 05:25:57,752 [MainThread  ] [INFO ]  Begin experiment for model_id=28\n",
      "2019-01-20 05:25:57,754 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 28, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:25:58,680 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 05:25:58,681 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 298us/step - loss: 0.2150 - acc: 0.9267 - val_loss: 0.2165 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89871, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1553 - acc: 0.9367 - val_loss: 0.2507 - val_acc: 0.8951\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89871\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1450 - acc: 0.9406 - val_loss: 0.2211 - val_acc: 0.8989\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89871 to 0.89887, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1414 - acc: 0.9422 - val_loss: 0.2014 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89887 to 0.90869, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 207us/step - loss: 0.1352 - acc: 0.9445 - val_loss: 0.1758 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90869 to 0.92565, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1329 - acc: 0.9461 - val_loss: 0.1994 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92565\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1300 - acc: 0.9475 - val_loss: 0.1976 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92565\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1284 - acc: 0.9480 - val_loss: 0.1957 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92565\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1256 - acc: 0.9493 - val_loss: 0.1961 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92565\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1238 - acc: 0.9501 - val_loss: 0.2099 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92565\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 301us/step - loss: 0.1199 - acc: 0.9511 - val_loss: 0.2065 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91481, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 207us/step - loss: 0.1174 - acc: 0.9525 - val_loss: 0.2030 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91481\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.1161 - acc: 0.9527 - val_loss: 0.2189 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91481\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1150 - acc: 0.9533 - val_loss: 0.2056 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91481\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1149 - acc: 0.9533 - val_loss: 0.2001 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91481 to 0.91666, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1139 - acc: 0.9538 - val_loss: 0.1954 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91666 to 0.91922, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1128 - acc: 0.9542 - val_loss: 0.1898 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91922 to 0.92180, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1120 - acc: 0.9543 - val_loss: 0.1917 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92180 to 0.92439, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1116 - acc: 0.9544 - val_loss: 0.1941 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92439\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1113 - acc: 0.9548 - val_loss: 0.1989 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92439\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1101 - acc: 0.9551 - val_loss: 0.2005 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92439\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1098 - acc: 0.9556 - val_loss: 0.2039 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92439\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1088 - acc: 0.9559 - val_loss: 0.1927 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92439 to 0.92492, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1091 - acc: 0.9556 - val_loss: 0.2056 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92492\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1080 - acc: 0.9560 - val_loss: 0.2054 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92492\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1073 - acc: 0.9563 - val_loss: 0.2192 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92492\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1074 - acc: 0.9563 - val_loss: 0.1984 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92492\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 12s 206us/step - loss: 0.1068 - acc: 0.9566 - val_loss: 0.1982 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92492\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 306us/step - loss: 0.1072 - acc: 0.9563 - val_loss: 0.1984 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92149, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1071 - acc: 0.9564 - val_loss: 0.2005 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92149\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1068 - acc: 0.9566 - val_loss: 0.1947 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92149 to 0.92314, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 207us/step - loss: 0.1067 - acc: 0.9566 - val_loss: 0.1997 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92314\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 207us/step - loss: 0.1071 - acc: 0.9567 - val_loss: 0.2018 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92314\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1065 - acc: 0.9566 - val_loss: 0.1966 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92314 to 0.92325, saving model to /mnt/seals/models/28/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1069 - acc: 0.9568 - val_loss: 0.1993 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92325\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 207us/step - loss: 0.1063 - acc: 0.9568 - val_loss: 0.1979 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92325\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 207us/step - loss: 0.1066 - acc: 0.9566 - val_loss: 0.2017 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92325\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1063 - acc: 0.9567 - val_loss: 0.2030 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92325\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1061 - acc: 0.9570 - val_loss: 0.2026 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92325\n",
      "3139/3139 [==============================] - 2s 770us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:34:49,902 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 05:25:59', 'fit_val_loss': 0.20181902812008845, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 4, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 12, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '523', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 05:34:48', 'fit_train_loss': 0.107105643046374, 'dropout': 0.2, 'fit_stopped_epoch3': 5, 'path_model': '/mnt/seals/models/28/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 05:34:45', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 24, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 05:34:42', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 395271, 'fit_test_acc': 0.5543166613571201, 'layer_2_size': 0, 'fit_train_acc': 0.9566739664704602, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9214018700723339, 'pooling': 'max', 'model_id': 28, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 05:34:49,904 [MainThread  ] [INFO ]  model 28 test acc: 0.5543166613571201\n",
      "2019-01-20 05:34:49,905 [MainThread  ] [INFO ]  Begin experiment for model_id=29\n",
      "2019-01-20 05:34:49,907 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 29, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:34:50,852 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 05:34:50,853 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 308us/step - loss: 0.2025 - acc: 0.9263 - val_loss: 0.2074 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89729, saving model to /mnt/seals/models/29/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1506 - acc: 0.9388 - val_loss: 0.1960 - val_acc: 0.9059\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89729 to 0.90588, saving model to /mnt/seals/models/29/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1430 - acc: 0.9417 - val_loss: 0.1755 - val_acc: 0.9285\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90588 to 0.92846, saving model to /mnt/seals/models/29/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 207us/step - loss: 0.1361 - acc: 0.9444 - val_loss: 0.1795 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92846\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1338 - acc: 0.9452 - val_loss: 0.2505 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92846\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1298 - acc: 0.9469 - val_loss: 0.1708 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92846 to 0.93062, saving model to /mnt/seals/models/29/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1273 - acc: 0.9485 - val_loss: 0.1915 - val_acc: 0.9240\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93062\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1251 - acc: 0.9487 - val_loss: 0.2395 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93062\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1245 - acc: 0.9490 - val_loss: 0.2310 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93062\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1218 - acc: 0.9502 - val_loss: 0.2342 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93062\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1205 - acc: 0.9508 - val_loss: 0.1845 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93062\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 303us/step - loss: 0.1156 - acc: 0.9527 - val_loss: 0.1921 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91788, saving model to /mnt/seals/models/29/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1138 - acc: 0.9530 - val_loss: 0.1928 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91788\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1130 - acc: 0.9534 - val_loss: 0.1932 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91788\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1120 - acc: 0.9541 - val_loss: 0.1961 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91788\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1120 - acc: 0.9541 - val_loss: 0.1869 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91788 to 0.92274, saving model to /mnt/seals/models/29/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1110 - acc: 0.9544 - val_loss: 0.1942 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92274\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1101 - acc: 0.9548 - val_loss: 0.1929 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92274\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1094 - acc: 0.9552 - val_loss: 0.2006 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92274\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1094 - acc: 0.9551 - val_loss: 0.2033 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92274\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1089 - acc: 0.9550 - val_loss: 0.2109 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92274\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 309us/step - loss: 0.1095 - acc: 0.9550 - val_loss: 0.1929 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91969, saving model to /mnt/seals/models/29/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1097 - acc: 0.9551 - val_loss: 0.1913 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91969 to 0.92031, saving model to /mnt/seals/models/29/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1095 - acc: 0.9554 - val_loss: 0.1932 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92031\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1096 - acc: 0.9551 - val_loss: 0.1957 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92031\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1093 - acc: 0.9553 - val_loss: 0.1952 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92031\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1095 - acc: 0.9551 - val_loss: 0.1937 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92031\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1090 - acc: 0.9552 - val_loss: 0.1925 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.92031 to 0.92118, saving model to /mnt/seals/models/29/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1091 - acc: 0.9553 - val_loss: 0.1917 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92118\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1083 - acc: 0.9556 - val_loss: 0.1928 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92118\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 215us/step - loss: 0.1087 - acc: 0.9556 - val_loss: 0.1942 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92118\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1087 - acc: 0.9554 - val_loss: 0.1971 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92118\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1088 - acc: 0.9556 - val_loss: 0.1964 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92118\n",
      "3139/3139 [==============================] - 3s 844us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:42:29,539 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 05:34:51', 'fit_val_loss': 0.19373041714664707, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 5, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 4, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '450', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 05:42:28', 'fit_train_loss': 0.10947010506207057, 'dropout': 0.2, 'fit_stopped_epoch3': 6, 'path_model': '/mnt/seals/models/29/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 05:42:25', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 18, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 05:42:21', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 395271, 'fit_test_acc': 0.5712010194329404, 'layer_2_size': 0, 'fit_train_acc': 0.9551062320617114, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.920110458745029, 'pooling': 'max', 'model_id': 29, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 05:42:29,541 [MainThread  ] [INFO ]  model 29 test acc: 0.5712010194329404\n",
      "2019-01-20 05:42:29,543 [MainThread  ] [INFO ]  Begin experiment for model_id=30\n",
      "2019-01-20 05:42:29,544 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 30, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:42:30,483 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 05:42:30,484 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 18s 304us/step - loss: 0.1954 - acc: 0.9275 - val_loss: 0.1889 - val_acc: 0.9110\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91105, saving model to /mnt/seals/models/30/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 207us/step - loss: 0.1514 - acc: 0.9383 - val_loss: 0.2180 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91105\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1433 - acc: 0.9416 - val_loss: 0.2133 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91105\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1381 - acc: 0.9439 - val_loss: 0.1976 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91105\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1349 - acc: 0.9453 - val_loss: 0.1725 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91105 to 0.93040, saving model to /mnt/seals/models/30/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1314 - acc: 0.9464 - val_loss: 0.2036 - val_acc: 0.9101\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93040\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1287 - acc: 0.9475 - val_loss: 0.2870 - val_acc: 0.8944\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93040\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 207us/step - loss: 0.1274 - acc: 0.9483 - val_loss: 0.2103 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93040\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1239 - acc: 0.9495 - val_loss: 0.2278 - val_acc: 0.9005\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93040\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1227 - acc: 0.9497 - val_loss: 0.1994 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93040\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 308us/step - loss: 0.1188 - acc: 0.9516 - val_loss: 0.2188 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90475, saving model to /mnt/seals/models/30/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1160 - acc: 0.9529 - val_loss: 0.1923 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90475 to 0.91675, saving model to /mnt/seals/models/30/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1145 - acc: 0.9535 - val_loss: 0.2050 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91675\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1137 - acc: 0.9538 - val_loss: 0.2030 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91675\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1128 - acc: 0.9541 - val_loss: 0.1963 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91675\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1118 - acc: 0.9547 - val_loss: 0.1936 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91675 to 0.91724, saving model to /mnt/seals/models/30/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1108 - acc: 0.9550 - val_loss: 0.1977 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91724\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1110 - acc: 0.9550 - val_loss: 0.2025 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91724\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1097 - acc: 0.9553 - val_loss: 0.2063 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91724\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1093 - acc: 0.9553 - val_loss: 0.2074 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91724\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1090 - acc: 0.9552 - val_loss: 0.1959 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.91724 to 0.92011, saving model to /mnt/seals/models/30/model.h5\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1084 - acc: 0.9557 - val_loss: 0.2145 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92011\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1079 - acc: 0.9561 - val_loss: 0.1983 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92011\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1076 - acc: 0.9560 - val_loss: 0.2130 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92011\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1065 - acc: 0.9566 - val_loss: 0.2052 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92011\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1051 - acc: 0.9569 - val_loss: 0.1997 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.92011 to 0.92156, saving model to /mnt/seals/models/30/model.h5\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1053 - acc: 0.9569 - val_loss: 0.2066 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92156\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1051 - acc: 0.9572 - val_loss: 0.2197 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92156\n",
      "Epoch 19/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1049 - acc: 0.9571 - val_loss: 0.2191 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92156\n",
      "Epoch 20/30\n",
      "60597/60597 [==============================] - 13s 208us/step - loss: 0.1038 - acc: 0.9579 - val_loss: 0.2071 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92156\n",
      "Epoch 21/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1031 - acc: 0.9577 - val_loss: 0.2015 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92156\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 314us/step - loss: 0.1039 - acc: 0.9576 - val_loss: 0.2084 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91619, saving model to /mnt/seals/models/30/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1040 - acc: 0.9573 - val_loss: 0.2118 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91619\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1035 - acc: 0.9578 - val_loss: 0.2134 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91619\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1036 - acc: 0.9576 - val_loss: 0.2142 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91619\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1040 - acc: 0.9573 - val_loss: 0.2127 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91619\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1031 - acc: 0.9581 - val_loss: 0.2141 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91619\n",
      "3139/3139 [==============================] - 3s 806us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:51:00,795 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 05:42:31', 'fit_val_loss': 0.20521113436269642, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 4, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 15, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '503', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 05:50:59', 'fit_train_loss': 0.1064994235919553, 'dropout': 0.2, 'fit_stopped_epoch3': 0, 'path_model': '/mnt/seals/models/30/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 05:50:56', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 22, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 05:50:54', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 395271, 'fit_test_acc': 0.567696718700223, 'layer_2_size': 0, 'fit_train_acc': 0.9565537342427637, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9194202194190085, 'pooling': 'max', 'model_id': 30, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 05:51:00,796 [MainThread  ] [INFO ]  model 30 test acc: 0.567696718700223\n",
      "2019-01-20 05:51:00,799 [MainThread  ] [INFO ]  Begin experiment for model_id=31\n",
      "2019-01-20 05:51:00,800 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 31, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 256, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:51:01,750 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 05:51:01,751 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 311us/step - loss: 0.1944 - acc: 0.9284 - val_loss: 0.2116 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89279, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1495 - acc: 0.9387 - val_loss: 0.1814 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89279 to 0.92216, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1424 - acc: 0.9422 - val_loss: 0.2001 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92216\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1366 - acc: 0.9444 - val_loss: 0.2146 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92216\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1321 - acc: 0.9462 - val_loss: 0.2061 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92216\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1293 - acc: 0.9477 - val_loss: 0.2160 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92216\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1251 - acc: 0.9492 - val_loss: 0.1881 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92216\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 313us/step - loss: 0.1290 - acc: 0.9475 - val_loss: 0.1980 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90949, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1257 - acc: 0.9492 - val_loss: 0.1844 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90949 to 0.91661, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1233 - acc: 0.9498 - val_loss: 0.1977 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91661\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1206 - acc: 0.9508 - val_loss: 0.1894 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91661\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1192 - acc: 0.9513 - val_loss: 0.1917 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91661 to 0.91675, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1169 - acc: 0.9522 - val_loss: 0.1874 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91675 to 0.92071, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 210us/step - loss: 0.1163 - acc: 0.9528 - val_loss: 0.1948 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92071\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1151 - acc: 0.9529 - val_loss: 0.1929 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92071\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1135 - acc: 0.9537 - val_loss: 0.1918 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92071\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1125 - acc: 0.9542 - val_loss: 0.1878 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92071 to 0.92309, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1110 - acc: 0.9545 - val_loss: 0.2125 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92309\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1105 - acc: 0.9550 - val_loss: 0.1874 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92309\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1089 - acc: 0.9557 - val_loss: 0.1874 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92309 to 0.92390, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1080 - acc: 0.9562 - val_loss: 0.2035 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92390\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1075 - acc: 0.9563 - val_loss: 0.2037 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92390\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 13s 214us/step - loss: 0.1065 - acc: 0.9567 - val_loss: 0.1973 - val_acc: 0.9226\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92390\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1056 - acc: 0.9568 - val_loss: 0.2046 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92390\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1051 - acc: 0.9570 - val_loss: 0.1988 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92390\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 19s 313us/step - loss: 0.1061 - acc: 0.9567 - val_loss: 0.1969 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91842, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1059 - acc: 0.9570 - val_loss: 0.2009 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91842\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1054 - acc: 0.9571 - val_loss: 0.1995 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91842\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1053 - acc: 0.9571 - val_loss: 0.2024 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91842\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1050 - acc: 0.9572 - val_loss: 0.1973 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91842\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1053 - acc: 0.9571 - val_loss: 0.1969 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91842 to 0.91860, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1052 - acc: 0.9572 - val_loss: 0.1947 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91860 to 0.91920, saving model to /mnt/seals/models/31/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 13s 209us/step - loss: 0.1047 - acc: 0.9575 - val_loss: 0.2010 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91920\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1049 - acc: 0.9573 - val_loss: 0.2011 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91920\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1045 - acc: 0.9575 - val_loss: 0.1975 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91920\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 13s 213us/step - loss: 0.1045 - acc: 0.9575 - val_loss: 0.1980 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91920\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.1045 - acc: 0.9572 - val_loss: 0.2030 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.91920\n",
      "3139/3139 [==============================] - 3s 823us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:59:38,113 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 05:51:02', 'fit_val_loss': 0.19687341829933727, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 1, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 12, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '507', 'layer_1_size': 256, 'fit_dt_test_end': '2019-01-20 05:59:36', 'fit_train_loss': 0.1052887635156597, 'dropout': 0.2, 'fit_stopped_epoch3': 6, 'path_model': '/mnt/seals/models/31/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 05:59:34', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 22, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 05:59:30', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 395271, 'fit_test_acc': 0.5696081554635234, 'layer_2_size': 0, 'fit_train_acc': 0.9571407507348695, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9185963854230847, 'pooling': 'max', 'model_id': 31, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 05:59:38,114 [MainThread  ] [INFO ]  model 31 test acc: 0.5696081554635234\n",
      "2019-01-20 05:59:38,116 [MainThread  ] [INFO ]  Begin experiment for model_id=32\n",
      "2019-01-20 05:59:38,117 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 32, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:59:39,063 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 05:59:39,064 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 360us/step - loss: 0.1972 - acc: 0.9208 - val_loss: 0.1917 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91419, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1816 - acc: 0.9254 - val_loss: 0.2153 - val_acc: 0.8984\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91419\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1723 - acc: 0.9309 - val_loss: 0.2488 - val_acc: 0.8967\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91419\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1649 - acc: 0.9331 - val_loss: 0.2344 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91419\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1586 - acc: 0.9361 - val_loss: 0.1854 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91419 to 0.91973, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1558 - acc: 0.9373 - val_loss: 0.2320 - val_acc: 0.8984\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91973\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1592 - acc: 0.9350 - val_loss: 0.2130 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91973\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 256us/step - loss: 0.1695 - acc: 0.9302 - val_loss: 0.2145 - val_acc: 0.9059\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91973\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1659 - acc: 0.9319 - val_loss: 0.2001 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91973\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1642 - acc: 0.9326 - val_loss: 0.1832 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.91973 to 0.92078, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1638 - acc: 0.9328 - val_loss: 0.1933 - val_acc: 0.9164\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92078\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1612 - acc: 0.9343 - val_loss: 0.2244 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92078\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1660 - acc: 0.9311 - val_loss: 0.2015 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92078\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1650 - acc: 0.9315 - val_loss: 0.1949 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92078\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1595 - acc: 0.9345 - val_loss: 0.2172 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92078\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 368us/step - loss: 0.1523 - acc: 0.9370 - val_loss: 0.1779 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92441, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1491 - acc: 0.9381 - val_loss: 0.1855 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92441 to 0.92514, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1469 - acc: 0.9394 - val_loss: 0.1807 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92514 to 0.92797, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1467 - acc: 0.9398 - val_loss: 0.1841 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92797\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1451 - acc: 0.9403 - val_loss: 0.1794 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92797 to 0.92944, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1453 - acc: 0.9405 - val_loss: 0.1851 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92944\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1439 - acc: 0.9413 - val_loss: 0.1877 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92944\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1430 - acc: 0.9414 - val_loss: 0.1854 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92944\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1422 - acc: 0.9416 - val_loss: 0.1831 - val_acc: 0.9272\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92944\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1416 - acc: 0.9421 - val_loss: 0.1868 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92944\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 369us/step - loss: 0.1438 - acc: 0.9411 - val_loss: 0.1842 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92630, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1432 - acc: 0.9415 - val_loss: 0.1829 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92630 to 0.92675, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1435 - acc: 0.9410 - val_loss: 0.1848 - val_acc: 0.9258\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92675\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1428 - acc: 0.9414 - val_loss: 0.1823 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92675 to 0.92681, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1425 - acc: 0.9417 - val_loss: 0.1824 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92681 to 0.92732, saving model to /mnt/seals/models/32/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1423 - acc: 0.9415 - val_loss: 0.1816 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92732\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1427 - acc: 0.9414 - val_loss: 0.1842 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92732\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1433 - acc: 0.9411 - val_loss: 0.1828 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92732\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1425 - acc: 0.9416 - val_loss: 0.1841 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92732\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1423 - acc: 0.9419 - val_loss: 0.1848 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92732\n",
      "3139/3139 [==============================] - 3s 932us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:09:31,775 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 05:59:39', 'fit_val_loss': 0.18234880851985807, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 9, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 4, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '584', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 06:09:30', 'fit_train_loss': 0.14281991820423462, 'dropout': 0.2, 'fit_stopped_epoch3': 4, 'path_model': '/mnt/seals/models/32/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 06:09:27', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 20, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 06:09:23', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 529031, 'fit_test_acc': 0.5460337687161516, 'layer_2_size': 512, 'fit_train_acc': 0.9413691102275106, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9268124490010173, 'pooling': 'max', 'model_id': 32, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 06:09:31,777 [MainThread  ] [INFO ]  model 32 test acc: 0.5460337687161516\n",
      "2019-01-20 06:09:31,780 [MainThread  ] [INFO ]  Begin experiment for model_id=33\n",
      "2019-01-20 06:09:31,781 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 33, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:09:32,740 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 06:09:32,741 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 355us/step - loss: 0.1933 - acc: 0.9232 - val_loss: 0.2176 - val_acc: 0.8904\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89036, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1657 - acc: 0.9333 - val_loss: 0.2413 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89036 to 0.89898, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1586 - acc: 0.9362 - val_loss: 0.1998 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89898 to 0.90945, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1521 - acc: 0.9386 - val_loss: 0.1952 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90945 to 0.91091, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1548 - acc: 0.9379 - val_loss: 0.2005 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91091 to 0.91350, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1485 - acc: 0.9413 - val_loss: 0.2237 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91350\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1470 - acc: 0.9416 - val_loss: 0.1773 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91350 to 0.92169, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1436 - acc: 0.9425 - val_loss: 0.1786 - val_acc: 0.9272\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92169 to 0.92719, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1486 - acc: 0.9407 - val_loss: 0.1926 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92719\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1459 - acc: 0.9417 - val_loss: 0.2402 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92719\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1498 - acc: 0.9405 - val_loss: 0.1887 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92719\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1512 - acc: 0.9399 - val_loss: 0.1917 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92719\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1494 - acc: 0.9406 - val_loss: 0.1739 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92719\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 368us/step - loss: 0.1308 - acc: 0.9476 - val_loss: 0.1794 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92352, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1282 - acc: 0.9486 - val_loss: 0.1936 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92352\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1282 - acc: 0.9486 - val_loss: 0.1766 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92352 to 0.92494, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1263 - acc: 0.9495 - val_loss: 0.1835 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92494\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 256us/step - loss: 0.1265 - acc: 0.9489 - val_loss: 0.1787 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92494\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 256us/step - loss: 0.1252 - acc: 0.9495 - val_loss: 0.1752 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92494\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1244 - acc: 0.9497 - val_loss: 0.1790 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92494\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1240 - acc: 0.9499 - val_loss: 0.1809 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92494\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 365us/step - loss: 0.1258 - acc: 0.9494 - val_loss: 0.1800 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92338, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1258 - acc: 0.9495 - val_loss: 0.1795 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92338 to 0.92419, saving model to /mnt/seals/models/33/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1250 - acc: 0.9500 - val_loss: 0.1792 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92419\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1260 - acc: 0.9495 - val_loss: 0.1803 - val_acc: 0.9230\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92419\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1259 - acc: 0.9492 - val_loss: 0.1797 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92419\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1257 - acc: 0.9496 - val_loss: 0.1794 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92419\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1247 - acc: 0.9499 - val_loss: 0.1795 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92419\n",
      "3139/3139 [==============================] - 3s 954us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:17:31,404 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 06:09:33', 'fit_val_loss': 0.17997983536518125, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 7, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 2, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '469', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 06:17:29', 'fit_train_loss': 0.1257827334420851, 'dropout': 0.2, 'fit_stopped_epoch3': 1, 'path_model': '/mnt/seals/models/33/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 06:17:26', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 13, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 06:17:22', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 395911, 'fit_test_acc': 0.5747053201656578, 'layer_2_size': 512, 'fit_train_acc': 0.9493822351112569, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9233835251848597, 'pooling': 'max', 'model_id': 33, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 06:17:31,405 [MainThread  ] [INFO ]  model 33 test acc: 0.5747053201656578\n",
      "2019-01-20 06:17:31,406 [MainThread  ] [INFO ]  Begin experiment for model_id=34\n",
      "2019-01-20 06:17:31,408 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 34, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:17:32,328 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 06:17:32,329 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 367us/step - loss: 0.1968 - acc: 0.9203 - val_loss: 0.1852 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92490, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 254us/step - loss: 0.1765 - acc: 0.9262 - val_loss: 0.2087 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92490\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 256us/step - loss: 0.1668 - acc: 0.9301 - val_loss: 0.2782 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92490\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1562 - acc: 0.9370 - val_loss: 0.2297 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92490\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 256us/step - loss: 0.1641 - acc: 0.9318 - val_loss: 0.2172 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92490\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1600 - acc: 0.9333 - val_loss: 0.1959 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92490\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 374us/step - loss: 0.1594 - acc: 0.9342 - val_loss: 0.2312 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89448, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1529 - acc: 0.9374 - val_loss: 0.2208 - val_acc: 0.8921\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89448\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1488 - acc: 0.9392 - val_loss: 0.2165 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89448 to 0.90123, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1444 - acc: 0.9413 - val_loss: 0.2094 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90123 to 0.90150, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 256us/step - loss: 0.1412 - acc: 0.9427 - val_loss: 0.2126 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90150\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1387 - acc: 0.9436 - val_loss: 0.2015 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.90150 to 0.90893, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1373 - acc: 0.9442 - val_loss: 0.2044 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.90893\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1347 - acc: 0.9456 - val_loss: 0.1989 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.90893 to 0.90976, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 263us/step - loss: 0.1332 - acc: 0.9461 - val_loss: 0.1958 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90976\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1323 - acc: 0.9466 - val_loss: 0.1917 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90976\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1302 - acc: 0.9475 - val_loss: 0.2001 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.90976\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1288 - acc: 0.9480 - val_loss: 0.1963 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.90976 to 0.91194, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1276 - acc: 0.9485 - val_loss: 0.2109 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.91194\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1259 - acc: 0.9489 - val_loss: 0.1894 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.91194 to 0.91238, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1246 - acc: 0.9496 - val_loss: 0.1997 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.91238\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1240 - acc: 0.9498 - val_loss: 0.1985 - val_acc: 0.9066\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.91238\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1232 - acc: 0.9505 - val_loss: 0.1993 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.91238\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1221 - acc: 0.9507 - val_loss: 0.2007 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.91238\n",
      "Epoch 19/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1211 - acc: 0.9512 - val_loss: 0.1940 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.91238 to 0.91619, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 20/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1205 - acc: 0.9513 - val_loss: 0.1977 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.91619\n",
      "Epoch 21/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1195 - acc: 0.9520 - val_loss: 0.1908 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.91619\n",
      "Epoch 22/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1184 - acc: 0.9523 - val_loss: 0.1988 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.91619\n",
      "Epoch 23/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1183 - acc: 0.9522 - val_loss: 0.2080 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.91619\n",
      "Epoch 24/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1177 - acc: 0.9524 - val_loss: 0.1843 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.91619 to 0.91935, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 25/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1166 - acc: 0.9529 - val_loss: 0.2032 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.91935\n",
      "Epoch 26/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1164 - acc: 0.9531 - val_loss: 0.1989 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.91935\n",
      "Epoch 27/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1149 - acc: 0.9535 - val_loss: 0.2192 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.91935\n",
      "Epoch 28/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1147 - acc: 0.9533 - val_loss: 0.1940 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.91935\n",
      "Epoch 29/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1136 - acc: 0.9541 - val_loss: 0.1970 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.91935\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 367us/step - loss: 0.1132 - acc: 0.9543 - val_loss: 0.2011 - val_acc: 0.9112\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91123, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 255us/step - loss: 0.1129 - acc: 0.9544 - val_loss: 0.1967 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91123 to 0.91341, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1125 - acc: 0.9545 - val_loss: 0.1972 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91341 to 0.91399, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1125 - acc: 0.9545 - val_loss: 0.1966 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91399\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1127 - acc: 0.9545 - val_loss: 0.1960 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91399\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1120 - acc: 0.9545 - val_loss: 0.1975 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91399\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1123 - acc: 0.9546 - val_loss: 0.1952 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91399 to 0.91459, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1119 - acc: 0.9546 - val_loss: 0.1967 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91459\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1118 - acc: 0.9550 - val_loss: 0.2011 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91459 to 0.91497, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1121 - acc: 0.9549 - val_loss: 0.1978 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91497\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1117 - acc: 0.9548 - val_loss: 0.2011 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91497\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1117 - acc: 0.9550 - val_loss: 0.1973 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.91497\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1113 - acc: 0.9551 - val_loss: 0.1969 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.91497\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1114 - acc: 0.9549 - val_loss: 0.1982 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.91497 to 0.91532, saving model to /mnt/seals/models/34/model.h5\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1110 - acc: 0.9550 - val_loss: 0.1979 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.91532\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1108 - acc: 0.9553 - val_loss: 0.1987 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.91532\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1103 - acc: 0.9555 - val_loss: 0.1955 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.91532\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1108 - acc: 0.9552 - val_loss: 0.2010 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.91532\n",
      "Epoch 19/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1105 - acc: 0.9556 - val_loss: 0.1953 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.91532\n",
      "3139/3139 [==============================] - 3s 934us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:32:24,373 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 06:17:33', 'fit_val_loss': 0.19694810912496133, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 0, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 23, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '884', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 06:32:22', 'fit_train_loss': 0.11128564363200942, 'dropout': 0.2, 'fit_stopped_epoch3': 13, 'path_model': '/mnt/seals/models/34/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 06:32:19', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 39, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 06:32:17', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 329351, 'fit_test_acc': 0.5543166613571201, 'layer_2_size': 512, 'fit_train_acc': 0.9550920877900948, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.914922534973544, 'pooling': 'max', 'model_id': 34, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 06:32:24,375 [MainThread  ] [INFO ]  model 34 test acc: 0.5543166613571201\n",
      "2019-01-20 06:32:24,377 [MainThread  ] [INFO ]  Begin experiment for model_id=35\n",
      "2019-01-20 06:32:24,378 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 35, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 512, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:32:25,320 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 06:32:25,321 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 21s 351us/step - loss: 0.1973 - acc: 0.9210 - val_loss: 0.1933 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91036, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1702 - acc: 0.9316 - val_loss: 0.1965 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91036 to 0.91232, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1617 - acc: 0.9348 - val_loss: 0.1854 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91232 to 0.91521, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1573 - acc: 0.9367 - val_loss: 0.2042 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91521\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1529 - acc: 0.9388 - val_loss: 0.2031 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91521\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1499 - acc: 0.9394 - val_loss: 0.1872 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91521 to 0.91889, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1478 - acc: 0.9406 - val_loss: 0.1838 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91889 to 0.92650, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1457 - acc: 0.9410 - val_loss: 0.1793 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92650\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1446 - acc: 0.9421 - val_loss: 0.1843 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92650\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1440 - acc: 0.9426 - val_loss: 0.1904 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92650\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1429 - acc: 0.9428 - val_loss: 0.1827 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92650\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1393 - acc: 0.9441 - val_loss: 0.2029 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92650\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 355us/step - loss: 0.1346 - acc: 0.9457 - val_loss: 0.1862 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92247, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1317 - acc: 0.9467 - val_loss: 0.1868 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92247\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1312 - acc: 0.9469 - val_loss: 0.1917 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92247\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1294 - acc: 0.9476 - val_loss: 0.1866 - val_acc: 0.9230\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92247 to 0.92303, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1288 - acc: 0.9482 - val_loss: 0.1942 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92303\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 238us/step - loss: 0.1289 - acc: 0.9482 - val_loss: 0.1803 - val_acc: 0.9269\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92303 to 0.92695, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1276 - acc: 0.9486 - val_loss: 0.1814 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92695\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1267 - acc: 0.9489 - val_loss: 0.1919 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92695\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1265 - acc: 0.9489 - val_loss: 0.1905 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92695\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1262 - acc: 0.9495 - val_loss: 0.1883 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92695\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1262 - acc: 0.9495 - val_loss: 0.1874 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92695\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 21s 349us/step - loss: 0.1257 - acc: 0.9496 - val_loss: 0.1877 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91995, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1265 - acc: 0.9491 - val_loss: 0.1865 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91995 to 0.92140, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1256 - acc: 0.9495 - val_loss: 0.1888 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92140\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1255 - acc: 0.9494 - val_loss: 0.1862 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92140 to 0.92216, saving model to /mnt/seals/models/35/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1254 - acc: 0.9496 - val_loss: 0.1842 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92216\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 235us/step - loss: 0.1255 - acc: 0.9493 - val_loss: 0.1873 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92216\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 236us/step - loss: 0.1254 - acc: 0.9497 - val_loss: 0.1861 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92216\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 237us/step - loss: 0.1258 - acc: 0.9492 - val_loss: 0.1852 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92216\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1255 - acc: 0.9496 - val_loss: 0.1867 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92216\n",
      "3139/3139 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:40:49,516 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 06:32:26', 'fit_val_loss': 0.18878080779477546, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 6, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 5, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '495', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 06:40:48', 'fit_train_loss': 0.12561618411556918, 'dropout': 0.2, 'fit_stopped_epoch3': 3, 'path_model': '/mnt/seals/models/35/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 06:40:44', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 17, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 06:40:41', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 266375, 'fit_test_acc': 0.5530423701815865, 'layer_2_size': 512, 'fit_train_acc': 0.9495095399080481, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9202885792736996, 'pooling': 'max', 'model_id': 35, 'fit_dt_test_duration_seconds': '3'}\n",
      "2019-01-20 06:40:49,517 [MainThread  ] [INFO ]  model 35 test acc: 0.5530423701815865\n",
      "2019-01-20 06:40:49,519 [MainThread  ] [INFO ]  Begin experiment for model_id=36\n",
      "2019-01-20 06:40:49,520 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 36, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:40:50,475 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 06:40:50,477 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 377us/step - loss: 0.1923 - acc: 0.9230 - val_loss: 0.2369 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90835, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1644 - acc: 0.9333 - val_loss: 0.1931 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90835 to 0.91319, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1571 - acc: 0.9360 - val_loss: 0.2044 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91319\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1565 - acc: 0.9382 - val_loss: 0.2003 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91319\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1529 - acc: 0.9399 - val_loss: 0.1823 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91319 to 0.91820, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1514 - acc: 0.9404 - val_loss: 0.1952 - val_acc: 0.9269\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91820 to 0.92686, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1509 - acc: 0.9408 - val_loss: 0.1864 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92686\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 256us/step - loss: 0.1464 - acc: 0.9424 - val_loss: 0.2098 - val_acc: 0.9110\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92686\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1465 - acc: 0.9424 - val_loss: 0.1905 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92686\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1448 - acc: 0.9431 - val_loss: 0.1777 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92686\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1431 - acc: 0.9440 - val_loss: 0.1727 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92686 to 0.92844, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 16s 256us/step - loss: 0.1533 - acc: 0.9396 - val_loss: 0.1711 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.92844 to 0.93113, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1500 - acc: 0.9409 - val_loss: 0.1833 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93113\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1443 - acc: 0.9435 - val_loss: 0.1710 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93113\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1416 - acc: 0.9445 - val_loss: 0.1923 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93113\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1405 - acc: 0.9450 - val_loss: 0.1825 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93113\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1431 - acc: 0.9441 - val_loss: 0.1998 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93113\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 375us/step - loss: 0.1384 - acc: 0.9454 - val_loss: 0.1837 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92189, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1344 - acc: 0.9470 - val_loss: 0.1911 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92189\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1325 - acc: 0.9469 - val_loss: 0.1796 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92189\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1316 - acc: 0.9476 - val_loss: 0.1859 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92189\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1309 - acc: 0.9477 - val_loss: 0.1909 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92189\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1302 - acc: 0.9480 - val_loss: 0.1956 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92189\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 385us/step - loss: 0.1348 - acc: 0.9464 - val_loss: 0.1825 - val_acc: 0.9226\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92256, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1336 - acc: 0.9469 - val_loss: 0.1805 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92256 to 0.92325, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1336 - acc: 0.9470 - val_loss: 0.1841 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92325\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1332 - acc: 0.9475 - val_loss: 0.1795 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92325 to 0.92352, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 263us/step - loss: 0.1336 - acc: 0.9469 - val_loss: 0.1791 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92352 to 0.92392, saving model to /mnt/seals/models/36/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1329 - acc: 0.9471 - val_loss: 0.1803 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92392\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1325 - acc: 0.9475 - val_loss: 0.1793 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92392\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1325 - acc: 0.9477 - val_loss: 0.1800 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92392\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1323 - acc: 0.9475 - val_loss: 0.1796 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92392\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 257us/step - loss: 0.1326 - acc: 0.9476 - val_loss: 0.1804 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92392\n",
      "3139/3139 [==============================] - 3s 944us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:50:16,078 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 06:40:51', 'fit_val_loss': 0.17954941770233715, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 11, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 0, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '557', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 06:50:14', 'fit_train_loss': 0.13322504211025296, 'dropout': 0.2, 'fit_stopped_epoch3': 4, 'path_model': '/mnt/seals/models/36/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 06:50:11', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 18, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 06:50:09', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 364935, 'fit_test_acc': 0.5594138260592545, 'layer_2_size': 256, 'fit_train_acc': 0.9474915248430124, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.923517119408843, 'pooling': 'max', 'model_id': 36, 'fit_dt_test_duration_seconds': '2'}\n",
      "2019-01-20 06:50:16,080 [MainThread  ] [INFO ]  model 36 test acc: 0.5594138260592545\n",
      "2019-01-20 06:50:16,082 [MainThread  ] [INFO ]  Begin experiment for model_id=37\n",
      "2019-01-20 06:50:16,083 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 37, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 06:50:17,038 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 06:50:17,039 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 380us/step - loss: 0.1982 - acc: 0.9214 - val_loss: 0.2094 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89896, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1709 - acc: 0.9323 - val_loss: 0.2156 - val_acc: 0.9019\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89896 to 0.90187, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 258us/step - loss: 0.1663 - acc: 0.9333 - val_loss: 0.2062 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90187 to 0.91020, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1614 - acc: 0.9357 - val_loss: 0.2153 - val_acc: 0.8957\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91020\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1575 - acc: 0.9371 - val_loss: 0.1982 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91020\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1507 - acc: 0.9407 - val_loss: 0.2032 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91020\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1493 - acc: 0.9408 - val_loss: 0.1679 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91020 to 0.92365, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1526 - acc: 0.9390 - val_loss: 0.2105 - val_acc: 0.9035\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92365\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 263us/step - loss: 0.1528 - acc: 0.9393 - val_loss: 0.1918 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92365\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 263us/step - loss: 0.1467 - acc: 0.9416 - val_loss: 0.1728 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92365 to 0.93060, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1412 - acc: 0.9438 - val_loss: 0.2125 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93060\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1454 - acc: 0.9426 - val_loss: 0.2117 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93060\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 16s 259us/step - loss: 0.1424 - acc: 0.9435 - val_loss: 0.1814 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93060\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 16s 260us/step - loss: 0.1409 - acc: 0.9444 - val_loss: 0.1985 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93060\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1369 - acc: 0.9456 - val_loss: 0.1801 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93060\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 387us/step - loss: 0.1295 - acc: 0.9488 - val_loss: 0.1776 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92519, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1261 - acc: 0.9502 - val_loss: 0.1756 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92519 to 0.92539, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1245 - acc: 0.9501 - val_loss: 0.1715 - val_acc: 0.9276\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92539 to 0.92757, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1232 - acc: 0.9509 - val_loss: 0.1750 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92757 to 0.92766, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1232 - acc: 0.9508 - val_loss: 0.1791 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92766\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1221 - acc: 0.9513 - val_loss: 0.1756 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92766\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1216 - acc: 0.9513 - val_loss: 0.1757 - val_acc: 0.9272\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92766\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1213 - acc: 0.9517 - val_loss: 0.1786 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92766\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1210 - acc: 0.9521 - val_loss: 0.1803 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92766\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 24s 389us/step - loss: 0.1226 - acc: 0.9512 - val_loss: 0.1765 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92503, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1214 - acc: 0.9518 - val_loss: 0.1779 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92503 to 0.92508, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1214 - acc: 0.9517 - val_loss: 0.1745 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92508 to 0.92650, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1207 - acc: 0.9520 - val_loss: 0.1772 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92650\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1213 - acc: 0.9520 - val_loss: 0.1768 - val_acc: 0.9255\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92650\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1214 - acc: 0.9517 - val_loss: 0.1758 - val_acc: 0.9255\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92650\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1205 - acc: 0.9524 - val_loss: 0.1766 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92650\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1215 - acc: 0.9516 - val_loss: 0.1756 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92650 to 0.92677, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 263us/step - loss: 0.1207 - acc: 0.9518 - val_loss: 0.1776 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92677\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1205 - acc: 0.9521 - val_loss: 0.1770 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92677\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1205 - acc: 0.9520 - val_loss: 0.1731 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92677 to 0.92788, saving model to /mnt/seals/models/37/model.h5\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 16s 263us/step - loss: 0.1203 - acc: 0.9521 - val_loss: 0.1810 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92788\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1204 - acc: 0.9520 - val_loss: 0.1742 - val_acc: 0.9272\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92788\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1202 - acc: 0.9523 - val_loss: 0.1785 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92788\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1210 - acc: 0.9519 - val_loss: 0.1775 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92788\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1198 - acc: 0.9522 - val_loss: 0.1747 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92788\n",
      "3139/3139 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:01:46,011 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 06:50:17', 'fit_val_loss': 0.17703149306060667, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 9, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 3, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '678', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 07:01:44', 'fit_train_loss': 0.12047819194861453, 'dropout': 0.2, 'fit_stopped_epoch3': 10, 'path_model': '/mnt/seals/models/37/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 07:01:41', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 25, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 07:01:36', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 297351, 'fit_test_acc': 0.5594138260592545, 'layer_2_size': 256, 'fit_train_acc': 0.9521287168601044, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9252315871138822, 'pooling': 'max', 'model_id': 37, 'fit_dt_test_duration_seconds': '3'}\n",
      "2019-01-20 07:01:46,013 [MainThread  ] [INFO ]  model 37 test acc: 0.5594138260592545\n",
      "2019-01-20 07:01:46,016 [MainThread  ] [INFO ]  Begin experiment for model_id=38\n",
      "2019-01-20 07:01:46,017 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 38, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:01:46,978 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 07:01:46,979 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 24s 388us/step - loss: 0.1976 - acc: 0.9214 - val_loss: 0.1941 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90918, saving model to /mnt/seals/models/38/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1675 - acc: 0.9316 - val_loss: 0.1909 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90918 to 0.91187, saving model to /mnt/seals/models/38/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1582 - acc: 0.9360 - val_loss: 0.1923 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91187 to 0.91466, saving model to /mnt/seals/models/38/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1520 - acc: 0.9384 - val_loss: 0.2194 - val_acc: 0.9013\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91466\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1490 - acc: 0.9396 - val_loss: 0.2269 - val_acc: 0.8965\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91466\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1468 - acc: 0.9405 - val_loss: 0.1929 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91466 to 0.91764, saving model to /mnt/seals/models/38/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1534 - acc: 0.9363 - val_loss: 0.1808 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91764\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1503 - acc: 0.9375 - val_loss: 0.2274 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91764\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 261us/step - loss: 0.1499 - acc: 0.9380 - val_loss: 0.2054 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91764\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1480 - acc: 0.9391 - val_loss: 0.2343 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91764\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1468 - acc: 0.9396 - val_loss: 0.1820 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91764\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 387us/step - loss: 0.1425 - acc: 0.9404 - val_loss: 0.2012 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90778, saving model to /mnt/seals/models/38/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1390 - acc: 0.9418 - val_loss: 0.1918 - val_acc: 0.9145\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90778 to 0.91454, saving model to /mnt/seals/models/38/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1380 - acc: 0.9422 - val_loss: 0.1973 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91454\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1369 - acc: 0.9429 - val_loss: 0.1873 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91454 to 0.91744, saving model to /mnt/seals/models/38/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1296 - acc: 0.9466 - val_loss: 0.1857 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91744\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1277 - acc: 0.9477 - val_loss: 0.1950 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91744\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 263us/step - loss: 0.1261 - acc: 0.9484 - val_loss: 0.1991 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91744\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1251 - acc: 0.9489 - val_loss: 0.1853 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91744\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1255 - acc: 0.9488 - val_loss: 0.1921 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91744\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.1343 - acc: 0.9439 - val_loss: 0.1908 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91503, saving model to /mnt/seals/models/38/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1292 - acc: 0.9465 - val_loss: 0.1918 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91503\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 262us/step - loss: 0.1280 - acc: 0.9474 - val_loss: 0.1924 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91503\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1274 - acc: 0.9476 - val_loss: 0.1907 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91503\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1269 - acc: 0.9477 - val_loss: 0.1913 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91503\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1270 - acc: 0.9478 - val_loss: 0.1909 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91503\n",
      "3139/3139 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:09:33,588 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 07:01:47', 'fit_val_loss': 0.19731336267214464, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 5, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 3, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '458', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 07:09:32', 'fit_train_loss': 0.1380418389942185, 'dropout': 0.2, 'fit_stopped_epoch3': 0, 'path_model': '/mnt/seals/models/38/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 07:09:28', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 11, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 07:09:26', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 263559, 'fit_test_acc': 0.5715195922268238, 'layer_2_size': 256, 'fit_train_acc': 0.9422272367147076, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9126291575277238, 'pooling': 'max', 'model_id': 38, 'fit_dt_test_duration_seconds': '3'}\n",
      "2019-01-20 07:09:33,589 [MainThread  ] [INFO ]  model 38 test acc: 0.5715195922268238\n",
      "2019-01-20 07:09:33,590 [MainThread  ] [INFO ]  Begin experiment for model_id=39\n",
      "2019-01-20 07:09:33,591 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 39, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 256, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:09:34,516 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 07:09:34,517 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 377us/step - loss: 0.1962 - acc: 0.9231 - val_loss: 0.2458 - val_acc: 0.8925\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89250, saving model to /mnt/seals/models/39/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1671 - acc: 0.9340 - val_loss: 0.2254 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89250 to 0.89713, saving model to /mnt/seals/models/39/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1548 - acc: 0.9384 - val_loss: 0.2192 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89713 to 0.90996, saving model to /mnt/seals/models/39/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1489 - acc: 0.9403 - val_loss: 0.1911 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90996 to 0.91434, saving model to /mnt/seals/models/39/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1452 - acc: 0.9415 - val_loss: 0.1691 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91434 to 0.93414, saving model to /mnt/seals/models/39/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1421 - acc: 0.9435 - val_loss: 0.2250 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93414\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1401 - acc: 0.9443 - val_loss: 0.1846 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93414\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1378 - acc: 0.9447 - val_loss: 0.1870 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93414\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1363 - acc: 0.9454 - val_loss: 0.2124 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93414\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1371 - acc: 0.9454 - val_loss: 0.2214 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93414\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 22s 369us/step - loss: 0.1313 - acc: 0.9469 - val_loss: 0.1864 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91875, saving model to /mnt/seals/models/39/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1285 - acc: 0.9480 - val_loss: 0.1887 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91875\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1279 - acc: 0.9484 - val_loss: 0.1896 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91875\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1268 - acc: 0.9485 - val_loss: 0.1886 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91875\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 241us/step - loss: 0.1262 - acc: 0.9486 - val_loss: 0.2023 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91875\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1255 - acc: 0.9492 - val_loss: 0.1892 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91875\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 373us/step - loss: 0.1282 - acc: 0.9479 - val_loss: 0.1896 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91468, saving model to /mnt/seals/models/39/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1284 - acc: 0.9480 - val_loss: 0.1894 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91468\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 242us/step - loss: 0.1284 - acc: 0.9482 - val_loss: 0.1928 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91468\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 243us/step - loss: 0.1276 - acc: 0.9482 - val_loss: 0.1923 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91468\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 239us/step - loss: 0.1283 - acc: 0.9480 - val_loss: 0.1929 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91468\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 245us/step - loss: 0.1273 - acc: 0.9483 - val_loss: 0.1934 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91468\n",
      "3139/3139 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:15:46,929 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 07:09:35', 'fit_val_loss': 0.1910859874805013, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 4, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 0, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '365', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 07:15:45', 'fit_train_loss': 0.1489190670339507, 'dropout': 0.2, 'fit_stopped_epoch3': 0, 'path_model': '/mnt/seals/models/39/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 07:15:42', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 7, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 07:15:40', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 231559, 'fit_test_acc': 0.5635552723797388, 'layer_2_size': 256, 'fit_train_acc': 0.9403058817290744, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.914343624043643, 'pooling': 'max', 'model_id': 39, 'fit_dt_test_duration_seconds': '3'}\n",
      "2019-01-20 07:15:46,930 [MainThread  ] [INFO ]  model 39 test acc: 0.5635552723797388\n",
      "2019-01-20 07:15:46,932 [MainThread  ] [INFO ]  Begin experiment for model_id=40\n",
      "2019-01-20 07:15:46,933 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 40, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:15:47,881 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 07:15:47,882 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.1943 - acc: 0.9206 - val_loss: 0.2095 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89800, saving model to /mnt/seals/models/40/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1712 - acc: 0.9311 - val_loss: 0.1786 - val_acc: 0.9255\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89800 to 0.92548, saving model to /mnt/seals/models/40/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1600 - acc: 0.9368 - val_loss: 0.1857 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92548\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1561 - acc: 0.9385 - val_loss: 0.1985 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92548\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1535 - acc: 0.9399 - val_loss: 0.1708 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92548 to 0.93360, saving model to /mnt/seals/models/40/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1505 - acc: 0.9413 - val_loss: 0.2095 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93360\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 264us/step - loss: 0.1485 - acc: 0.9422 - val_loss: 0.2210 - val_acc: 0.8978\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93360\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1460 - acc: 0.9433 - val_loss: 0.2079 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93360\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1449 - acc: 0.9436 - val_loss: 0.2414 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93360\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1423 - acc: 0.9443 - val_loss: 0.1893 - val_acc: 0.9181\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93360\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 24s 403us/step - loss: 0.1374 - acc: 0.9461 - val_loss: 0.1870 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91929, saving model to /mnt/seals/models/40/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1351 - acc: 0.9470 - val_loss: 0.1977 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91929\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1329 - acc: 0.9482 - val_loss: 0.1968 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91929\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 268us/step - loss: 0.1317 - acc: 0.9489 - val_loss: 0.1956 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91929\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1299 - acc: 0.9494 - val_loss: 0.1912 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91929\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 268us/step - loss: 0.1297 - acc: 0.9493 - val_loss: 0.2019 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91929\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 25s 407us/step - loss: 0.1342 - acc: 0.9474 - val_loss: 0.1915 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91657, saving model to /mnt/seals/models/40/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 268us/step - loss: 0.1334 - acc: 0.9476 - val_loss: 0.1957 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91657\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1334 - acc: 0.9480 - val_loss: 0.1923 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91657 to 0.91704, saving model to /mnt/seals/models/40/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1327 - acc: 0.9482 - val_loss: 0.1994 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91704\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1335 - acc: 0.9478 - val_loss: 0.1955 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91704\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1320 - acc: 0.9485 - val_loss: 0.1960 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91704\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1324 - acc: 0.9484 - val_loss: 0.1925 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91704\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1315 - acc: 0.9487 - val_loss: 0.1933 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91704\n",
      "3139/3139 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:23:10,651 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 07:15:48', 'fit_val_loss': 0.19571206021933188, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 4, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 0, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '433', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 07:23:09', 'fit_train_loss': 0.13344295797567252, 'dropout': 0.2, 'fit_stopped_epoch3': 2, 'path_model': '/mnt/seals/models/40/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 07:23:05', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 9, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 07:23:02', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 282887, 'fit_test_acc': 0.5664224275246894, 'layer_2_size': 128, 'fit_train_acc': 0.9476211867651231, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9126291590141239, 'pooling': 'max', 'model_id': 40, 'fit_dt_test_duration_seconds': '3'}\n",
      "2019-01-20 07:23:10,652 [MainThread  ] [INFO ]  model 40 test acc: 0.5664224275246894\n",
      "2019-01-20 07:23:10,654 [MainThread  ] [INFO ]  Begin experiment for model_id=41\n",
      "2019-01-20 07:23:10,655 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 41, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:23:11,597 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 07:23:11,598 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.1924 - acc: 0.9225 - val_loss: 0.1834 - val_acc: 0.9317\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93171, saving model to /mnt/seals/models/41/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 268us/step - loss: 0.1617 - acc: 0.9345 - val_loss: 0.2247 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93171\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1538 - acc: 0.9383 - val_loss: 0.1769 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.93171\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 263us/step - loss: 0.1494 - acc: 0.9400 - val_loss: 0.2109 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93171\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1464 - acc: 0.9418 - val_loss: 0.1917 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93171\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 265us/step - loss: 0.1445 - acc: 0.9426 - val_loss: 0.2285 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93171\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.1511 - acc: 0.9383 - val_loss: 0.1955 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91194, saving model to /mnt/seals/models/41/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 267us/step - loss: 0.1458 - acc: 0.9407 - val_loss: 0.1947 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91194 to 0.91230, saving model to /mnt/seals/models/41/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1421 - acc: 0.9421 - val_loss: 0.1957 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91230\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1384 - acc: 0.9438 - val_loss: 0.1917 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91230 to 0.91437, saving model to /mnt/seals/models/41/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 17s 273us/step - loss: 0.1358 - acc: 0.9449 - val_loss: 0.1930 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91437\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1339 - acc: 0.9462 - val_loss: 0.1871 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91437 to 0.91995, saving model to /mnt/seals/models/41/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 268us/step - loss: 0.1322 - acc: 0.9466 - val_loss: 0.1945 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91995\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1296 - acc: 0.9480 - val_loss: 0.1962 - val_acc: 0.9103\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91995\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1285 - acc: 0.9481 - val_loss: 0.2094 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91995\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1277 - acc: 0.9484 - val_loss: 0.1939 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91995\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 272us/step - loss: 0.1259 - acc: 0.9492 - val_loss: 0.1970 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91995\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.1301 - acc: 0.9476 - val_loss: 0.1926 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91334, saving model to /mnt/seals/models/41/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 17s 273us/step - loss: 0.1298 - acc: 0.9476 - val_loss: 0.1936 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91334\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 17s 273us/step - loss: 0.1294 - acc: 0.9478 - val_loss: 0.1941 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91334\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1291 - acc: 0.9479 - val_loss: 0.1949 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91334\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1289 - acc: 0.9479 - val_loss: 0.1895 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91334 to 0.91746, saving model to /mnt/seals/models/41/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1289 - acc: 0.9481 - val_loss: 0.1958 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91746\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 272us/step - loss: 0.1282 - acc: 0.9481 - val_loss: 0.1954 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91746\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 17s 272us/step - loss: 0.1283 - acc: 0.9483 - val_loss: 0.1952 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91746\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 272us/step - loss: 0.1281 - acc: 0.9482 - val_loss: 0.1956 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91746\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 17s 272us/step - loss: 0.1278 - acc: 0.9484 - val_loss: 0.1908 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91746\n",
      "3139/3139 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:31:26,786 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 07:23:12', 'fit_val_loss': 0.19493833671038288, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 0, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 5, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '486', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 07:31:25', 'fit_train_loss': 0.12905311953577447, 'dropout': 0.2, 'fit_stopped_epoch3': 4, 'path_model': '/mnt/seals/models/41/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 07:31:21', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 12, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 07:31:18', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 248071, 'fit_test_acc': 0.5444409047467347, 'layer_2_size': 128, 'fit_train_acc': 0.9479064431417039, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9125846260206361, 'pooling': 'max', 'model_id': 41, 'fit_dt_test_duration_seconds': '3'}\n",
      "2019-01-20 07:31:26,787 [MainThread  ] [INFO ]  model 41 test acc: 0.5444409047467347\n",
      "2019-01-20 07:31:26,789 [MainThread  ] [INFO ]  Begin experiment for model_id=42\n",
      "2019-01-20 07:31:26,790 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 42, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:31:27,731 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 07:31:27,732 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.2003 - acc: 0.9207 - val_loss: 0.2115 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90461, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 17s 273us/step - loss: 0.1693 - acc: 0.9308 - val_loss: 0.1928 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90461 to 0.90980, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1635 - acc: 0.9327 - val_loss: 0.1938 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90980\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1627 - acc: 0.9331 - val_loss: 0.2015 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90980 to 0.91209, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1605 - acc: 0.9340 - val_loss: 0.1981 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91209 to 0.91238, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 272us/step - loss: 0.1509 - acc: 0.9395 - val_loss: 0.1929 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91238 to 0.91969, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1486 - acc: 0.9407 - val_loss: 0.2391 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91969\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 266us/step - loss: 0.1466 - acc: 0.9413 - val_loss: 0.2317 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91969\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1445 - acc: 0.9419 - val_loss: 0.1911 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91969\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 268us/step - loss: 0.1449 - acc: 0.9421 - val_loss: 0.1877 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91969\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 268us/step - loss: 0.1421 - acc: 0.9433 - val_loss: 0.1864 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.91969 to 0.92387, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1416 - acc: 0.9437 - val_loss: 0.2018 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92387\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1402 - acc: 0.9445 - val_loss: 0.1800 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92387\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1400 - acc: 0.9442 - val_loss: 0.1889 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92387\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1405 - acc: 0.9438 - val_loss: 0.2331 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92387\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1395 - acc: 0.9442 - val_loss: 0.1891 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92387\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.1299 - acc: 0.9483 - val_loss: 0.1919 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91880, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1280 - acc: 0.9486 - val_loss: 0.1887 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91880 to 0.91973, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1263 - acc: 0.9495 - val_loss: 0.1855 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91973 to 0.92167, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1269 - acc: 0.9495 - val_loss: 0.1840 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92167\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1255 - acc: 0.9500 - val_loss: 0.1818 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92167 to 0.92285, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1241 - acc: 0.9504 - val_loss: 0.1839 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92285\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1244 - acc: 0.9504 - val_loss: 0.1830 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92285\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 16s 272us/step - loss: 0.1243 - acc: 0.9506 - val_loss: 0.1837 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92285\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 17s 273us/step - loss: 0.1238 - acc: 0.9506 - val_loss: 0.1935 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92285\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1235 - acc: 0.9509 - val_loss: 0.1732 - val_acc: 0.9276\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92285 to 0.92764, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 16s 269us/step - loss: 0.1236 - acc: 0.9509 - val_loss: 0.1894 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92764\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 17s 273us/step - loss: 0.1222 - acc: 0.9512 - val_loss: 0.1855 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92764\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 16s 270us/step - loss: 0.1235 - acc: 0.9508 - val_loss: 0.1836 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92764\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 17s 274us/step - loss: 0.1221 - acc: 0.9515 - val_loss: 0.1768 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92764\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1216 - acc: 0.9515 - val_loss: 0.1796 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92764\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.1219 - acc: 0.9515 - val_loss: 0.1804 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92292, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 17s 276us/step - loss: 0.1216 - acc: 0.9516 - val_loss: 0.1803 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92292 to 0.92358, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 17s 274us/step - loss: 0.1216 - acc: 0.9517 - val_loss: 0.1814 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92358\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 17s 273us/step - loss: 0.1213 - acc: 0.9517 - val_loss: 0.1820 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92358\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1218 - acc: 0.9516 - val_loss: 0.1804 - val_acc: 0.9236\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.92358 to 0.92358, saving model to /mnt/seals/models/42/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 16s 271us/step - loss: 0.1221 - acc: 0.9517 - val_loss: 0.1819 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92358\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 17s 273us/step - loss: 0.1208 - acc: 0.9521 - val_loss: 0.1816 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92358\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 16s 272us/step - loss: 0.1211 - acc: 0.9521 - val_loss: 0.1811 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92358\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 17s 276us/step - loss: 0.1210 - acc: 0.9519 - val_loss: 0.1807 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92358\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 17s 274us/step - loss: 0.1214 - acc: 0.9517 - val_loss: 0.1804 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92358\n",
      "3139/3139 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:43:38,610 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 07:31:28', 'fit_val_loss': 0.18199143144406582, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 10, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 9, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '720', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 07:43:37', 'fit_train_loss': 0.12132883892487478, 'dropout': 0.2, 'fit_stopped_epoch3': 4, 'path_model': '/mnt/seals/models/42/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 07:43:33', 'layer_3_size': 128, 'batch_size': 32, 'fit_num_epochs': 26, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 07:43:28', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 230663, 'fit_test_acc': 0.5861739407454604, 'layer_2_size': 128, 'fit_train_acc': 0.9517232273341716, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.923316727106708, 'pooling': 'max', 'model_id': 42, 'fit_dt_test_duration_seconds': '3'}\n",
      "2019-01-20 07:43:38,612 [MainThread  ] [INFO ]  model 42 test acc: 0.5861739407454604\n",
      "2019-01-20 07:43:38,614 [MainThread  ] [INFO ]  Begin experiment for model_id=43\n",
      "2019-01-20 07:43:38,615 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 43, 'layer_3_size': 0, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 128, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:43:39,563 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 07:43:39,565 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 24s 389us/step - loss: 0.1957 - acc: 0.9223 - val_loss: 0.2281 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89680, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1625 - acc: 0.9351 - val_loss: 0.2329 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89680 to 0.89769, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 244us/step - loss: 0.1566 - acc: 0.9367 - val_loss: 0.2037 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89769 to 0.90668, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1508 - acc: 0.9391 - val_loss: 0.1844 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90668 to 0.91849, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1474 - acc: 0.9404 - val_loss: 0.2322 - val_acc: 0.8970\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91849\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1453 - acc: 0.9414 - val_loss: 0.2502 - val_acc: 0.8986\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91849\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1500 - acc: 0.9385 - val_loss: 0.1966 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91849\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1470 - acc: 0.9400 - val_loss: 0.2189 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91849\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1439 - acc: 0.9413 - val_loss: 0.1939 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91849\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 387us/step - loss: 0.1366 - acc: 0.9444 - val_loss: 0.1954 - val_acc: 0.9103\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91029, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1344 - acc: 0.9452 - val_loss: 0.1901 - val_acc: 0.9120\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91029 to 0.91198, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1335 - acc: 0.9459 - val_loss: 0.1861 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91198 to 0.91624, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1324 - acc: 0.9462 - val_loss: 0.1845 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91624\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1318 - acc: 0.9464 - val_loss: 0.1941 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91624\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1298 - acc: 0.9474 - val_loss: 0.1955 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91624\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1297 - acc: 0.9474 - val_loss: 0.1786 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91624 to 0.92145, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1290 - acc: 0.9478 - val_loss: 0.1952 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92145\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 247us/step - loss: 0.1280 - acc: 0.9479 - val_loss: 0.1831 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92145\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1277 - acc: 0.9484 - val_loss: 0.1868 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92145\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1270 - acc: 0.9483 - val_loss: 0.1882 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92145\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1270 - acc: 0.9485 - val_loss: 0.1781 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.92145 to 0.92211, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1258 - acc: 0.9490 - val_loss: 0.1813 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92211\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1256 - acc: 0.9491 - val_loss: 0.1882 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92211\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1252 - acc: 0.9491 - val_loss: 0.1767 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.92211 to 0.92390, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1255 - acc: 0.9494 - val_loss: 0.1891 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92390\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1239 - acc: 0.9500 - val_loss: 0.1810 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92390\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1243 - acc: 0.9498 - val_loss: 0.1846 - val_acc: 0.9195\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92390\n",
      "Epoch 19/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1231 - acc: 0.9503 - val_loss: 0.1917 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92390\n",
      "Epoch 20/30\n",
      "60597/60597 [==============================] - 15s 246us/step - loss: 0.1233 - acc: 0.9503 - val_loss: 0.1813 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92390\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.1242 - acc: 0.9496 - val_loss: 0.1849 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91860, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1232 - acc: 0.9501 - val_loss: 0.1837 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91860 to 0.91920, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 15s 248us/step - loss: 0.1231 - acc: 0.9501 - val_loss: 0.1834 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91920 to 0.91969, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 15s 251us/step - loss: 0.1228 - acc: 0.9504 - val_loss: 0.1813 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91969 to 0.92129, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 15s 253us/step - loss: 0.1229 - acc: 0.9503 - val_loss: 0.1871 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92129\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1231 - acc: 0.9504 - val_loss: 0.1819 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92129\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1229 - acc: 0.9503 - val_loss: 0.1816 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.92129 to 0.92156, saving model to /mnt/seals/models/43/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1233 - acc: 0.9501 - val_loss: 0.1829 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92156\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1230 - acc: 0.9501 - val_loss: 0.1858 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92156\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 15s 250us/step - loss: 0.1224 - acc: 0.9505 - val_loss: 0.1820 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92156\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 15s 252us/step - loss: 0.1224 - acc: 0.9506 - val_loss: 0.1827 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92156\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 15s 249us/step - loss: 0.1231 - acc: 0.9503 - val_loss: 0.1806 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92156\n",
      "3139/3139 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:54:55,587 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 07:43:40', 'fit_val_loss': 0.1819169657337398, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 3, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 14, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '664', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 07:54:54', 'fit_train_loss': 0.12309552206751839, 'dropout': 0.2, 'fit_stopped_epoch3': 6, 'path_model': '/mnt/seals/models/43/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 07:54:50', 'layer_3_size': 0, 'batch_size': 32, 'fit_num_epochs': 26, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 07:54:45', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 214151, 'fit_test_acc': 0.5622809812042051, 'layer_2_size': 128, 'fit_train_acc': 0.9503653101148583, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9210010874003841, 'pooling': 'max', 'model_id': 43, 'fit_dt_test_duration_seconds': '3'}\n",
      "2019-01-20 07:54:55,588 [MainThread  ] [INFO ]  model 43 test acc: 0.5622809812042051\n",
      "2019-01-20 07:54:55,591 [MainThread  ] [INFO ]  Begin experiment for model_id=44\n",
      "2019-01-20 07:54:55,592 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 44, 'layer_3_size': 512, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 07:54:56,572 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 07:54:56,573 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 382us/step - loss: 0.2035 - acc: 0.9239 - val_loss: 0.2171 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89593, saving model to /mnt/seals/models/44/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 224us/step - loss: 0.1608 - acc: 0.9348 - val_loss: 0.2774 - val_acc: 0.8859\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89593\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1522 - acc: 0.9381 - val_loss: 0.2213 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89593 to 0.90101, saving model to /mnt/seals/models/44/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1450 - acc: 0.9410 - val_loss: 0.1726 - val_acc: 0.9269\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90101 to 0.92690, saving model to /mnt/seals/models/44/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1407 - acc: 0.9432 - val_loss: 0.1908 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92690\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1366 - acc: 0.9446 - val_loss: 0.2212 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92690\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1353 - acc: 0.9455 - val_loss: 0.1985 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92690\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 223us/step - loss: 0.1335 - acc: 0.9458 - val_loss: 0.1914 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92690\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1301 - acc: 0.9472 - val_loss: 0.2391 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92690\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 373us/step - loss: 0.1309 - acc: 0.9469 - val_loss: 0.1862 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91820, saving model to /mnt/seals/models/44/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1282 - acc: 0.9480 - val_loss: 0.2093 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91820\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1276 - acc: 0.9482 - val_loss: 0.1963 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91820\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1255 - acc: 0.9494 - val_loss: 0.2089 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91820\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1257 - acc: 0.9492 - val_loss: 0.2010 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91820\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1241 - acc: 0.9499 - val_loss: 0.1924 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91820\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 378us/step - loss: 0.1274 - acc: 0.9482 - val_loss: 0.1922 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91519, saving model to /mnt/seals/models/44/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1273 - acc: 0.9483 - val_loss: 0.1931 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91519 to 0.91526, saving model to /mnt/seals/models/44/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1272 - acc: 0.9483 - val_loss: 0.1894 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91526 to 0.91715, saving model to /mnt/seals/models/44/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1270 - acc: 0.9486 - val_loss: 0.1914 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91715\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1273 - acc: 0.9488 - val_loss: 0.1915 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91715 to 0.91715, saving model to /mnt/seals/models/44/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1264 - acc: 0.9485 - val_loss: 0.1926 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91715\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1267 - acc: 0.9486 - val_loss: 0.1930 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91715\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1262 - acc: 0.9488 - val_loss: 0.1926 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91715\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1264 - acc: 0.9486 - val_loss: 0.1950 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91715\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1259 - acc: 0.9490 - val_loss: 0.1912 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.91715 to 0.91748, saving model to /mnt/seals/models/44/model.h5\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1256 - acc: 0.9491 - val_loss: 0.1914 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91748\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1256 - acc: 0.9492 - val_loss: 0.2000 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.91748\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1258 - acc: 0.9491 - val_loss: 0.1979 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.91748\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1256 - acc: 0.9491 - val_loss: 0.1938 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.91748\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1258 - acc: 0.9492 - val_loss: 0.1983 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.91748\n",
      "3139/3139 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 08:02:44,779 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 07:54:57', 'fit_val_loss': 0.195042921569282, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 3, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 0, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '458', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 08:02:43', 'fit_train_loss': 0.1263923314893289, 'dropout': 0.2, 'fit_stopped_epoch3': 9, 'path_model': '/mnt/seals/models/44/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 08:02:39', 'layer_3_size': 512, 'batch_size': 32, 'fit_num_epochs': 15, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 08:02:35', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 197639, 'fit_test_acc': 0.5782096208983754, 'layer_2_size': 0, 'fit_train_acc': 0.9485712563898889, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9159244933627787, 'pooling': 'max', 'model_id': 44, 'fit_dt_test_duration_seconds': '3'}\n",
      "2019-01-20 08:02:44,780 [MainThread  ] [INFO ]  model 44 test acc: 0.5782096208983754\n",
      "2019-01-20 08:02:44,782 [MainThread  ] [INFO ]  Begin experiment for model_id=45\n",
      "2019-01-20 08:02:44,783 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 45, 'layer_3_size': 256, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 08:02:45,743 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 08:02:45,744 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 376us/step - loss: 0.1894 - acc: 0.9262 - val_loss: 0.2700 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88878, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1583 - acc: 0.9359 - val_loss: 0.1934 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88878 to 0.90931, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1504 - acc: 0.9389 - val_loss: 0.2376 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90931\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1456 - acc: 0.9410 - val_loss: 0.2164 - val_acc: 0.9065\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90931\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 225us/step - loss: 0.1424 - acc: 0.9424 - val_loss: 0.2161 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90931\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1388 - acc: 0.9436 - val_loss: 0.2058 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.90931 to 0.91802, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1369 - acc: 0.9444 - val_loss: 0.1969 - val_acc: 0.9104\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91802\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1342 - acc: 0.9457 - val_loss: 0.2075 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91802\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1327 - acc: 0.9461 - val_loss: 0.2125 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91802\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1314 - acc: 0.9467 - val_loss: 0.2086 - val_acc: 0.9066\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91802\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1289 - acc: 0.9477 - val_loss: 0.2044 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91802\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 379us/step - loss: 0.1272 - acc: 0.9487 - val_loss: 0.1929 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91570, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1254 - acc: 0.9491 - val_loss: 0.1998 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91570\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1245 - acc: 0.9498 - val_loss: 0.1913 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91570\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1238 - acc: 0.9498 - val_loss: 0.1982 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91570 to 0.91846, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1231 - acc: 0.9499 - val_loss: 0.1873 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91846 to 0.92116, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1221 - acc: 0.9506 - val_loss: 0.2024 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92116\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1223 - acc: 0.9502 - val_loss: 0.1890 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.92116 to 0.92125, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1216 - acc: 0.9504 - val_loss: 0.1930 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92125\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1210 - acc: 0.9510 - val_loss: 0.1985 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92125\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1210 - acc: 0.9507 - val_loss: 0.2005 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92125\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1203 - acc: 0.9515 - val_loss: 0.1967 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92125\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1195 - acc: 0.9516 - val_loss: 0.1940 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.92125 to 0.92158, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1190 - acc: 0.9516 - val_loss: 0.1923 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92158 to 0.92165, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 14/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1187 - acc: 0.9517 - val_loss: 0.1974 - val_acc: 0.9206\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92165\n",
      "Epoch 15/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1182 - acc: 0.9518 - val_loss: 0.2148 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92165\n",
      "Epoch 16/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1176 - acc: 0.9522 - val_loss: 0.1984 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92165\n",
      "Epoch 17/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1176 - acc: 0.9523 - val_loss: 0.2000 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92165\n",
      "Epoch 18/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1174 - acc: 0.9524 - val_loss: 0.2079 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92165\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 379us/step - loss: 0.1179 - acc: 0.9521 - val_loss: 0.1969 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91991, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1176 - acc: 0.9521 - val_loss: 0.2005 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91991\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1173 - acc: 0.9522 - val_loss: 0.2006 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91991\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1172 - acc: 0.9524 - val_loss: 0.1990 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91991\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1170 - acc: 0.9526 - val_loss: 0.1983 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91991\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1175 - acc: 0.9521 - val_loss: 0.1955 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91991 to 0.92145, saving model to /mnt/seals/models/45/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1175 - acc: 0.9520 - val_loss: 0.1963 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92145\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 226us/step - loss: 0.1174 - acc: 0.9524 - val_loss: 0.2024 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92145\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1167 - acc: 0.9526 - val_loss: 0.1990 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92145\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1169 - acc: 0.9525 - val_loss: 0.2014 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92145\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1172 - acc: 0.9523 - val_loss: 0.1979 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92145\n",
      "3139/3139 [==============================] - 4s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 08:12:56,193 [MainThread  ] [INFO ]  {'data_total_rows_valid': 6416, 'fit_dt_train_start': '2019-01-20 08:02:46', 'fit_val_loss': 0.1982618471853751, 'data_total_rows_test': 3139, 'data_total_rows_train': 60597, 'verbose': True, 'sequence_model': nan, 'fit_stopped_epoch1': 5, 'sequence_length': 1.0, 'sequence_model_layers': nan, 'fit_stopped_epoch2': 12, 'model_weights_path': None, 'fit_dt_train_duration_seconds': '599', 'layer_1_size': 128, 'fit_dt_test_end': '2019-01-20 08:12:54', 'fit_train_loss': 0.1170418192687441, 'dropout': 0.2, 'fit_stopped_epoch3': 5, 'path_model': '/mnt/seals/models/45/', 'frame_size': (299, 299), 'fit_dt_test_start': '2019-01-20 08:12:50', 'layer_3_size': 256, 'batch_size': 32, 'fit_num_epochs': 25, 'num_features': 1536, 'fit_dt_train_end': '2019-01-20 08:12:45', 'convolution_kernel_size': 3, 'pretrained_model_name': 'inception_resnet_v2', 'model_param_count': 197639, 'fit_test_acc': 0.5552723797387703, 'layer_2_size': 0, 'fit_train_acc': 0.9526402936250555, 'architecture': 'image_mlp_frozen', 'fit_val_acc': 0.9189971683923146, 'pooling': 'max', 'model_id': 45, 'fit_dt_test_duration_seconds': '4'}\n",
      "2019-01-20 08:12:56,195 [MainThread  ] [INFO ]  model 45 test acc: 0.5552723797387703\n",
      "2019-01-20 08:12:56,198 [MainThread  ] [INFO ]  Begin experiment for model_id=46\n",
      "2019-01-20 08:12:56,199 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence_length': 1.0, 'dropout': 0.2, 'model_id': 46, 'layer_3_size': 128, 'architecture': 'image_MLP_frozen', 'layer_1_size': 128, 'sequence_model': nan, 'sequence_model_layers': nan, 'pooling': 'max', 'layer_2_size': 0, 'pretrained_model_name': 'inception_resnet_v2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 08:12:57,151 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 08:12:57,153 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60597, valid=6416, test=3139\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 381us/step - loss: 0.1853 - acc: 0.9275 - val_loss: 0.2659 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88667, saving model to /mnt/seals/models/46/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 227us/step - loss: 0.1539 - acc: 0.9376 - val_loss: 0.2147 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88667 to 0.89664, saving model to /mnt/seals/models/46/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1446 - acc: 0.9413 - val_loss: 0.2038 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89664 to 0.90399, saving model to /mnt/seals/models/46/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1402 - acc: 0.9431 - val_loss: 0.1934 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90399 to 0.91245, saving model to /mnt/seals/models/46/model.h5\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1355 - acc: 0.9448 - val_loss: 0.2086 - val_acc: 0.9041\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91245\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1337 - acc: 0.9453 - val_loss: 0.2275 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91245\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1306 - acc: 0.9468 - val_loss: 0.2031 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91245 to 0.91628, saving model to /mnt/seals/models/46/model.h5\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1270 - acc: 0.9484 - val_loss: 0.1798 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91628 to 0.92539, saving model to /mnt/seals/models/46/model.h5\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1256 - acc: 0.9492 - val_loss: 0.2030 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92539\n",
      "Epoch 10/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1226 - acc: 0.9502 - val_loss: 0.2073 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92539\n",
      "Epoch 11/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1221 - acc: 0.9503 - val_loss: 0.2134 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92539\n",
      "Epoch 12/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1219 - acc: 0.9507 - val_loss: 0.2283 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92539\n",
      "Epoch 13/30\n",
      "60597/60597 [==============================] - 14s 232us/step - loss: 0.1190 - acc: 0.9516 - val_loss: 0.2204 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92539\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 382us/step - loss: 0.1144 - acc: 0.9538 - val_loss: 0.1848 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92521, saving model to /mnt/seals/models/46/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1127 - acc: 0.9544 - val_loss: 0.1956 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92521\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 229us/step - loss: 0.1121 - acc: 0.9546 - val_loss: 0.1918 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92521\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1117 - acc: 0.9548 - val_loss: 0.2073 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92521\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1112 - acc: 0.9549 - val_loss: 0.1970 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92521\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1109 - acc: 0.9552 - val_loss: 0.1984 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92521\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 23s 385us/step - loss: 0.1120 - acc: 0.9546 - val_loss: 0.1943 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91938, saving model to /mnt/seals/models/46/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1119 - acc: 0.9544 - val_loss: 0.1934 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91938\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 14s 234us/step - loss: 0.1119 - acc: 0.9550 - val_loss: 0.1950 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91938\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1121 - acc: 0.9546 - val_loss: 0.1959 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91938\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 14s 233us/step - loss: 0.1115 - acc: 0.9550 - val_loss: 0.1963 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91938\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1113 - acc: 0.9551 - val_loss: 0.1929 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91938 to 0.92127, saving model to /mnt/seals/models/46/model.h5\n",
      "Epoch 7/30\n",
      "60597/60597 [==============================] - 14s 228us/step - loss: 0.1114 - acc: 0.9550 - val_loss: 0.1968 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92127\n",
      "Epoch 8/30\n",
      "60597/60597 [==============================] - 14s 230us/step - loss: 0.1112 - acc: 0.9552 - val_loss: 0.1980 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92127\n",
      "Epoch 9/30\n",
      "60597/60597 [==============================] - 14s 231us/step - loss: 0.1113 - acc: 0.9553 - val_loss: 0.1999 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92127\n",
      "Epoch 10/30\n",
      "46240/60597 [=====================>........] - ETA: 3s - loss: 0.1110 - acc: 0.9553"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-6b97b13d88ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                 verbose=True)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0marchitecture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-0e720ca0379e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;31m# reduce learning rate and fit some more\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mhistory3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopped_epoch3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;31m# end time training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-0e720ca0379e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, learning_rate, epochs, patience)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 verbose=self.verbose)\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;31m# get number of epochs actually trained (might have early stopped)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m         \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 08:20:27,025 [MainThread  ] [ERROR]  Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    self.events.trigger('post_execute')\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/pylab/backend_inline.py\", line 113, in flush_figures\n",
      "    return show(True)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/pylab/backend_inline.py\", line 36, in show\n",
      "    display(figure_manager.canvas.figure)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/display.py\", line 298, in display\n",
      "    format_dict, md_dict = format(obj, include=include, exclude=exclude)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/formatters.py\", line 180, in format\n",
      "    data = formatter(obj)\n",
      "  File \"<decorator-gen-9>\", line 2, in __call__\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/formatters.py\", line 224, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/formatters.py\", line 341, in __call__\n",
      "    return printer(obj)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/pylabtools.py\", line 244, in <lambda>\n",
      "    png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png', **kwargs))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/pylabtools.py\", line 128, in print_figure\n",
      "    fig.canvas.print_figure(bytes_io, **kw)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/matplotlib/backend_bases.py\", line 2075, in print_figure\n",
      "    **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/matplotlib/backends/backend_agg.py\", line 523, in print_png\n",
      "    self.figure.dpi, metadata=metadata)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "### Run experiments\n",
    "###################\n",
    "\n",
    "for row in experiments.values:\n",
    "    \n",
    "    # get experiment params from dataframe row\n",
    "    experiment = dict(zip(experiments.columns, row))\n",
    "    print(experiment)\n",
    "\n",
    "    logging.info(\"Begin experiment for model_id={}\".format(experiment['model_id']))\n",
    "    \n",
    "    architecture = Architecture(model_id = experiment['model_id'], \n",
    "                                architecture = experiment['architecture'], \n",
    "                                sequence_length = experiment['sequence_length'], \n",
    "                                pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                                pooling = experiment['pooling'],\n",
    "                                sequence_model = experiment['sequence_model'],\n",
    "                                sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                                layer_1_size = experiment['layer_1_size'],\n",
    "                                layer_2_size = experiment['layer_2_size'],\n",
    "                                layer_3_size = experiment['layer_3_size'],\n",
    "                                dropout = experiment['dropout'],\n",
    "                                verbose=True)\n",
    "    \n",
    "    architecture.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### image_MLP_trainable\n",
    "#######################\n",
    "\n",
    "architecture = 'video_LRCNN_trainable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### video_LRCNN_trainable\n",
    "#########################\n",
    "\n",
    "architecture = 'video_LRCNN_trainable'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - custom weights MLP loaded into trainable and LRCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "### C3D\n",
    "#######\n",
    "\n",
    "architecture = 'C3D'\n",
    "\n",
    "############\n",
    "### C3Dsmall\n",
    "############\n",
    "\n",
    "architecture = 'C3Dsmall' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:50:01.871676Z",
     "start_time": "2019-01-20T00:50:01.868446Z"
    }
   },
   "outputs": [],
   "source": [
    "# architecture = Architecture(model_id = 1221, \n",
    "#                             architecture = 'image_MLP_trainable',\n",
    "#                             sequence_length = 1, \n",
    "#                             pretrained_model_name = \"vgg16\", \n",
    "#                             pooling = 'max', \n",
    "#                             layer_1_size=32,\n",
    "#                             layer_2_size=0, \n",
    "#                             layer_3_size=0,\n",
    "#                             dropout=0.2,\n",
    "#                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:50:08.825434Z",
     "start_time": "2019-01-20T00:50:07.388240Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(model_id = 55, \n",
    "                            architecture = 'image_MLP_frozen',\n",
    "                            sequence_length = 1, \n",
    "                            pretrained_model_name = \"vgg16\", \n",
    "                            pooling = 'max', \n",
    "                            layer_1_size=256,\n",
    "                            layer_2_size=128, \n",
    "                            layer_3_size=0,\n",
    "                            dropout=0.2,\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:50:19.882928Z",
     "start_time": "2019-01-20T00:50:09.634082Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "architecture.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## image_MLP_trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.875295Z",
     "start_time": "2019-01-20T00:01:43.392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = \"vgg16\"\n",
    "pooling=\"max\"\n",
    "sequence_length = 2\n",
    "\n",
    "layer_1_size = 128\n",
    "layer_2_size = 64\n",
    "layer_3_size = 32\n",
    "dropout=0.20\n",
    "\n",
    "data = Data(sequence_length = 1, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=pretrained_modesl_name,\n",
    "            pooling = pooling,\n",
    "            return_generator=True,\n",
    "            batch_size=32)\n",
    "\n",
    "num_classes = data.num_classes \n",
    "frame_size = data.frame_size\n",
    "num_features = pretrained_model_len_features[pretrained_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.876587Z",
     "start_time": "2019-01-20T00:01:43.393Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(model_id = 1, \n",
    "                            architecture = 'image_MLP_trainable',\n",
    "                            sequence_length = 1, \n",
    "                            num_classes = num_classes, \n",
    "                            pretrained_model_name = pretrained_model_name, \n",
    "                            pooling = 'max', \n",
    "                            layer_1_size=128,\n",
    "                            layer_2_size=0, \n",
    "                            layer_3_size=0,\n",
    "                            dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.877762Z",
     "start_time": "2019-01-20T00:01:43.395Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fit(model_id=1337, model = architecture.model, data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## image_MLP_frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.878958Z",
     "start_time": "2019-01-20T00:01:43.397Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = \"vgg16\"\n",
    "pooling=\"max\"\n",
    "layer_1_size = 128\n",
    "layer_2_size = 64\n",
    "layer_3_size = 32\n",
    "dropout=0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.880069Z",
     "start_time": "2019-01-20T00:01:43.400Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = 1, \n",
    "            return_CNN_features = True, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.881261Z",
     "start_time": "2019-01-20T00:01:43.403Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_classes = data.num_classes \n",
    "frame_size = data.frame_size\n",
    "num_features = pretrained_model_len_features[pretrained_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.882376Z",
     "start_time": "2019-01-20T00:01:43.404Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(model_id = 1, \n",
    "                            architecture = 'image_MLP_frozen',\n",
    "                            sequence_length = 1, \n",
    "                            num_classes = num_classes, \n",
    "                            pretrained_model_name = pretrained_model_name, \n",
    "                            pooling = 'max', \n",
    "                            layer_1_size=128,\n",
    "                            layer_2_size=0, \n",
    "                            layer_3_size=0,\n",
    "                            dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.883366Z",
     "start_time": "2019-01-20T00:01:43.406Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "fit_history = fit(model_id = 1, model = architecture.model, data = data, learning_rate = 0.001, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## video_MLP_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.884556Z",
     "start_time": "2019-01-20T00:01:43.408Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = \"vgg16\"\n",
    "pooling=\"max\"\n",
    "sequence_length = 3\n",
    "layer_1_size = 128\n",
    "layer_2_size = 64\n",
    "layer_3_size = 32\n",
    "dropout=0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.885632Z",
     "start_time": "2019-01-20T00:01:43.411Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = True, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.886791Z",
     "start_time": "2019-01-20T00:01:43.413Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_classes = data.num_classes \n",
    "frame_size = data.frame_size\n",
    "num_features = pretrained_model_len_features[pretrained_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.887814Z",
     "start_time": "2019-01-20T00:01:43.414Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(model_id = 1, \n",
    "                            architecture = 'video_MLP_concat',\n",
    "                            sequence_length = 3, \n",
    "                            num_classes = num_classes, \n",
    "                            pretrained_model_name = pretrained_model_name, \n",
    "                            pooling = 'max', \n",
    "                            layer_1_size=128,\n",
    "                            layer_2_size=0, \n",
    "                            layer_3_size=0,\n",
    "                            dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.888908Z",
     "start_time": "2019-01-20T00:01:43.415Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "fit_history = fit(model_id = 1, model = architecture.model, data = data, learning_rate = 0.001, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## video_LRCNN_frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.889895Z",
     "start_time": "2019-01-20T00:01:43.418Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = \"vgg16\"\n",
    "pooling=\"max\"\n",
    "sequence_length = \n",
    "layer_1_size = 128\n",
    "layer_2_size = 64\n",
    "layer_3_size = 32\n",
    "dropout=0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.890963Z",
     "start_time": "2019-01-20T00:01:43.420Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = True, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.892039Z",
     "start_time": "2019-01-20T00:01:43.422Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(model_id=1,\n",
    "                            architecture=\"video_LRCNN_frozen\", \n",
    "                            sequence_model = 'LSTM',\n",
    "                            sequence_model_layers = 1,\n",
    "                            sequence_length = sequence_length,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name='vgg16', \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=8, \n",
    "                            dropout=0.2,\n",
    "                            convolution_kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.893274Z",
     "start_time": "2019-01-20T00:01:43.424Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "fit_history = fit(model_id=1, model=architecture.model, data=data, learning_rate = 0.001, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## video_LRCNN_trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.894825Z",
     "start_time": "2019-01-20T00:01:43.426Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequence_length=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.896011Z",
     "start_time": "2019-01-20T00:01:43.427Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=\"vgg16\",\n",
    "            pooling = \"max\",\n",
    "            batch_size=32,\n",
    "            return_generator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.897325Z",
     "start_time": "2019-01-20T00:01:43.429Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(model_id = 4,\n",
    "                            architecture=\"video_LRCNN_trainable\", \n",
    "                            sequence_model = 'LSTM',\n",
    "                            sequence_model_layers = 1,\n",
    "                            sequence_length = sequence_length,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name='vgg16', \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=8, \n",
    "                            dropout=0.2,\n",
    "                            convolution_kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.898485Z",
     "start_time": "2019-01-20T00:01:43.431Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "fit_history = fit(model_id = 1, model = architecture.model, data = data, learning_rate = 0.001, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T23:14:32.403927Z",
     "start_time": "2019-01-07T23:14:32.400506Z"
    }
   },
   "source": [
    "## C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.900757Z",
     "start_time": "2019-01-20T00:01:43.434Z"
    }
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(model_id = 4,\n",
    "                            architecture=\"C3D\", \n",
    "                            sequence_length = 16,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.901887Z",
     "start_time": "2019-01-20T00:01:43.435Z"
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "fit_history = fit(model_id = 122, model = architecture.model, data = data, learning_rate = 0.001, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## C3Dsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.903186Z",
     "start_time": "2019-01-20T00:01:43.437Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = 16, \n",
    "            return_CNN_features = False, \n",
    "            frame_size = (112,112),\n",
    "            return_generator=True,\n",
    "            batch_size=32,\n",
    "            verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.904356Z",
     "start_time": "2019-01-20T00:01:43.439Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(model_id = 4,\n",
    "                            architecture=\"C3Dsmall\", \n",
    "                            sequence_length = 16,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.905603Z",
     "start_time": "2019-01-20T00:01:43.441Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "fit_history = fit(model_id = 122, model = model, data = data, learning_rate = 0.001, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.908895Z",
     "start_time": "2019-01-20T00:01:43.447Z"
    }
   },
   "outputs": [],
   "source": [
    "path_models = pwd + 'models/'\n",
    "\n",
    "results = []\n",
    "\n",
    "for folder, subs, files in os.walk(path_models):\n",
    "    for filename in files:\n",
    "        if 'results.json' in filename:\n",
    "            with open(os.path.abspath(os.path.join(folder, filename))) as f:\n",
    "                data = json.load(f)\n",
    "            results.append(data)\n",
    "\n",
    "results = pd.DataFrame(results)        \n",
    "results.sort_values(\"fit_val_acc\", inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.910098Z",
     "start_time": "2019-01-20T00:01:43.449Z"
    }
   },
   "outputs": [],
   "source": [
    "results.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
