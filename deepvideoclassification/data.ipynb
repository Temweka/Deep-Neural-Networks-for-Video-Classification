{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:17:59.768442Z",
     "start_time": "2019-01-12T12:17:59.765396Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:01.067756Z",
     "start_time": "2019-01-12T12:18:00.074032Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import h5py\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:02.294484Z",
     "start_time": "2019-01-12T12:18:01.070932Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:02.302134Z",
     "start_time": "2019-01-12T12:18:02.297118Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pretrained model functions\n",
    "from deepvideoclassification.models import precompute_CNN_features\n",
    "from deepvideoclassification.models import load_pretrained_model_preprocessor\n",
    "from deepvideoclassification.models import load_pretrained_model\n",
    "\n",
    "# import pretrained model properties\n",
    "from deepvideoclassification.models import pretrained_model_len_features\n",
    "from deepvideoclassification.models import pretrained_model_sizes\n",
    "from deepvideoclassification.models import pretrained_model_names, poolings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:02.307946Z",
     "start_time": "2019-01-12T12:18:02.304591Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:02.316086Z",
     "start_time": "2019-01-12T12:18:02.310592Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:02.419044Z",
     "start_time": "2019-01-12T12:18:02.413754Z"
    }
   },
   "outputs": [],
   "source": [
    "# read vid folders\n",
    "def get_video_paths():\n",
    "    \"\"\"\n",
    "    Return list of video paths \n",
    "\n",
    "    Videos should be in /data/video_1/, /data/video_2/ style folders \n",
    "    with sequentially numbered frame images e.g. /data/video_1/frame00001.jpg\n",
    "\n",
    "    There should be at least 3 videos, 1 for each of train/test/valid splits\n",
    "    Split assignment is given in /data/labels.csv (also to be provided by user)\n",
    "\n",
    "    Functionality to use different parts of a video as train/valid/test \n",
    "    not currently implemented.\n",
    "    \"\"\"\n",
    "    path_videos = []\n",
    "    for filename in os.listdir(path_data):\n",
    "        if os.path.isdir(os.path.join(path_data, filename)):\n",
    "            path_videos.append(filename)\n",
    "\n",
    "    path_videos = [path_data + v + '/' for v in path_videos]\n",
    "\n",
    "    # make sure that there is video data in /data/ and give instructions if not done correctly\n",
    "    assert len(path_videos)>0, \"There need to be at least 3 video folders (at least 1 for each of train, valid, \\\n",
    "    and test splits) in /data/ - each video should be its own folder of frame images with ascending time-ordered \\\n",
    "    filenames e.g. /data/vid1/frame00001.jpg ... videos assignment to train/valid/test split should be given in \\\n",
    "    /data/labels.csv ... cross-validation or train/valid/test splits within a single long video not currently implemented\"\n",
    "\n",
    "    return path_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:02.637814Z",
     "start_time": "2019-01-12T12:18:02.629599Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_frames(target_size):\n",
    "    \"\"\"\n",
    "    Resize the frames of all videos and save them to /cache/ \n",
    "    to make model fitting faster .\n",
    "\n",
    "    We resize once upfront rather than each we use a pretrained model or architecture.\n",
    "\n",
    "    Our models require inputs resized to:\n",
    "    * 224 x 224 VGG16, ResNet50, DenseNet, MobileNet\n",
    "    * 299 x 299 XCeption, InceptionV3, InceptionResNetV2\n",
    "    * 112 x 112 3D CNN \n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/'):\n",
    "        \n",
    "        os.makedirs(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/')\n",
    "\n",
    "        # read vid paths\n",
    "        path_videos = get_video_paths()\n",
    "\n",
    "        # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "        for c,path_video in enumerate(path_videos):\n",
    "\n",
    "            logger.info(\"resizing vid {}/{} to {}x{}\".format(c+1,len(path_videos),target_size[0], target_size[1]))\n",
    "\n",
    "            # get vid name from path\n",
    "            video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "            # create directory for resized frames - just storing arrays now so commented out\n",
    "            # e.g. path_vid_resized = /cache/frames/224_224/s23-4847/\n",
    "            # path_vid_resized = path_cache + 'frames/'\n",
    "            # path_vid_resized += str(target_size[0]) + \"_\" + str(target_size[1]) + '/' \n",
    "            # path_vid_resized += video_name + '/'\n",
    "\n",
    "            # load frame paths for vid\n",
    "            path_frames = os.listdir(path_video)\n",
    "            path_frames = [path_video + f for f in path_frames if f != '.DS_Store']\n",
    "            path_frames.sort()\n",
    "\n",
    "            # load frames\n",
    "            frames = []\n",
    "            for path_frame in path_frames:\n",
    "\n",
    "                # open image and resize\n",
    "                filename = path_frame.split(\"/\").pop()\n",
    "                img_frame = Image.open(path_frame)\n",
    "                img_frame = img_frame.resize(target_size)\n",
    "                # img_frame.save(path_vid_resized + filename, \"JPEG\", quality = 100)\n",
    "\n",
    "                # convert to array and append to list\n",
    "                img_frame = np.array(img_frame)\n",
    "                frames.append(img_frame)\n",
    "\n",
    "            # save array of resized frames\n",
    "            np.save(path_cache + \"frames/\" + str(target_size[0]) + \"_\" + str(target_size[1]) + \"/\" + video_name, np.array(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T13:19:33.859690Z",
     "start_time": "2019-01-12T13:19:33.854555Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    # read labels - should be CSV with columns \"video\",\"frame\",\"label\",\"split\"\n",
    "    # e.g. \"s1-218\", \"s1-218-00001.jpeg\", \"noseal\", \"train\"\n",
    "    labels = None\n",
    "    try:\n",
    "        labels = pd.read_csv(path_data + 'labels.csv', usecols=['video','frame','label','split'])\n",
    "    except ValueError as e:\n",
    "        raise Exception(\"Labels file must contain columns ['video','frame','label','split'] - if you only have ['video','frame','label'], use Jupyter notebook in notebooks/add_splits_to_labels_file.ipynb to add train/valid/test splits to your labels file\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise Exception(\"No labels found - please save labels file to /data/labels.csv\") from e\n",
    "\n",
    "    return labels.sort_values([\"video\",\"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:03.033071Z",
     "start_time": "2019-01-12T12:18:03.026578Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_video_label_arrays():\n",
    "    \"\"\"\n",
    "    Create numpy array with labels for each vid and a label_map.json file\n",
    "    in /cache/labels/\n",
    "    \"\"\"\n",
    "\n",
    "    # create folder for labels\n",
    "    if not os.path.exists(path_cache + 'labels/'):\n",
    "        os.makedirs(path_cache + 'labels/')\n",
    "\n",
    "    # load labels\n",
    "    labels = get_labels()\n",
    "\n",
    "    # build label_map\n",
    "    label_dummies = pd.get_dummies(labels, columns = ['label'])\n",
    "\n",
    "    # get label columns list and build label map dict\n",
    "    label_columns = []\n",
    "    label_map = {}\n",
    "    label_map_idx = 0\n",
    "    for i, col in enumerate(label_dummies.columns):\n",
    "        if col[:6] == 'label_':\n",
    "            label_columns.append(col)\n",
    "            label_map[label_map_idx] = col\n",
    "            label_map_idx+=1\n",
    "\n",
    "    # save label map to json\n",
    "    with open(path_cache + 'labels/label_map.json', 'w') as fp:\n",
    "        json.dump(label_map, fp)\n",
    "\n",
    "    # get video paths\n",
    "    path_videos = get_video_paths()\n",
    "\n",
    "    # save numpy array of labels for each vid\n",
    "    for path_video in path_videos:\n",
    "\n",
    "        # get vid name from path\n",
    "        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "        vid_labels = np.array(label_dummies[label_dummies['video'] == video_name][label_columns])\n",
    "\n",
    "        # save labels array for this vid\n",
    "        np.save(path_cache + \"/labels/\" + video_name, np.array(vid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:03.266087Z",
     "start_time": "2019-01-12T12:18:03.260777Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_label_map():\n",
    "    \"\"\"\n",
    "    Returns label map - read from disk\n",
    "    \"\"\"\n",
    "\n",
    "    # load label map from disk\n",
    "    label_map = None\n",
    "    try:\n",
    "        if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "            with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                label_map = json.load(fp)\n",
    "        else:\n",
    "            # build labels and label map\n",
    "            create_video_label_arrays()\n",
    "            if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "                with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                    label_map = json.load(fp)\n",
    "    except Exception as e:\n",
    "        logger.error ('label map not found - make sure /data/labels.csv exists and data cache has been built')\n",
    "\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T12:18:03.433360Z",
     "start_time": "2019-01-12T12:18:03.425749Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Generator (used in Data) that generates data for Keras fit_generator method because full dataset too big to load into memory\n",
    "    \n",
    "    > inherits from keras.utils.Sequence\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, h5_path, h5_row_count):\n",
    "        \"\"\"\n",
    "        Initialization DataGenerator class\n",
    "        \n",
    "        :batch_size: number of samples to return in batch \n",
    "        :h5_path: path to h5 dataset (where we stored the generated sequence data via save_frame_sequences_to_h5())\n",
    "        :h5_row_count: number of rows in h5 dataset\n",
    "        \n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.h5_path = h5_path\n",
    "        self.h5_row_count = h5_row_count\n",
    "        \n",
    "        # init (shuffle dataset)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.h5_row_count / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        x, y = self.__data_generation(batch_indexes)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.h5_row_count)\n",
    "        \n",
    "        # shuffle indexes -> shuffle samples returned in each batch\n",
    "        np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batch_indexes):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples\n",
    "        \n",
    "        :batch_indexes: list (of size batch_size) with indexes into h5 file\n",
    "        \"\"\" \n",
    "        x, y = None, None\n",
    "\n",
    "        # slices into h5 file need to be sorted\n",
    "        batch_indexes.sort()\n",
    "\n",
    "        # read sample from h5 file\n",
    "        with h5py.File(self.h5_path, 'r') as h5:\n",
    "            ### read sample indexes from h5 file\n",
    "            # sample sequences\n",
    "            x = h5['sequences'][batch_indexes,:]\n",
    "            # sample labels\n",
    "            y = h5['labels'][batch_indexes,:]\n",
    "\n",
    "        return x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T13:23:49.337320Z",
     "start_time": "2019-01-12T13:23:49.277525Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def __init__(self, sequence_length, \n",
    "                    return_CNN_features = False, pretrained_model_name = None, pooling = None, \n",
    "                    frame_size = None, augmentation = False, oversampling = False,\n",
    "                    model_weights_path = None, custom_model_name = None,\n",
    "                    return_generator = False, batch_size = None,\n",
    "                    verbose = True):\n",
    "        \"\"\"\n",
    "        Data object constructor\n",
    "        \n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        :return_CNN_features: whether to return precomputed features or return frames (or sequences of features/frames if sequence_length>1)\n",
    "\n",
    "        :return_features: if True then return features (or sequences of feature) from pretrained model, if False then return frames (or sequences of frames)        \n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :frame_size: size that frames are resized to (this is looked up for pretrained models)\n",
    "        :augmentation: whether to apply data augmentation (horizontal flips)\n",
    "        :oversampling: whether to apply oversampling to create class balance\n",
    "        \n",
    "        :model_weights_path: path to custom model weights if we want to load CNN model we've fine-tuned to produce features (e.g. for LRCNN)\n",
    "        :custom_model_name: custom output name to append to pretrained model name\n",
    "        \n",
    "        :return_generator: if True and sequence_length > 1 and return_CNN_features == False, then do not return dataset, instead construct h5 file with sequences for each split and return generator that samples from that (dataset of sequecne frames too big to load into memory)\n",
    "        :batch_size: size of batches that generator must return\n",
    "        \n",
    "        :verbose: whether to log details\n",
    "        \n",
    "        Notes: \n",
    "        * if pretrained_model_name != None and return_CNN_features=False then will first apply preprocessor to frames (or frame sequences)\n",
    "        * if return_generator = True and sequence_length > 1 and return_CNN_features == False, large h5 files will be created in cache before returning generator\n",
    "        \"\"\"\n",
    "    \n",
    "        # required params\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frame_size = frame_size\n",
    "        \n",
    "        # optional params\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.return_CNN_features = return_CNN_features\n",
    "        self.augmentation = augmentation\n",
    "        self.oversampling = oversampling\n",
    "        \n",
    "        # init model data\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_valid = []\n",
    "        self.y_valid = []\n",
    "        # \n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        # fix case sensitivity\n",
    "        if type(self.pretrained_model_name) == str:\n",
    "            self.pretrained_model_name = self.pretrained_model_name.lower()\n",
    "        if type(self.pooling) == str:\n",
    "            self.pooling = self.pooling.lower()\n",
    "        \n",
    "        ################\n",
    "        ### Prepare data\n",
    "        ################\n",
    "        \n",
    "        # get video paths\n",
    "        self.path_videos = get_video_paths()\n",
    "        \n",
    "        # create label array for each video and load label map\n",
    "        create_video_label_arrays()\n",
    "        self.label_map = load_label_map()\n",
    "        \n",
    "        # get labels\n",
    "        self.labels = get_labels()\n",
    "        \n",
    "        # check that there is 1 frame file for each label file and raise error if they don't match\n",
    "        paths_frames = []\n",
    "        for folder, subs, files in os.walk(path_data):        \n",
    "            for filename in files:\n",
    "                if filename[-4:].lower() == '.jpg' or filename[-4:].lower() == 'jpeg' or filename[-4:].lower() == 'png':\n",
    "                    paths_frames.append(os.path.abspath(os.path.join(folder, filename)))\n",
    "        if len(paths_frames) != len(self.labels):\n",
    "            error_msg = 'IMPORTANT ERROR: Number of frames ({}) in /data/ video folders needs to match number of labels ({}) in labels.csv - use notebooks/helper_check_frames_against_labels.ipynb to investigate... Note, only labels.csv and the frames you want to use (in video subfolders) should be in /data/'.format(len(paths_frames), len(self.labels))\n",
    "            logger.info(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "        \n",
    "        # pull number of classes from labels shape\n",
    "        self.num_classes = self.labels['label'].nunique()\n",
    "        \n",
    "        # create dict mapping video to train/valid/test split assignment\n",
    "        video_splits = self.labels[['video','split']].drop_duplicates()\n",
    "        video_splits.set_index(\"video\", inplace=True)\n",
    "        video_splits = video_splits.to_dict()['split']\n",
    "        self.video_splits = video_splits\n",
    "        \n",
    "        # look up target size for pretrained model\n",
    "        if pretrained_model_name is not None:\n",
    "            self.frame_size = pretrained_model_sizes[pretrained_model_name]\n",
    "        \n",
    "        # precompute resized frames (won't recompute if already resized)\n",
    "        resize_frames(self.frame_size)\n",
    "\n",
    "        # pre compute CNN features (won't recompute if already computed)\n",
    "        if return_CNN_features and pretrained_model_name is not None:\n",
    "            if model_weights_path is not None and custom_model_name is not None:\n",
    "                # precompute with custom weights input and name\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling, self.model_weights_path, self.custom_model_name)\n",
    "            else:\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # get preprocessor given pretrained if we will need to apply preprocessor \n",
    "        # (i.e. if return_CNN_features == False and pretrained_model_name != None)\n",
    "        if not return_CNN_features and pretrained_model_name is not None:\n",
    "            self.preprocess_input = load_pretrained_model_preprocessor(self.pretrained_model_name)\n",
    "        \n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.return_generator = return_generator\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # do some checks\n",
    "        if self.return_generator:\n",
    "            assert self.batch_size != None, \"batch size required to construct generator\"\n",
    "        if self.return_generator:\n",
    "            assert self.return_CNN_features == False, \"generator only implemented for frame sequences - features usually large enough to load into memory [may take a few minutes]\"\n",
    "        \n",
    "        ###################################\n",
    "        ### load features / build sequences\n",
    "        ###################################\n",
    "        \n",
    "        \n",
    "        # load features/frames from all videos and concat into big array for each of train, valid and test\n",
    "        if self.sequence_length > 1:\n",
    "            \n",
    "            ### sequences\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Loading features sequence data into memory [may take a few minutes]\")\n",
    "                \n",
    "                #####################\n",
    "                ### feature sequences\n",
    "                #####################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    features = np.load(path_features + video_name + '.npy')\n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(features) + 1):\n",
    "                        x.append(features[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: labels\n",
    "                    # load precomputed labels\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(self.labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                        \n",
    "            else:\n",
    "\n",
    "                ###################\n",
    "                ### frame sequences\n",
    "                ###################\n",
    "                \n",
    "                # load full frame sequecne dataset into memory and return\n",
    "                if not return_generator:\n",
    "                    \n",
    "                    ##############################################################################\n",
    "                    ### load full sequence dataset into memory (will likely run into memory error)\n",
    "                    ##############################################################################\n",
    "                    \n",
    "                    if verbose:\n",
    "                        logging.info(\"Loading frame sequence data into memory [may take a few minutes]\")\n",
    "\n",
    "                    # load resized numpy array\n",
    "                    path_vid_resized = path_cache + 'frames/'\n",
    "                    path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "                    path_labels = path_cache + 'labels/'\n",
    "\n",
    "                    # read vid paths\n",
    "                    path_videos = get_video_paths()\n",
    "\n",
    "                    # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                    for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                        # get vid name from path\n",
    "                        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "                        ### create sequence: features\n",
    "                        # load precomputed frames\n",
    "                        frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "\n",
    "                        # first apply preprocessing if pretrained model given\n",
    "                        if pretrained_model_name != None:\n",
    "                            frames = self.preprocess_input(frames)\n",
    "\n",
    "                        # build sequences\n",
    "                        x = []\n",
    "                        for i in range(sequence_length, len(frames) + 1):\n",
    "                            x.append(frames[i-sequence_length:i])\n",
    "                        x = np.array(x)\n",
    "\n",
    "\n",
    "                        ### create sequence: labels\n",
    "                        # load precomputed labels\n",
    "                        labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                        # temp lists to store sequences\n",
    "                        y = []\n",
    "                        for i in range(sequence_length, len(self.labels) + 1):\n",
    "                            y.append(labels[i-1])\n",
    "                        y = (np.array(y))\n",
    "\n",
    "                        ### build output\n",
    "                        if self.video_splits[video_name] == \"train\":\n",
    "                            self.x_train.append(x)\n",
    "                            self.y_train.append(y)\n",
    "                        if self.video_splits[video_name] == \"valid\":\n",
    "                            self.x_valid.append(x)\n",
    "                            self.y_valid.append(y)\n",
    "                        if self.video_splits[video_name] == \"test\":\n",
    "                            self.x_test.append(x)\n",
    "                            self.y_test.append(y)\n",
    "                else:\n",
    "                    #############################\n",
    "                    ### Build sequences generator\n",
    "                    #############################\n",
    "            \n",
    "                    # compute and save h5 sequence files (save_frame_sequences_to_h5 returns \n",
    "                    # the sequence sizes which we need for our generator)\n",
    "                    self.total_rows_train, self.total_rows_valid, self.total_rows_test = self.save_frame_sequences_to_h5()\n",
    "                    \n",
    "                    # init generators\n",
    "                    self.generator_train = DataGenerator(self.batch_size, self.path_h5_train, self.total_rows_train)\n",
    "                    self.generator_valid = DataGenerator(self.batch_size, self.path_h5_valid, self.total_rows_valid)\n",
    "                    self.generator_test = DataGenerator(self.batch_size, self.path_h5_test, self.total_rows_test)\n",
    "                \n",
    "        else:\n",
    "\n",
    "            ### not sequence\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Loading features data into memory [may take a few minutes]\")\n",
    "                \n",
    "                ###################\n",
    "                ### feature vectors\n",
    "                ###################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### load precomputed features\n",
    "                    x = np.load(path_features + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    if x.shape[0] != y.shape[0]:\n",
    "                        print(\"XXX\", path_video, x.shape, y.shape)\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            else:\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Loading frames into memory [may take a few minutes]\")\n",
    "                \n",
    "                #################\n",
    "                ### single frames\n",
    "                #################\n",
    "                \n",
    "                # load resized numpy array\n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    # load precomputed numpy arrays for frames and labels\n",
    "                    x = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    # apply preprocessing if pretrained model given\n",
    "                    if pretrained_model_name != None:\n",
    "                        x = self.preprocess_input(x)\n",
    "                \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            \n",
    "            \n",
    "        #################################\n",
    "        ### get file paths for each split\n",
    "        #################################\n",
    "        #\n",
    "        # Note: only makes sense for sequence_length = 1\n",
    "        \n",
    "        # get file paths: train\n",
    "        dflab = self.labels[self.labels['split'] == 'train']\n",
    "        self.paths_train = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: valid\n",
    "        dflab = self.labels[self.labels['split'] == 'valid']\n",
    "        self.paths_valid = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: test\n",
    "        dflab = self.labels[self.labels['split'] == 'test']\n",
    "        self.paths_test = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        ### reshape list outputs (if not using generator)\n",
    "        #################################################\n",
    "        \n",
    "        if not return_generator:\n",
    "            ## e.g. (9846, 224, 224, 3) for frames [return_CNN_features=True]\n",
    "            ## or  (9846, 512) for features [return_CNN_features=False]\n",
    "            self.x_train = np.concatenate(self.x_train, axis=0)\n",
    "            self.y_train = np.concatenate(self.y_train, axis=0)\n",
    "            self.x_valid = np.concatenate(self.x_valid, axis=0)\n",
    "            self.y_valid = np.concatenate(self.y_valid, axis=0)\n",
    "            self.x_test = np.concatenate(self.x_test, axis=0)\n",
    "            self.y_test = np.concatenate(self.y_test, axis=0)\n",
    "            \n",
    "            # shuffle train and validation set\n",
    "            self.shuffle()\n",
    "            \n",
    "\n",
    "    def __str__(self):\n",
    "        return \"x_train: {}, y_train: {} ... x_valid: {}, y_valid: {} ... x_test: {}, y_test: {}\".format(self.x_train.shape,self.y_train.shape,self.x_valid.shape,self.y_valid.shape,self.x_test.shape,self.y_test.shape)\n",
    "            \n",
    "    def shuffle(self):\n",
    "        \"\"\"\n",
    "        Randomize the order of samples in train and valid splits\n",
    "        \"\"\"\n",
    "        ###########\n",
    "        ### shuffle\n",
    "        ###########\n",
    "        print(self.x_train.shape, self.y_train.shape, len(self.paths_train))\n",
    "        if self.sequence_length == 1:\n",
    "            self.x_train, self.y_train, self.paths_train = shuffle(self.x_train, self.y_train, self.paths_train)\n",
    "            self.x_valid, self.y_valid, self.paths_valid = shuffle(self.x_valid, self.y_valid, self.paths_valid)\n",
    "        else:\n",
    "            self.x_train, self.y_train = shuffle(self.x_train, self.y_train)\n",
    "            self.x_valid, self.y_valid = shuffle(self.x_valid, self.y_valid)\n",
    "\n",
    "        \n",
    "\n",
    "    # Even at small sequence lengths, loading the full dataset as \n",
    "    # a sequence into memory is not feasible so we need to use generators\n",
    "    # that iterate over the dataset without loading it all into memory\n",
    "    # \n",
    "    # For now, we will assume that we will load the features datasets into memory\n",
    "    # because this is more feasible but for large datasets, we'd want to use generators for that too. \n",
    "    # An implementation for a feature generator  can be done by pattern matching the implementation for frames \n",
    "    # \n",
    "    # we first precompute a sequences h5 file (it's too big to fit in memory but we never have more than 1\n",
    "    # video's sequences in memory) ...then we will initialize a generator that samples sequences from the \n",
    "    # h5 file and returns batches that will be passed to our model's fit_generator method\n",
    "\n",
    "    def save_frame_sequences_to_h5(self):\n",
    "        \"\"\"\n",
    "        Save sequence of frames to h5 files (1 for each split) in cache \n",
    "        because dataset too big to load into memory\n",
    "        \n",
    "        Will create generator that reads random rows from these h5 files\n",
    "        \n",
    "        Inspired by: https://stackoverflow.com/questions/41849649/write-to-hdf5-and-shuffle-big-arrays-of-data\n",
    "        \"\"\"\n",
    "    \n",
    "        #######################\n",
    "        ### setup h5 file paths\n",
    "        #######################\n",
    "        \n",
    "        if not os.path.exists(path_cache + 'sequences/'):\n",
    "            os.makedirs(path_cache + 'sequences/')\n",
    "\n",
    "        path_h5_base = path_cache + 'sequences/'\n",
    "\n",
    "        # store h5 files in subfolder in cache/sequences/ either with pretrained model name or resize name\n",
    "        # since we need to run preprocessing for pretrained models but not for vanilla resizing (3DCNN)\n",
    "        if pretrained_model_name is not None:\n",
    "            path_h5_base += pretrained_model_name + '/'\n",
    "        else:\n",
    "            path_h5_base += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "        if not os.path.exists(path_h5_base):\n",
    "            os.makedirs(path_h5_base)\n",
    "\n",
    "        self.path_h5_train = path_h5_base + '/h5_' + str(self.sequence_length) + 'train.h5'\n",
    "        self.path_h5_valid = path_h5_base + '/h5_' + str(self.sequence_length) + 'valid.h5'\n",
    "        self.path_h5_test = path_h5_base + '/h5_' + str(self.sequence_length) + 'test.h5'\n",
    "    \n",
    "        # build h5 file if doesn't exists()\n",
    "        if not os.path.exists(self.path_h5_train) or not os.path.exists(self.path_h5_valid) or not os.path.exists(self.path_h5_test):\n",
    "            \n",
    "            if verbose:\n",
    "                logging.info(\"Computing frame sequence h5 files: {} [may take a few minutes]\".format(path_h5_base))\n",
    "\n",
    "            ##################################################\n",
    "            ### get size of train/valid/test sequence datasets\n",
    "            ##################################################\n",
    "\n",
    "            # total number of rows of sequence data we have for each split\n",
    "            # this is not the same as the number of frames since we exclude\n",
    "            # the first (self.sequence_length-1) frames\n",
    "            total_rows_train = 0\n",
    "            total_rows_valid = 0\n",
    "            total_rows_test = 0\n",
    "\n",
    "            # load resized numpy array\n",
    "            path_vid_resized = path_cache + 'frames/'\n",
    "            path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "            path_labels = path_cache + 'labels/'\n",
    "\n",
    "            # read vid paths\n",
    "            path_videos = get_video_paths()\n",
    "\n",
    "            # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "            for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                # get vid name from path\n",
    "                video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "                # load resized frames\n",
    "                frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "\n",
    "                # build sequences\n",
    "                x = []\n",
    "                for i in range(self.sequence_length, len(frames) + 1):\n",
    "                    x.append(frames[i-self.sequence_length:i])\n",
    "                x = np.array(x)\n",
    "\n",
    "                if self.video_splits[video_name] == \"train\":\n",
    "                    total_rows_train += len(x)\n",
    "                if self.video_splits[video_name] == \"valid\":\n",
    "                    total_rows_valid += len(x)\n",
    "                if self.video_splits[video_name] == \"test\":\n",
    "                    total_rows_test += len(x)\n",
    "\n",
    "            # calc shapes required for full sequence dataset\n",
    "            h5_shape_train_x = (total_rows_train, self.sequence_length, self.frame_size[0], self.frame_size[1], 3)\n",
    "            h5_shape_train_y = (total_rows_train, self.num_classes)\n",
    "\n",
    "            h5_shape_valid_x = (total_rows_valid, self.sequence_length, self.frame_size[0], self.frame_size[1], 3)\n",
    "            h5_shape_valid_y = (total_rows_valid, self.num_classes)\n",
    "\n",
    "            h5_shape_test_x = (total_rows_test, self.sequence_length, self.frame_size[0], self.frame_size[1], 3)\n",
    "            h5_shape_test_y = (total_rows_test, self.num_classes)\n",
    "\n",
    "\n",
    "            ################################\n",
    "            ### Initialize and open h5 files\n",
    "            ################################\n",
    "\n",
    "            # open h5 file to store big sequence dataset feature and label arrays\n",
    "            # path_h5file = MODEL -> SEQUENCE LENGTH\n",
    "            f_train = h5py.File(self.path_h5_train, 'a')\n",
    "            f_valid = h5py.File(self.path_h5_valid, 'a')\n",
    "            f_test = h5py.File(self.path_h5_test, 'a')\n",
    "\n",
    "            # initialize h5 datasets\n",
    "            h5_train_x = f_train.create_dataset('sequences', shape= h5_shape_train_x, dtype='uint8')\n",
    "            h5_train_y = f_train.create_dataset('labels', shape= h5_shape_train_y, dtype='uint8')\n",
    "\n",
    "            h5_valid_x = f_valid.create_dataset('sequences', shape= h5_shape_valid_x, dtype='uint8')\n",
    "            h5_valid_y = f_valid.create_dataset('labels', shape= h5_shape_valid_y, dtype='uint8')\n",
    "\n",
    "            h5_test_x = f_test.create_dataset('sequences', shape= h5_shape_test_x, dtype='uint8')\n",
    "            h5_test_y = f_test.create_dataset('labels', shape= h5_shape_test_y, dtype='uint8')\n",
    "\n",
    "            ##################################################\n",
    "            ### Build h5 files for this sequence / model combo\n",
    "            ##################################################\n",
    "\n",
    "            # load resized numpy array\n",
    "            path_vid_resized = path_cache + 'frames/'\n",
    "            path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "            path_labels = path_cache + 'labels/'\n",
    "\n",
    "            # read vid paths\n",
    "            path_videos = get_video_paths()\n",
    "\n",
    "            # keep track of where we are in the h5 file\n",
    "            h5_cursor_train = 0\n",
    "            h5_cursor_valid = 0\n",
    "            h5_cursor_test = 0\n",
    "\n",
    "            # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "            for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                # get vid name from path\n",
    "                video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "                ### create sequence: features\n",
    "                # load precomputed frames\n",
    "                frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                \n",
    "                # first apply preprocessing if pretrained model given\n",
    "                if pretrained_model_name != None:\n",
    "                    frames = self.preprocess_input(frames)\n",
    "                    \n",
    "                # build sequences\n",
    "                x = []\n",
    "                for i in range(self.sequence_length, len(frames) + 1):\n",
    "                    x.append(frames[i-self.sequence_length:i])\n",
    "                x = np.array(x)\n",
    "\n",
    "                ### create sequence: labels\n",
    "                # load precomputed labels\n",
    "                labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                # temp lists to store sequences\n",
    "                y = []\n",
    "                for i in range(self.sequence_length, len(self.labels) + 1):\n",
    "                    y.append(labels[i-1])\n",
    "                y = (np.array(y))\n",
    "\n",
    "                ### write this vid's data to relevant h5 dataset\n",
    "                if self.video_splits[video_name] == \"train\":\n",
    "                    h5_train_x[h5_cursor_train:h5_cursor_train + x.shape[0], :, :, :, :] = x\n",
    "                    h5_train_y[h5_cursor_train:h5_cursor_train + y.shape[0], :] = y\n",
    "                    h5_cursor_train += len(x)\n",
    "                if self.video_splits[video_name] == \"valid\":\n",
    "                    h5_valid_x[h5_cursor_valid:h5_cursor_valid + x.shape[0], :, :, :, :] = x\n",
    "                    h5_valid_y[h5_cursor_valid:h5_cursor_valid + y.shape[0], :] = y\n",
    "                    h5_cursor_valid += len(x)\n",
    "                if self.video_splits[video_name] == \"test\":\n",
    "                    h5_test_x[h5_cursor_test:h5_cursor_test + x.shape[0], :, :, :, :] = x\n",
    "                    h5_test_y[h5_cursor_test:h5_cursor_test + y.shape[0], :] = y\n",
    "                    h5_cursor_test += len(x)\n",
    "            \n",
    "            # save total row counts to file\n",
    "            with open(path_h5_base + 'h5_meta.json', 'w') as fp:\n",
    "                json.dump({'total_rows_train':total_rows_train,\n",
    "                           'total_rows_valid': total_rows_valid,\n",
    "                           'total_rows_test':total_rows_test}\n",
    "                          , fp)\n",
    "                    \n",
    "            # close h5 files\n",
    "            f_train.close()\n",
    "            f_valid.close()\n",
    "            f_test.close()\n",
    "        \n",
    "            # return total samples for each split so we can pass them to our DataGenerator\n",
    "            return total_rows_train, total_rows_valid, total_rows_test\n",
    "        \n",
    "        else:\n",
    "            # h5 sequence file already exists - just load the sequence meta and return sequence lengths \n",
    "            # so we can pass them to our DataGenerator\n",
    "            total_rows_train, total_rows_valid, total_rows_test = None, None, None\n",
    "            with open(path_h5_base + 'h5_meta.json', 'r') as fp:\n",
    "                h5_meta = json.load(fp)\n",
    "                total_rows_train = h5_meta['total_rows_train']\n",
    "                total_rows_valid = h5_meta['total_rows_valid']\n",
    "                total_rows_test = h5_meta['total_rows_test']\n",
    "                \n",
    "            # return total samples for each split so we can pass them to our DataGenerator\n",
    "            return total_rows_train, total_rows_valid, total_rows_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TEST GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T15:43:38.799879Z",
     "start_time": "2019-01-11T15:43:38.796735Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.models import Architecture\n",
    "from deepvideoclassification.models import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T15:43:41.287040Z",
     "start_time": "2019-01-11T15:43:41.283674Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = \"vgg16\"\n",
    "pooling=\"max\"\n",
    "sequence_length = 3\n",
    "\n",
    "layer_1_size = 128\n",
    "layer_2_size = 64\n",
    "layer_3_size = 32\n",
    "dropout=0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## train with no generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:53:43.917880Z",
     "start_time": "2019-01-11T16:52:42.619542Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling)\n",
    "\n",
    "num_classes = data.num_classes \n",
    "frame_size = data.frame_size\n",
    "num_features = pretrained_model_len_features[pretrained_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:57:00.634326Z",
     "start_time": "2019-01-11T16:56:59.407512Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(architecture=\"video_LRCNN_trainable\", \n",
    "                            sequence_model = 'LSTM',\n",
    "                            sequence_model_layers = 1,\n",
    "                            sequence_length = sequence_length,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name='vgg16', \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=8, \n",
    "                            dropout=0.2,\n",
    "                            convolution_kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T17:13:25.237102Z",
     "start_time": "2019-01-11T16:57:02.331628Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train model with no data generator\n",
    "train(architecture.model, data, path_model = pwd+'models/', learning_rate = 0.001, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## train with generator - seq length 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:16:14.949162Z",
     "start_time": "2019-01-11T16:16:14.945216Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = 'vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:16:15.314050Z",
     "start_time": "2019-01-11T16:16:15.114667Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling,\n",
    "            batch_size=32,\n",
    "            return_generator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:16:21.965754Z",
     "start_time": "2019-01-11T16:16:21.960539Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.generator_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:18:38.074621Z",
     "start_time": "2019-01-11T16:18:38.071575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:25:52.668117Z",
     "start_time": "2019-01-11T16:25:51.556468Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(architecture=\"video_LRCNN_trainable\", \n",
    "                            sequence_model = 'LSTM',\n",
    "                            sequence_model_layers = 1,\n",
    "                            sequence_length = sequence_length,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name='vgg16', \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=8, \n",
    "                            dropout=0.2,\n",
    "                            convolution_kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:25:53.732149Z",
     "start_time": "2019-01-11T16:25:53.676936Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create optimizer with given learning rate \n",
    "opt = Adam()\n",
    "\n",
    "# compile model\n",
    "architecture.model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:31:15.185724Z",
     "start_time": "2019-01-11T16:25:54.691109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train model on dataset\n",
    "architecture.model.fit_generator(generator=data.generator_train,\n",
    "                    validation_data=data.generator_valid,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:36:33.436803Z",
     "start_time": "2019-01-11T16:31:15.190349Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train model on dataset\n",
    "architecture.model.fit_generator(generator=data.generator_train,\n",
    "                    validation_data=data.generator_valid,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:41:51.832347Z",
     "start_time": "2019-01-11T16:36:33.468020Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train model on dataset\n",
    "architecture.model.fit_generator(generator=data.generator_train,\n",
    "                    validation_data=data.generator_valid,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## train with generator - seq length 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T17:30:49.854438Z",
     "start_time": "2019-01-11T17:30:49.851684Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = 'vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T17:31:43.842867Z",
     "start_time": "2019-01-11T17:31:43.839563Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequence_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T17:31:44.916035Z",
     "start_time": "2019-01-11T17:31:44.004605Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling,\n",
    "            batch_size=32,\n",
    "            return_generator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T17:31:44.922387Z",
     "start_time": "2019-01-11T17:31:44.918967Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T17:31:46.237436Z",
     "start_time": "2019-01-11T17:31:44.925061Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(architecture=\"video_LRCNN_trainable\", \n",
    "                            sequence_model = 'LSTM',\n",
    "                            sequence_model_layers = 1,\n",
    "                            sequence_length = sequence_length,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name='vgg16', \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=8, \n",
    "                            dropout=0.2,\n",
    "                            convolution_kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T17:31:46.297844Z",
     "start_time": "2019-01-11T17:31:46.240551Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create optimizer with given learning rate \n",
    "opt = Adam()\n",
    "\n",
    "# compile model\n",
    "architecture.model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T17:32:10.919156Z",
     "start_time": "2019-01-11T17:31:46.301061Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train model on dataset\n",
    "architecture.model.fit_generator(generator=data.generator_train,\n",
    "                    validation_data=data.generator_valid,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=12,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T13:23:51.957787Z",
     "start_time": "2019-01-12T13:23:50.653966Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-12 13:23:50,657 [MainThread  ] [INFO ]  Building resized and feature cache\n",
      "2019-01-12 13:23:51,933 [MainThread  ] [INFO ]  IMPORTANT ERROR: Number of frames (88087) in /data/ video folders needs to match number of labels (92886) in labels.csv - use notebooks/helper_extract_frames.ipynb to investigate... Note, only labels.csv and the frames you want to use (in video subfolders) should be in /data/\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "IMPORTANT ERROR: Number of frames (88087) in /data/ video folders needs to match number of labels (92886) in labels.csv - use notebooks/helper_extract_frames.ipynb to investigate... Note, only labels.csv and the frames you want to use (in video subfolders) should be in /data/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-91ee775d4826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mreturn_CNN_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \u001b[0mpretrained_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         pooling=pooling)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-0b091cfdd864>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sequence_length, return_CNN_features, pretrained_model_name, pooling, frame_size, augmentation, oversampling, model_weights_path, custom_model_name, return_generator, batch_size, verbose)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'IMPORTANT ERROR: Number of frames ({}) in /data/ video folders needs to match number of labels ({}) in labels.csv - use notebooks/helper_extract_frames.ipynb to investigate... Note, only labels.csv and the frames you want to use (in video subfolders) should be in /data/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# pull number of classes from labels shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: IMPORTANT ERROR: Number of frames (88087) in /data/ video folders needs to match number of labels (92886) in labels.csv - use notebooks/helper_extract_frames.ipynb to investigate... Note, only labels.csv and the frames you want to use (in video subfolders) should be in /data/"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    logger.info(\"Building resized and feature cache\")\n",
    "    # build feature cache in advance by running python3 data.py\n",
    "    for pretrained_model_name in pretrained_model_names:\n",
    "        for pooling in poolings:\n",
    "            data = Data(sequence_length=1, \n",
    "                        return_CNN_features=True,\n",
    "                        pretrained_model_name = pretrained_model_name,\n",
    "                        pooling=pooling)\n",
    "            \n",
    "            \n",
    "    # build h5 cache\n",
    "    logger.info(\"Building h5 cache\")\n",
    "    for sequence_length in [2,3,5,10,20]:\n",
    "        for pretrained_model_name in pretrained_model_names:\n",
    "\n",
    "            data = Data(sequence_length=sequence_length, \n",
    "                        return_CNN_features=False, \n",
    "                        pretrained_model_name = pretrained_model_name, \n",
    "                        return_generator = True,\n",
    "                        verbose=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
