{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:36:25.348859Z",
     "start_time": "2019-01-07T10:36:25.345696Z"
    }
   },
   "outputs": [],
   "source": [
    "### TODO:\n",
    "# * add train/valid/test generators to data\n",
    "# * need option to apply preprocessor when requesting frame data\n",
    "# * make sure don't recompute sequences if inputs don't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:00.470823Z",
     "start_time": "2019-01-07T17:27:00.467204Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:01.599504Z",
     "start_time": "2019-01-07T17:27:00.686737Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:03.731180Z",
     "start_time": "2019-01-07T17:27:02.487014Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import pretrained model functions\n",
    "from deepvideoclassification.models import precompute_CNN_features\n",
    "from deepvideoclassification.models import load_pretrained_model_preprocessor\n",
    "from deepvideoclassification.models import load_pretrained_model\n",
    "\n",
    "# import pretrained model properties\n",
    "from deepvideoclassification.models import pretrained_model_len_features\n",
    "from deepvideoclassification.models import pretrained_model_sizes\n",
    "from deepvideoclassification.models import pretrained_model_names, poolings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:03.737516Z",
     "start_time": "2019-01-07T17:27:03.734106Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:03.745112Z",
     "start_time": "2019-01-07T17:27:03.740125Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:03.752607Z",
     "start_time": "2019-01-07T17:27:03.747849Z"
    }
   },
   "outputs": [],
   "source": [
    "# read vid folders\n",
    "def get_video_paths():\n",
    "    \"\"\"\n",
    "    Return list of video paths \n",
    "\n",
    "    Videos should be in /data/video_1/, /data/video_2/ style folders \n",
    "    with sequentially numbered frame images e.g. /data/video_1/frame00001.jpg\n",
    "\n",
    "    There should be at least 3 videos, 1 for each of train/test/valid splits\n",
    "    Split assignment is given in /data/labels.csv (also to be provided by user)\n",
    "\n",
    "    Functionality to use different parts of a video as train/valid/test \n",
    "    not currently implemented.\n",
    "    \"\"\"\n",
    "    path_videos = []\n",
    "    for filename in os.listdir(path_data):\n",
    "        if os.path.isdir(os.path.join(path_data, filename)):\n",
    "            path_videos.append(filename)\n",
    "\n",
    "    path_videos = [path_data + v + '/' for v in path_videos]\n",
    "\n",
    "    # make sure that there is video data in /data/ and give instructions if not done correctly\n",
    "    assert len(path_videos)>0, \"There need to be at least 3 video folders (at least 1 for each of train, valid, \\\n",
    "    and test splits) in /data/ - each video should be its own folder of frame images with ascending time-ordered \\\n",
    "    filenames e.g. /data/vid1/frame00001.jpg ... videos assignment to train/valid/test split should be given in \\\n",
    "    /data/labels.csv ... cross-validation or train/valid/test splits within a single long video not currently implemented\"\n",
    "\n",
    "    return path_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:04.021653Z",
     "start_time": "2019-01-07T17:27:04.013756Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_frames(target_size):\n",
    "    \"\"\"\n",
    "    Resize the frames of all videos and save them to /cache/ \n",
    "    to make model fitting faster .\n",
    "\n",
    "    We resize once upfront rather than each we use a pretrained model or architecture.\n",
    "\n",
    "    Our models require inputs resized to:\n",
    "    * 224 x 224 VGG16, ResNet50, DenseNet, MobileNet\n",
    "    * 299 x 299 XCeption, InceptionV3, InceptionResNetV2\n",
    "    * 112 x 112 3D CNN \n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/'):\n",
    "        \n",
    "        os.makedirs(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/')\n",
    "\n",
    "        # read vid paths\n",
    "        path_videos = get_video_paths()\n",
    "\n",
    "        # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "        for c,path_video in enumerate(path_videos):\n",
    "\n",
    "            logger.info(\"resizing vid {}/{} to {}x{}\".format(c+1,len(path_videos),target_size[0], target_size[1]))\n",
    "\n",
    "            # get vid name from path\n",
    "            video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "            # create directory for resized frames - just storing arrays now so commented out\n",
    "            # e.g. path_vid_resized = /cache/frames/224_224/s23-4847/\n",
    "            # path_vid_resized = path_cache + 'frames/'\n",
    "            # path_vid_resized += str(target_size[0]) + \"_\" + str(target_size[1]) + '/' \n",
    "            # path_vid_resized += video_name + '/'\n",
    "\n",
    "            # load frame paths for vid\n",
    "            path_frames = os.listdir(path_video)\n",
    "            path_frames = [path_video + f for f in path_frames if f != '.DS_Store']\n",
    "            path_frames.sort()\n",
    "\n",
    "            # load frames\n",
    "            frames = []\n",
    "            for path_frame in path_frames:\n",
    "\n",
    "                # open image and resize\n",
    "                filename = path_frame.split(\"/\").pop()\n",
    "                img_frame = Image.open(path_frame)\n",
    "                img_frame = img_frame.resize(target_size)\n",
    "                # img_frame.save(path_vid_resized + filename, \"JPEG\", quality = 100)\n",
    "\n",
    "                # convert to array and append to list\n",
    "                img_frame = np.array(img_frame)\n",
    "                frames.append(img_frame)\n",
    "\n",
    "            # save array of resized frames\n",
    "            np.save(path_cache + \"frames/\" + str(target_size[0]) + \"_\" + str(target_size[1]) + \"/\" + video_name, np.array(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:04.585569Z",
     "start_time": "2019-01-07T17:27:04.580719Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    # read labels - should be CSV with columns \"video\",\"frame\",\"label\",\"split\"\n",
    "    # e.g. \"s1-218\", \"s1-218-00001.jpeg\", \"noseal\", \"train\"\n",
    "    labels = None\n",
    "    try:\n",
    "        labels = pd.read_csv(path_data + 'labels.csv', usecols=['video','frame','label','split'])\n",
    "    except ValueError as e:\n",
    "        raise Exception(\"Labels file must contain columns ['video','frame','label','split'] - if you only have ['video','frame','label'], use the helper function add_splits_to_labels_file to add train/valid/test splits to your labels file\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise Exception(\"No labels found - please save labels file to /data/labels.csv\") from e\n",
    "\n",
    "    return labels.sort_values([\"video\",\"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:04.806647Z",
     "start_time": "2019-01-07T17:27:04.800084Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_video_label_arrays():\n",
    "    \"\"\"\n",
    "    Create numpy array with labels for each vid and a label_map.json file\n",
    "    in /cache/labels/\n",
    "    \"\"\"\n",
    "\n",
    "    # create folder for labels\n",
    "    if not os.path.exists(path_cache + 'labels/'):\n",
    "        os.makedirs(path_cache + 'labels/')\n",
    "\n",
    "    # load labels\n",
    "    labels = get_labels()\n",
    "\n",
    "    # build label_map\n",
    "    label_dummies = pd.get_dummies(labels, columns = ['label'])\n",
    "\n",
    "    # get label columns list and build label map dict\n",
    "    label_columns = []\n",
    "    label_map = {}\n",
    "    label_map_idx = 0\n",
    "    for i, col in enumerate(label_dummies.columns):\n",
    "        if col[:6] == 'label_':\n",
    "            label_columns.append(col)\n",
    "            label_map[label_map_idx] = col\n",
    "            label_map_idx+=1\n",
    "\n",
    "    # save label map to json\n",
    "    with open(path_cache + 'labels/label_map.json', 'w') as fp:\n",
    "        json.dump(label_map, fp)\n",
    "\n",
    "    # get video paths\n",
    "    path_videos = get_video_paths()\n",
    "\n",
    "    # save numpy array of labels for each vid\n",
    "    for path_video in path_videos:\n",
    "\n",
    "        # get vid name from path\n",
    "        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "        vid_labels = np.array(label_dummies[label_dummies['video'] == video_name][label_columns])\n",
    "\n",
    "        # save labels array for this vid\n",
    "        np.save(path_cache + \"/labels/\" + video_name, np.array(vid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:04.952646Z",
     "start_time": "2019-01-07T17:27:04.947461Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_label_map():\n",
    "    \"\"\"\n",
    "    Returns label map - read from disk\n",
    "    \"\"\"\n",
    "\n",
    "    # load label map from disk\n",
    "    label_map = None\n",
    "    try:\n",
    "        if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "            with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                label_map = json.load(fp)\n",
    "        else:\n",
    "            # build labels and label map\n",
    "            create_video_label_arrays()\n",
    "            if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "                with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                    label_map = json.load(fp)\n",
    "    except Exception as e:\n",
    "        logger.error ('label map not found - make sure /data/labels.csv exists and data cache has been built')\n",
    "\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:44:22.365765Z",
     "start_time": "2019-01-07T17:44:22.331665Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def __init__(self, sequence_length, \n",
    "                    return_CNN_features = False, pretrained_model_name = None, pooling = None, \n",
    "                    frame_size = None, augmentation = False, oversampling = False,\n",
    "                    model_weights_path = None, custom_model_name = None):\n",
    "        \"\"\"\n",
    "        Data object constructor\n",
    "        \n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        :return_CNN_features: whether to return precomputed features or return frames (or sequences of features/frames if sequence_length>1)\n",
    "\n",
    "        :return_features: if True then return features (or sequences of feature) from pretrained model, if False then return frames (or sequences of frames)        \n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :frame_size: size that frames are resized to (this is looked up for pretrained models)\n",
    "        :augmentation: whether to apply data augmentation (horizontal flips)\n",
    "        :oversampling: whether to apply oversampling to create class balance\n",
    "        \n",
    "        :model_weights_path: path to custom model weights if we want to load CNN model we've fine-tuned to produce features (e.g. for LRCNN)\n",
    "        :custom_model_name: custom output name to append to pretrained model name\n",
    "        \n",
    "        \n",
    "        Notes: \n",
    "        * if pretrained_model_name != None and return_CNN_features=False then will first apply preprocessor to frames (or frame sequences)\n",
    "        \"\"\"\n",
    "    \n",
    "        # required params\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frame_size = frame_size\n",
    "        \n",
    "        # optional params\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.return_CNN_features = return_CNN_features\n",
    "        self.augmentation = augmentation\n",
    "        self.oversampling = oversampling\n",
    "        \n",
    "        # init model data\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_valid = []\n",
    "        self.y_valid = []\n",
    "        # \n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        # fix case sensitivity\n",
    "        if type(self.pretrained_model_name) == str:\n",
    "            self.pretrained_model_name = self.pretrained_model_name.lower()\n",
    "        if type(self.pooling) == str:\n",
    "            self.pooling = self.pooling.lower()\n",
    "        \n",
    "        ################\n",
    "        ### Prepare data\n",
    "        ################\n",
    "        \n",
    "        # get video paths\n",
    "        self.path_videos = get_video_paths()\n",
    "        \n",
    "        # create label array for each video and load label map\n",
    "        create_video_label_arrays()\n",
    "        self.label_map = load_label_map()\n",
    "        \n",
    "        # get labels\n",
    "        self.labels = get_labels()\n",
    "        \n",
    "        # create dict mapping video to train/valid/test split assignment\n",
    "        video_splits = self.labels[['video','split']].drop_duplicates()\n",
    "        video_splits.set_index(\"video\", inplace=True)\n",
    "        video_splits = video_splits.to_dict()['split']\n",
    "        self.video_splits = video_splits\n",
    "        \n",
    "        # look up target size for pretrained model\n",
    "        if pretrained_model_name is not None:\n",
    "            self.frame_size = pretrained_model_sizes[pretrained_model_name]\n",
    "        \n",
    "        # precompute resized frames (won't recompute if already resized)\n",
    "        resize_frames(self.frame_size)\n",
    "\n",
    "        # pre compute CNN features (won't recompute if already computed)\n",
    "        if return_CNN_features and pretrained_model_name is not None:\n",
    "            if model_weights_path is not None and custom_model_name is not None:\n",
    "                # precompute with custom weights input and name\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling, self.model_weights_path, self.custom_model_name)\n",
    "            else:\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # get preprocessor given pretrained if we will need to apply preprocessor \n",
    "        # (i.e. if return_CNN_features == False and pretrained_model_name != None)\n",
    "        if not return_CNN_features and pretrained_model_name is not None:\n",
    "            self.preprocess_input = load_pretrained_model_preprocessor(self.pretrained_model_name)\n",
    "        \n",
    "        \n",
    "        ###################################\n",
    "        ### load features / build sequences\n",
    "        ###################################\n",
    "        \n",
    "        \n",
    "        # load features/frames from all videos and concat into big array for each of train, valid and test\n",
    "        if self.sequence_length > 1:\n",
    "            \n",
    "            ###################\n",
    "            ### frame sequences\n",
    "            ###################\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                #####################\n",
    "                ### feature sequences\n",
    "                #####################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    features = np.load(path_features + video_name + '.npy')\n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(features) + 1):\n",
    "                        x.append(features[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: labels\n",
    "                    # load precomputed labels\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                        \n",
    "            else:\n",
    "\n",
    "                ###################\n",
    "                ### frame sequences\n",
    "                ###################\n",
    "                \n",
    "                # load resized numpy array\n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed frames\n",
    "                    frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    \n",
    "                    # first apply preprocessing if pretrained model given\n",
    "                    if pretrained_model_name != None:\n",
    "                        frames = self.preprocess_input(frames)\n",
    "                    \n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(frames) + 1):\n",
    "                        x.append(frames[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: labels\n",
    "                    # load precomputed labels\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "\n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                \n",
    "        else:\n",
    "            ###############\n",
    "            ### no sequence\n",
    "            ###############\n",
    "            if return_CNN_features:\n",
    "                \n",
    "                ###################\n",
    "                ### feature vectors\n",
    "                ###################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### load precomputed features\n",
    "                    x = np.load(path_features + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            else:\n",
    "                \n",
    "                #################\n",
    "                ### single frames\n",
    "                #################\n",
    "                \n",
    "                # load resized numpy array\n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    # load precomputed numpy arrays for frames and labels\n",
    "                    x = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    # apply preprocessing if pretrained model given\n",
    "                    if pretrained_model_name != None:\n",
    "                        x = self.preprocess_input(x)\n",
    "                \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            \n",
    "            \n",
    "            \n",
    "        ########################\n",
    "        ### reshape list outputs\n",
    "        ########################\n",
    "        ## e.g. (9846, 224, 224, 3) for frames [return_CNN_features=True]\n",
    "        ## or  (9846, 512) for features [return_CNN_features=False]\n",
    "        self.x_train = np.concatenate(self.x_train, axis=0)\n",
    "        self.y_train = np.concatenate(self.y_train, axis=0)\n",
    "        self.x_valid = np.concatenate(self.x_valid, axis=0)\n",
    "        self.y_valid = np.concatenate(self.y_valid, axis=0)\n",
    "        self.x_test = np.concatenate(self.x_test, axis=0)\n",
    "        self.y_test = np.concatenate(self.y_test, axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #################################\n",
    "        ### get file paths for each split\n",
    "        #################################\n",
    "        #\n",
    "        # Note: only makes sense for sequence_length = 1\n",
    "        \n",
    "        # get file paths: train\n",
    "        dflab = self.labels[self.labels['split'] == 'train']\n",
    "        self.paths_train = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: valid\n",
    "        dflab = self.labels[self.labels['split'] == 'valid']\n",
    "        self.paths_valid = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: test\n",
    "        dflab = self.labels[self.labels['split'] == 'test']\n",
    "        self.paths_test = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "        \n",
    "        # pull number of classes from labels shape\n",
    "        self.num_classes = self.y_train.shape[1]\n",
    "            \n",
    "\n",
    "    def __str__(self):\n",
    "        return \"x_train: {}, y_train: {} ... x_valid: {}, y_valid: {} ... x_test: {}, y_test: {}\".format(self.x_train.shape,self.y_train.shape,self.x_valid.shape,self.y_valid.shape,self.x_test.shape,self.y_test.shape)\n",
    "            \n",
    "    def shuffle(self):\n",
    "        \"\"\"\n",
    "        randomize the order of samples in train and valid splits\n",
    "        \"\"\"\n",
    "        ###########\n",
    "        ### shuffle\n",
    "        ###########\n",
    "        # paths will no longer be correct (they're for debugging anyway)\n",
    "        self.x_train, self.y_train, self.paths_train = shuffle(self.x_train, self.y_train, self.paths_train)\n",
    "        self.x_valid, self.y_valid, self.paths_valid = shuffle(self.x_valid, self.y_valid, self.paths_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:27:05.668716Z",
     "start_time": "2019-01-07T17:27:05.665435Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = Data(sequence_length = 1, \n",
    "#             return_CNN_features = True, \n",
    "#             pretrained_model_name='vgg16', \n",
    "#             pooling='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-07T17:45:41.743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-07 17:45:42,887 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-07 17:46:28,602 [MainThread  ] [INFO ]  Computing pretrained model features for video 1/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 17:52:44,255 [MainThread  ] [INFO ]  Computing pretrained model features for video 2/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 17:57:38,111 [MainThread  ] [INFO ]  Computing pretrained model features for video 3/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:03:54,149 [MainThread  ] [INFO ]  Computing pretrained model features for video 4/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:10:08,922 [MainThread  ] [INFO ]  Computing pretrained model features for video 5/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:16:25,122 [MainThread  ] [INFO ]  Computing pretrained model features for video 6/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:20:25,520 [MainThread  ] [INFO ]  Computing pretrained model features for video 7/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:21:23,275 [MainThread  ] [INFO ]  Computing pretrained model features for video 8/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:22:25,444 [MainThread  ] [INFO ]  Computing pretrained model features for video 9/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:28:05,487 [MainThread  ] [INFO ]  Computing pretrained model features for video 10/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:34:19,621 [MainThread  ] [INFO ]  Computing pretrained model features for video 11/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:40:37,047 [MainThread  ] [INFO ]  Computing pretrained model features for video 12/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:41:36,699 [MainThread  ] [INFO ]  Computing pretrained model features for video 13/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:47:50,287 [MainThread  ] [INFO ]  Computing pretrained model features for video 14/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:52:33,715 [MainThread  ] [INFO ]  Computing pretrained model features for video 15/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:58:46,135 [MainThread  ] [INFO ]  Computing pretrained model features for video 16/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 18:59:43,549 [MainThread  ] [INFO ]  Computing pretrained model features for video 17/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:04:39,379 [MainThread  ] [INFO ]  Computing pretrained model features for video 18/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:10:51,805 [MainThread  ] [INFO ]  Computing pretrained model features for video 19/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:11:53,183 [MainThread  ] [INFO ]  Computing pretrained model features for video 20/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:12:51,958 [MainThread  ] [INFO ]  Computing pretrained model features for video 21/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:13:54,278 [MainThread  ] [INFO ]  Computing pretrained model features for video 22/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:14:57,246 [MainThread  ] [INFO ]  Computing pretrained model features for video 23/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:21:18,670 [MainThread  ] [INFO ]  Computing pretrained model features for video 24/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:27:31,979 [MainThread  ] [INFO ]  Computing pretrained model features for video 25/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:32:59,528 [MainThread  ] [INFO ]  Computing pretrained model features for video 26/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:38:56,969 [MainThread  ] [INFO ]  Computing pretrained model features for video 27/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:45:08,441 [MainThread  ] [INFO ]  Computing pretrained model features for video 28/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:46:27,252 [MainThread  ] [INFO ]  Computing pretrained model features for video 29/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:52:42,568 [MainThread  ] [INFO ]  Computing pretrained model features for video 30/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 19:53:42,379 [MainThread  ] [INFO ]  Computing pretrained model features for video 31/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 20:00:01,539 [MainThread  ] [INFO ]  Computing pretrained model features for video 32/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 20:06:12,332 [MainThread  ] [INFO ]  Computing pretrained model features for video 33/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 20:12:26,869 [MainThread  ] [INFO ]  Computing pretrained model features for video 34/36 using pretrained model: inception_resnet_v2, pooling: avg\n",
      "2019-01-07 20:18:43,718 [MainThread  ] [INFO ]  Computing pretrained model features for video 35/36 using pretrained model: inception_resnet_v2, pooling: avg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # build feature cache in advance by running python3 data.py\n",
    "    for pretrained_model_name in pretrained_model_names:\n",
    "        for pooling in poolings:\n",
    "            data = Data(sequence_length=1, \n",
    "                        return_CNN_features=True,\n",
    "                        pretrained_model_name = pretrained_model_name,\n",
    "                        pooling=pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:44:58.268678Z",
     "start_time": "2019-01-07T17:44:58.129716Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix penguin lables data\n",
    "# labels = get_labels()\n",
    "# labels = labels[labels['video'] != \"20161014_no8_3\"]\n",
    "# labels = labels[labels['video'] != \"20161014_no8_4\"]\n",
    "# labels.loc[labels['video'] == '20160930_no8_1_2','video']='20160930_no8_2'\n",
    "# labels.to_csv(pwd + '/data/labels.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
