{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO:\n",
    "# * add train/valid/test generators to data\n",
    "# * need option to apply preprocessor when requesting frame data\n",
    "# * make sure don't recompute sequences if inputs don't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T00:25:51.405086Z",
     "start_time": "2019-01-06T00:25:51.401182Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T00:25:55.284991Z",
     "start_time": "2019-01-06T00:25:51.780848Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T00:25:56.922122Z",
     "start_time": "2019-01-06T00:25:56.918509Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T00:25:57.303543Z",
     "start_time": "2019-01-06T00:25:57.299009Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T00:25:57.606232Z",
     "start_time": "2019-01-06T00:25:57.600729Z"
    }
   },
   "outputs": [],
   "source": [
    "# read vid folders\n",
    "def get_video_paths():\n",
    "    \"\"\"\n",
    "    Return list of video paths \n",
    "\n",
    "    Videos should be in /data/video_1/, /data/video_2/ style folders \n",
    "    with sequentially numbered frame images e.g. /data/video_1/frame00001.jpg\n",
    "\n",
    "    There should be at least 3 videos, 1 for each of train/test/valid splits\n",
    "    Split assignment is given in /data/labels.csv (also to be provided by user)\n",
    "\n",
    "    Functionality to use different parts of a video as train/valid/test \n",
    "    not currently implemented.\n",
    "    \"\"\"\n",
    "    path_videos = []\n",
    "    for filename in os.listdir(path_data):\n",
    "        if os.path.isdir(os.path.join(path_data, filename)):\n",
    "            path_videos.append(filename)\n",
    "\n",
    "    path_videos = [path_data + v + '/' for v in path_videos]\n",
    "\n",
    "    # make sure that there is video data in /data/ and give instructions if not done correctly\n",
    "    assert len(path_videos)>0, \"There need to be at least 3 video folders (at least 1 for each of train, valid, \\\n",
    "    and test splits) in /data/ - each video should be its own folder of frame images with ascending time-ordered \\\n",
    "    filenames e.g. /data/vid1/frame00001.jpg ... videos assignment to train/valid/test split should be given in \\\n",
    "    /data/labels.csv ... cross-validation or train/valid/test splits within a single long video not currently implemented\"\n",
    "\n",
    "    return path_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T10:39:23.836562Z",
     "start_time": "2019-01-06T10:39:23.827890Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_frames(target_size):\n",
    "    \"\"\"\n",
    "    Resize the frames of all videos and save them to /cache/ \n",
    "    to make model fitting faster .\n",
    "\n",
    "    We resize once upfront rather than each we use a pretrained model or architecture.\n",
    "\n",
    "    Our models require inputs resized to:\n",
    "    * 224 x 224 VGG16, ResNet50, DenseNet, MobileNet\n",
    "    * 299 x 299 XCeption, InceptionV3, InceptionResNetV2\n",
    "    * 112 x 112 3D CNN \n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/'):\n",
    "\n",
    "        # read vid paths\n",
    "        path_videos = get_video_paths()\n",
    "\n",
    "        # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "        for c,path_video in enumerate(path_videos):\n",
    "\n",
    "            logger.info(\"resizing vid {}/{} to {}x{}\".format(c+1,len(path_videos),target_size[0], target_size[1]))\n",
    "\n",
    "            # get vid name from path\n",
    "            video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "            # create directory for resized frames - just storing arrays now so commented out\n",
    "            # e.g. path_vid_resized = /cache/frames/224_224/s23-4847/\n",
    "            # path_vid_resized = path_cache + 'frames/'\n",
    "            # path_vid_resized += str(target_size[0]) + \"_\" + str(target_size[1]) + '/' \n",
    "            # path_vid_resized += video_name + '/'\n",
    "\n",
    "            # load frame paths for vid\n",
    "            path_frames = os.listdir(path_video)\n",
    "            path_frames = [path_video + f for f in path_frames if f != '.DS_Store']\n",
    "            path_frames.sort()\n",
    "\n",
    "            # load frames\n",
    "            frames = []\n",
    "            for path_frame in path_frames:\n",
    "\n",
    "                # open image and resize\n",
    "                filename = path_frame.split(\"/\").pop()\n",
    "                img_frame = Image.open(path_frame)\n",
    "                img_frame = img_frame.resize(target_size)\n",
    "                # img_frame.save(path_vid_resized + filename, \"JPEG\", quality = 100)\n",
    "\n",
    "                # convert to array and append to list\n",
    "                img_frame = np.array(img_frame)\n",
    "                frames.append(img_frame)\n",
    "\n",
    "            # save array of resized frames\n",
    "            np.save(\"/mnt/seals/cache/frames/\" + str(target_size[0]) + \"_\" + str(target_size[1]) + \"/\" + video_name, np.array(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T00:25:59.125238Z",
     "start_time": "2019-01-06T00:25:59.120659Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    # read labels - should be CSV with columns \"video\",\"frame\",\"label\",\"split\"\n",
    "    # e.g. \"s1-218\", \"s1-218-00001.jpeg\", \"noseal\", \"train\"\n",
    "    labels = None\n",
    "    try:\n",
    "        labels = pd.read_csv(path_data + 'labels.csv', usecols=['video','frame','label','split'])\n",
    "    except ValueError as e:\n",
    "        raise Exception(\"Labels file must contain columns ['video','frame','label','split'] - if you only have ['video','frame','label'], use the helper function add_splits_to_labels_file to add train/valid/test splits to your labels file\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise Exception(\"No labels found - please save labels file to /data/labels.csv\") from e\n",
    "\n",
    "    return labels.sort_values([\"video\",\"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T00:25:59.593054Z",
     "start_time": "2019-01-06T00:25:59.586128Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_video_label_arrays():\n",
    "    \"\"\"\n",
    "    Create numpy array with labels for each vid and a label_map.json file\n",
    "    in /cache/labels/\n",
    "    \"\"\"\n",
    "\n",
    "    # create folder for labels\n",
    "    if not os.path.exists(path_cache + 'labels/'):\n",
    "        os.makedirs(path_cache + 'labels/')\n",
    "\n",
    "    # load labels\n",
    "    labels = get_labels()\n",
    "\n",
    "    # build label_map\n",
    "    label_dummies = pd.get_dummies(labels, columns = ['label'])\n",
    "\n",
    "    # get label columns list and build label map dict\n",
    "    label_columns = []\n",
    "    label_map = {}\n",
    "    label_map_idx = 0\n",
    "    for i, col in enumerate(label_dummies.columns):\n",
    "        if col[:6] == 'label_':\n",
    "            label_columns.append(col)\n",
    "            label_map[label_map_idx] = col\n",
    "            label_map_idx+=1\n",
    "\n",
    "    # save label map to json\n",
    "    with open(path_cache + 'labels/label_map.json', 'w') as fp:\n",
    "        json.dump(label_map, fp)\n",
    "\n",
    "    # get video paths\n",
    "    path_videos = get_video_paths()\n",
    "\n",
    "    # save numpy array of labels for each vid\n",
    "    for path_video in path_videos:\n",
    "\n",
    "        # get vid name from path\n",
    "        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "        vid_labels = np.array(label_dummies[label_dummies['video'] == video_name][label_columns])\n",
    "\n",
    "        # save labels array for this vid\n",
    "        np.save(\"/mnt/seals/cache/labels/\" + video_name, np.array(vid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T00:25:59.921890Z",
     "start_time": "2019-01-06T00:25:59.916380Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_label_map():\n",
    "    \"\"\"\n",
    "    Returns label map - read from disk\n",
    "    \"\"\"\n",
    "\n",
    "    # load label map from disk\n",
    "    label_map = None\n",
    "    try:\n",
    "        if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "            with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                label_map = json.load(fp)\n",
    "        else:\n",
    "            # build labels and label map\n",
    "            create_video_label_arrays()\n",
    "            if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "                with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                    label_map = json.load(fp)\n",
    "    except Exception as e:\n",
    "        logger.error ('label map not found - make sure /data/labels.csv exists and data cache has been built')\n",
    "\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T11:15:10.896532Z",
     "start_time": "2019-01-06T11:15:10.889196Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_model(pretrained_model_name, pooling):\n",
    "    \"\"\" Load pretrained model with given pooling applied\n",
    "    \n",
    "    Args:\n",
    "        pretrained_model: name of pretrained model [\"Xception\", \"VGG16\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNetV2\"]\n",
    "        pooling: pooling strategy for final pretrained model layer [\"max\",\"avg\"]\n",
    "    \n",
    "    Returns:\n",
    "        Pretrained model object (excluding dense softmax 1000 ImageNet classes layer)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize output\n",
    "    model = None\n",
    "    \n",
    "    pretrained_model_name = pretrained_model_name.lower()\n",
    "    \n",
    "    ###########################\n",
    "    ### import pretrained model\n",
    "    ###########################\n",
    "    if pretrained_model_name == \"xception\":   \n",
    "        from keras.applications.xception import Xception\n",
    "        model = Xception(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"vgg16\":   \n",
    "        from keras.applications.vgg16 import VGG16\n",
    "        model = VGG16(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"resnet50\":   \n",
    "        from keras.applications.resnet50 import ResNet50\n",
    "        model = ResNet50(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"inception_v3\":   \n",
    "        from keras.applications.inception_v3 import InceptionV3\n",
    "        model = InceptionV3(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"inception_resnet_v2\":   \n",
    "        from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "        model = InceptionResNetV2(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"mobilenetv2_1.00_224\":   \n",
    "        from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "        model = MobileNetV2(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    else:\n",
    "        raise NameError('Invalid pretrained model name - must be one of [\"Xception\", \"VGG16\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNetV2\"]')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T12:19:35.923061Z",
     "start_time": "2019-01-06T12:19:35.917395Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_model_preprocessor(pretrained_model_name):\n",
    "    \"\"\"\n",
    "    Return preprocessing function for a given pretrained model\n",
    "    \"\"\"\n",
    "\n",
    "    preprocess_input = None\n",
    "\n",
    "    pretrained_model_name = pretrained_model_name.lower()\n",
    "        \n",
    "    if pretrained_model_name == \"xception\":   \n",
    "        from keras.applications.xception import preprocess_input\n",
    "    elif pretrained_model_name == \"vgg16\":   \n",
    "        from keras.applications.vgg16 import preprocess_input\n",
    "    elif pretrained_model_name == \"resnet50\":   \n",
    "        from keras.applications.resnet50 import preprocess_input\n",
    "    elif pretrained_model_name == \"inception_v3\":   \n",
    "        from keras.applications.inception_v3 import preprocess_input\n",
    "    elif pretrained_model_name == \"inception_resnet_v2\":   \n",
    "        from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "    elif pretrained_model_name == \"mobilenetv2_1.00_224\":   \n",
    "        from keras.applications.mobilenet_v2 import preprocess_input\n",
    "    else:\n",
    "        raise NameError('Invalid pretrained model name - must be one of [\"Xception\", \"VGG16\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNetV2\"]')\n",
    "        \n",
    "    return preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T12:19:36.371018Z",
     "start_time": "2019-01-06T12:19:36.366460Z"
    }
   },
   "outputs": [],
   "source": [
    "# define pretrained model shapes\n",
    "pretrained_model_sizes = {}\n",
    "#\n",
    "pretrained_model_sizes['vgg16'] = (224,224)\n",
    "pretrained_model_sizes['resnet50'] = (224,224)\n",
    "pretrained_model_sizes['mobilenetv2_1.00_224'] = (224,224)\n",
    "#\n",
    "pretrained_model_sizes['xception'] = (299,299)\n",
    "pretrained_model_sizes['inception_v3'] = (299,299)\n",
    "pretrained_model_sizes['inception_resnet_v2'] = (299,299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T12:19:36.851208Z",
     "start_time": "2019-01-06T12:19:36.841287Z"
    }
   },
   "outputs": [],
   "source": [
    "def precompute_CNN_features(pretrained_model_name, pooling):\n",
    "    \"\"\" Save pretrained features array computed over all frames of each video using given pretrained model and pooling method\n",
    "    \n",
    "    Args:\n",
    "        pretrained_model_name: pretrained model object loaded using `load_pretrained_model`\n",
    "        pooling: pooling method used with pretrained model\n",
    "    \n",
    "    Returns:\n",
    "        None. Saves pretrained frames to `/cache/features/*pretrained_model_name*/*pooling*/*video_name*.npy`\n",
    "    \"\"\"\n",
    "    \n",
    "    pretrained_model_name = pretrained_model_name.lower()\n",
    "    \n",
    "    # setup path to save features\n",
    "    path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "    \n",
    "    if not os.path.exists(path_features):\n",
    "        \n",
    "        os.makedirs(path_features)\n",
    "        \n",
    "        # load pretrained model\n",
    "        pretrained_model = load_pretrained_model(pretrained_model_name, pooling)\n",
    "\n",
    "        # load preprocessing function\n",
    "        preprocess_input = load_pretrained_model_preprocessor(pretrained_model_name)\n",
    "\n",
    "        # lookup pretrained model input shape\n",
    "        model_input_size = pretrained_model_sizes[pretrained_model_name]\n",
    "        \n",
    "        # precompute features for each video using pretrained model\n",
    "        path_videos = get_video_paths()\n",
    "\n",
    "        for c, path_video in enumerate(path_videos):\n",
    "\n",
    "            if verbose:\n",
    "                logging.info(\"Computing pretrained model features for video {}/{} using pretrained model: {}, pooling: {}\".format(c+1,len(path_videos),pretrained_model_name, pooling))\n",
    "\n",
    "            # get video name from video path\n",
    "            video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "            # build output path\n",
    "            path_output = path_features + video_name\n",
    "\n",
    "            try:\n",
    "                if not os.path.exists(path_output + '.npy'):\n",
    "\n",
    "                    path_frames = path_data + video_name + \"/\"\n",
    "\n",
    "                    # initialize features list\n",
    "                    features = []\n",
    "\n",
    "                    frame_paths = os.listdir(path_frames)\n",
    "                    frame_paths = [path_frames + f for f in frame_paths if f != '.DS_Store']\n",
    "\n",
    "                    # sort paths in sequence (they were created with incrementing filenames through time)\n",
    "                    frame_paths.sort()\n",
    "\n",
    "                    # load each frame in vid and get features\n",
    "                    for j, frame_path in enumerate(frame_paths):\n",
    "\n",
    "                        # load image & preprocess\n",
    "                        image = cv2.imread(frame_path, cv2.COLOR_BGR2RGB)\n",
    "                        img = cv2.resize(image, model_input_size, interpolation=cv2.INTER_AREA)\n",
    "                        img = img_to_array(img)\n",
    "                        img = np.expand_dims(img, axis=0)\n",
    "                        img = preprocess_input(img)\n",
    "\n",
    "                        # get features from pretrained model\n",
    "                        feature = pretrained_model.predict(img).ravel()\n",
    "                        features.append(feature)\n",
    "\n",
    "                    # convert to arrays\n",
    "                    features = np.array(features)\n",
    "\n",
    "                    np.save(path_output, features)\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        logger.info(\"Features already cached: {}\".format(path_output))\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(\"Error precomputing features {} / {},{}\".format(video_namepretrained_model_name, pooling))\n",
    "                logging.fatal(e, exc_info=True)\n",
    "                \n",
    "    else:\n",
    "        if verbose:\n",
    "            logger.info(\"Features already cached: {}\".format(path_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T12:19:37.594929Z",
     "start_time": "2019-01-06T12:19:37.566781Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def __init__(self, sequence_length, \n",
    "                 return_CNN_features = False, pretrained_model_name = None, pooling = None, \n",
    "                 target_size = None, augmentation = False, oversampling = False):\n",
    "        \"\"\"\n",
    "        Data object constructor\n",
    "        \n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        :return_CNN_features: whether to return precomputed features or return frames (or sequences of features/frames if sequence_length>1)\n",
    "\n",
    "        :return_features: if True then return features (or sequences of feature) from pretrained model, if False then return frames (or sequences of frames)        \n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :target_size: size that frames are resized to (this is looked up for pretrained models)\n",
    "        :augmentation: whether to apply data augmentation (horizontal flips)\n",
    "        :oversampling: whether to apply oversampling to create class balance\n",
    "        \n",
    "        \n",
    "        Notes: \n",
    "        * if pretrained_model_name != None and return_CNN_features=False then will first apply preprocessor to frames (or frame sequences)\n",
    "        \"\"\"\n",
    "    \n",
    "        # required params\n",
    "        self.sequence_length = sequence_length\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # optional params\n",
    "        pretrained_model_name = pretrained_model_name.lower()\n",
    "        pooling = pooling.lower()\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling.lower()\n",
    "        self.return_CNN_features = return_CNN_features\n",
    "        self.augmentation = augmentation\n",
    "        self.oversampling = oversampling\n",
    "        \n",
    "        # model data\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_valid = []\n",
    "        self.y_valid = []\n",
    "        # \n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        \n",
    "        ################\n",
    "        ### Prepare data\n",
    "        ################\n",
    "        \n",
    "        # get video paths\n",
    "        self.path_videos = get_video_paths()\n",
    "        \n",
    "        # create label array for each video and load label map\n",
    "        create_video_label_arrays()\n",
    "        self.label_map = load_label_map()\n",
    "        \n",
    "        # get labels\n",
    "        self.labels = get_labels()\n",
    "        \n",
    "        # create dict mapping video to train/valid/test split assignment\n",
    "        video_splits = self.labels[['video','split']].drop_duplicates()\n",
    "        video_splits.set_index(\"video\", inplace=True)\n",
    "        video_splits = video_splits.to_dict()['split']\n",
    "        self.video_splits = video_splits\n",
    "        \n",
    "        # look up target size for pretrained model\n",
    "        if pretrained_model_name is not None:\n",
    "            self.target_size = pretrained_model_sizes[pretrained_model_name]\n",
    "        \n",
    "        # precompute resized frames (won't recompute if already resized)\n",
    "        resize_frames(self.target_size)\n",
    "\n",
    "        # pre compute CNN features (won't recompute if already computed)\n",
    "        if return_CNN_features and pretrained_model_name is not None:\n",
    "            precompute_CNN_features(self.pretrained_model_name, self.pooling)\n",
    "            \n",
    "        # get preprocessor given pretrained if we will need to apply preprocessor \n",
    "        # (i.e. if return_CNN_features == False and pretrained_model_name != None)\n",
    "        if not return_CNN_features and pretrained_model_name is not None:\n",
    "            self.preprocess_input = load_pretrained_model_preprocessor(self.pretrained_model_name)\n",
    "        \n",
    "        \n",
    "        ###################################\n",
    "        ### load features / build sequences\n",
    "        ###################################\n",
    "        \n",
    "        \n",
    "        # load features/frames from all videos and concat into big array for each of train, valid and test\n",
    "        if self.sequence_length > 1:\n",
    "            \n",
    "            ###################\n",
    "            ### frame sequences\n",
    "            ###################\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                #####################\n",
    "                ### feature sequences\n",
    "                #####################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    features = np.load(path_features + video_name + '.npy')\n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(features) + 1):\n",
    "                        x.append(features[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: labels\n",
    "                    # load precomputed labels\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                        \n",
    "            else:\n",
    "\n",
    "                ###################\n",
    "                ### frame sequences\n",
    "                ###################\n",
    "                \n",
    "                # load resized numpy array\n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.target_size[0]) + \"_\" + str(self.target_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed frames\n",
    "                    frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    \n",
    "                    # first apply preprocessing if pretrained model given\n",
    "                    if pretrained_model_name != None:\n",
    "                        frames = self.preprocess_input(frames)\n",
    "                    \n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(frames) + 1):\n",
    "                        x.append(frames[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: labels\n",
    "                    # load precomputed labels\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "\n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                \n",
    "        else:\n",
    "            ###############\n",
    "            ### no sequence\n",
    "            ###############\n",
    "            if return_CNN_features:\n",
    "                \n",
    "                ###################\n",
    "                ### feature vectors\n",
    "                ###################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### load precomputed features\n",
    "                    x = np.load(path_features + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            else:\n",
    "                \n",
    "                #################\n",
    "                ### single frames\n",
    "                #################\n",
    "                \n",
    "                # load resized numpy array\n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.target_size[0]) + \"_\" + str(self.target_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    # load precomputed numpy arrays for frames and labels\n",
    "                    x = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    # apply preprocessing if pretrained model given\n",
    "                    if pretrained_model_name != None:\n",
    "                        x = self.preprocess_input(x)\n",
    "                \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            \n",
    "            \n",
    "            \n",
    "        ########################\n",
    "        ### reshape list outputs\n",
    "        ########################\n",
    "        ## e.g. (9846, 224, 224, 3) for frames [return_CNN_features=True]\n",
    "        ## or  (9846, 512) for features [return_CNN_features=False]\n",
    "        self.x_train = np.concatenate(self.x_train, axis=0)\n",
    "        self.y_train = np.concatenate(self.y_train, axis=0)\n",
    "        self.x_valid = np.concatenate(self.x_valid, axis=0)\n",
    "        self.y_valid = np.concatenate(self.y_valid, axis=0)\n",
    "        self.x_test = np.concatenate(self.x_test, axis=0)\n",
    "        self.y_test = np.concatenate(self.y_test, axis=0)\n",
    "        \n",
    "        # pull number of classes from labels shape\n",
    "        self.num_classes = self.y_train.shape[1]\n",
    "            \n",
    "\n",
    "        ###########\n",
    "        ### shuffle\n",
    "        ###########\n",
    "        self.x_train, self.y_train = shuffle(self.x_train, self.y_train)\n",
    "        self.x_valid, self.y_valid = shuffle(self.x_valid, self.y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T12:24:16.999175Z",
     "start_time": "2019-01-06T12:24:16.995415Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_names = [\"inception_resnet_v2\", \"inception_v3\", \"mobilenetv2_1.00_224\", \"resnet50\", \"vgg16\", \"xception\"]\n",
    "poolings = ['max','avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-06T12:24:17.502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-06 12:28:30,010 [MainThread  ] [INFO ]  Computing pretrained model features for video 1/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:29:31,887 [MainThread  ] [INFO ]  Computing pretrained model features for video 2/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:29:55,540 [MainThread  ] [INFO ]  Computing pretrained model features for video 3/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:30:12,294 [MainThread  ] [INFO ]  Computing pretrained model features for video 4/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:30:28,234 [MainThread  ] [INFO ]  Computing pretrained model features for video 5/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:31:03,931 [MainThread  ] [INFO ]  Computing pretrained model features for video 6/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:31:16,858 [MainThread  ] [INFO ]  Computing pretrained model features for video 7/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:31:49,679 [MainThread  ] [INFO ]  Computing pretrained model features for video 8/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:32:07,592 [MainThread  ] [INFO ]  Computing pretrained model features for video 9/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:32:36,354 [MainThread  ] [INFO ]  Computing pretrained model features for video 10/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:33:15,970 [MainThread  ] [INFO ]  Computing pretrained model features for video 11/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:33:53,872 [MainThread  ] [INFO ]  Computing pretrained model features for video 12/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:34:14,569 [MainThread  ] [INFO ]  Computing pretrained model features for video 13/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:34:30,501 [MainThread  ] [INFO ]  Computing pretrained model features for video 14/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:35:04,353 [MainThread  ] [INFO ]  Computing pretrained model features for video 15/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:35:20,175 [MainThread  ] [INFO ]  Computing pretrained model features for video 16/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:35:34,425 [MainThread  ] [INFO ]  Computing pretrained model features for video 17/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:36:00,474 [MainThread  ] [INFO ]  Computing pretrained model features for video 18/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:36:44,361 [MainThread  ] [INFO ]  Computing pretrained model features for video 19/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:37:54,322 [MainThread  ] [INFO ]  Computing pretrained model features for video 20/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:38:12,138 [MainThread  ] [INFO ]  Computing pretrained model features for video 21/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:38:32,971 [MainThread  ] [INFO ]  Computing pretrained model features for video 22/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:39:03,925 [MainThread  ] [INFO ]  Computing pretrained model features for video 23/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:39:23,863 [MainThread  ] [INFO ]  Computing pretrained model features for video 24/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:39:45,657 [MainThread  ] [INFO ]  Computing pretrained model features for video 25/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:40:18,374 [MainThread  ] [INFO ]  Computing pretrained model features for video 26/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:40:32,237 [MainThread  ] [INFO ]  Computing pretrained model features for video 27/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:40:49,178 [MainThread  ] [INFO ]  Computing pretrained model features for video 28/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:41:05,126 [MainThread  ] [INFO ]  Computing pretrained model features for video 29/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:41:45,723 [MainThread  ] [INFO ]  Computing pretrained model features for video 30/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:42:17,800 [MainThread  ] [INFO ]  Computing pretrained model features for video 31/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:43:21,542 [MainThread  ] [INFO ]  Computing pretrained model features for video 32/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:43:45,291 [MainThread  ] [INFO ]  Computing pretrained model features for video 33/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:44:01,959 [MainThread  ] [INFO ]  Computing pretrained model features for video 34/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:44:30,485 [MainThread  ] [INFO ]  Computing pretrained model features for video 35/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:44:55,184 [MainThread  ] [INFO ]  Computing pretrained model features for video 36/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:45:10,026 [MainThread  ] [INFO ]  Computing pretrained model features for video 37/46 using pretrained model: inception_resnet_v2, pooling: max\n",
      "2019-01-06 12:45:42,562 [MainThread  ] [INFO ]  Computing pretrained model features for video 38/46 using pretrained model: inception_resnet_v2, pooling: max\n"
     ]
    }
   ],
   "source": [
    "for pretrained_model_name in pretrained_model_names:\n",
    "    for pooling in poolings:\n",
    "        data = Data(sequence_length = 1, return_CNN_features = True, pretrained_model_name = pretrained_model_name, pooling=pooling)\n",
    "        print(data.x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
