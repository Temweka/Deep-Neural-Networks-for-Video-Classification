{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:21.373915Z",
     "start_time": "2019-01-10T21:39:21.371553Z"
    }
   },
   "outputs": [],
   "source": [
    "### TODO:\n",
    "# * add train/valid/test generators to data\n",
    "# * need option to apply preprocessor when requesting frame data\n",
    "# * make sure don't recompute sequences if inputs don't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:21.380138Z",
     "start_time": "2019-01-10T21:39:21.376520Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:22.303679Z",
     "start_time": "2019-01-10T21:39:21.382591Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.624028Z",
     "start_time": "2019-01-10T21:39:22.306561Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import pretrained model functions\n",
    "from deepvideoclassification.models import precompute_CNN_features\n",
    "from deepvideoclassification.models import load_pretrained_model_preprocessor\n",
    "from deepvideoclassification.models import load_pretrained_model\n",
    "\n",
    "# import pretrained model properties\n",
    "from deepvideoclassification.models import pretrained_model_len_features\n",
    "from deepvideoclassification.models import pretrained_model_sizes\n",
    "from deepvideoclassification.models import pretrained_model_names, poolings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.630441Z",
     "start_time": "2019-01-10T21:39:23.627047Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.637109Z",
     "start_time": "2019-01-10T21:39:23.632909Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.645401Z",
     "start_time": "2019-01-10T21:39:23.639954Z"
    }
   },
   "outputs": [],
   "source": [
    "# read vid folders\n",
    "def get_video_paths():\n",
    "    \"\"\"\n",
    "    Return list of video paths \n",
    "\n",
    "    Videos should be in /data/video_1/, /data/video_2/ style folders \n",
    "    with sequentially numbered frame images e.g. /data/video_1/frame00001.jpg\n",
    "\n",
    "    There should be at least 3 videos, 1 for each of train/test/valid splits\n",
    "    Split assignment is given in /data/labels.csv (also to be provided by user)\n",
    "\n",
    "    Functionality to use different parts of a video as train/valid/test \n",
    "    not currently implemented.\n",
    "    \"\"\"\n",
    "    path_videos = []\n",
    "    for filename in os.listdir(path_data):\n",
    "        if os.path.isdir(os.path.join(path_data, filename)):\n",
    "            path_videos.append(filename)\n",
    "\n",
    "    path_videos = [path_data + v + '/' for v in path_videos]\n",
    "\n",
    "    # make sure that there is video data in /data/ and give instructions if not done correctly\n",
    "    assert len(path_videos)>0, \"There need to be at least 3 video folders (at least 1 for each of train, valid, \\\n",
    "    and test splits) in /data/ - each video should be its own folder of frame images with ascending time-ordered \\\n",
    "    filenames e.g. /data/vid1/frame00001.jpg ... videos assignment to train/valid/test split should be given in \\\n",
    "    /data/labels.csv ... cross-validation or train/valid/test splits within a single long video not currently implemented\"\n",
    "\n",
    "    return path_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.655676Z",
     "start_time": "2019-01-10T21:39:23.647703Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_frames(target_size):\n",
    "    \"\"\"\n",
    "    Resize the frames of all videos and save them to /cache/ \n",
    "    to make model fitting faster .\n",
    "\n",
    "    We resize once upfront rather than each we use a pretrained model or architecture.\n",
    "\n",
    "    Our models require inputs resized to:\n",
    "    * 224 x 224 VGG16, ResNet50, DenseNet, MobileNet\n",
    "    * 299 x 299 XCeption, InceptionV3, InceptionResNetV2\n",
    "    * 112 x 112 3D CNN \n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/'):\n",
    "        \n",
    "        os.makedirs(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/')\n",
    "\n",
    "        # read vid paths\n",
    "        path_videos = get_video_paths()\n",
    "\n",
    "        # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "        for c,path_video in enumerate(path_videos):\n",
    "\n",
    "            logger.info(\"resizing vid {}/{} to {}x{}\".format(c+1,len(path_videos),target_size[0], target_size[1]))\n",
    "\n",
    "            # get vid name from path\n",
    "            video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "            # create directory for resized frames - just storing arrays now so commented out\n",
    "            # e.g. path_vid_resized = /cache/frames/224_224/s23-4847/\n",
    "            # path_vid_resized = path_cache + 'frames/'\n",
    "            # path_vid_resized += str(target_size[0]) + \"_\" + str(target_size[1]) + '/' \n",
    "            # path_vid_resized += video_name + '/'\n",
    "\n",
    "            # load frame paths for vid\n",
    "            path_frames = os.listdir(path_video)\n",
    "            path_frames = [path_video + f for f in path_frames if f != '.DS_Store']\n",
    "            path_frames.sort()\n",
    "\n",
    "            # load frames\n",
    "            frames = []\n",
    "            for path_frame in path_frames:\n",
    "\n",
    "                # open image and resize\n",
    "                filename = path_frame.split(\"/\").pop()\n",
    "                img_frame = Image.open(path_frame)\n",
    "                img_frame = img_frame.resize(target_size)\n",
    "                # img_frame.save(path_vid_resized + filename, \"JPEG\", quality = 100)\n",
    "\n",
    "                # convert to array and append to list\n",
    "                img_frame = np.array(img_frame)\n",
    "                frames.append(img_frame)\n",
    "\n",
    "            # save array of resized frames\n",
    "            np.save(path_cache + \"frames/\" + str(target_size[0]) + \"_\" + str(target_size[1]) + \"/\" + video_name, np.array(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.662359Z",
     "start_time": "2019-01-10T21:39:23.657943Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    # read labels - should be CSV with columns \"video\",\"frame\",\"label\",\"split\"\n",
    "    # e.g. \"s1-218\", \"s1-218-00001.jpeg\", \"noseal\", \"train\"\n",
    "    labels = None\n",
    "    try:\n",
    "        labels = pd.read_csv(path_data + 'labels.csv', usecols=['video','frame','label','split'])\n",
    "    except ValueError as e:\n",
    "        raise Exception(\"Labels file must contain columns ['video','frame','label','split'] - if you only have ['video','frame','label'], use the helper function add_splits_to_labels_file to add train/valid/test splits to your labels file\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise Exception(\"No labels found - please save labels file to /data/labels.csv\") from e\n",
    "\n",
    "    return labels.sort_values([\"video\",\"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.670832Z",
     "start_time": "2019-01-10T21:39:23.664779Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_video_label_arrays():\n",
    "    \"\"\"\n",
    "    Create numpy array with labels for each vid and a label_map.json file\n",
    "    in /cache/labels/\n",
    "    \"\"\"\n",
    "\n",
    "    # create folder for labels\n",
    "    if not os.path.exists(path_cache + 'labels/'):\n",
    "        os.makedirs(path_cache + 'labels/')\n",
    "\n",
    "    # load labels\n",
    "    labels = get_labels()\n",
    "\n",
    "    # build label_map\n",
    "    label_dummies = pd.get_dummies(labels, columns = ['label'])\n",
    "\n",
    "    # get label columns list and build label map dict\n",
    "    label_columns = []\n",
    "    label_map = {}\n",
    "    label_map_idx = 0\n",
    "    for i, col in enumerate(label_dummies.columns):\n",
    "        if col[:6] == 'label_':\n",
    "            label_columns.append(col)\n",
    "            label_map[label_map_idx] = col\n",
    "            label_map_idx+=1\n",
    "\n",
    "    # save label map to json\n",
    "    with open(path_cache + 'labels/label_map.json', 'w') as fp:\n",
    "        json.dump(label_map, fp)\n",
    "\n",
    "    # get video paths\n",
    "    path_videos = get_video_paths()\n",
    "\n",
    "    # save numpy array of labels for each vid\n",
    "    for path_video in path_videos:\n",
    "\n",
    "        # get vid name from path\n",
    "        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "        vid_labels = np.array(label_dummies[label_dummies['video'] == video_name][label_columns])\n",
    "\n",
    "        # save labels array for this vid\n",
    "        np.save(path_cache + \"/labels/\" + video_name, np.array(vid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.678010Z",
     "start_time": "2019-01-10T21:39:23.673002Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_label_map():\n",
    "    \"\"\"\n",
    "    Returns label map - read from disk\n",
    "    \"\"\"\n",
    "\n",
    "    # load label map from disk\n",
    "    label_map = None\n",
    "    try:\n",
    "        if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "            with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                label_map = json.load(fp)\n",
    "        else:\n",
    "            # build labels and label map\n",
    "            create_video_label_arrays()\n",
    "            if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "                with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                    label_map = json.load(fp)\n",
    "    except Exception as e:\n",
    "        logger.error ('label map not found - make sure /data/labels.csv exists and data cache has been built')\n",
    "\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.715446Z",
     "start_time": "2019-01-10T21:39:23.680608Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def __init__(self, sequence_length, \n",
    "                    return_CNN_features = False, pretrained_model_name = None, pooling = None, \n",
    "                    frame_size = None, augmentation = False, oversampling = False,\n",
    "                    model_weights_path = None, custom_model_name = None):\n",
    "        \"\"\"\n",
    "        Data object constructor\n",
    "        \n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        :return_CNN_features: whether to return precomputed features or return frames (or sequences of features/frames if sequence_length>1)\n",
    "\n",
    "        :return_features: if True then return features (or sequences of feature) from pretrained model, if False then return frames (or sequences of frames)        \n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :frame_size: size that frames are resized to (this is looked up for pretrained models)\n",
    "        :augmentation: whether to apply data augmentation (horizontal flips)\n",
    "        :oversampling: whether to apply oversampling to create class balance\n",
    "        \n",
    "        :model_weights_path: path to custom model weights if we want to load CNN model we've fine-tuned to produce features (e.g. for LRCNN)\n",
    "        :custom_model_name: custom output name to append to pretrained model name\n",
    "        \n",
    "        \n",
    "        Notes: \n",
    "        * if pretrained_model_name != None and return_CNN_features=False then will first apply preprocessor to frames (or frame sequences)\n",
    "        \"\"\"\n",
    "    \n",
    "        # required params\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frame_size = frame_size\n",
    "        \n",
    "        # optional params\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.return_CNN_features = return_CNN_features\n",
    "        self.augmentation = augmentation\n",
    "        self.oversampling = oversampling\n",
    "        \n",
    "        # init model data\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_valid = []\n",
    "        self.y_valid = []\n",
    "        # \n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        # fix case sensitivity\n",
    "        if type(self.pretrained_model_name) == str:\n",
    "            self.pretrained_model_name = self.pretrained_model_name.lower()\n",
    "        if type(self.pooling) == str:\n",
    "            self.pooling = self.pooling.lower()\n",
    "        \n",
    "        ################\n",
    "        ### Prepare data\n",
    "        ################\n",
    "        \n",
    "        # get video paths\n",
    "        self.path_videos = get_video_paths()\n",
    "        \n",
    "        # create label array for each video and load label map\n",
    "        create_video_label_arrays()\n",
    "        self.label_map = load_label_map()\n",
    "        \n",
    "        # get labels\n",
    "        self.labels = get_labels()\n",
    "        \n",
    "        # create dict mapping video to train/valid/test split assignment\n",
    "        video_splits = self.labels[['video','split']].drop_duplicates()\n",
    "        video_splits.set_index(\"video\", inplace=True)\n",
    "        video_splits = video_splits.to_dict()['split']\n",
    "        self.video_splits = video_splits\n",
    "        \n",
    "        # look up target size for pretrained model\n",
    "        if pretrained_model_name is not None:\n",
    "            self.frame_size = pretrained_model_sizes[pretrained_model_name]\n",
    "        \n",
    "        # precompute resized frames (won't recompute if already resized)\n",
    "        resize_frames(self.frame_size)\n",
    "\n",
    "        # pre compute CNN features (won't recompute if already computed)\n",
    "        if return_CNN_features and pretrained_model_name is not None:\n",
    "            if model_weights_path is not None and custom_model_name is not None:\n",
    "                # precompute with custom weights input and name\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling, self.model_weights_path, self.custom_model_name)\n",
    "            else:\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # get preprocessor given pretrained if we will need to apply preprocessor \n",
    "        # (i.e. if return_CNN_features == False and pretrained_model_name != None)\n",
    "        if not return_CNN_features and pretrained_model_name is not None:\n",
    "            self.preprocess_input = load_pretrained_model_preprocessor(self.pretrained_model_name)\n",
    "        \n",
    "        \n",
    "        ###################################\n",
    "        ### load features / build sequences\n",
    "        ###################################\n",
    "        \n",
    "        \n",
    "        # load features/frames from all videos and concat into big array for each of train, valid and test\n",
    "        if self.sequence_length > 1:\n",
    "            \n",
    "            ### sequences\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                #####################\n",
    "                ### feature sequences\n",
    "                #####################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    features = np.load(path_features + video_name + '.npy')\n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(features) + 1):\n",
    "                        x.append(features[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: labels\n",
    "                    # load precomputed labels\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                        \n",
    "            else:\n",
    "\n",
    "                ###################\n",
    "                ### frame sequences\n",
    "                ###################\n",
    "                \n",
    "                # load resized numpy array\n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed frames\n",
    "                    frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    \n",
    "                    # first apply preprocessing if pretrained model given\n",
    "                    if pretrained_model_name != None:\n",
    "                        frames = self.preprocess_input(frames)\n",
    "                    \n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(frames) + 1):\n",
    "                        x.append(frames[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: labels\n",
    "                    # load precomputed labels\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "\n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                \n",
    "        else:\n",
    "\n",
    "            ### not sequence\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                ###################\n",
    "                ### feature vectors\n",
    "                ###################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### load precomputed features\n",
    "                    x = np.load(path_features + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            else:\n",
    "                \n",
    "                #################\n",
    "                ### single frames\n",
    "                #################\n",
    "                \n",
    "                # load resized numpy array\n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    # load precomputed numpy arrays for frames and labels\n",
    "                    x = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    # apply preprocessing if pretrained model given\n",
    "                    if pretrained_model_name != None:\n",
    "                        x = self.preprocess_input(x)\n",
    "                \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            \n",
    "            \n",
    "            \n",
    "        ########################\n",
    "        ### reshape list outputs\n",
    "        ########################\n",
    "        ## e.g. (9846, 224, 224, 3) for frames [return_CNN_features=True]\n",
    "        ## or  (9846, 512) for features [return_CNN_features=False]\n",
    "        self.x_train = np.concatenate(self.x_train, axis=0)\n",
    "        self.y_train = np.concatenate(self.y_train, axis=0)\n",
    "        self.x_valid = np.concatenate(self.x_valid, axis=0)\n",
    "        self.y_valid = np.concatenate(self.y_valid, axis=0)\n",
    "        self.x_test = np.concatenate(self.x_test, axis=0)\n",
    "        self.y_test = np.concatenate(self.y_test, axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #################################\n",
    "        ### get file paths for each split\n",
    "        #################################\n",
    "        #\n",
    "        # Note: only makes sense for sequence_length = 1\n",
    "        \n",
    "        # get file paths: train\n",
    "        dflab = self.labels[self.labels['split'] == 'train']\n",
    "        self.paths_train = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: valid\n",
    "        dflab = self.labels[self.labels['split'] == 'valid']\n",
    "        self.paths_valid = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: test\n",
    "        dflab = self.labels[self.labels['split'] == 'test']\n",
    "        self.paths_test = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "        \n",
    "        # pull number of classes from labels shape\n",
    "        self.num_classes = self.y_train.shape[1]\n",
    "            \n",
    "\n",
    "    def __str__(self):\n",
    "        return \"x_train: {}, y_train: {} ... x_valid: {}, y_valid: {} ... x_test: {}, y_test: {}\".format(self.x_train.shape,self.y_train.shape,self.x_valid.shape,self.y_valid.shape,self.x_test.shape,self.y_test.shape)\n",
    "            \n",
    "    def shuffle(self):\n",
    "        \"\"\"\n",
    "        randomize the order of samples in train and valid splits\n",
    "        \"\"\"\n",
    "        ###########\n",
    "        ### shuffle\n",
    "        ###########\n",
    "        # paths will no longer be correct (they're for debugging anyway)\n",
    "        self.x_train, self.y_train, self.paths_train = shuffle(self.x_train, self.y_train, self.paths_train)\n",
    "        self.x_valid, self.y_valid, self.paths_valid = shuffle(self.x_valid, self.y_valid, self.paths_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.726529Z",
     "start_time": "2019-01-10T21:39:23.717677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Even at small sequence lengths, loading the full dataset as \n",
    "# a sequence into memory is not feasible so we need to use generators\n",
    "# that iterate over the dataset without loading it all into memory\n",
    "# \n",
    "# For now, we will assume that we will load the features datasets into memory\n",
    "# because this is more feasible but for large datasets, we'd want to use generators\n",
    "# for that too. An implementation for that can be done by pattern matching the implementation below.\n",
    "# \n",
    "# Our frames are in separate directories so we cannot use keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load('data/' + ID + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:23.731919Z",
     "start_time": "2019-01-10T21:39:23.728621Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.models import Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:42:08.122947Z",
     "start_time": "2019-01-10T21:42:08.119496Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.models import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:27:42.039648Z",
     "start_time": "2019-01-10T22:27:42.035674Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = \"vgg16\"\n",
    "pooling=\"max\"\n",
    "sequence_length = 5\n",
    "\n",
    "layer_1_size = 128\n",
    "layer_2_size = 64\n",
    "layer_3_size = 32\n",
    "dropout=0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:56:18.529406Z",
     "start_time": "2019-01-10T22:55:11.347051Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling)\n",
    "\n",
    "num_classes = data.num_classes \n",
    "frame_size = data.frame_size\n",
    "num_features = pretrained_model_len_features[pretrained_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:55.328054Z",
     "start_time": "2019-01-10T21:39:44.611062Z"
    }
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(architecture=\"image_MLP_trainable\", \n",
    "                     sequence_length = 1,\n",
    "                     num_classes = data.num_classes, \n",
    "                     frame_size = data.frame_size, \n",
    "                     pretrained_model_name='vgg16', \n",
    "                     pooling='max',\n",
    "                     layer_1_size=128, \n",
    "                     layer_2_size=32, \n",
    "                     layer_3_size=16, \n",
    "                     dropout=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build generator dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:10:22.280455Z",
     "start_time": "2019-01-10T22:10:22.039016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/mnt/seals/cache/\u001b[00m\r\n",
      "├── \u001b[01;34mfeatures\u001b[00m\r\n",
      "│   ├── \u001b[01;34minception_resnet_v2\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mavg\u001b[00m\r\n",
      "│   │   └── \u001b[01;34mmax\u001b[00m\r\n",
      "│   ├── \u001b[01;34minception_v3\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mavg\u001b[00m\r\n",
      "│   │   └── \u001b[01;34mmax\u001b[00m\r\n",
      "│   ├── \u001b[01;34mmobilenetv2_1.00_224\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mavg\u001b[00m\r\n",
      "│   │   └── \u001b[01;34mmax\u001b[00m\r\n",
      "│   ├── \u001b[01;34mresnet50\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mavg\u001b[00m\r\n",
      "│   │   └── \u001b[01;34mmax\u001b[00m\r\n",
      "│   ├── \u001b[01;34mvgg16\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mavg\u001b[00m\r\n",
      "│   │   └── \u001b[01;34mmax\u001b[00m\r\n",
      "│   └── \u001b[01;34mxception\u001b[00m\r\n",
      "│       ├── \u001b[01;34mavg\u001b[00m\r\n",
      "│       └── \u001b[01;34mmax\u001b[00m\r\n",
      "├── \u001b[01;34mframes\u001b[00m\r\n",
      "│   ├── \u001b[01;34m112_112\u001b[00m\r\n",
      "│   ├── \u001b[01;34m224_224\u001b[00m\r\n",
      "│   ├── \u001b[01;34m299_299\u001b[00m\r\n",
      "│   └── \u001b[01;34m80_80\u001b[00m\r\n",
      "└── \u001b[01;34mlabels\u001b[00m\r\n",
      "\r\n",
      "25 directories\r\n"
     ]
    }
   ],
   "source": [
    "!tree /mnt/seals/cache/ -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first calc total size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:56:55.855045Z",
     "start_time": "2019-01-10T22:56:55.852128Z"
    }
   },
   "outputs": [],
   "source": [
    "video_splits = data.video_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:14:04.707907Z",
     "start_time": "2019-01-10T23:13:57.209998Z"
    }
   },
   "outputs": [],
   "source": [
    "# total number of rows of sequence data we have for each split\n",
    "# this is not the same as the number of frames since we exclude\n",
    "# the first (sequence_length-1) frames\n",
    "total_rows_train = 0\n",
    "total_rows_valid = 0\n",
    "total_rows_test = 0\n",
    "\n",
    "# load resized numpy array\n",
    "path_vid_resized = path_cache + 'frames/'\n",
    "path_vid_resized += str(frame_size[0]) + \"_\" + str(frame_size[1]) + '/' \n",
    "\n",
    "path_labels = path_cache + 'labels/'\n",
    "\n",
    "# read vid paths\n",
    "path_videos = get_video_paths()\n",
    "\n",
    "# loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "for c, path_video in enumerate(path_videos):\n",
    "\n",
    "    # get vid name from path\n",
    "    video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "    # load resized frames\n",
    "    frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "\n",
    "    # build sequences\n",
    "    x = []\n",
    "    for i in range(sequence_length, len(frames) + 1):\n",
    "        x.append(frames[i-sequence_length:i])\n",
    "    x = np.array(x)\n",
    "\n",
    "    if video_splits[video_name] == \"train\":\n",
    "        total_rows_train += len(x)\n",
    "    if video_splits[video_name] == \"valid\":\n",
    "        total_rows_valid += len(x)\n",
    "    if video_splits[video_name] == \"test\":\n",
    "        total_rows_test += len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:14:07.971158Z",
     "start_time": "2019-01-10T23:14:07.966282Z"
    }
   },
   "outputs": [],
   "source": [
    "# calc shapes required for full sequence dataset\n",
    "h5_shape_train_x = (total_rows_train, sequence_length, frame_size[0], frame_size[1], 3)\n",
    "h5_shape_train_y = (total_rows_train, num_classes)\n",
    "\n",
    "h5_shape_valid_x = (total_rows_valid, sequence_length, frame_size[0], frame_size[1], 3)\n",
    "h5_shape_valid_y = (total_rows_valid, num_classes)\n",
    "\n",
    "h5_shape_test_x = (total_rows_test, sequence_length, frame_size[0], frame_size[1], 3)\n",
    "h5_shape_test_y = (total_rows_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:14:14.306033Z",
     "start_time": "2019-01-10T23:14:14.301717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (10619, 5, 224, 224, 3) ... (10619, 2)\n",
      "valid (1360, 5, 224, 224, 3) ... (1360, 2)\n",
      "test (295, 5, 224, 224, 3) ... (295, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"train {} ... {}\".format(h5_shape_train_x, h5_shape_train_y))\n",
    "print(\"valid {} ... {}\".format(h5_shape_valid_x, h5_shape_valid_y))\n",
    "print(\"test {} ... {}\".format(h5_shape_test_x, h5_shape_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:14:19.100690Z",
     "start_time": "2019-01-10T23:14:19.094761Z"
    }
   },
   "outputs": [],
   "source": [
    "# open h5 file to store big sequence dataset feature and label arrays\n",
    "# path_h5file = RESIZE -> MODEL -> SEQUENCE LENGTH\n",
    "f_train = h5py.File('train_sequences' + str(sequence_length) + '.h5', 'a')\n",
    "f_valid = h5py.File('valid_sequences' + str(sequence_length) + '.h5', 'a')\n",
    "f_test = h5py.File('test_sequences' + str(sequence_length) + '.h5', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:14:27.275288Z",
     "start_time": "2019-01-10T23:14:27.246560Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize h5 datasets\n",
    "h5_train_x = f_train.create_dataset('sequences', shape= h5_shape_train_x, dtype='uint8')\n",
    "h5_train_y = f_train.create_dataset('labels', shape= h5_shape_train_y, dtype='uint8')\n",
    "\n",
    "h5_valid_x = f_valid.create_dataset('sequences', shape= h5_shape_valid_x, dtype='uint8')\n",
    "h5_valid_y = f_valid.create_dataset('labels', shape= h5_shape_valid_y, dtype='uint8')\n",
    "\n",
    "h5_test_x = f_test.create_dataset('sequences', shape= h5_shape_test_x, dtype='uint8')\n",
    "h5_test_y = f_test.create_dataset('labels', shape= h5_shape_test_y, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:14:57.051743Z",
     "start_time": "2019-01-10T23:14:43.583039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 46 s23-4847\n",
      "XX 0 (152, 2) .. (152, 5, 224, 224, 3)\n",
      "1 46 s43-5211\n",
      "XX 152 (217, 2) .. (217, 5, 224, 224, 3)\n",
      "2 46 s2-1133\n",
      "XX 369 (152, 2) .. (152, 5, 224, 224, 3)\n",
      "3 46 s21-919\n",
      "XX 521 (143, 2) .. (143, 5, 224, 224, 3)\n",
      "4 46 s20-842\n",
      "XX 664 (327, 2) .. (327, 5, 224, 224, 3)\n",
      "5 46 s37-3930\n",
      "XX 991 (115, 2) .. (115, 5, 224, 224, 3)\n",
      "6 46 s5-1102\n",
      "XX 1106 (299, 2) .. (299, 5, 224, 224, 3)\n",
      "7 46 s19-672\n",
      "XX 1405 (162, 2) .. (162, 5, 224, 224, 3)\n",
      "8 46 s26-8164\n",
      "XX 1567 (262, 2) .. (262, 5, 224, 224, 3)\n",
      "9 46 s41-4712\n",
      "XX 1829 (364, 2) .. (364, 5, 224, 224, 3)\n",
      "10 46 s18-630\n",
      "XX 2193 (346, 2) .. (346, 5, 224, 224, 3)\n",
      "11 46 s25-5886\n",
      "XX 2539 (189, 2) .. (189, 5, 224, 224, 3)\n",
      "12 46 s35-3664\n",
      "XX 2728 (143, 2) .. (143, 5, 224, 224, 3)\n",
      "13 46 s33-3405\n",
      "XX 2871 (309, 2) .. (309, 5, 224, 224, 3)\n",
      "14 46 s45-6301\n",
      "XX 3180 (143, 2) .. (143, 5, 224, 224, 3)\n",
      "15 46 s16-0\n",
      "XX 3323 (125, 2) .. (125, 5, 224, 224, 3)\n",
      "16 46 s39-4336\n",
      "XX 3448 (235, 2) .. (235, 5, 224, 224, 3)\n",
      "17 46 s29-316\n",
      "XX 3683 (401, 2) .. (401, 5, 224, 224, 3)\n",
      "18 46 s12-3465\n",
      "XX 4084 (640, 2) .. (640, 5, 224, 224, 3)\n",
      "19 46 s46-8087\n",
      "XX 4724 (162, 2) .. (162, 5, 224, 224, 3)\n",
      "20 46 s31-784\n",
      "XX 4886 (189, 2) .. (189, 5, 224, 224, 3)\n",
      "21 46 s28-20\n",
      "XX 5075 (281, 2) .. (281, 5, 224, 224, 3)\n",
      "22 46 s3-1993\n",
      "XX 5356 (180, 2) .. (180, 5, 224, 224, 3)\n",
      "23 46 s9-5491\n",
      "XX 5536 (198, 2) .. (198, 5, 224, 224, 3)\n",
      "24 46 s11-7363\n",
      "XX 5734 (299, 2) .. (299, 5, 224, 224, 3)\n",
      "25 46 s22-3733\n",
      "XX 6033 (125, 2) .. (125, 5, 224, 224, 3)\n",
      "26 46 s13-14\n",
      "XX 6158 (152, 2) .. (152, 5, 224, 224, 3)\n",
      "27 46 s15-2589\n",
      "XX 6310 (143, 2) .. (143, 5, 224, 224, 3)\n",
      "28 46 s40-4508\n",
      "XX 6453 (373, 2) .. (373, 5, 224, 224, 3)\n",
      "29 46 s17-2973\n",
      "XX 6826 (290, 2) .. (290, 5, 224, 224, 3)\n",
      "30 46 s6-1247\n",
      "XX 7116 (585, 2) .. (585, 5, 224, 224, 3)\n",
      "31 46 s42-4950\n",
      "XX 7701 (217, 2) .. (217, 5, 224, 224, 3)\n",
      "32 46 s30-516\n",
      "XX 7918 (152, 2) .. (152, 5, 224, 224, 3)\n",
      "33 46 s34-3590\n",
      "XX 8070 (262, 2) .. (262, 5, 224, 224, 3)\n",
      "34 46 s36-3838\n",
      "XX 8332 (226, 2) .. (226, 5, 224, 224, 3)\n",
      "35 46 s1-218\n",
      "XX 8558 (134, 2) .. (134, 5, 224, 224, 3)\n",
      "36 46 s38-4060\n",
      "XX 8692 (299, 2) .. (299, 5, 224, 224, 3)\n",
      "37 46 s7-2029\n",
      "XX 8991 (391, 2) .. (391, 5, 224, 224, 3)\n",
      "38 46 s8-2244\n",
      "XX 9382 (630, 2) .. (630, 5, 224, 224, 3)\n",
      "39 46 s10-6558\n",
      "XX 10012 (180, 2) .. (180, 5, 224, 224, 3)\n",
      "40 46 s32-3110\n",
      "XX 10192 (1403, 2) .. (1403, 5, 224, 224, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't broadcast (1403, 5, 224, 224, 3) -> (427, 5, 224, 224, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-ba8ed186bfb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m### write this vid's data to relevant h5 dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvideo_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mh5_train_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh5_cursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh5_cursor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mh5_train_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh5_cursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh5_cursor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvideo_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0mmshape_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/selections.py\u001b[0m in \u001b[0;36mbroadcast\u001b[0;34m(self, target_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0mtshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't broadcast %s -> %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mtshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mtshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't broadcast (1403, 5, 224, 224, 3) -> (427, 5, 224, 224, 3)"
     ]
    }
   ],
   "source": [
    "# load resized numpy array\n",
    "path_vid_resized = path_cache + 'frames/'\n",
    "path_vid_resized += str(frame_size[0]) + \"_\" + str(frame_size[1]) + '/' \n",
    "\n",
    "path_labels = path_cache + 'labels/'\n",
    "\n",
    "# read vid paths\n",
    "path_videos = get_video_paths()\n",
    "\n",
    "# keep track of where we are in the h5 file\n",
    "h5_cursor = 0\n",
    "\n",
    "# loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "for c, path_video in enumerate(path_videos):\n",
    "\n",
    "    # get vid name from path\n",
    "    video_name = path_video.split(\"/\")[-2]\n",
    "    \n",
    "    print(c, len(path_videos), video_name)\n",
    "\n",
    "    ### create sequence: features\n",
    "    # load precomputed frames\n",
    "    frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "\n",
    "    # first apply preprocessing if pretrained model given\n",
    "#     if pretrained_model_name != None:\n",
    "#         frames = self.preprocess_input(frames)\n",
    "\n",
    "    # build sequences\n",
    "    x = []\n",
    "    for i in range(sequence_length, len(frames) + 1):\n",
    "        x.append(frames[i-sequence_length:i])\n",
    "    x = np.array(x)\n",
    "\n",
    "    ### create sequence: labels\n",
    "    # load precomputed labels\n",
    "    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "    # temp lists to store sequences\n",
    "    y = []\n",
    "    for i in range(sequence_length, len(labels) + 1):\n",
    "        y.append(labels[i-1])\n",
    "    y = (np.array(y))\n",
    "\n",
    "    print(\"XX\", h5_cursor, y.shape, \"..\", x.shape)\n",
    "    \n",
    "    ### write this vid's data to relevant h5 dataset\n",
    "    if video_splits[video_name] == \"train\":\n",
    "        h5_train_x[h5_cursor:h5_cursor + x.shape[0], :, :, :, :] = x\n",
    "        h5_train_y[h5_cursor:h5_cursor + y.shape[0], :] = y\n",
    "    if video_splits[video_name] == \"valid\":\n",
    "        h5_valid_x[h5_cursor:h5_cursor + x.shape[0], :, :, :, :] = x\n",
    "        h5_valid_y[h5_cursor:h5_cursor + y.shape[0], :] = y\n",
    "    if video_splits[video_name] == \"test\":\n",
    "        h5_test_x[h5_cursor:h5_cursor + x.shape[0], :, :, :, :] = x\n",
    "        h5_test_y[h5_cursor:h5_cursor + y.shape[0], :] = y\n",
    "\n",
    "    # update cursor\n",
    "    h5_cursor += len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:13:20.560857Z",
     "start_time": "2019-01-10T23:13:20.554866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10192"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:13:06.584694Z",
     "start_time": "2019-01-10T23:13:06.579642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10619, 5, 224, 224, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_shape_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:13:35.567469Z",
     "start_time": "2019-01-10T23:13:35.561999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_shape_train_x[0] - h5_cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:00:42.723353Z",
     "start_time": "2019-01-10T23:00:42.719787Z"
    }
   },
   "outputs": [],
   "source": [
    "# close h5 files\n",
    "f_train.close()\n",
    "f_valid.close()\n",
    "f_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:00:47.335790Z",
     "start_time": "2019-01-10T23:00:47.332589Z"
    }
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:07:23.732995Z",
     "start_time": "2019-01-10T22:07:23.499177Z"
    }
   },
   "outputs": [],
   "source": [
    "data_to_write = np.random.random(size=(100,20)) # or some such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:08:11.233284Z",
     "start_time": "2019-01-10T22:08:11.227475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_write.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:12:24.186746Z",
     "start_time": "2019-01-10T22:12:24.180376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87288674, 0.0479354 , 0.21496869, 0.52457312, 0.36355362,\n",
       "        0.5738816 , 0.51950428, 0.12935186, 0.65829541, 0.7267599 ,\n",
       "        0.85523122, 0.60086587, 0.87617385, 0.6988311 , 0.47135551,\n",
       "        0.13803998, 0.68947727, 0.83573227, 0.61033383, 0.23938601],\n",
       "       [0.53659324, 0.88290034, 0.97825525, 0.38554264, 0.25060313,\n",
       "        0.56811374, 0.713326  , 0.05882883, 0.33015174, 0.55246261,\n",
       "        0.48120046, 0.40404853, 0.58548799, 0.73555519, 0.81325294,\n",
       "        0.60537432, 0.19730834, 0.87475184, 0.55161567, 0.59570509]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_write[[3,5],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:07:23.732995Z",
     "start_time": "2019-01-10T22:07:23.499177Z"
    }
   },
   "outputs": [],
   "source": [
    "with h5py.File('name-of-file.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"name-of-dataset\",  data=data_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:12:07.990477Z",
     "start_time": "2019-01-10T22:12:07.983663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87288674 0.0479354  0.21496869 0.52457312 0.36355362 0.5738816\n",
      "  0.51950428 0.12935186 0.65829541 0.7267599  0.85523122 0.60086587\n",
      "  0.87617385 0.6988311  0.47135551 0.13803998 0.68947727 0.83573227\n",
      "  0.61033383 0.23938601]\n",
      " [0.53659324 0.88290034 0.97825525 0.38554264 0.25060313 0.56811374\n",
      "  0.713326   0.05882883 0.33015174 0.55246261 0.48120046 0.40404853\n",
      "  0.58548799 0.73555519 0.81325294 0.60537432 0.19730834 0.87475184\n",
      "  0.55161567 0.59570509]]\n",
      "<class 'numpy.ndarray'>\n",
      "(2, 20)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('name-of-file.h5', 'r') as hf:\n",
    "    data = hf['name-of-dataset'][[3,5],:]\n",
    "    print(data)\n",
    "    print(type(data))\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## fit with no generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T22:01:07.381232Z",
     "start_time": "2019-01-10T21:42:19.134292Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10775 samples, validate on 1380 samples\n",
      "Epoch 1/10\n",
      "10775/10775 [==============================] - 118s 11ms/step - loss: 1.4871 - acc: 0.6240 - val_loss: 0.5746 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78116, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/10\n",
      "10775/10775 [==============================] - 111s 10ms/step - loss: 0.5598 - acc: 0.7252 - val_loss: 0.4317 - val_acc: 0.8449\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.78116 to 0.84493, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/10\n",
      "10775/10775 [==============================] - 111s 10ms/step - loss: 0.4653 - acc: 0.7873 - val_loss: 0.3968 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84493 to 0.86014, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/10\n",
      "10775/10775 [==============================] - 111s 10ms/step - loss: 0.4131 - acc: 0.8214 - val_loss: 0.3566 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86014 to 0.86957, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/10\n",
      "10775/10775 [==============================] - 111s 10ms/step - loss: 0.3678 - acc: 0.8443 - val_loss: 0.3810 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86957 to 0.88478, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/10\n",
      "10775/10775 [==============================] - 111s 10ms/step - loss: 0.3505 - acc: 0.8530 - val_loss: 0.3225 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.88478 to 0.88696, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/10\n",
      "10775/10775 [==============================] - 111s 10ms/step - loss: 0.3393 - acc: 0.8604 - val_loss: 0.2916 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.88696 to 0.90145, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 8/10\n",
      "10775/10775 [==============================] - 111s 10ms/step - loss: 0.3257 - acc: 0.8697 - val_loss: 0.3332 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90145\n",
      "Epoch 9/10\n",
      "10775/10775 [==============================] - 111s 10ms/step - loss: 0.3219 - acc: 0.8634 - val_loss: 0.3316 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90145\n",
      "Epoch 10/10\n",
      "10775/10775 [==============================] - 111s 10ms/step - loss: 0.3108 - acc: 0.8716 - val_loss: 0.3227 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90145\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "fit_history = train(architecture.model, data, path_model = pwd+'models/', learning_rate = 0.001, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:55.333830Z",
     "start_time": "2019-01-10T21:39:55.330846Z"
    }
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # build feature cache in advance by running python3 data.py\n",
    "#     for pretrained_model_name in pretrained_model_names:\n",
    "#         for pooling in poolings:\n",
    "#             data = Data(sequence_length=1, \n",
    "#                         return_CNN_features=True,\n",
    "#                         pretrained_model_name = pretrained_model_name,\n",
    "#                         pooling=pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:55.339268Z",
     "start_time": "2019-01-10T21:39:55.336212Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix penguin lables data\n",
    "# labels = get_labels()\n",
    "# labels = labels[labels['video'] != \"20161014_no8_3\"]\n",
    "# labels = labels[labels['video'] != \"20161014_no8_4\"]\n",
    "# labels.loc[labels['video'] == '20160930_no8_1_2','video']='20160930_no8_2'\n",
    "# labels.to_csv(pwd + '/data/labels.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
