{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:21.373915Z",
     "start_time": "2019-01-10T21:39:21.371553Z"
    }
   },
   "outputs": [],
   "source": [
    "### TODO:\n",
    "# * check mobilenetv2_1.00_224 sequences bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:12.088391Z",
     "start_time": "2019-01-11T09:47:12.085261Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:12.295000Z",
     "start_time": "2019-01-11T09:47:12.290279Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import h5py\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:12.516250Z",
     "start_time": "2019-01-11T09:47:12.512326Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pretrained model functions\n",
    "from deepvideoclassification.models import precompute_CNN_features\n",
    "from deepvideoclassification.models import load_pretrained_model_preprocessor\n",
    "from deepvideoclassification.models import load_pretrained_model\n",
    "\n",
    "# import pretrained model properties\n",
    "from deepvideoclassification.models import pretrained_model_len_features\n",
    "from deepvideoclassification.models import pretrained_model_sizes\n",
    "from deepvideoclassification.models import pretrained_model_names, poolings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T15:39:58.787Z"
    }
   },
   "outputs": [],
   "source": [
    "load_pretrained_model_preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:13.009889Z",
     "start_time": "2019-01-11T09:47:13.006110Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:13.685046Z",
     "start_time": "2019-01-11T09:47:13.680359Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:14.238158Z",
     "start_time": "2019-01-11T09:47:14.233087Z"
    }
   },
   "outputs": [],
   "source": [
    "# read vid folders\n",
    "def get_video_paths():\n",
    "    \"\"\"\n",
    "    Return list of video paths \n",
    "\n",
    "    Videos should be in /data/video_1/, /data/video_2/ style folders \n",
    "    with sequentially numbered frame images e.g. /data/video_1/frame00001.jpg\n",
    "\n",
    "    There should be at least 3 videos, 1 for each of train/test/valid splits\n",
    "    Split assignment is given in /data/labels.csv (also to be provided by user)\n",
    "\n",
    "    Functionality to use different parts of a video as train/valid/test \n",
    "    not currently implemented.\n",
    "    \"\"\"\n",
    "    path_videos = []\n",
    "    for filename in os.listdir(path_data):\n",
    "        if os.path.isdir(os.path.join(path_data, filename)):\n",
    "            path_videos.append(filename)\n",
    "\n",
    "    path_videos = [path_data + v + '/' for v in path_videos]\n",
    "\n",
    "    # make sure that there is video data in /data/ and give instructions if not done correctly\n",
    "    assert len(path_videos)>0, \"There need to be at least 3 video folders (at least 1 for each of train, valid, \\\n",
    "    and test splits) in /data/ - each video should be its own folder of frame images with ascending time-ordered \\\n",
    "    filenames e.g. /data/vid1/frame00001.jpg ... videos assignment to train/valid/test split should be given in \\\n",
    "    /data/labels.csv ... cross-validation or train/valid/test splits within a single long video not currently implemented\"\n",
    "\n",
    "    return path_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:14.792672Z",
     "start_time": "2019-01-11T09:47:14.784851Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_frames(target_size):\n",
    "    \"\"\"\n",
    "    Resize the frames of all videos and save them to /cache/ \n",
    "    to make model fitting faster .\n",
    "\n",
    "    We resize once upfront rather than each we use a pretrained model or architecture.\n",
    "\n",
    "    Our models require inputs resized to:\n",
    "    * 224 x 224 VGG16, ResNet50, DenseNet, MobileNet\n",
    "    * 299 x 299 XCeption, InceptionV3, InceptionResNetV2\n",
    "    * 112 x 112 3D CNN \n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/'):\n",
    "        \n",
    "        os.makedirs(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/')\n",
    "\n",
    "        # read vid paths\n",
    "        path_videos = get_video_paths()\n",
    "\n",
    "        # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "        for c,path_video in enumerate(path_videos):\n",
    "\n",
    "            logger.info(\"resizing vid {}/{} to {}x{}\".format(c+1,len(path_videos),target_size[0], target_size[1]))\n",
    "\n",
    "            # get vid name from path\n",
    "            video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "            # create directory for resized frames - just storing arrays now so commented out\n",
    "            # e.g. path_vid_resized = /cache/frames/224_224/s23-4847/\n",
    "            # path_vid_resized = path_cache + 'frames/'\n",
    "            # path_vid_resized += str(target_size[0]) + \"_\" + str(target_size[1]) + '/' \n",
    "            # path_vid_resized += video_name + '/'\n",
    "\n",
    "            # load frame paths for vid\n",
    "            path_frames = os.listdir(path_video)\n",
    "            path_frames = [path_video + f for f in path_frames if f != '.DS_Store']\n",
    "            path_frames.sort()\n",
    "\n",
    "            # load frames\n",
    "            frames = []\n",
    "            for path_frame in path_frames:\n",
    "\n",
    "                # open image and resize\n",
    "                filename = path_frame.split(\"/\").pop()\n",
    "                img_frame = Image.open(path_frame)\n",
    "                img_frame = img_frame.resize(target_size)\n",
    "                # img_frame.save(path_vid_resized + filename, \"JPEG\", quality = 100)\n",
    "\n",
    "                # convert to array and append to list\n",
    "                img_frame = np.array(img_frame)\n",
    "                frames.append(img_frame)\n",
    "\n",
    "            # save array of resized frames\n",
    "            np.save(path_cache + \"frames/\" + str(target_size[0]) + \"_\" + str(target_size[1]) + \"/\" + video_name, np.array(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:15.589594Z",
     "start_time": "2019-01-11T09:47:15.585016Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    # read labels - should be CSV with columns \"video\",\"frame\",\"label\",\"split\"\n",
    "    # e.g. \"s1-218\", \"s1-218-00001.jpeg\", \"noseal\", \"train\"\n",
    "    labels = None\n",
    "    try:\n",
    "        labels = pd.read_csv(path_data + 'labels.csv', usecols=['video','frame','label','split'])\n",
    "    except ValueError as e:\n",
    "        raise Exception(\"Labels file must contain columns ['video','frame','label','split'] - if you only have ['video','frame','label'], use the helper function add_splits_to_labels_file to add train/valid/test splits to your labels file\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise Exception(\"No labels found - please save labels file to /data/labels.csv\") from e\n",
    "\n",
    "    return labels.sort_values([\"video\",\"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:16.005472Z",
     "start_time": "2019-01-11T09:47:15.998726Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_video_label_arrays():\n",
    "    \"\"\"\n",
    "    Create numpy array with labels for each vid and a label_map.json file\n",
    "    in /cache/labels/\n",
    "    \"\"\"\n",
    "\n",
    "    # create folder for labels\n",
    "    if not os.path.exists(path_cache + 'labels/'):\n",
    "        os.makedirs(path_cache + 'labels/')\n",
    "\n",
    "    # load labels\n",
    "    labels = get_labels()\n",
    "\n",
    "    # build label_map\n",
    "    label_dummies = pd.get_dummies(labels, columns = ['label'])\n",
    "\n",
    "    # get label columns list and build label map dict\n",
    "    label_columns = []\n",
    "    label_map = {}\n",
    "    label_map_idx = 0\n",
    "    for i, col in enumerate(label_dummies.columns):\n",
    "        if col[:6] == 'label_':\n",
    "            label_columns.append(col)\n",
    "            label_map[label_map_idx] = col\n",
    "            label_map_idx+=1\n",
    "\n",
    "    # save label map to json\n",
    "    with open(path_cache + 'labels/label_map.json', 'w') as fp:\n",
    "        json.dump(label_map, fp)\n",
    "\n",
    "    # get video paths\n",
    "    path_videos = get_video_paths()\n",
    "\n",
    "    # save numpy array of labels for each vid\n",
    "    for path_video in path_videos:\n",
    "\n",
    "        # get vid name from path\n",
    "        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "        vid_labels = np.array(label_dummies[label_dummies['video'] == video_name][label_columns])\n",
    "\n",
    "        # save labels array for this vid\n",
    "        np.save(path_cache + \"/labels/\" + video_name, np.array(vid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:16.554202Z",
     "start_time": "2019-01-11T09:47:16.549342Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_label_map():\n",
    "    \"\"\"\n",
    "    Returns label map - read from disk\n",
    "    \"\"\"\n",
    "\n",
    "    # load label map from disk\n",
    "    label_map = None\n",
    "    try:\n",
    "        if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "            with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                label_map = json.load(fp)\n",
    "        else:\n",
    "            # build labels and label map\n",
    "            create_video_label_arrays()\n",
    "            if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "                with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                    label_map = json.load(fp)\n",
    "    except Exception as e:\n",
    "        logger.error ('label map not found - make sure /data/labels.csv exists and data cache has been built')\n",
    "\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T10:40:45.395457Z",
     "start_time": "2019-01-11T10:40:45.387226Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Generator (used in Data) that generates data for Keras fit_generator method because full dataset too big to load into memory\n",
    "    \n",
    "    > inherits from keras.utils.Sequence\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, h5_path, h5_row_count):\n",
    "        \"\"\"\n",
    "        Initialization DataGenerator class\n",
    "        \n",
    "        :batch_size: number of samples to return in batch \n",
    "        :h5_path: path to h5 dataset (where we stored the generated sequence data via save_frame_sequences_to_h5())\n",
    "        :h5_row_count: number of rows in h5 dataset\n",
    "        \n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.h5_path = h5_path\n",
    "        self.h5_row_count = h5_row_count\n",
    "        \n",
    "        # init (shuffle dataset)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(h5_row_count / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        x, y = self.__data_generation(batch_indexes)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(h5_row_count)\n",
    "        \n",
    "        # shuffle indexes -> shuffle samples returned in each batch\n",
    "        np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batch_indexes):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples\n",
    "        \n",
    "        :batch_indexes: list (of size batch_size) with indexes into h5 file\n",
    "        \"\"\" \n",
    "        x, y = None, None\n",
    "\n",
    "        # slices into h5 file need to be sorted\n",
    "        batch_indexes.sort()\n",
    "\n",
    "        # read sample from h5 file\n",
    "        with h5py.File(h5_path, 'r') as h5:\n",
    "            ### read sample indexes from h5 file\n",
    "            # sample sequences\n",
    "            x = h5['sequences'][batch_indexes,:]\n",
    "            # sample labels\n",
    "            y = h5['labels'][batch_indexes,:]\n",
    "\n",
    "        return x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T12:50:26.639Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def __init__(self, sequence_length, \n",
    "                    return_CNN_features = False, pretrained_model_name = None, pooling = None, \n",
    "                    frame_size = None, augmentation = False, oversampling = False,\n",
    "                    model_weights_path = None, custom_model_name = None,\n",
    "                    return_generator = False, batch_size = None,\n",
    "                    verbose = False):\n",
    "        \"\"\"\n",
    "        Data object constructor\n",
    "        \n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        :return_CNN_features: whether to return precomputed features or return frames (or sequences of features/frames if sequence_length>1)\n",
    "\n",
    "        :return_features: if True then return features (or sequences of feature) from pretrained model, if False then return frames (or sequences of frames)        \n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :frame_size: size that frames are resized to (this is looked up for pretrained models)\n",
    "        :augmentation: whether to apply data augmentation (horizontal flips)\n",
    "        :oversampling: whether to apply oversampling to create class balance\n",
    "        \n",
    "        :model_weights_path: path to custom model weights if we want to load CNN model we've fine-tuned to produce features (e.g. for LRCNN)\n",
    "        :custom_model_name: custom output name to append to pretrained model name\n",
    "        \n",
    "        :return_generator: if True and sequence_length > 1 and return_CNN_features == False, then do not return dataset, instead construct h5 file with sequences for each split and return generator that samples from that (dataset of sequecne frames too big to load into memory)\n",
    "        :batch_size: size of batches that generator must return\n",
    "        \n",
    "        :verbose: whether to log details\n",
    "        \n",
    "        Notes: \n",
    "        * if pretrained_model_name != None and return_CNN_features=False then will first apply preprocessor to frames (or frame sequences)\n",
    "        * if return_generator = True and sequence_length > 1 and return_CNN_features == False, large h5 files will be created in cache before returning generator\n",
    "        \"\"\"\n",
    "    \n",
    "        # required params\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frame_size = frame_size\n",
    "        \n",
    "        # optional params\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.return_CNN_features = return_CNN_features\n",
    "        self.augmentation = augmentation\n",
    "        self.oversampling = oversampling\n",
    "        \n",
    "        # init model data\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_valid = []\n",
    "        self.y_valid = []\n",
    "        # \n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        # fix case sensitivity\n",
    "        if type(self.pretrained_model_name) == str:\n",
    "            self.pretrained_model_name = self.pretrained_model_name.lower()\n",
    "        if type(self.pooling) == str:\n",
    "            self.pooling = self.pooling.lower()\n",
    "        \n",
    "        ################\n",
    "        ### Prepare data\n",
    "        ################\n",
    "        \n",
    "        # get video paths\n",
    "        self.path_videos = get_video_paths()\n",
    "        \n",
    "        # create label array for each video and load label map\n",
    "        create_video_label_arrays()\n",
    "        self.label_map = load_label_map()\n",
    "        \n",
    "        # get labels\n",
    "        self.labels = get_labels()\n",
    "        \n",
    "        # pull number of classes from labels shape\n",
    "        self.num_classes = self.labels['label'].nunique()\n",
    "        \n",
    "        # create dict mapping video to train/valid/test split assignment\n",
    "        video_splits = self.labels[['video','split']].drop_duplicates()\n",
    "        video_splits.set_index(\"video\", inplace=True)\n",
    "        video_splits = video_splits.to_dict()['split']\n",
    "        self.video_splits = video_splits\n",
    "        \n",
    "        # look up target size for pretrained model\n",
    "        if pretrained_model_name is not None:\n",
    "            self.frame_size = pretrained_model_sizes[pretrained_model_name]\n",
    "            print(self.frame_size)\n",
    "        \n",
    "        # precompute resized frames (won't recompute if already resized)\n",
    "        resize_frames(self.frame_size)\n",
    "\n",
    "        # pre compute CNN features (won't recompute if already computed)\n",
    "        if return_CNN_features and pretrained_model_name is not None:\n",
    "            if model_weights_path is not None and custom_model_name is not None:\n",
    "                # precompute with custom weights input and name\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling, self.model_weights_path, self.custom_model_name)\n",
    "            else:\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # get preprocessor given pretrained if we will need to apply preprocessor \n",
    "        # (i.e. if return_CNN_features == False and pretrained_model_name != None)\n",
    "        if not return_CNN_features and pretrained_model_name is not None:\n",
    "            self.preprocess_input = load_pretrained_model_preprocessor(self.pretrained_model_name)\n",
    "        \n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.return_generator = return_generator\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # do some checks\n",
    "        if self.return_generator:\n",
    "            assert self.batch_size != None, \"batch size required to construct generator\"\n",
    "        if self.return_generator:\n",
    "            assert self.return_CNN_features == False, \"generator only implemented for frame sequences - features usually large enough to load into memory\"\n",
    "        \n",
    "        ###################################\n",
    "        ### load features / build sequences\n",
    "        ###################################\n",
    "        \n",
    "        \n",
    "        # load features/frames from all videos and concat into big array for each of train, valid and test\n",
    "        if self.sequence_length > 1:\n",
    "            \n",
    "            ### sequences\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Loading features sequence data into memory\")\n",
    "                \n",
    "                #####################\n",
    "                ### feature sequences\n",
    "                #####################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    features = np.load(path_features + video_name + '.npy')\n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(features) + 1):\n",
    "                        x.append(features[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: labels\n",
    "                    # load precomputed labels\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                        \n",
    "            else:\n",
    "\n",
    "                ###################\n",
    "                ### frame sequences\n",
    "                ###################\n",
    "                \n",
    "                # load full frame sequecne dataset into memory and return\n",
    "                if not return_generator:\n",
    "                    \n",
    "                    ##############################################################################\n",
    "                    ### load full sequence dataset into memory (will likely run into memory error)\n",
    "                    ##############################################################################\n",
    "                    \n",
    "                    if verbose:\n",
    "                        logging.info(\"Loading frame sequence data into memory\")\n",
    "\n",
    "                    # load resized numpy array\n",
    "                    path_vid_resized = path_cache + 'frames/'\n",
    "                    path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "                    path_labels = path_cache + 'labels/'\n",
    "\n",
    "                    # read vid paths\n",
    "                    path_videos = get_video_paths()\n",
    "\n",
    "                    # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                    for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                        # get vid name from path\n",
    "                        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "                        ### create sequence: features\n",
    "                        # load precomputed frames\n",
    "                        frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "\n",
    "                        # first apply preprocessing if pretrained model given\n",
    "                        if pretrained_model_name != None:\n",
    "                            frames = self.preprocess_input(frames)\n",
    "\n",
    "                        # build sequences\n",
    "                        x = []\n",
    "                        for i in range(sequence_length, len(frames) + 1):\n",
    "                            x.append(frames[i-sequence_length:i])\n",
    "                        x = np.array(x)\n",
    "\n",
    "\n",
    "                        ### create sequence: labels\n",
    "                        # load precomputed labels\n",
    "                        labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                        # temp lists to store sequences\n",
    "                        y = []\n",
    "                        for i in range(sequence_length, len(labels) + 1):\n",
    "                            y.append(labels[i-1])\n",
    "                        y = (np.array(y))\n",
    "\n",
    "                        ### build output\n",
    "                        if self.video_splits[video_name] == \"train\":\n",
    "                            self.x_train.append(x)\n",
    "                            self.y_train.append(y)\n",
    "                        if self.video_splits[video_name] == \"valid\":\n",
    "                            self.x_valid.append(x)\n",
    "                            self.y_valid.append(y)\n",
    "                        if self.video_splits[video_name] == \"test\":\n",
    "                            self.x_test.append(x)\n",
    "                            self.y_test.append(y)\n",
    "                else:\n",
    "                    #############################\n",
    "                    ### Build sequences generator\n",
    "                    #############################\n",
    "            \n",
    "                    # compute and save h5 sequence files\n",
    "                    self.save_frame_sequences_to_h5()\n",
    "                    \n",
    "                    # set generator\n",
    "                    self.train_generator = DataGenerator(self.batch_size, self.path_h5_train, self.total_rows_train)\n",
    "                    self.valid_generator = DataGenerator(self.batch_size, self.path_h5_valid, self.total_rows_valid)\n",
    "                    self.test_generator = DataGenerator(self.batch_size, self.path_h5_test, self.total_rows_test)\n",
    "                \n",
    "        else:\n",
    "\n",
    "            ### not sequence\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Loading features data into memory\")\n",
    "                \n",
    "                ###################\n",
    "                ### feature vectors\n",
    "                ###################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### load precomputed features\n",
    "                    x = np.load(path_features + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            else:\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Loading frames into memory\")\n",
    "                \n",
    "                #################\n",
    "                ### single frames\n",
    "                #################\n",
    "                \n",
    "                # load resized numpy array\n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    # load precomputed numpy arrays for frames and labels\n",
    "                    x = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    # apply preprocessing if pretrained model given\n",
    "                    if pretrained_model_name != None:\n",
    "                        x = self.preprocess_input(x)\n",
    "                \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            \n",
    "            \n",
    "        #################################\n",
    "        ### get file paths for each split\n",
    "        #################################\n",
    "        #\n",
    "        # Note: only makes sense for sequence_length = 1\n",
    "        \n",
    "        # get file paths: train\n",
    "        dflab = self.labels[self.labels['split'] == 'train']\n",
    "        self.paths_train = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: valid\n",
    "        dflab = self.labels[self.labels['split'] == 'valid']\n",
    "        self.paths_valid = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: test\n",
    "        dflab = self.labels[self.labels['split'] == 'test']\n",
    "        self.paths_test = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        ### reshape list outputs (if not using generator)\n",
    "        #################################################\n",
    "        \n",
    "        if not return_generator:\n",
    "            ## e.g. (9846, 224, 224, 3) for frames [return_CNN_features=True]\n",
    "            ## or  (9846, 512) for features [return_CNN_features=False]\n",
    "            self.x_train = np.concatenate(self.x_train, axis=0)\n",
    "            self.y_train = np.concatenate(self.y_train, axis=0)\n",
    "            self.x_valid = np.concatenate(self.x_valid, axis=0)\n",
    "            self.y_valid = np.concatenate(self.y_valid, axis=0)\n",
    "            self.x_test = np.concatenate(self.x_test, axis=0)\n",
    "            self.y_test = np.concatenate(self.y_test, axis=0)\n",
    "            \n",
    "            # shuffle train and validation set\n",
    "            self.shuffle()\n",
    "            \n",
    "\n",
    "    def __str__(self):\n",
    "        return \"x_train: {}, y_train: {} ... x_valid: {}, y_valid: {} ... x_test: {}, y_test: {}\".format(self.x_train.shape,self.y_train.shape,self.x_valid.shape,self.y_valid.shape,self.x_test.shape,self.y_test.shape)\n",
    "            \n",
    "    def shuffle(self):\n",
    "        \"\"\"\n",
    "        Randomize the order of samples in train and valid splits\n",
    "        \"\"\"\n",
    "        ###########\n",
    "        ### shuffle\n",
    "        ###########\n",
    "        # paths will no longer be correct (they're for debugging anyway)\n",
    "        self.x_train, self.y_train, self.paths_train = shuffle(self.x_train, self.y_train, self.paths_train)\n",
    "        self.x_valid, self.y_valid, self.paths_valid = shuffle(self.x_valid, self.y_valid, self.paths_valid)\n",
    "        \n",
    "\n",
    "    # Even at small sequence lengths, loading the full dataset as \n",
    "    # a sequence into memory is not feasible so we need to use generators\n",
    "    # that iterate over the dataset without loading it all into memory\n",
    "    # \n",
    "    # For now, we will assume that we will load the features datasets into memory\n",
    "    # because this is more feasible but for large datasets, we'd want to use generators for that too. \n",
    "    # An implementation for a feature generator  can be done by pattern matching the implementation for frames \n",
    "    # \n",
    "    # we first precompute a sequences h5 file (it's too big to fit in memory but we never have more than 1\n",
    "    # video's sequences in memory) ...then we will initialize a generator that samples sequences from the \n",
    "    # h5 file and returns batches that will be passed to our model's fit_generator method\n",
    "\n",
    "    def save_frame_sequences_to_h5(self):\n",
    "        \"\"\"\n",
    "        Save sequence of frames to h5 files (1 for each split) in cache \n",
    "        because dataset too big to load into memory\n",
    "        \n",
    "        Will create generator that reads random rows from these h5 files\n",
    "        \n",
    "        Inspired by: https://stackoverflow.com/questions/41849649/write-to-hdf5-and-shuffle-big-arrays-of-data\n",
    "        \"\"\"\n",
    "    \n",
    "        #######################\n",
    "        ### setup h5 file paths\n",
    "        #######################\n",
    "        \n",
    "        if not os.path.exists(path_cache + 'sequences/'):\n",
    "            os.makedirs(path_cache + 'sequences/')\n",
    "\n",
    "        path_h5_base = path_cache + 'sequences/'\n",
    "\n",
    "        # store h5 files in subfolder in cache/sequences/ either with pretrained model name or resize name\n",
    "        # since we need to run preprocessing for pretrained models but not for vanilla resizing (3DCNN)\n",
    "        if pretrained_model_name is not None:\n",
    "            path_h5_base += pretrained_model_name + '/'\n",
    "        else:\n",
    "            path_h5_base += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "        if not os.path.exists(path_h5_base):\n",
    "            os.makedirs(path_h5_base)\n",
    "\n",
    "        self.path_h5_train = path_h5_base + '/h5_' + str(self.sequence_length) + 'train.h5'\n",
    "        self.path_h5_valid = path_h5_base + '/h5_' + str(self.sequence_length) + 'valid.h5'\n",
    "        self.path_h5_test = path_h5_base + '/h5_' + str(self.sequence_length) + 'test.h5'\n",
    "    \n",
    "        # build h5 file if doesn't exists()\n",
    "        if not os.path.exists(self.path_h5_train) or not os.path.exists(self.path_h5_valid) or not os.path.exists(self.path_h5_test):\n",
    "            \n",
    "            if verbose:\n",
    "                logging.info(\"Computing frame sequence h5 files: {}\".format(path_h5_base))\n",
    "\n",
    "            ##################################################\n",
    "            ### get size of train/valid/test sequence datasets\n",
    "            ##################################################\n",
    "\n",
    "            # total number of rows of sequence data we have for each split\n",
    "            # this is not the same as the number of frames since we exclude\n",
    "            # the first (self.sequence_length-1) frames\n",
    "            total_rows_train = 0\n",
    "            total_rows_valid = 0\n",
    "            total_rows_test = 0\n",
    "\n",
    "            # load resized numpy array\n",
    "            path_vid_resized = path_cache + 'frames/'\n",
    "            path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "            \n",
    "            print(path_vid_resized)\n",
    "\n",
    "            path_labels = path_cache + 'labels/'\n",
    "\n",
    "            # read vid paths\n",
    "            path_videos = get_video_paths()\n",
    "\n",
    "            # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "            for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                # get vid name from path\n",
    "                video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "                # load resized frames\n",
    "                frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "\n",
    "                # build sequences\n",
    "                x = []\n",
    "                for i in range(self.sequence_length, len(frames) + 1):\n",
    "                    x.append(frames[i-self.sequence_length:i])\n",
    "                x = np.array(x)\n",
    "\n",
    "                if self.video_splits[video_name] == \"train\":\n",
    "                    total_rows_train += len(x)\n",
    "                if self.video_splits[video_name] == \"valid\":\n",
    "                    total_rows_valid += len(x)\n",
    "                if self.video_splits[video_name] == \"test\":\n",
    "                    total_rows_test += len(x)\n",
    "\n",
    "            # calc shapes required for full sequence dataset\n",
    "            h5_shape_train_x = (total_rows_train, self.sequence_length, self.frame_size[0], self.frame_size[1], 3)\n",
    "            h5_shape_train_y = (total_rows_train, self.num_classes)\n",
    "\n",
    "            h5_shape_valid_x = (total_rows_valid, self.sequence_length, self.frame_size[0], self.frame_size[1], 3)\n",
    "            h5_shape_valid_y = (total_rows_valid, self.num_classes)\n",
    "\n",
    "            h5_shape_test_x = (total_rows_test, self.sequence_length, self.frame_size[0], self.frame_size[1], 3)\n",
    "            h5_shape_test_y = (total_rows_test, self.num_classes)\n",
    "\n",
    "\n",
    "            ################################\n",
    "            ### Initialize and open h5 files\n",
    "            ################################\n",
    "\n",
    "            # open h5 file to store big sequence dataset feature and label arrays\n",
    "            # path_h5file = MODEL -> SEQUENCE LENGTH\n",
    "            f_train = h5py.File(self.path_h5_train, 'a')\n",
    "            f_valid = h5py.File(self.path_h5_valid, 'a')\n",
    "            f_test = h5py.File(self.path_h5_test, 'a')\n",
    "\n",
    "            # initialize h5 datasets\n",
    "            h5_train_x = f_train.create_dataset('sequences', shape= h5_shape_train_x, dtype='uint8')\n",
    "            h5_train_y = f_train.create_dataset('labels', shape= h5_shape_train_y, dtype='uint8')\n",
    "\n",
    "            h5_valid_x = f_valid.create_dataset('sequences', shape= h5_shape_valid_x, dtype='uint8')\n",
    "            h5_valid_y = f_valid.create_dataset('labels', shape= h5_shape_valid_y, dtype='uint8')\n",
    "\n",
    "            h5_test_x = f_test.create_dataset('sequences', shape= h5_shape_test_x, dtype='uint8')\n",
    "            h5_test_y = f_test.create_dataset('labels', shape= h5_shape_test_y, dtype='uint8')\n",
    "\n",
    "            ##################################################\n",
    "            ### Build h5 files for this sequence / model combo\n",
    "            ##################################################\n",
    "\n",
    "            # load resized numpy array\n",
    "            path_vid_resized = path_cache + 'frames/'\n",
    "            path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "            path_labels = path_cache + 'labels/'\n",
    "\n",
    "            # read vid paths\n",
    "            path_videos = get_video_paths()\n",
    "\n",
    "            # keep track of where we are in the h5 file\n",
    "            h5_cursor_train = 0\n",
    "            h5_cursor_valid = 0\n",
    "            h5_cursor_test = 0\n",
    "\n",
    "            # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "            for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                # get vid name from path\n",
    "                video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "                print(c, len(path_videos), video_name)\n",
    "\n",
    "                ### create sequence: features\n",
    "                # load precomputed frames\n",
    "                frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                \n",
    "                # first apply preprocessing if pretrained model given\n",
    "                if pretrained_model_name != None:\n",
    "                    frames = self.preprocess_input(frames)\n",
    "                    \n",
    "                # build sequences\n",
    "                x = []\n",
    "                for i in range(self.sequence_length, len(frames) + 1):\n",
    "                    x.append(frames[i-self.sequence_length:i])\n",
    "                x = np.array(x)\n",
    "\n",
    "                ### create sequence: labels\n",
    "                # load precomputed labels\n",
    "                labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                # temp lists to store sequences\n",
    "                y = []\n",
    "                for i in range(self.sequence_length, len(labels) + 1):\n",
    "                    y.append(labels[i-1])\n",
    "                y = (np.array(y))\n",
    "\n",
    "                ### write this vid's data to relevant h5 dataset\n",
    "                if video_splits[video_name] == \"train\":\n",
    "                    h5_train_x[h5_cursor_train:h5_cursor_train + x.shape[0], :, :, :, :] = x\n",
    "                    h5_train_y[h5_cursor_train:h5_cursor_train + y.shape[0], :] = y\n",
    "                    h5_cursor_train += len(x)\n",
    "                if video_splits[video_name] == \"valid\":\n",
    "                    h5_valid_x[h5_cursor_valid:h5_cursor_valid + x.shape[0], :, :, :, :] = x\n",
    "                    h5_valid_y[h5_cursor_valid:h5_cursor_valid + y.shape[0], :] = y\n",
    "                    h5_cursor_valid += len(x)\n",
    "                if video_splits[video_name] == \"test\":\n",
    "                    h5_test_x[h5_cursor_test:h5_cursor_test + x.shape[0], :, :, :, :] = x\n",
    "                    h5_test_y[h5_cursor_test:h5_cursor_test + y.shape[0], :] = y\n",
    "                    h5_cursor_test += len(x)\n",
    "\n",
    "            # store total samples for each split so we can pass them to our DataGenerator\n",
    "            self.total_rows_train = total_rows_train\n",
    "            self.total_rows_valid = total_rows_valid\n",
    "            self.total_rows_test = total_rows_test\n",
    "                    \n",
    "            # close h5 files\n",
    "            f_train.close()\n",
    "            f_valid.close()\n",
    "            f_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:19.210308Z",
     "start_time": "2019-01-11T09:47:19.207078Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.models import Architecture\n",
    "from deepvideoclassification.models import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:47:29.235053Z",
     "start_time": "2019-01-11T09:47:29.231404Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = \"vgg16\"\n",
    "pooling=\"max\"\n",
    "sequence_length = 3\n",
    "\n",
    "layer_1_size = 128\n",
    "layer_2_size = 64\n",
    "layer_3_size = 32\n",
    "dropout=0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:48:15.110894Z",
     "start_time": "2019-01-11T09:47:30.234118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    }
   ],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling)\n",
    "\n",
    "num_classes = data.num_classes \n",
    "frame_size = data.frame_size\n",
    "num_features = pretrained_model_len_features[pretrained_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:48:17.460934Z",
     "start_time": "2019-01-11T09:48:16.125822Z"
    }
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(architecture=\"video_LRCNN_trainable\", \n",
    "                            sequence_model = 'LSTM',\n",
    "                            sequence_model_layers = 1,\n",
    "                            sequence_length = sequence_length,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name='vgg16', \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=8, \n",
    "                            dropout=0.2,\n",
    "                            convolution_kernel_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train with no generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T10:19:21.698226Z",
     "start_time": "2019-01-11T09:48:39.728035Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10697 samples, validate on 1370 samples\n",
      "Epoch 1/10\n",
      "10697/10697 [==============================] - 345s 32ms/step - loss: 0.9478 - acc: 0.6290 - val_loss: 0.5617 - val_acc: 0.7438\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74380, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/10\n",
      "10697/10697 [==============================] - 330s 31ms/step - loss: 0.5763 - acc: 0.7182 - val_loss: 0.5537 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74380 to 0.85255, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/10\n",
      "10697/10697 [==============================] - 329s 31ms/step - loss: 0.5434 - acc: 0.7408 - val_loss: 0.5750 - val_acc: 0.7080\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.85255\n",
      "Epoch 4/10\n",
      "10697/10697 [==============================] - 330s 31ms/step - loss: 0.5071 - acc: 0.7674 - val_loss: 0.4915 - val_acc: 0.7646\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.85255\n",
      "Epoch 5/10\n",
      "10697/10697 [==============================] - 329s 31ms/step - loss: 0.4911 - acc: 0.7739 - val_loss: 0.5200 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.85255 to 0.86971, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/10\n",
      " 6368/10697 [================>.............] - ETA: 1:58 - loss: 0.4855 - acc: 0.7877"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-2e2291d27cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train model with no data generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'models/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/seals/deepvideoclassification/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, path_model, learning_rate, epochs, batch_size, patience, verbose)\u001b[0m\n\u001b[1;32m    794\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m               verbose=verbose)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model with no data generator\n",
    "train(architecture.model, data, path_model = pwd+'models/', learning_rate = 0.001, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train with generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> need to store generator params in json with sequences file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T12:50:29.488Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling,\n",
    "            batch_size=32,\n",
    "            return_generator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build generator dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:48:06.867719Z",
     "start_time": "2019-01-10T23:48:06.864025Z"
    }
   },
   "outputs": [],
   "source": [
    "h5_path = 'train_sequences' + str(sequence_length) + '.h5'\n",
    "h5_file_len = h5_shape_train_x[0]\n",
    "sample_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:48:13.161091Z",
     "start_time": "2019-01-10T23:48:12.997373Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y = get_sample_from_h5(h5_path, h5_file_len, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T23:48:21.608509Z",
     "start_time": "2019-01-10T23:48:21.603099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 5, 224, 224, 3), (32, 2))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T00:45:23.807681Z",
     "start_time": "2019-01-11T00:44:15.915419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:44:16,106 [MainThread  ] [INFO ]  Computing frame sequence h5 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n",
      "path_h5_base /mnt/seals/cache/sequences/inception_resnet_v2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:44:16,308 [MainThread  ] [INFO ]  Computing frame sequence h5 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n",
      "path_h5_base /mnt/seals/cache/sequences/inception_v3/\n",
      "/mnt/seals/cache/frames/299_299/\n",
      "0 46 s23-4847\n",
      "1 46 s43-5211\n",
      "2 46 s2-1133\n",
      "3 46 s21-919\n",
      "4 46 s20-842\n",
      "5 46 s37-3930\n",
      "6 46 s5-1102\n",
      "7 46 s19-672\n",
      "8 46 s26-8164\n",
      "9 46 s41-4712\n",
      "10 46 s18-630\n",
      "11 46 s25-5886\n",
      "12 46 s35-3664\n",
      "13 46 s33-3405\n",
      "14 46 s45-6301\n",
      "15 46 s16-0\n",
      "16 46 s39-4336\n",
      "17 46 s29-316\n",
      "18 46 s12-3465\n",
      "19 46 s46-8087\n",
      "20 46 s31-784\n",
      "21 46 s28-20\n",
      "22 46 s3-1993\n",
      "23 46 s9-5491\n",
      "24 46 s11-7363\n",
      "25 46 s22-3733\n",
      "26 46 s13-14\n",
      "27 46 s15-2589\n",
      "28 46 s40-4508\n",
      "29 46 s17-2973\n",
      "30 46 s6-1247\n",
      "31 46 s42-4950\n",
      "32 46 s30-516\n",
      "33 46 s34-3590\n",
      "34 46 s36-3838\n",
      "35 46 s1-218\n",
      "36 46 s38-4060\n",
      "37 46 s7-2029\n",
      "38 46 s8-2244\n",
      "39 46 s10-6558\n",
      "40 46 s32-3110\n",
      "41 46 s14-1705\n",
      "42 46 s27-8212\n",
      "43 46 s24-5851\n",
      "44 46 s44-5304\n",
      "45 46 s4-6975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:45:17,088 [MainThread  ] [INFO ]  Computing frame sequence h5 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n",
      "path_h5_base /mnt/seals/cache/sequences/mobilenetv2_1.00_224/\n",
      "/mnt/seals/cache/frames/224_224/\n",
      "0 46 s23-4847\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'B') according to the casting rule ''same_kind''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-37f78916b2c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mpretrained_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mreturn_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     verbose=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-211-0716af89a58b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sequence_length, return_CNN_features, pretrained_model_name, pooling, frame_size, augmentation, oversampling, model_weights_path, custom_model_name, return_generator, verbose)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;31m# compute and save h5 sequence files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_frame_sequences_to_h5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;31m# TODO set generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-211-0716af89a58b>\u001b[0m in \u001b[0;36msave_frame_sequences_to_h5\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0;31m# first apply preprocessing if pretrained model given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpretrained_model_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;31m# build sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/applications/mobilenet_v2.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet_v2.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[0;34m(x, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mPreprocessed\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \"\"\"\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m128.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'B') according to the casting rule ''same_kind''"
     ]
    }
   ],
   "source": [
    "# build h5 cache\n",
    "for sequence_length in [2,3,5,10,20]:\n",
    "    for pretrained_model_name in pretrained_model_names:\n",
    "\n",
    "        data = Data(sequence_length=sequence_length, \n",
    "                    return_CNN_features=False, \n",
    "                    pretrained_model_name = pretrained_model_name, \n",
    "                    return_generator = True,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T00:37:39.837693Z",
     "start_time": "2019-01-11T00:37:33.432762Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:33,620 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:34,692 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/avg/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:35,157 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_v3/max/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:35,720 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_v3/avg/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:36,287 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/mobilenetv2_1.00_224/max/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:36,702 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/mobilenetv2_1.00_224/avg/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:37,114 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/max/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:37,676 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/avg/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:38,237 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/max/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:38,563 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:38,890 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/xception/max/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-11 00:37:39,454 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/xception/avg/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299)\n"
     ]
    }
   ],
   "source": [
    "# build h5 caches\n",
    "# build feature cache in advance by running python3 data.py\n",
    "for pretrained_model_name in pretrained_model_names:\n",
    "    for pooling in poolings:\n",
    "        data = Data(sequence_length=1, \n",
    "                    return_CNN_features=True,\n",
    "                    pretrained_model_name = pretrained_model_name,\n",
    "                    pooling=pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T21:39:55.333830Z",
     "start_time": "2019-01-10T21:39:55.330846Z"
    }
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # build feature cache in advance by running python3 data.py\n",
    "#     for pretrained_model_name in pretrained_model_names:\n",
    "#         for pooling in poolings:\n",
    "#             data = Data(sequence_length=1, \n",
    "#                         return_CNN_features=True,\n",
    "#                         pretrained_model_name = pretrained_model_name,\n",
    "#                         pooling=pooling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
