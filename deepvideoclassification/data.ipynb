{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:35.983159Z",
     "start_time": "2019-01-14T14:57:35.979773Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:38.225836Z",
     "start_time": "2019-01-14T14:57:36.140277Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import h5py\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:39.535695Z",
     "start_time": "2019-01-14T14:57:38.228159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T22:19:49.186290Z",
     "start_time": "2019-01-15T22:19:49.181997Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pretrained model functions\n",
    "from deepvideoclassification.models import precompute_CNN_features\n",
    "from deepvideoclassification.models import load_pretrained_model_preprocessor\n",
    "from deepvideoclassification.models import load_pretrained_model\n",
    "\n",
    "# import pretrained model properties\n",
    "from deepvideoclassification.models import pretrained_model_len_features\n",
    "from deepvideoclassification.models import pretrained_model_sizes\n",
    "from deepvideoclassification.models import pretrained_model_names, poolings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:39.554829Z",
     "start_time": "2019-01-14T14:57:39.551045Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:39.562972Z",
     "start_time": "2019-01-14T14:57:39.557227Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:39.570661Z",
     "start_time": "2019-01-14T14:57:39.565428Z"
    }
   },
   "outputs": [],
   "source": [
    "# read vid folders\n",
    "def get_video_paths():\n",
    "    \"\"\"\n",
    "    Return list of video paths \n",
    "\n",
    "    Videos should be in /data/video_1/, /data/video_2/ style folders \n",
    "    with sequentially numbered frame images e.g. /data/video_1/frame00001.jpg\n",
    "\n",
    "    There should be at least 3 videos, 1 for each of train/test/valid splits\n",
    "    Split assignment is given in /data/labels.csv (also to be provided by user)\n",
    "\n",
    "    Functionality to use different parts of a video as train/valid/test \n",
    "    not currently implemented.\n",
    "    \"\"\"\n",
    "    path_videos = []\n",
    "    for filename in os.listdir(path_data):\n",
    "        if os.path.isdir(os.path.join(path_data, filename)):\n",
    "            path_videos.append(filename)\n",
    "\n",
    "    path_videos = [path_data + v + '/' for v in path_videos]\n",
    "\n",
    "    # make sure that there is video data in /data/ and give instructions if not done correctly\n",
    "    assert len(path_videos)>0, \"There need to be at least 3 video folders (at least 1 for each of train, valid, \\\n",
    "    and test splits) in /data/ - each video should be its own folder of frame images with ascending time-ordered \\\n",
    "    filenames e.g. /data/vid1/frame00001.jpg ... videos assignment to train/valid/test split should be given in \\\n",
    "    /data/labels.csv ... cross-validation or train/valid/test splits within a single long video not currently implemented\"\n",
    "\n",
    "    return path_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:39.581698Z",
     "start_time": "2019-01-14T14:57:39.573524Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_frames(target_size):\n",
    "    \"\"\"\n",
    "    Resize the frames of all videos and save them to /cache/ \n",
    "    to make model fitting faster .\n",
    "\n",
    "    We resize once upfront rather than each we use a pretrained model or architecture.\n",
    "\n",
    "    Our models require inputs resized to:\n",
    "    * 224 x 224 VGG16, ResNet50, DenseNet, MobileNet\n",
    "    * 299 x 299 XCeption, InceptionV3, InceptionResNetV2\n",
    "    * 112 x 112 3D CNN \n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/'):\n",
    "        \n",
    "        os.makedirs(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/')\n",
    "\n",
    "        # read vid paths\n",
    "        path_videos = get_video_paths()\n",
    "\n",
    "        # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "        for c,path_video in enumerate(path_videos):\n",
    "\n",
    "            logger.info(\"resizing vid {}/{} to {}x{}\".format(c+1,len(path_videos),target_size[0], target_size[1]))\n",
    "\n",
    "            # get vid name from path\n",
    "            video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "            # create directory for resized frames - just storing arrays now so commented out\n",
    "            # e.g. path_vid_resized = /cache/frames/224_224/s23-4847/\n",
    "            # path_vid_resized = path_cache + 'frames/'\n",
    "            # path_vid_resized += str(target_size[0]) + \"_\" + str(target_size[1]) + '/' \n",
    "            # path_vid_resized += video_name + '/'\n",
    "\n",
    "            # load frame paths for vid\n",
    "            path_frames = os.listdir(path_video)\n",
    "            path_frames = [path_video + f for f in path_frames if f != '.DS_Store']\n",
    "            path_frames.sort()\n",
    "\n",
    "            # load frames\n",
    "            frames = []\n",
    "            for path_frame in path_frames:\n",
    "\n",
    "                # open image and resize\n",
    "                filename = path_frame.split(\"/\").pop()\n",
    "                img_frame = Image.open(path_frame)\n",
    "                img_frame = img_frame.resize(target_size)\n",
    "                # img_frame.save(path_vid_resized + filename, \"JPEG\", quality = 100)\n",
    "\n",
    "                # convert to array and append to list\n",
    "                img_frame = np.array(img_frame)\n",
    "                frames.append(img_frame)\n",
    "\n",
    "            # save array of resized frames\n",
    "            np.save(path_cache + \"frames/\" + str(target_size[0]) + \"_\" + str(target_size[1]) + \"/\" + video_name, np.array(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:39.588989Z",
     "start_time": "2019-01-14T14:57:39.584328Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    # read labels - should be CSV with columns \"video\",\"frame\",\"label\",\"split\"\n",
    "    # e.g. \"s1-218\", \"s1-218-00001.jpeg\", \"noseal\", \"train\"\n",
    "    labels = None\n",
    "    try:\n",
    "        labels = pd.read_csv(path_data + 'labels.csv', usecols=['video','frame','label','split'])\n",
    "    except ValueError as e:\n",
    "        raise Exception(\"Labels file must contain columns ['video','frame','label','split'] - if you only have ['video','frame','label'], use Jupyter notebook in notebooks/add_splits_to_labels_file.ipynb to add train/valid/test splits to your labels file\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise Exception(\"No labels found - please save labels file to /data/labels.csv\") from e\n",
    "\n",
    "    return labels.sort_values([\"video\",\"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:39.597868Z",
     "start_time": "2019-01-14T14:57:39.591550Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_video_label_arrays():\n",
    "    \"\"\"\n",
    "    Create numpy array with labels for each vid and a label_map.json file\n",
    "    in /cache/labels/\n",
    "    \"\"\"\n",
    "\n",
    "    # create folder for labels\n",
    "    if not os.path.exists(path_cache + 'labels/'):\n",
    "        os.makedirs(path_cache + 'labels/')\n",
    "\n",
    "    # load labels\n",
    "    labels = get_labels()\n",
    "\n",
    "    # build label_map\n",
    "    label_dummies = pd.get_dummies(labels, columns = ['label'])\n",
    "\n",
    "    # get label columns list and build label map dict\n",
    "    label_columns = []\n",
    "    label_map = {}\n",
    "    label_map_idx = 0\n",
    "    for i, col in enumerate(label_dummies.columns):\n",
    "        if col[:6] == 'label_':\n",
    "            label_columns.append(col)\n",
    "            label_map[label_map_idx] = col\n",
    "            label_map_idx+=1\n",
    "\n",
    "    # save label map to json\n",
    "    with open(path_cache + 'labels/label_map.json', 'w') as fp:\n",
    "        json.dump(label_map, fp)\n",
    "\n",
    "    # get video paths\n",
    "    path_videos = get_video_paths()\n",
    "\n",
    "    # save numpy array of labels for each vid\n",
    "    for path_video in path_videos:\n",
    "\n",
    "        # get vid name from path\n",
    "        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "        vid_labels = np.array(label_dummies[label_dummies['video'] == video_name][label_columns])\n",
    "\n",
    "        # save labels array for this vid\n",
    "        np.save(path_cache + \"/labels/\" + video_name, np.array(vid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:39.605739Z",
     "start_time": "2019-01-14T14:57:39.600706Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_label_map():\n",
    "    \"\"\"\n",
    "    Returns label map - read from disk\n",
    "    \"\"\"\n",
    "\n",
    "    # load label map from disk\n",
    "    label_map = None\n",
    "    try:\n",
    "        if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "            with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                label_map = json.load(fp)\n",
    "        else:\n",
    "            # build labels and label map\n",
    "            create_video_label_arrays()\n",
    "            if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "                with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                    label_map = json.load(fp)\n",
    "    except Exception as e:\n",
    "        logger.error ('label map not found - make sure /data/labels.csv exists and data cache has been built')\n",
    "\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T14:57:39.615618Z",
     "start_time": "2019-01-14T14:57:39.608349Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Generator (used in Data) that generates data for Keras fit_generator method because full dataset too big to load into memory\n",
    "    \n",
    "    > inherits from keras.utils.Sequence\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, h5_path, h5_row_count):\n",
    "        \"\"\"\n",
    "        Initialization DataGenerator class\n",
    "        \n",
    "        :batch_size: number of samples to return in batch \n",
    "        :h5_path: path to h5 dataset (where we stored the generated sequence data via save_frame_sequences_to_h5())\n",
    "        :h5_row_count: number of rows in h5 dataset\n",
    "        \n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.h5_path = h5_path\n",
    "        self.h5_row_count = h5_row_count\n",
    "        \n",
    "        # init (shuffle dataset)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.h5_row_count / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        x, y = self.__data_generation(batch_indexes)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.h5_row_count)\n",
    "        \n",
    "        # shuffle indexes -> shuffle samples returned in each batch\n",
    "        np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batch_indexes):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples\n",
    "        \n",
    "        :batch_indexes: list (of size batch_size) with indexes into h5 file\n",
    "        \"\"\" \n",
    "        x, y = None, None\n",
    "\n",
    "        # slices into h5 file need to be sorted\n",
    "        batch_indexes.sort()\n",
    "\n",
    "        # read sample from h5 file\n",
    "        with h5py.File(self.h5_path, 'r') as h5:\n",
    "            ### read sample indexes from h5 file\n",
    "            # sample sequences\n",
    "            x = h5['sequences'][batch_indexes,:]\n",
    "            # sample labels\n",
    "            y = h5['labels'][batch_indexes,:]\n",
    "\n",
    "        return x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T20:46:09.014166Z",
     "start_time": "2019-01-15T20:46:08.951153Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def __init__(self, sequence_length, \n",
    "                    return_CNN_features = False, pretrained_model_name = None, pooling = None, \n",
    "                    frame_size = None, augmentation = False, oversampling = False,\n",
    "                    model_weights_path = None, custom_model_name = None,\n",
    "                    return_generator = False, batch_size = None,\n",
    "                    verbose = True):\n",
    "        \"\"\"\n",
    "        Data object constructor\n",
    "        \n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        :return_CNN_features: whether to return precomputed features or return frames (or sequences of features/frames if sequence_length>1)\n",
    "\n",
    "        :return_features: if True then return features (or sequences of feature) from pretrained model, if False then return frames (or sequences of frames)        \n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :frame_size: size that frames are resized to (this is looked up for pretrained models)\n",
    "        :augmentation: whether to apply data augmentation (horizontal flips)\n",
    "        :oversampling: whether to apply oversampling to create class balance\n",
    "        \n",
    "        :model_weights_path: path to custom model weights if we want to load CNN model we've fine-tuned to produce features (e.g. for LRCNN)\n",
    "        :custom_model_name: custom output name to append to pretrained model name\n",
    "        \n",
    "        :return_generator: if True and sequence_length > 1 and return_CNN_features == False, then do not return dataset, instead construct h5 file with sequences for each split and return generator that samples from that (dataset of sequecne frames too big to load into memory)\n",
    "        :batch_size: size of batches that generator must return\n",
    "        \n",
    "        :verbose: whether to log details\n",
    "        \n",
    "        Notes: \n",
    "        * if pretrained_model_name != None and return_CNN_features=False then will first apply preprocessor to frames (or frame sequences)\n",
    "        * if return_generator = True and sequence_length > 1 and return_CNN_features == False, large h5 files will be created in cache before returning generator\n",
    "        \"\"\"\n",
    "    \n",
    "        # required params\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frame_size = frame_size\n",
    "        \n",
    "        # optional params\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.return_CNN_features = return_CNN_features\n",
    "        self.augmentation = augmentation\n",
    "        self.oversampling = oversampling\n",
    "        \n",
    "        # init model data\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_valid = []\n",
    "        self.y_valid = []\n",
    "        # \n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        # fix case sensitivity\n",
    "        if type(self.pretrained_model_name) == str:\n",
    "            self.pretrained_model_name = self.pretrained_model_name.lower()\n",
    "        if type(self.pooling) == str:\n",
    "            self.pooling = self.pooling.lower()\n",
    "        \n",
    "        ################\n",
    "        ### Prepare data\n",
    "        ################\n",
    "        \n",
    "        # get video paths\n",
    "        self.path_videos = get_video_paths()\n",
    "        \n",
    "        # create label array for each video and load label map\n",
    "        create_video_label_arrays()\n",
    "        self.label_map = load_label_map()\n",
    "        \n",
    "        # get labels\n",
    "        self.labels = get_labels()\n",
    "        \n",
    "        # check that there is 1 frame file for each label file and raise error if they don't match\n",
    "        paths_frames = []\n",
    "        for folder, subs, files in os.walk(path_data):        \n",
    "            for filename in files:\n",
    "                if filename[-4:].lower() == '.jpg' or filename[-4:].lower() == 'jpeg' or filename[-4:].lower() == 'png':\n",
    "                    paths_frames.append(os.path.abspath(os.path.join(folder, filename)))\n",
    "        if len(paths_frames) != len(self.labels):\n",
    "            error_msg = 'IMPORTANT ERROR: Number of frames ({}) in /data/ video folders needs to match number of labels ({}) in labels.csv - use notebooks/helper_check_frames_against_labels.ipynb to investigate... Note, only labels.csv and the frames you want to use (in video subfolders) should be in /data/'.format(len(paths_frames), len(self.labels))\n",
    "            logger.info(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "        \n",
    "        # pull number of classes from labels shape\n",
    "        self.num_classes = self.labels['label'].nunique()\n",
    "        \n",
    "        # create dict mapping video to train/valid/test split assignment\n",
    "        video_splits = self.labels[['video','split']].drop_duplicates()\n",
    "        video_splits.set_index(\"video\", inplace=True)\n",
    "        video_splits = video_splits.to_dict()['split']\n",
    "        self.video_splits = video_splits\n",
    "        \n",
    "        # look up target size for pretrained model\n",
    "        if pretrained_model_name is not None:\n",
    "            self.frame_size = pretrained_model_sizes[pretrained_model_name]\n",
    "        \n",
    "        # precompute resized frames (won't recompute if already resized)\n",
    "        resize_frames(self.frame_size)\n",
    "\n",
    "        # pre compute CNN features (won't recompute if already computed)\n",
    "        if return_CNN_features and pretrained_model_name is not None:\n",
    "            # check if pass custom weights to precompute from\n",
    "            if model_weights_path is not None and custom_model_name is not None:\n",
    "                # precompute with custom weights input and name\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling, self.model_weights_path, self.custom_model_name)\n",
    "            else:\n",
    "                precompute_CNN_features(self.pretrained_model_name, self.pooling)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # get preprocessor given pretrained if we will need to apply preprocessor \n",
    "        # (i.e. if return_CNN_features == False and pretrained_model_name != None)\n",
    "        if not return_CNN_features and pretrained_model_name is not None:\n",
    "            self.preprocess_input = load_pretrained_model_preprocessor(self.pretrained_model_name)\n",
    "        \n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.return_generator = return_generator\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # do some checks\n",
    "        if self.return_generator:\n",
    "            assert self.batch_size != None, \"batch size required to construct generator\"\n",
    "        if self.return_generator:\n",
    "            assert self.return_CNN_features == False, \"generator only implemented for frame sequences - features usually large enough to load into memory [may take a few minutes]\"\n",
    "        \n",
    "        ###################################\n",
    "        ### load features / build sequences\n",
    "        ###################################\n",
    "        \n",
    "        \n",
    "        # load features/frames from all videos and concat into big array for each of train, valid and test\n",
    "        if self.sequence_length > 1:\n",
    "            \n",
    "            ### sequences\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Loading features sequence data into memory [may take a few minutes]\")\n",
    "                \n",
    "                #####################\n",
    "                ### feature sequences\n",
    "                #####################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and load precomputed features into memory as sequences\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    if verbose:\n",
    "                        logging.info(\"Loading features sequence data into memory {}/{}\".format(c+1,len(path_videos)))\n",
    "                    \n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    features = np.load(path_features + video_name + '.npy')\n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(features) + 1):\n",
    "                        x.append(features[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: labels\n",
    "                    # load precomputed labels\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                        \n",
    "            else:\n",
    "\n",
    "                ###################\n",
    "                ### frame sequences\n",
    "                ###################\n",
    "                \n",
    "                # load full frame sequecne dataset into memory and return\n",
    "                if not return_generator:\n",
    "                    \n",
    "                    ##############################################################################\n",
    "                    ### load full sequence dataset into memory (will likely run into memory error)\n",
    "                    ##############################################################################\n",
    "                    \n",
    "                    if verbose:\n",
    "                        logging.info(\"Loading frame sequence data into memory [may take a few minutes]\")\n",
    "\n",
    "                    # load resized numpy array\n",
    "                    path_vid_resized = path_cache + 'frames/'\n",
    "                    path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "                    path_labels = path_cache + 'labels/'\n",
    "\n",
    "                    # read vid paths\n",
    "                    path_videos = get_video_paths()\n",
    "\n",
    "                    # loop over all vids and load full frame sequences into memory \n",
    "                    # (recommend using generator if lots of data to avoid out of memory issues)\n",
    "                    for c, path_video in enumerate(path_videos):\n",
    "                        \n",
    "                        if verbose:\n",
    "                            logging.info(\"Loading frame sequence data into memory {}/{}\".format(c+1,len(path_videos)))\n",
    "\n",
    "                        # get vid name from path\n",
    "                        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "                        ### create sequence: features\n",
    "                        # load precomputed frames\n",
    "                        frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "\n",
    "                        # first apply preprocessing if pretrained model given\n",
    "                        if pretrained_model_name != None:\n",
    "                            frames = self.preprocess_input(frames.astype(np.float32))\n",
    "\n",
    "                        # build sequences\n",
    "                        x = []\n",
    "                        for i in range(sequence_length, len(frames) + 1):\n",
    "                            x.append(frames[i-sequence_length:i])\n",
    "                        x = np.array(x)\n",
    "\n",
    "\n",
    "                        ### create sequence: labels\n",
    "                        # load precomputed labels\n",
    "                        labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                        # temp lists to store sequences\n",
    "                        y = []\n",
    "                        for i in range(sequence_length, len(labels) + 1):\n",
    "                            y.append(labels[i-1])\n",
    "                        y = (np.array(y))\n",
    "\n",
    "                        ### build output\n",
    "                        if self.video_splits[video_name] == \"train\":\n",
    "                            self.x_train.append(x)\n",
    "                            self.y_train.append(y)\n",
    "                        if self.video_splits[video_name] == \"valid\":\n",
    "                            self.x_valid.append(x)\n",
    "                            self.y_valid.append(y)\n",
    "                        if self.video_splits[video_name] == \"test\":\n",
    "                            self.x_test.append(x)\n",
    "                            self.y_test.append(y)\n",
    "                else:\n",
    "                    #############################\n",
    "                    ### Build sequences generator\n",
    "                    #############################\n",
    "            \n",
    "                    # compute and save h5 sequence files (save_frame_sequences_to_h5 returns \n",
    "                    # the sequence sizes which we need for our generator)\n",
    "                    self.total_rows_train, self.total_rows_valid, self.total_rows_test = self.save_frame_sequences_to_h5()\n",
    "                    \n",
    "                    # init generators\n",
    "                    self.generator_train = DataGenerator(self.batch_size, self.path_h5_train, self.total_rows_train)\n",
    "                    self.generator_valid = DataGenerator(self.batch_size, self.path_h5_valid, self.total_rows_valid)\n",
    "                    self.generator_test = DataGenerator(self.batch_size, self.path_h5_test, self.total_rows_test)\n",
    "                \n",
    "        else:\n",
    "\n",
    "            ### not sequence\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Loading features data into memory [may take a few minutes]\")\n",
    "                \n",
    "                ###################\n",
    "                ### feature vectors\n",
    "                ###################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                if not return_CNN_features and pretrained_model_name is not None:\n",
    "                    path_features = path_cache + 'features/' + pretrained_model_name + \"__\" + custom_model_name + \"/\" + pooling + '/'\n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and load precomputed features\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    if verbose:\n",
    "                        logging.info(\"Loading features data into memory: {}/{}\".format(c+1,len(path_videos)))\n",
    "                    \n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### load precomputed features\n",
    "                    x = np.load(path_features + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    if x.shape[0] != y.shape[0]:\n",
    "                        print(\"XXX\", path_video, x.shape, y.shape)\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            else:\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Loading frames into memory [may take a few minutes]\")\n",
    "                \n",
    "                #################\n",
    "                ### single frames\n",
    "                #################\n",
    "                \n",
    "                # load resized numpy array\n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and load frames into memory\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    if verbose:\n",
    "                        logging.info(\"Loading frames into memory: {}/{}\".format(c+1,len(path_videos)))\n",
    "                    \n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    # load precomputed numpy arrays for frames and labels\n",
    "                    x = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    # apply preprocessing if pretrained model given\n",
    "                    if pretrained_model_name != None:\n",
    "                        x = self.preprocess_input(x.astype(np.float32))\n",
    "                \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            \n",
    "            \n",
    "        #################################\n",
    "        ### get file paths for each split\n",
    "        #################################\n",
    "        #\n",
    "        # Note: only makes sense for sequence_length = 1\n",
    "        \n",
    "        # get file paths: train\n",
    "        dflab = self.labels[self.labels['split'] == 'train']\n",
    "        self.paths_train = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: valid\n",
    "        dflab = self.labels[self.labels['split'] == 'valid']\n",
    "        self.paths_valid = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "\n",
    "        # get file paths: test\n",
    "        dflab = self.labels[self.labels['split'] == 'test']\n",
    "        self.paths_test = list(path_data + dflab['video'] + \"/\" + dflab['frame'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        ### reshape list outputs (if not using generator)\n",
    "        #################################################\n",
    "        \n",
    "        if not return_generator:\n",
    "            ## e.g. (9846, 224, 224, 3) for frames [return_CNN_features=True]\n",
    "            ## or  (9846, 512) for features [return_CNN_features=False]\n",
    "            self.x_train = np.concatenate(self.x_train, axis=0)\n",
    "            self.y_train = np.concatenate(self.y_train, axis=0)\n",
    "            self.x_valid = np.concatenate(self.x_valid, axis=0)\n",
    "            self.y_valid = np.concatenate(self.y_valid, axis=0)\n",
    "            self.x_test = np.concatenate(self.x_test, axis=0)\n",
    "            self.y_test = np.concatenate(self.y_test, axis=0)\n",
    "            \n",
    "            # shuffle train and validation set\n",
    "            self.shuffle()\n",
    "            \n",
    "\n",
    "    def __str__(self):\n",
    "        return \"x_train: {}, y_train: {} ... x_valid: {}, y_valid: {} ... x_test: {}, y_test: {}\".format(self.x_train.shape,self.y_train.shape,self.x_valid.shape,self.y_valid.shape,self.x_test.shape,self.y_test.shape)\n",
    "            \n",
    "    def shuffle(self):\n",
    "        \"\"\"\n",
    "        Randomize the order of samples in train and valid splits\n",
    "        \"\"\"\n",
    "        ###########\n",
    "        ### shuffle\n",
    "        ###########\n",
    "        print(self.x_train.shape, self.y_train.shape, len(self.paths_train))\n",
    "        if self.sequence_length == 1:\n",
    "            self.x_train, self.y_train, self.paths_train = shuffle(self.x_train, self.y_train, self.paths_train)\n",
    "            self.x_valid, self.y_valid, self.paths_valid = shuffle(self.x_valid, self.y_valid, self.paths_valid)\n",
    "        else:\n",
    "            self.x_train, self.y_train = shuffle(self.x_train, self.y_train)\n",
    "            self.x_valid, self.y_valid = shuffle(self.x_valid, self.y_valid)\n",
    "\n",
    "        \n",
    "\n",
    "    # Even at small sequence lengths, loading the full dataset as \n",
    "    # a sequence into memory is not feasible so we need to use generators\n",
    "    # that iterate over the dataset without loading it all into memory\n",
    "    # \n",
    "    # For now, we will assume that we will load the features datasets into memory\n",
    "    # because this is more feasible but for large datasets, we'd want to use generators for that too. \n",
    "    # An implementation for a feature generator  can be done by pattern matching the implementation for frames \n",
    "    # \n",
    "    # we first precompute a sequences h5 file (it's too big to fit in memory but we never have more than 1\n",
    "    # video's sequences in memory) ...then we will initialize a generator that samples sequences from the \n",
    "    # h5 file and returns batches that will be passed to our model's fit_generator method\n",
    "\n",
    "    def save_frame_sequences_to_h5(self):\n",
    "        \"\"\"\n",
    "        Save sequence of frames to h5 files (1 for each split) in cache \n",
    "        because dataset too big to load into memory\n",
    "        \n",
    "        Will create generator that reads random rows from these h5 files\n",
    "        \n",
    "        Inspired by: https://stackoverflow.com/questions/41849649/write-to-hdf5-and-shuffle-big-arrays-of-data\n",
    "        \"\"\"\n",
    "    \n",
    "        #######################\n",
    "        ### setup h5 file paths\n",
    "        #######################\n",
    "        \n",
    "        if not os.path.exists(path_cache + 'sequences/'):\n",
    "            os.makedirs(path_cache + 'sequences/')\n",
    "\n",
    "        path_h5_base = path_cache + 'sequences/'\n",
    "\n",
    "        # store h5 files in subfolder in cache/sequences/ either with pretrained model name or resize name\n",
    "        # since we need to run preprocessing for pretrained models but not for vanilla resizing (3DCNN)\n",
    "        if pretrained_model_name is not None:\n",
    "            path_h5_base += pretrained_model_name + '/'\n",
    "        else:\n",
    "            path_h5_base += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "        if not os.path.exists(path_h5_base):\n",
    "            os.makedirs(path_h5_base)\n",
    "\n",
    "        self.path_h5_train = path_h5_base + 'h5_' + str(self.sequence_length) + '_train.h5'\n",
    "        self.path_h5_valid = path_h5_base + 'h5_' + str(self.sequence_length) + '_valid.h5'\n",
    "        self.path_h5_test = path_h5_base + 'h5_' + str(self.sequence_length) + '_test.h5'\n",
    "    \n",
    "        # build h5 file if doesn't exists()\n",
    "        if not os.path.exists(self.path_h5_train) or not os.path.exists(self.path_h5_valid) or not os.path.exists(self.path_h5_test) or not os.path.exists(path_h5_base + 'h5_meta.json'):\n",
    "            \n",
    "            # delete partially created cache\n",
    "            paths_to_clear = [self.path_h5_train, self.path_h5_valid, self.path_h5_test, path_h5_base + 'h5_meta.json']\n",
    "            for path_to_clear in paths_to_clear:                \n",
    "                if os.path.exists(path_to_clear):\n",
    "                    print(\"Removing partially created sequences cache file: {}\".format(path_to_clear))\n",
    "                    os.remove(path_to_clear)\n",
    "             \n",
    "            if verbose:\n",
    "                logging.info(\"Computing frame sequence h5 files: {} [may take a few minutes]\".format(path_h5_base))\n",
    "\n",
    "            ##################################################\n",
    "            ### get size of train/valid/test sequence datasets\n",
    "            ##################################################\n",
    "\n",
    "            # total number of rows of sequence data we have for each split\n",
    "            # this is not the same as the number of frames since we exclude\n",
    "            # the first (self.sequence_length-1) frames\n",
    "            total_rows_train = 0\n",
    "            total_rows_valid = 0\n",
    "            total_rows_test = 0\n",
    "\n",
    "            # load resized numpy array\n",
    "            path_vid_resized = path_cache + 'frames/'\n",
    "            path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "            path_labels = path_cache + 'labels/'\n",
    "\n",
    "            # read vid paths\n",
    "            path_videos = get_video_paths()\n",
    "\n",
    "            # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "            for c, path_video in enumerate(path_videos):\n",
    "                                \n",
    "                if verbose:\n",
    "                    logging.info(\"Computing frame sequence h5 files: {}/{} [precompute]\".format(c+1,len(path_videos)))\n",
    "\n",
    "                # get vid name from path\n",
    "                video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "                # load resized frames\n",
    "                frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "\n",
    "                # build sequences\n",
    "                x = []\n",
    "                for i in range(self.sequence_length, len(frames) + 1):\n",
    "                    x.append(frames[i-self.sequence_length:i])\n",
    "                x = np.array(x)\n",
    "\n",
    "                if self.video_splits[video_name] == \"train\":\n",
    "                    total_rows_train += len(x)\n",
    "                if self.video_splits[video_name] == \"valid\":\n",
    "                    total_rows_valid += len(x)\n",
    "                if self.video_splits[video_name] == \"test\":\n",
    "                    total_rows_test += len(x)\n",
    "\n",
    "            # calc shapes required for full sequence dataset\n",
    "            h5_shape_train_x = (total_rows_train, self.sequence_length, self.frame_size[0], self.frame_size[1], 3)\n",
    "            h5_shape_train_y = (total_rows_train, self.num_classes)\n",
    "\n",
    "            h5_shape_valid_x = (total_rows_valid, self.sequence_length, self.frame_size[0], self.frame_size[1], 3)\n",
    "            h5_shape_valid_y = (total_rows_valid, self.num_classes)\n",
    "\n",
    "            h5_shape_test_x = (total_rows_test, self.sequence_length, self.frame_size[0], self.frame_size[1], 3)\n",
    "            h5_shape_test_y = (total_rows_test, self.num_classes)\n",
    "\n",
    "\n",
    "            ################################\n",
    "            ### Initialize and open h5 files\n",
    "            ################################\n",
    "\n",
    "            # open h5 file to store big sequence dataset feature and label arrays\n",
    "            # path_h5file = MODEL -> SEQUENCE LENGTH\n",
    "            f_train = h5py.File(self.path_h5_train, 'a')\n",
    "            f_valid = h5py.File(self.path_h5_valid, 'a')\n",
    "            f_test = h5py.File(self.path_h5_test, 'a')\n",
    "\n",
    "            # initialize h5 datasets\n",
    "            h5_train_x = f_train.create_dataset('sequences', shape= h5_shape_train_x, dtype='uint8')\n",
    "            h5_train_y = f_train.create_dataset('labels', shape= h5_shape_train_y, dtype='uint8')\n",
    "\n",
    "            h5_valid_x = f_valid.create_dataset('sequences', shape= h5_shape_valid_x, dtype='uint8')\n",
    "            h5_valid_y = f_valid.create_dataset('labels', shape= h5_shape_valid_y, dtype='uint8')\n",
    "\n",
    "            h5_test_x = f_test.create_dataset('sequences', shape= h5_shape_test_x, dtype='uint8')\n",
    "            h5_test_y = f_test.create_dataset('labels', shape= h5_shape_test_y, dtype='uint8')\n",
    "\n",
    "            ##################################################\n",
    "            ### Build h5 files for this sequence / model combo\n",
    "            ##################################################\n",
    "\n",
    "            # load resized numpy array\n",
    "            path_vid_resized = path_cache + 'frames/'\n",
    "            path_vid_resized += str(self.frame_size[0]) + \"_\" + str(self.frame_size[1]) + '/' \n",
    "\n",
    "            path_labels = path_cache + 'labels/'\n",
    "\n",
    "            # read vid paths\n",
    "            path_videos = get_video_paths()\n",
    "\n",
    "            # keep track of where we are in the h5 file\n",
    "            h5_cursor_train = 0\n",
    "            h5_cursor_valid = 0\n",
    "            h5_cursor_test = 0\n",
    "\n",
    "            # loop over all vids and build sequences file\n",
    "            for c, path_video in enumerate(path_videos):\n",
    "                \n",
    "                if verbose:\n",
    "                    logging.info(\"Computing frame sequence h5 files: {}/{} [build h5 file]\".format(c+1,len(path_videos)))\n",
    "\n",
    "                # get vid name from path\n",
    "                video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "                ### create sequence: features\n",
    "                # load precomputed frames\n",
    "                frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                \n",
    "                # first apply preprocessing if pretrained model given\n",
    "                if pretrained_model_name != None:\n",
    "                    frames = self.preprocess_input(frames.astype(np.float32))\n",
    "                    \n",
    "                # build sequences\n",
    "                x = []\n",
    "                for i in range(self.sequence_length, len(frames) + 1):\n",
    "                    x.append(frames[i-self.sequence_length:i])\n",
    "                x = np.array(x)\n",
    "\n",
    "                ### create sequence: labels\n",
    "                # load precomputed labels\n",
    "                labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                # temp lists to store sequences\n",
    "                y = []\n",
    "                for i in range(self.sequence_length, len(labels) + 1):\n",
    "                    y.append(labels[i-1])\n",
    "                y = (np.array(y))\n",
    "\n",
    "                ### write this vid's data to relevant h5 dataset\n",
    "                if self.video_splits[video_name] == \"train\":\n",
    "                    h5_train_x[h5_cursor_train:h5_cursor_train + x.shape[0], :, :, :, :] = x\n",
    "                    h5_train_y[h5_cursor_train:h5_cursor_train + y.shape[0], :] = y\n",
    "                    h5_cursor_train += len(x)\n",
    "                if self.video_splits[video_name] == \"valid\":\n",
    "                    h5_valid_x[h5_cursor_valid:h5_cursor_valid + x.shape[0], :, :, :, :] = x\n",
    "                    h5_valid_y[h5_cursor_valid:h5_cursor_valid + y.shape[0], :] = y\n",
    "                    h5_cursor_valid += len(x)\n",
    "                if self.video_splits[video_name] == \"test\":\n",
    "                    h5_test_x[h5_cursor_test:h5_cursor_test + x.shape[0], :, :, :, :] = x\n",
    "                    h5_test_y[h5_cursor_test:h5_cursor_test + y.shape[0], :] = y\n",
    "                    h5_cursor_test += len(x)\n",
    "            \n",
    "            # save total row counts to file\n",
    "            with open(path_h5_base + 'h5_meta.json', 'w') as fp:\n",
    "                json.dump({'total_rows_train':total_rows_train,\n",
    "                           'total_rows_valid': total_rows_valid,\n",
    "                           'total_rows_test':total_rows_test}\n",
    "                          , fp)\n",
    "                    \n",
    "            # close h5 files\n",
    "            f_train.close()\n",
    "            f_valid.close()\n",
    "            f_test.close()\n",
    "        \n",
    "            # return total samples for each split so we can pass them to our DataGenerator\n",
    "            return total_rows_train, total_rows_valid, total_rows_test\n",
    "        \n",
    "        else:\n",
    "            # h5 sequence file already exists - just load the sequence meta and return sequence lengths \n",
    "            # so we can pass them to our DataGenerator\n",
    "            total_rows_train, total_rows_valid, total_rows_test = None, None, None\n",
    "            \n",
    "            with open(path_h5_base + 'h5_meta.json', 'r') as fp:\n",
    "                h5_meta = json.load(fp)\n",
    "                total_rows_train = h5_meta['total_rows_train']\n",
    "                total_rows_valid = h5_meta['total_rows_valid']\n",
    "                total_rows_test = h5_meta['total_rows_test']\n",
    "                \n",
    "            # return total samples for each split so we can pass them to our DataGenerator\n",
    "            return total_rows_train, total_rows_valid, total_rows_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T15:46:23.349489Z",
     "start_time": "2019-01-14T15:46:23.345971Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.models import Architecture\n",
    "from deepvideoclassification.models import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T15:46:23.545803Z",
     "start_time": "2019-01-14T15:46:23.542142Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_name = \"vgg16\"\n",
    "pooling=\"max\"\n",
    "sequence_length = 3\n",
    "\n",
    "layer_1_size = 128\n",
    "layer_2_size = 64\n",
    "layer_3_size = 32\n",
    "dropout=0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train with no generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:53:43.917880Z",
     "start_time": "2019-01-11T16:52:42.619542Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling)\n",
    "\n",
    "num_classes = data.num_classes \n",
    "frame_size = data.frame_size\n",
    "num_features = pretrained_model_len_features[pretrained_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:57:00.634326Z",
     "start_time": "2019-01-11T16:56:59.407512Z"
    }
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(architecture=\"video_LRCNN_trainable\", \n",
    "                            sequence_model = 'LSTM',\n",
    "                            sequence_model_layers = 1,\n",
    "                            sequence_length = sequence_length,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name='vgg16', \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=8, \n",
    "                            dropout=0.2,\n",
    "                            convolution_kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T17:13:25.237102Z",
     "start_time": "2019-01-11T16:57:02.331628Z"
    }
   },
   "outputs": [],
   "source": [
    "# train model with no data generator\n",
    "train(architecture.model, data, path_model = pwd+'models/', learning_rate = 0.001, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:51.526416Z",
     "start_time": "2019-01-14T22:37:59.607Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = Data(sequence_length = sequence_length, \n",
    "            return_CNN_features = False, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling,\n",
    "            batch_size=32,\n",
    "            return_generator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:51.528947Z",
     "start_time": "2019-01-14T22:38:00.306Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:51.530512Z",
     "start_time": "2019-01-14T22:38:00.931Z"
    }
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(architecture=\"video_LRCNN_trainable\", \n",
    "                            sequence_model = 'LSTM',\n",
    "                            sequence_model_layers = 1,\n",
    "                            sequence_length = sequence_length,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name='vgg16', \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=8, \n",
    "                            dropout=0.2,\n",
    "                            convolution_kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:51.531729Z",
     "start_time": "2019-01-14T22:38:01.541Z"
    }
   },
   "outputs": [],
   "source": [
    "# create optimizer with given learning rate \n",
    "opt = Adam()\n",
    "\n",
    "# compile model\n",
    "architecture.model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:51.533400Z",
     "start_time": "2019-01-14T22:38:03.082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train model on dataset\n",
    "architecture.model.fit_generator(generator=data.generator_train,\n",
    "                    validation_data=data.generator_valid,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train features model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T17:26:34.153407Z",
     "start_time": "2019-01-14T16:41:50.460090Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-14 16:41:52,117 [MainThread  ] [INFO ]  Computing pretrained model features for video 1/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:44:06,970 [MainThread  ] [INFO ]  Computing pretrained model features for video 2/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:45:53,712 [MainThread  ] [INFO ]  Computing pretrained model features for video 3/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:48:09,095 [MainThread  ] [INFO ]  Computing pretrained model features for video 4/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:50:24,553 [MainThread  ] [INFO ]  Computing pretrained model features for video 5/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:51:52,066 [MainThread  ] [INFO ]  Computing pretrained model features for video 6/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:52:13,442 [MainThread  ] [INFO ]  Computing pretrained model features for video 7/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:54:15,821 [MainThread  ] [INFO ]  Computing pretrained model features for video 8/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:56:31,185 [MainThread  ] [INFO ]  Computing pretrained model features for video 9/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:58:47,766 [MainThread  ] [INFO ]  Computing pretrained model features for video 10/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 16:59:08,952 [MainThread  ] [INFO ]  Computing pretrained model features for video 11/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:00:51,820 [MainThread  ] [INFO ]  Computing pretrained model features for video 12/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:03:08,737 [MainThread  ] [INFO ]  Computing pretrained model features for video 13/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:05:25,358 [MainThread  ] [INFO ]  Computing pretrained model features for video 14/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:05:47,383 [MainThread  ] [INFO ]  Computing pretrained model features for video 15/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:08:27,510 [MainThread  ] [INFO ]  Computing pretrained model features for video 16/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:10:26,668 [MainThread  ] [INFO ]  Computing pretrained model features for video 17/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:12:35,093 [MainThread  ] [INFO ]  Computing pretrained model features for video 18/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:14:51,386 [MainThread  ] [INFO ]  Computing pretrained model features for video 19/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:15:20,841 [MainThread  ] [INFO ]  Computing pretrained model features for video 20/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:17:37,825 [MainThread  ] [INFO ]  Computing pretrained model features for video 21/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:17:59,537 [MainThread  ] [INFO ]  Computing pretrained model features for video 22/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:20:17,568 [MainThread  ] [INFO ]  Computing pretrained model features for video 23/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:22:34,070 [MainThread  ] [INFO ]  Computing pretrained model features for video 24/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:24:17,235 [MainThread  ] [INFO ]  Computing pretrained model features for video 25/25 using pretrained model: vgg16, pooling: max\n",
      "2019-01-14 17:26:33,781 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-14 17:26:33,784 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-14 17:26:33,788 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-14 17:26:33,792 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-14 17:26:33,796 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-14 17:26:33,800 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-14 17:26:33,803 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-14 17:26:33,806 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-14 17:26:33,810 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-14 17:26:33,814 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-14 17:26:33,819 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-14 17:26:33,821 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-14 17:26:33,827 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-14 17:26:33,834 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-14 17:26:33,842 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-14 17:26:33,844 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-14 17:26:33,852 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-14 17:26:33,859 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-14 17:26:33,866 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-14 17:26:33,874 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-14 17:26:33,877 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-14 17:26:33,884 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-14 17:26:33,887 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-14 17:26:33,894 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-14 17:26:33,902 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-14 17:26:33,908 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n"
     ]
    }
   ],
   "source": [
    "data = Data(sequence_length = 1, \n",
    "            return_CNN_features = True, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T19:05:01.859123Z",
     "start_time": "2019-01-14T19:05:01.747317Z"
    }
   },
   "outputs": [],
   "source": [
    "architecture = Architecture(architecture=\"image_MLP_frozen\", \n",
    "                            sequence_length=1,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name='vgg16', \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=8, \n",
    "                            dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T19:06:30.816910Z",
     "start_time": "2019-01-14T19:05:02.958836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/30\n",
      "60597/60597 [==============================] - 13s 211us/step - loss: 0.2564 - acc: 0.9110 - val_loss: 0.2061 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92624, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/30\n",
      "60597/60597 [==============================] - 12s 205us/step - loss: 0.1719 - acc: 0.9335 - val_loss: 0.2001 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92624 to 0.93417, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/30\n",
      "60597/60597 [==============================] - 13s 212us/step - loss: 0.1516 - acc: 0.9408 - val_loss: 0.1723 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93417 to 0.94260, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/30\n",
      "60597/60597 [==============================] - 12s 203us/step - loss: 0.1416 - acc: 0.9448 - val_loss: 0.1944 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94260\n",
      "Epoch 5/30\n",
      "60597/60597 [==============================] - 12s 204us/step - loss: 0.1356 - acc: 0.9475 - val_loss: 0.1901 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94260\n",
      "Epoch 6/30\n",
      "60597/60597 [==============================] - 12s 206us/step - loss: 0.1305 - acc: 0.9494 - val_loss: 0.1706 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94260 to 0.94366, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/30\n",
      "16032/60597 [======>.......................] - ETA: 8s - loss: 0.1307 - acc: 0.9495"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-0e91ca0f8ea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'models/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/seals/deepvideoclassification/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, path_model, learning_rate, epochs, batch_size, patience, verbose)\u001b[0m\n\u001b[1;32m    794\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m               verbose=verbose)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "fit_history = train(architecture.model, data, path_model = pwd+'models/', learning_rate = 0.001, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T19:06:38.924696Z",
     "start_time": "2019-01-14T19:06:38.911100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 72        \n",
      "=================================================================\n",
      "Total params: 35,248\n",
      "Trainable params: 35,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "architecture.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T15:36:14.955928Z",
     "start_time": "2019-01-15T15:36:14.952169Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_names = ['inception_resnet_v2',\n",
    " 'inception_v3',\n",
    " 'mobilenetv2_1.00_224',\n",
    " 'resnet50',\n",
    " 'vgg16',\n",
    " 'xception']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:24:42.170820Z",
     "start_time": "2019-01-15T15:36:15.517660Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:15,521 [MainThread  ] [INFO ]  Building resized and feature cache\n",
      "2019-01-15 15:36:15,522 [MainThread  ] [INFO ]  Building resized and feature cache: inception_resnet_v2, max\n",
      "2019-01-15 15:36:16,484 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-15 15:36:16,486 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:16,488 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:16,701 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:16,741 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:16,794 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:16,882 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:16,939 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:16,955 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:17,032 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:17,119 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:17,208 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:17,221 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:17,287 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:17,375 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:17,462 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:17,482 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:17,565 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:17,642 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:17,724 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:17,812 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:17,831 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:17,919 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:17,933 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:18,021 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:18,108 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:18,175 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 1536) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:18,797 [MainThread  ] [INFO ]  Building resized and feature cache: inception_resnet_v2, avg\n",
      "2019-01-15 15:36:19,744 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/avg/\n",
      "2019-01-15 15:36:19,745 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:19,748 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:19,804 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:19,829 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:19,917 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:20,005 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:20,060 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:20,074 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:20,154 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:20,242 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:20,330 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:20,343 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:20,409 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:20,497 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:20,584 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:20,598 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:20,686 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:20,763 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:20,847 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:20,934 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:20,953 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:21,040 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:21,054 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:21,142 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:21,231 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:21,297 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 1536) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:21,880 [MainThread  ] [INFO ]  Building resized and feature cache: inception_v3, max\n",
      "2019-01-15 15:36:22,834 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_v3/max/\n",
      "2019-01-15 15:36:22,835 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:22,837 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:22,899 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:22,972 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:23,089 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:23,206 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:23,281 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:23,299 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:23,404 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:23,523 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:23,640 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:23,658 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:23,746 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:23,863 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:23,980 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:23,998 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:24,116 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:24,218 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:24,329 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:24,446 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:24,470 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:24,589 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:24,606 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:24,724 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:24,842 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:24,929 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 2048) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:25,735 [MainThread  ] [INFO ]  Building resized and feature cache: inception_v3, avg\n",
      "2019-01-15 15:36:26,687 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_v3/avg/\n",
      "2019-01-15 15:36:26,688 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:26,689 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:26,750 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:26,822 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:26,945 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:27,063 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:27,138 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:27,155 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:27,261 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:27,378 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:27,496 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:27,513 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:27,602 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:27,719 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:27,836 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:27,854 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:27,972 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:28,074 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:28,184 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:28,302 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:28,327 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:28,444 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:28,462 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:28,580 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:28,698 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:28,786 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 2048) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:29,623 [MainThread  ] [INFO ]  Building resized and feature cache: resnet50, max\n",
      "2019-01-15 15:36:30,597 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/max/\n",
      "2019-01-15 15:36:30,598 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:30,600 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:30,660 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:30,732 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:30,850 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:30,967 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:31,041 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:31,074 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:31,166 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:31,283 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:31,400 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:31,418 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:31,507 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:31,624 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:31,740 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:31,758 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:31,877 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:31,978 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:32,089 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:32,207 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:32,231 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:32,348 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:32,367 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:32,485 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:32,602 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:32,691 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 2048) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:33,508 [MainThread  ] [INFO ]  Building resized and feature cache: resnet50, avg\n",
      "2019-01-15 15:36:34,467 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/resnet50/avg/\n",
      "2019-01-15 15:36:34,469 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:34,470 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:34,532 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:34,604 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:34,720 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:34,838 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:34,913 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:34,931 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:35,036 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:35,154 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:35,271 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:35,289 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:35,377 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:35,494 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:35,612 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:35,629 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:35,747 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:35,849 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:35,961 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:36,078 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:36,103 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:36,219 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:36,238 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:36,356 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:36,473 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:36,561 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 2048) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:37,362 [MainThread  ] [INFO ]  Building resized and feature cache: vgg16, max\n",
      "2019-01-15 15:36:38,321 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/max/\n",
      "2019-01-15 15:36:38,322 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:38,324 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:38,365 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:38,378 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:38,394 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:38,410 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:38,422 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:38,427 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:38,443 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:38,460 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:38,478 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:38,485 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:38,504 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:38,534 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:38,563 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:38,569 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:38,596 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:38,622 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:38,651 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:38,679 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:38,687 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:38,715 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:38,720 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:38,749 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:38,779 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:38,801 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n",
      "2019-01-15 15:36:39,103 [MainThread  ] [INFO ]  Building resized and feature cache: vgg16, avg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:40,070 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-15 15:36:40,072 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:40,073 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:40,094 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:40,107 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:40,123 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:40,137 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:40,148 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:40,156 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:40,184 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:40,201 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:40,219 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:40,226 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:40,240 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:40,269 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:40,299 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:40,305 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:40,332 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:40,359 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:40,387 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:40,415 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:40,424 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:40,450 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:40,457 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:40,485 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:40,514 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:40,536 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n",
      "2019-01-15 15:36:40,804 [MainThread  ] [INFO ]  Building resized and feature cache: xception, max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:41,757 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/xception/max/\n",
      "2019-01-15 15:36:41,758 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:41,760 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:41,822 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:41,892 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:42,009 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:42,127 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:42,202 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:42,220 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:42,326 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:42,443 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:42,560 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:42,578 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:42,667 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:42,784 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:42,901 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:42,919 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:43,036 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:43,138 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:43,249 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:43,366 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:43,392 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:43,509 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:43,527 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:43,645 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:43,761 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:43,851 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 2048) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:44,603 [MainThread  ] [INFO ]  Building resized and feature cache: xception, avg\n",
      "2019-01-15 15:36:45,557 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/xception/avg/\n",
      "2019-01-15 15:36:45,558 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 15:36:45,560 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 15:36:45,625 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 15:36:45,693 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 15:36:45,809 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 15:36:45,927 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 15:36:46,002 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 15:36:46,020 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 15:36:46,125 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 15:36:46,243 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 15:36:46,360 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 15:36:46,379 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 15:36:46,467 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 15:36:46,583 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 15:36:46,701 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 15:36:46,719 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 15:36:46,836 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 15:36:46,938 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 15:36:47,050 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 15:36:47,166 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 15:36:47,192 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 15:36:47,309 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 15:36:47,327 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 15:36:47,444 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 15:36:47,562 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 15:36:47,651 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 2048) (60597, 8) 60597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:36:48,437 [MainThread  ] [INFO ]  Building h5 cache\n",
      "2019-01-15 15:36:48,438 [MainThread  ] [INFO ]  Building h5 cache: 2, inception_resnet_v2\n",
      "2019-01-15 15:36:49,483 [MainThread  ] [INFO ]  Building h5 cache: 2, inception_v3\n",
      "2019-01-15 15:36:50,502 [MainThread  ] [INFO ]  Building h5 cache: 2, resnet50\n",
      "2019-01-15 15:36:51,448 [MainThread  ] [INFO ]  Computing frame sequence h5 files: /mnt/seals/cache/sequences/resnet50/ [may take a few minutes]\n",
      "2019-01-15 15:36:51,451 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [precompute]\n",
      "2019-01-15 15:36:52,696 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [precompute]\n",
      "2019-01-15 15:36:53,703 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [precompute]\n",
      "2019-01-15 15:36:54,977 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [precompute]\n",
      "2019-01-15 15:36:56,228 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [precompute]\n",
      "2019-01-15 15:36:57,052 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [precompute]\n",
      "2019-01-15 15:36:57,295 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [precompute]\n",
      "2019-01-15 15:36:58,405 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [precompute]\n",
      "2019-01-15 15:36:59,633 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [precompute]\n",
      "2019-01-15 15:37:00,849 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [precompute]\n",
      "2019-01-15 15:37:01,101 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [precompute]\n",
      "2019-01-15 15:37:01,999 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [precompute]\n",
      "2019-01-15 15:37:03,209 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [precompute]\n",
      "2019-01-15 15:37:04,436 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [precompute]\n",
      "2019-01-15 15:37:04,697 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [precompute]\n",
      "2019-01-15 15:37:05,867 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [precompute]\n",
      "2019-01-15 15:37:06,949 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [precompute]\n",
      "2019-01-15 15:37:08,120 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [precompute]\n",
      "2019-01-15 15:37:09,374 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [precompute]\n",
      "2019-01-15 15:37:09,710 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [precompute]\n",
      "2019-01-15 15:37:10,956 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [precompute]\n",
      "2019-01-15 15:37:11,227 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [precompute]\n",
      "2019-01-15 15:37:12,468 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [precompute]\n",
      "2019-01-15 15:37:13,727 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [precompute]\n",
      "2019-01-15 15:37:14,715 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [precompute]\n",
      "2019-01-15 15:37:15,950 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [build h5 file]\n",
      "2019-01-15 15:37:28,814 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [build h5 file]\n",
      "2019-01-15 15:37:39,054 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [build h5 file]\n",
      "2019-01-15 15:37:52,546 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [build h5 file]\n",
      "2019-01-15 15:38:05,253 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [build h5 file]\n",
      "2019-01-15 15:38:13,566 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [build h5 file]\n",
      "2019-01-15 15:38:15,646 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [build h5 file]\n",
      "2019-01-15 15:38:26,842 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [build h5 file]\n",
      "2019-01-15 15:38:39,261 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [build h5 file]\n",
      "2019-01-15 15:38:52,284 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [build h5 file]\n",
      "2019-01-15 15:38:54,514 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [build h5 file]\n",
      "2019-01-15 15:39:07,664 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [build h5 file]\n",
      "2019-01-15 15:39:20,521 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [build h5 file]\n",
      "2019-01-15 15:39:33,136 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [build h5 file]\n",
      "2019-01-15 15:39:35,270 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [build h5 file]\n",
      "2019-01-15 15:39:48,135 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [build h5 file]\n",
      "2019-01-15 15:40:01,471 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [build h5 file]\n",
      "2019-01-15 15:40:13,316 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [build h5 file]\n",
      "2019-01-15 15:40:25,977 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [build h5 file]\n",
      "2019-01-15 15:40:29,025 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [build h5 file]\n",
      "2019-01-15 15:40:41,695 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [build h5 file]\n",
      "2019-01-15 15:40:45,075 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [build h5 file]\n",
      "2019-01-15 15:40:59,294 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [build h5 file]\n",
      "2019-01-15 15:41:11,709 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [build h5 file]\n",
      "2019-01-15 15:41:21,383 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [build h5 file]\n",
      "2019-01-15 15:41:34,346 [MainThread  ] [INFO ]  Building h5 cache: 2, vgg16\n",
      "2019-01-15 15:41:35,311 [MainThread  ] [INFO ]  Computing frame sequence h5 files: /mnt/seals/cache/sequences/vgg16/ [may take a few minutes]\n",
      "2019-01-15 15:41:35,313 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [precompute]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing partially created sequences cache file: /mnt/seals/cache/sequences/vgg16/h5_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:41:36,577 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [precompute]\n",
      "2019-01-15 15:41:37,641 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [precompute]\n",
      "2019-01-15 15:41:38,926 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [precompute]\n",
      "2019-01-15 15:41:40,264 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [precompute]\n",
      "2019-01-15 15:41:41,096 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [precompute]\n",
      "2019-01-15 15:41:41,324 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [precompute]\n",
      "2019-01-15 15:41:42,412 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [precompute]\n",
      "2019-01-15 15:41:43,620 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [precompute]\n",
      "2019-01-15 15:41:44,820 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [precompute]\n",
      "2019-01-15 15:41:45,080 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [precompute]\n",
      "2019-01-15 15:41:45,957 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [precompute]\n",
      "2019-01-15 15:41:47,568 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [precompute]\n",
      "2019-01-15 15:41:48,851 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [precompute]\n",
      "2019-01-15 15:41:49,135 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [precompute]\n",
      "2019-01-15 15:41:50,332 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [precompute]\n",
      "2019-01-15 15:41:51,493 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [precompute]\n",
      "2019-01-15 15:41:52,710 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [precompute]\n",
      "2019-01-15 15:41:53,996 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [precompute]\n",
      "2019-01-15 15:41:54,351 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [precompute]\n",
      "2019-01-15 15:41:55,525 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [precompute]\n",
      "2019-01-15 15:41:55,790 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [precompute]\n",
      "2019-01-15 15:41:56,947 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [precompute]\n",
      "2019-01-15 15:41:58,180 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [precompute]\n",
      "2019-01-15 15:41:59,193 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [precompute]\n",
      "2019-01-15 15:42:00,433 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [build h5 file]\n",
      "2019-01-15 15:42:13,027 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [build h5 file]\n",
      "2019-01-15 15:42:23,083 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [build h5 file]\n",
      "2019-01-15 15:42:35,773 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [build h5 file]\n",
      "2019-01-15 15:42:48,260 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [build h5 file]\n",
      "2019-01-15 15:42:56,232 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [build h5 file]\n",
      "2019-01-15 15:42:58,351 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [build h5 file]\n",
      "2019-01-15 15:43:09,579 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [build h5 file]\n",
      "2019-01-15 15:43:22,216 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [build h5 file]\n",
      "2019-01-15 15:43:36,433 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [build h5 file]\n",
      "2019-01-15 15:43:38,679 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [build h5 file]\n",
      "2019-01-15 15:43:48,046 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [build h5 file]\n",
      "2019-01-15 15:44:00,651 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [build h5 file]\n",
      "2019-01-15 15:44:13,511 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [build h5 file]\n",
      "2019-01-15 15:44:15,727 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [build h5 file]\n",
      "2019-01-15 15:44:29,556 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [build h5 file]\n",
      "2019-01-15 15:44:40,760 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [build h5 file]\n",
      "2019-01-15 15:44:52,663 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [build h5 file]\n",
      "2019-01-15 15:45:05,400 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [build h5 file]\n",
      "2019-01-15 15:45:08,432 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [build h5 file]\n",
      "2019-01-15 15:45:21,001 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [build h5 file]\n",
      "2019-01-15 15:45:23,252 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [build h5 file]\n",
      "2019-01-15 15:45:38,193 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [build h5 file]\n",
      "2019-01-15 15:45:50,680 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [build h5 file]\n",
      "2019-01-15 15:46:00,376 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [build h5 file]\n",
      "2019-01-15 15:46:13,580 [MainThread  ] [INFO ]  Building h5 cache: 2, xception\n",
      "2019-01-15 15:46:14,545 [MainThread  ] [INFO ]  Computing frame sequence h5 files: /mnt/seals/cache/sequences/xception/ [may take a few minutes]\n",
      "2019-01-15 15:46:14,548 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [precompute]\n",
      "2019-01-15 15:46:16,625 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [precompute]\n",
      "2019-01-15 15:46:18,466 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [precompute]\n",
      "2019-01-15 15:46:20,717 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [precompute]\n",
      "2019-01-15 15:46:22,962 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [precompute]\n",
      "2019-01-15 15:46:24,441 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [precompute]\n",
      "2019-01-15 15:46:24,875 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [precompute]\n",
      "2019-01-15 15:46:26,760 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [precompute]\n",
      "2019-01-15 15:46:29,928 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [precompute]\n",
      "2019-01-15 15:46:32,170 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [precompute]\n",
      "2019-01-15 15:46:32,670 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [precompute]\n",
      "2019-01-15 15:46:34,295 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [precompute]\n",
      "2019-01-15 15:46:36,526 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [precompute]\n",
      "2019-01-15 15:46:38,787 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [precompute]\n",
      "2019-01-15 15:46:39,296 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [precompute]\n",
      "2019-01-15 15:46:41,453 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [precompute]\n",
      "2019-01-15 15:46:43,394 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [precompute]\n",
      "2019-01-15 15:46:45,421 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [precompute]\n",
      "2019-01-15 15:46:47,622 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [precompute]\n",
      "2019-01-15 15:46:48,236 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [precompute]\n",
      "2019-01-15 15:46:50,350 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [precompute]\n",
      "2019-01-15 15:46:50,853 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [precompute]\n",
      "2019-01-15 15:46:53,041 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [precompute]\n",
      "2019-01-15 15:46:55,357 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [precompute]\n",
      "2019-01-15 15:46:57,151 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [precompute]\n",
      "2019-01-15 15:46:59,434 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [build h5 file]\n",
      "2019-01-15 15:47:13,640 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [build h5 file]\n",
      "2019-01-15 15:47:32,188 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [build h5 file]\n",
      "2019-01-15 15:47:48,768 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [build h5 file]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:48:04,207 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [build h5 file]\n",
      "2019-01-15 15:48:13,414 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [build h5 file]\n",
      "2019-01-15 15:48:15,854 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [build h5 file]\n",
      "2019-01-15 15:48:29,132 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [build h5 file]\n",
      "2019-01-15 15:48:46,860 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [build h5 file]\n",
      "2019-01-15 15:49:02,106 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [build h5 file]\n",
      "2019-01-15 15:49:04,866 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [build h5 file]\n",
      "2019-01-15 15:49:15,769 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [build h5 file]\n",
      "2019-01-15 15:49:32,691 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [build h5 file]\n",
      "2019-01-15 15:49:55,525 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [build h5 file]\n",
      "2019-01-15 15:49:58,347 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [build h5 file]\n",
      "2019-01-15 15:50:15,273 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [build h5 file]\n",
      "2019-01-15 15:50:29,961 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [build h5 file]\n",
      "2019-01-15 15:50:43,924 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [build h5 file]\n",
      "2019-01-15 15:51:00,846 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [build h5 file]\n",
      "2019-01-15 15:51:05,451 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [build h5 file]\n",
      "2019-01-15 15:51:18,684 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [build h5 file]\n",
      "2019-01-15 15:51:21,381 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [build h5 file]\n",
      "2019-01-15 15:51:38,479 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [build h5 file]\n",
      "2019-01-15 15:51:53,879 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [build h5 file]\n",
      "2019-01-15 15:52:04,505 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [build h5 file]\n",
      "2019-01-15 15:52:33,458 [MainThread  ] [INFO ]  Building h5 cache: 3, inception_resnet_v2\n",
      "2019-01-15 15:52:35,091 [MainThread  ] [INFO ]  Computing frame sequence h5 files: /mnt/seals/cache/sequences/inception_resnet_v2/ [may take a few minutes]\n",
      "2019-01-15 15:52:35,093 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [precompute]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing partially created sequences cache file: /mnt/seals/cache/sequences/inception_resnet_v2/h5_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 15:52:38,837 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [precompute]\n",
      "2019-01-15 15:52:41,191 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [precompute]\n",
      "2019-01-15 15:52:44,090 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [precompute]\n",
      "2019-01-15 15:52:47,010 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [precompute]\n",
      "2019-01-15 15:52:48,962 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [precompute]\n",
      "2019-01-15 15:52:49,509 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [precompute]\n",
      "2019-01-15 15:52:51,972 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [precompute]\n",
      "2019-01-15 15:52:54,835 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [precompute]\n",
      "2019-01-15 15:52:57,726 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [precompute]\n",
      "2019-01-15 15:52:58,392 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [precompute]\n",
      "2019-01-15 15:53:00,437 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [precompute]\n",
      "2019-01-15 15:53:03,331 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [precompute]\n",
      "2019-01-15 15:53:06,332 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [precompute]\n",
      "2019-01-15 15:53:07,013 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [precompute]\n",
      "2019-01-15 15:53:09,760 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [precompute]\n",
      "2019-01-15 15:53:12,273 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [precompute]\n",
      "2019-01-15 15:53:15,078 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [precompute]\n",
      "2019-01-15 15:53:18,009 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [precompute]\n",
      "2019-01-15 15:53:18,782 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [precompute]\n",
      "2019-01-15 15:53:21,619 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [precompute]\n",
      "2019-01-15 15:53:22,282 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [precompute]\n",
      "2019-01-15 15:53:25,128 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [precompute]\n",
      "2019-01-15 15:53:28,069 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [precompute]\n",
      "2019-01-15 15:53:30,335 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [precompute]\n",
      "2019-01-15 15:53:33,186 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [build h5 file]\n",
      "2019-01-15 15:53:49,838 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [build h5 file]\n",
      "2019-01-15 15:54:12,228 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [build h5 file]\n",
      "2019-01-15 15:54:36,703 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [build h5 file]\n",
      "2019-01-15 15:55:02,646 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [build h5 file]\n",
      "2019-01-15 15:55:25,505 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [build h5 file]\n",
      "2019-01-15 15:55:28,766 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [build h5 file]\n",
      "2019-01-15 15:55:48,623 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [build h5 file]\n",
      "2019-01-15 15:56:19,180 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [build h5 file]\n",
      "2019-01-15 15:56:43,645 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [build h5 file]\n",
      "2019-01-15 15:56:47,713 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [build h5 file]\n",
      "2019-01-15 15:57:01,663 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [build h5 file]\n",
      "2019-01-15 15:57:28,598 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [build h5 file]\n",
      "2019-01-15 15:57:51,800 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [build h5 file]\n",
      "2019-01-15 15:58:05,767 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [build h5 file]\n",
      "2019-01-15 15:58:27,312 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [build h5 file]\n",
      "2019-01-15 15:58:50,838 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [build h5 file]\n",
      "2019-01-15 15:59:11,340 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [build h5 file]\n",
      "2019-01-15 15:59:35,347 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [build h5 file]\n",
      "2019-01-15 15:59:47,249 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [build h5 file]\n",
      "2019-01-15 16:00:08,065 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [build h5 file]\n",
      "2019-01-15 16:00:18,588 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [build h5 file]\n",
      "2019-01-15 16:00:39,120 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [build h5 file]\n",
      "2019-01-15 16:01:05,964 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [build h5 file]\n",
      "2019-01-15 16:01:30,696 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [build h5 file]\n",
      "2019-01-15 16:01:58,446 [MainThread  ] [INFO ]  Building h5 cache: 3, inception_v3\n",
      "2019-01-15 16:02:01,952 [MainThread  ] [INFO ]  Computing frame sequence h5 files: /mnt/seals/cache/sequences/inception_v3/ [may take a few minutes]\n",
      "2019-01-15 16:02:01,956 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [precompute]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing partially created sequences cache file: /mnt/seals/cache/sequences/inception_v3/h5_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 16:02:06,658 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [precompute]\n",
      "2019-01-15 16:02:09,118 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [precompute]\n",
      "2019-01-15 16:02:12,107 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [precompute]\n",
      "2019-01-15 16:02:15,207 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [precompute]\n",
      "2019-01-15 16:02:17,298 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [precompute]\n",
      "2019-01-15 16:02:17,932 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [precompute]\n",
      "2019-01-15 16:02:20,533 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [precompute]\n",
      "2019-01-15 16:02:23,650 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [precompute]\n",
      "2019-01-15 16:02:29,514 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [precompute]\n",
      "2019-01-15 16:02:30,616 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [precompute]\n",
      "2019-01-15 16:02:34,968 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [precompute]\n",
      "2019-01-15 16:02:37,963 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [precompute]\n",
      "2019-01-15 16:02:40,997 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [precompute]\n",
      "2019-01-15 16:02:41,696 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [precompute]\n",
      "2019-01-15 16:02:44,508 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [precompute]\n",
      "2019-01-15 16:02:47,150 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [precompute]\n",
      "2019-01-15 16:02:49,959 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [precompute]\n",
      "2019-01-15 16:02:52,901 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [precompute]\n",
      "2019-01-15 16:02:53,717 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [precompute]\n",
      "2019-01-15 16:02:56,465 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [precompute]\n",
      "2019-01-15 16:02:57,149 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [precompute]\n",
      "2019-01-15 16:02:59,839 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [precompute]\n",
      "2019-01-15 16:03:02,865 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [precompute]\n",
      "2019-01-15 16:03:05,257 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [precompute]\n",
      "2019-01-15 16:03:08,233 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [build h5 file]\n",
      "2019-01-15 16:03:26,692 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [build h5 file]\n",
      "2019-01-15 16:03:39,868 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [build h5 file]\n",
      "2019-01-15 16:03:58,667 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [build h5 file]\n",
      "2019-01-15 16:04:17,986 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [build h5 file]\n",
      "2019-01-15 16:04:33,387 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [build h5 file]\n",
      "2019-01-15 16:04:37,360 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [build h5 file]\n",
      "2019-01-15 16:04:51,238 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [build h5 file]\n",
      "2019-01-15 16:05:09,288 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [build h5 file]\n",
      "2019-01-15 16:05:26,514 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [build h5 file]\n",
      "2019-01-15 16:05:30,942 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [build h5 file]\n",
      "2019-01-15 16:05:44,044 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [build h5 file]\n",
      "2019-01-15 16:05:59,472 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [build h5 file]\n",
      "2019-01-15 16:06:18,461 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [build h5 file]\n",
      "2019-01-15 16:06:23,231 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [build h5 file]\n",
      "2019-01-15 16:06:39,376 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [build h5 file]\n",
      "2019-01-15 16:06:56,941 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [build h5 file]\n",
      "2019-01-15 16:07:16,084 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [build h5 file]\n",
      "2019-01-15 16:07:35,767 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [build h5 file]\n",
      "2019-01-15 16:07:40,095 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [build h5 file]\n",
      "2019-01-15 16:07:58,441 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [build h5 file]\n",
      "2019-01-15 16:08:03,441 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [build h5 file]\n",
      "2019-01-15 16:08:21,954 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [build h5 file]\n",
      "2019-01-15 16:08:40,915 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [build h5 file]\n",
      "2019-01-15 16:08:57,756 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [build h5 file]\n",
      "2019-01-15 16:09:20,980 [MainThread  ] [INFO ]  Building h5 cache: 3, resnet50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing partially created sequences cache file: /mnt/seals/cache/sequences/resnet50/h5_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 16:09:26,310 [MainThread  ] [INFO ]  Computing frame sequence h5 files: /mnt/seals/cache/sequences/resnet50/ [may take a few minutes]\n",
      "2019-01-15 16:09:26,312 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [precompute]\n",
      "2019-01-15 16:09:29,536 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [precompute]\n",
      "2019-01-15 16:09:32,181 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [precompute]\n",
      "2019-01-15 16:09:35,574 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [precompute]\n",
      "2019-01-15 16:09:38,950 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [precompute]\n",
      "2019-01-15 16:09:41,179 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [precompute]\n",
      "2019-01-15 16:09:41,741 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [precompute]\n",
      "2019-01-15 16:09:44,712 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [precompute]\n",
      "2019-01-15 16:09:48,116 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [precompute]\n",
      "2019-01-15 16:09:51,516 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [precompute]\n",
      "2019-01-15 16:09:52,011 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [precompute]\n",
      "2019-01-15 16:09:53,237 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [precompute]\n",
      "2019-01-15 16:09:54,867 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [precompute]\n",
      "2019-01-15 16:09:56,568 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [precompute]\n",
      "2019-01-15 16:09:56,974 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [precompute]\n",
      "2019-01-15 16:09:58,614 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [precompute]\n",
      "2019-01-15 16:10:00,169 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [precompute]\n",
      "2019-01-15 16:10:01,836 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [precompute]\n",
      "2019-01-15 16:10:03,564 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [precompute]\n",
      "2019-01-15 16:10:04,060 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [precompute]\n",
      "2019-01-15 16:10:05,696 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [precompute]\n",
      "2019-01-15 16:10:06,059 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [precompute]\n",
      "2019-01-15 16:10:07,616 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [precompute]\n",
      "2019-01-15 16:10:09,225 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [precompute]\n",
      "2019-01-15 16:10:10,533 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [precompute]\n",
      "2019-01-15 16:10:12,139 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [build h5 file]\n",
      "2019-01-15 16:10:29,913 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [build h5 file]\n",
      "2019-01-15 16:10:45,010 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [build h5 file]\n",
      "2019-01-15 16:11:03,018 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [build h5 file]\n",
      "2019-01-15 16:11:21,060 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [build h5 file]\n",
      "2019-01-15 16:11:37,027 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [build h5 file]\n",
      "2019-01-15 16:11:46,067 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [build h5 file]\n",
      "2019-01-15 16:12:07,640 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [build h5 file]\n",
      "2019-01-15 16:12:26,990 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [build h5 file]\n",
      "2019-01-15 16:12:48,938 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [build h5 file]\n",
      "2019-01-15 16:12:52,083 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [build h5 file]\n",
      "2019-01-15 16:13:05,323 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [build h5 file]\n",
      "2019-01-15 16:13:24,215 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [build h5 file]\n",
      "2019-01-15 16:13:42,742 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [build h5 file]\n",
      "2019-01-15 16:13:45,871 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [build h5 file]\n",
      "2019-01-15 16:14:03,093 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [build h5 file]\n",
      "2019-01-15 16:14:22,611 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [build h5 file]\n",
      "2019-01-15 16:14:38,957 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [build h5 file]\n",
      "2019-01-15 16:14:58,898 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [build h5 file]\n",
      "2019-01-15 16:15:03,019 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [build h5 file]\n",
      "2019-01-15 16:15:21,906 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [build h5 file]\n",
      "2019-01-15 16:15:26,901 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [build h5 file]\n",
      "2019-01-15 16:15:44,309 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [build h5 file]\n",
      "2019-01-15 16:16:02,297 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [build h5 file]\n",
      "2019-01-15 16:16:21,585 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [build h5 file]\n",
      "2019-01-15 16:16:39,533 [MainThread  ] [INFO ]  Building h5 cache: 3, vgg16\n",
      "2019-01-15 16:16:40,541 [MainThread  ] [INFO ]  Building h5 cache: 3, xception\n",
      "2019-01-15 16:16:41,491 [MainThread  ] [INFO ]  Computing frame sequence h5 files: /mnt/seals/cache/sequences/xception/ [may take a few minutes]\n",
      "2019-01-15 16:16:41,493 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [precompute]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing partially created sequences cache file: /mnt/seals/cache/sequences/xception/h5_meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 16:16:44,358 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [precompute]\n",
      "2019-01-15 16:16:46,834 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [precompute]\n",
      "2019-01-15 16:16:49,777 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [precompute]\n",
      "2019-01-15 16:16:52,688 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [precompute]\n",
      "2019-01-15 16:16:54,740 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [precompute]\n",
      "2019-01-15 16:16:55,364 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [precompute]\n",
      "2019-01-15 16:16:57,886 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [precompute]\n",
      "2019-01-15 16:17:00,839 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [precompute]\n",
      "2019-01-15 16:17:03,743 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [precompute]\n",
      "2019-01-15 16:17:04,442 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [precompute]\n",
      "2019-01-15 16:17:06,643 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [precompute]\n",
      "2019-01-15 16:17:09,487 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [precompute]\n",
      "2019-01-15 16:17:12,437 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [precompute]\n",
      "2019-01-15 16:17:13,429 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [precompute]\n",
      "2019-01-15 16:17:16,330 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [precompute]\n",
      "2019-01-15 16:17:19,057 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [precompute]\n",
      "2019-01-15 16:17:21,943 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [precompute]\n",
      "2019-01-15 16:17:25,051 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [precompute]\n",
      "2019-01-15 16:17:25,909 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [precompute]\n",
      "2019-01-15 16:17:28,773 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [precompute]\n",
      "2019-01-15 16:17:29,473 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [precompute]\n",
      "2019-01-15 16:17:32,299 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [precompute]\n",
      "2019-01-15 16:17:35,233 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [precompute]\n",
      "2019-01-15 16:17:37,584 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 25/25 [precompute]\n",
      "2019-01-15 16:17:40,507 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 1/25 [build h5 file]\n",
      "2019-01-15 16:17:57,758 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 2/25 [build h5 file]\n",
      "2019-01-15 16:18:12,116 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 3/25 [build h5 file]\n",
      "2019-01-15 16:18:30,913 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 4/25 [build h5 file]\n",
      "2019-01-15 16:18:51,183 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 5/25 [build h5 file]\n",
      "2019-01-15 16:19:04,565 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 6/25 [build h5 file]\n",
      "2019-01-15 16:19:07,416 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 7/25 [build h5 file]\n",
      "2019-01-15 16:19:21,290 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 8/25 [build h5 file]\n",
      "2019-01-15 16:19:41,144 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 9/25 [build h5 file]\n",
      "2019-01-15 16:20:00,935 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 10/25 [build h5 file]\n",
      "2019-01-15 16:20:05,984 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 11/25 [build h5 file]\n",
      "2019-01-15 16:20:18,701 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 12/25 [build h5 file]\n",
      "2019-01-15 16:20:47,357 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 13/25 [build h5 file]\n",
      "2019-01-15 16:21:14,883 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 14/25 [build h5 file]\n",
      "2019-01-15 16:21:18,228 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 15/25 [build h5 file]\n",
      "2019-01-15 16:21:45,071 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 16/25 [build h5 file]\n",
      "2019-01-15 16:22:00,550 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 17/25 [build h5 file]\n",
      "2019-01-15 16:22:19,972 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 18/25 [build h5 file]\n",
      "2019-01-15 16:22:45,988 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 19/25 [build h5 file]\n",
      "2019-01-15 16:22:53,470 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 20/25 [build h5 file]\n",
      "2019-01-15 16:23:20,037 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 21/25 [build h5 file]\n",
      "2019-01-15 16:23:23,407 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 22/25 [build h5 file]\n",
      "2019-01-15 16:23:50,516 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 23/25 [build h5 file]\n",
      "2019-01-15 16:24:20,552 [MainThread  ] [INFO ]  Computing frame sequence h5 files: 24/25 [build h5 file]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't prepare for writing data (file write failed: time = Tue Jan 15 16:24:42 2019\n, filename = '/mnt/seals/cache/sequences/xception//h5_3train.h5', file descriptor = 114, errno = 28, error message = 'No space left on device', buf = 0x556afaacd79e, total write size = 77802, bytes this sub-write = 77802, bytes actually written = 18446744073709551615, offset = 48608813056)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-2102579c69df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                         \u001b[0mpretrained_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                         \u001b[0mreturn_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                         verbose=True, batch_size=32)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-52a71517ba25>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sequence_length, return_CNN_features, pretrained_model_name, pooling, frame_size, augmentation, oversampling, model_weights_path, custom_model_name, return_generator, batch_size, verbose)\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0;31m# compute and save h5 sequence files (save_frame_sequences_to_h5 returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;31m# the sequence sizes which we need for our generator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_rows_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_rows_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_rows_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_frame_sequences_to_h5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;31m# init generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-52a71517ba25>\u001b[0m in \u001b[0;36msave_frame_sequences_to_h5\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0;31m### write this vid's data to relevant h5 dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                     \u001b[0mh5_train_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh5_cursor_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh5_cursor_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                     \u001b[0mh5_train_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh5_cursor_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh5_cursor_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0mh5_cursor_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.H5PY_H5Dwrite\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't prepare for writing data (file write failed: time = Tue Jan 15 16:24:42 2019\n, filename = '/mnt/seals/cache/sequences/xception//h5_3train.h5', file descriptor = 114, errno = 28, error message = 'No space left on device', buf = 0x556afaacd79e, total write size = 77802, bytes this sub-write = 77802, bytes actually written = 18446744073709551615, offset = 48608813056)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    logger.info(\"Building resized and feature cache\")\n",
    "    # build feature cache in advance by running python3 data.py\n",
    "    for pretrained_model_name in pretrained_model_names:\n",
    "        for pooling in poolings:\n",
    "            logger.info(\"Building resized and feature cache: {}, {}\".format(pretrained_model_name, pooling))\n",
    "            data = Data(sequence_length=1, \n",
    "                        return_CNN_features=True,\n",
    "                        pretrained_model_name = pretrained_model_name,\n",
    "                        pooling=pooling)\n",
    "            \n",
    "\n",
    "    # build h5 cache\n",
    "    logger.info(\"Building h5 cache\")\n",
    "    for sequence_length in [2,3,5,10,20]:\n",
    "        for pretrained_model_name in pretrained_model_names:\n",
    "            logger.info(\"Building h5 cache: {}, {}\".format(sequence_length, pretrained_model_name))\n",
    "            data = Data(sequence_length=sequence_length, \n",
    "                        return_CNN_features=False, \n",
    "                        pretrained_model_name = pretrained_model_name, \n",
    "                        return_generator = True,\n",
    "                        verbose=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train some initial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T22:20:06.526541Z",
     "start_time": "2019-01-15T22:20:06.520389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'mobilenetv2_1.00_224',\n",
       " 'resnet50',\n",
       " 'vgg16',\n",
       " 'xception']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T22:39:45.304368Z",
     "start_time": "2019-01-15T22:39:45.300229Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_model_names = ['vgg16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T08:40:16.421448Z",
     "start_time": "2019-01-15T22:39:45.972857Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 22:39:46,940 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-15 22:39:46,942 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 22:39:46,944 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 22:39:46,981 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 22:39:46,997 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 22:39:47,017 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 22:39:47,044 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 22:39:47,056 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 22:39:47,075 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 22:39:47,092 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 22:39:47,110 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 22:39:47,127 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 22:39:47,145 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 22:39:47,160 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 22:39:47,177 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 22:39:47,196 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 22:39:47,205 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 22:39:47,223 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 22:39:47,238 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 22:39:47,266 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 22:39:47,296 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 22:39:47,307 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 22:39:47,332 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 22:39:47,341 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 22:39:47,365 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 22:39:47,395 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 22:39:47,416 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.1251 - acc: 0.9501 - val_loss: 0.1367 - val_acc: 0.9478\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94777, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.0995 - acc: 0.9597 - val_loss: 0.1418 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94777\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0911 - acc: 0.9630 - val_loss: 0.1588 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94777\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 24s 401us/step - loss: 0.0853 - acc: 0.9654 - val_loss: 0.1501 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94777\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.0811 - acc: 0.9670 - val_loss: 0.1475 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94777 to 0.94899, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0777 - acc: 0.9684 - val_loss: 0.1459 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94899\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0752 - acc: 0.9693 - val_loss: 0.1399 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.94899 to 0.95457, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.0733 - acc: 0.9701 - val_loss: 0.1689 - val_acc: 0.9402\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95457\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0705 - acc: 0.9710 - val_loss: 0.1615 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95457\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 24s 395us/step - loss: 0.0689 - acc: 0.9714 - val_loss: 0.1695 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95457\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0677 - acc: 0.9722 - val_loss: 0.2073 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95457\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.0661 - acc: 0.9726 - val_loss: 0.1722 - val_acc: 0.9345\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95457\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0646 - acc: 0.9732 - val_loss: 0.1793 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95457\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0627 - acc: 0.9740 - val_loss: 0.1820 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95457\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.0627 - acc: 0.9742 - val_loss: 0.1804 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95457\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0607 - acc: 0.9746 - val_loss: 0.1584 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95457\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0604 - acc: 0.9751 - val_loss: 0.1939 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 22:47:34,723 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-15 22:47:34,724 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 22:47:34,727 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 22:47:34,731 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 22:47:34,735 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 22:47:34,740 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 22:47:34,745 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 22:47:34,748 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 22:47:34,751 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 22:47:34,756 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 22:47:34,760 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 22:47:34,765 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 22:47:34,768 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 22:47:34,772 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 22:47:34,777 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 22:47:34,782 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 22:47:34,785 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 22:47:34,790 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 22:47:34,794 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 22:47:34,798 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 22:47:34,803 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 22:47:34,806 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 22:47:34,810 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 22:47:34,813 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 22:47:34,818 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 22:47:34,822 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 22:47:34,826 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.1255 - acc: 0.9498 - val_loss: 0.1419 - val_acc: 0.9502\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95018, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.0988 - acc: 0.9601 - val_loss: 0.1335 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95018\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0898 - acc: 0.9635 - val_loss: 0.1527 - val_acc: 0.9353\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95018\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 24s 395us/step - loss: 0.0853 - acc: 0.9653 - val_loss: 0.1552 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95018\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 24s 395us/step - loss: 0.0798 - acc: 0.9675 - val_loss: 0.1295 - val_acc: 0.9537\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.95018 to 0.95373, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0771 - acc: 0.9684 - val_loss: 0.1453 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95373\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 24s 394us/step - loss: 0.0735 - acc: 0.9699 - val_loss: 0.1650 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95373\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 24s 395us/step - loss: 0.0713 - acc: 0.9704 - val_loss: 0.1459 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95373\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.0693 - acc: 0.9714 - val_loss: 0.1752 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95373\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.0670 - acc: 0.9718 - val_loss: 0.2004 - val_acc: 0.9363\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95373\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 24s 393us/step - loss: 0.0663 - acc: 0.9724 - val_loss: 0.1664 - val_acc: 0.9415\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95373\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.0647 - acc: 0.9732 - val_loss: 0.1419 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95373\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.0635 - acc: 0.9739 - val_loss: 0.1579 - val_acc: 0.9466\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95373\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 24s 394us/step - loss: 0.0615 - acc: 0.9743 - val_loss: 0.1608 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95373\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 24s 395us/step - loss: 0.0605 - acc: 0.9749 - val_loss: 0.1786 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 22:54:32,036 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-15 22:54:32,038 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 22:54:32,040 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 22:54:32,044 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 22:54:32,048 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 22:54:32,052 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 22:54:32,057 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 22:54:32,060 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 22:54:32,063 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 22:54:32,067 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 22:54:32,072 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 22:54:32,076 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 22:54:32,078 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 22:54:32,082 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 22:54:32,087 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 22:54:32,091 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 22:54:32,094 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 22:54:32,098 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 22:54:32,102 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 22:54:32,106 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 22:54:32,110 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 22:54:32,113 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 22:54:32,117 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 22:54:32,120 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 22:54:32,124 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 22:54:32,128 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 22:54:32,132 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.1265 - acc: 0.9495 - val_loss: 0.1634 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92698, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.1000 - acc: 0.9596 - val_loss: 0.1434 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92698 to 0.94253, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 25s 405us/step - loss: 0.0908 - acc: 0.9634 - val_loss: 0.1602 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94253\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0851 - acc: 0.9655 - val_loss: 0.1261 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94253 to 0.95535, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0805 - acc: 0.9676 - val_loss: 0.1389 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95535\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0767 - acc: 0.9686 - val_loss: 0.1405 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95535\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 25s 421us/step - loss: 0.0736 - acc: 0.9696 - val_loss: 0.1496 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95535\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.0715 - acc: 0.9705 - val_loss: 0.1500 - val_acc: 0.9428\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95535\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.0687 - acc: 0.9717 - val_loss: 0.1557 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95535\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0671 - acc: 0.9723 - val_loss: 0.1526 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95535\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0658 - acc: 0.9727 - val_loss: 0.1754 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95535\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0637 - acc: 0.9735 - val_loss: 0.1742 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95535\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0630 - acc: 0.9739 - val_loss: 0.1658 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95535\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0606 - acc: 0.9748 - val_loss: 0.1701 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 23:01:16,531 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-15 23:01:16,533 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 23:01:16,535 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 23:01:16,540 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 23:01:16,545 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 23:01:16,549 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 23:01:16,554 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 23:01:16,557 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 23:01:16,560 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 23:01:16,564 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 23:01:16,569 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 23:01:16,574 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 23:01:16,576 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 23:01:16,580 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 23:01:16,585 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 23:01:16,589 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 23:01:16,592 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 23:01:16,596 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 23:01:16,601 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 23:01:16,606 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 23:01:16,610 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 23:01:16,613 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 23:01:16,617 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 23:01:16,620 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 23:01:16,624 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 23:01:16,629 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 23:01:16,633 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.1281 - acc: 0.9490 - val_loss: 0.1397 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94707, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.1003 - acc: 0.9597 - val_loss: 0.1470 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94707\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0920 - acc: 0.9630 - val_loss: 0.1711 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94707\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0710 - acc: 0.9705 - val_loss: 0.1706 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95075\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.0692 - acc: 0.9711 - val_loss: 0.1721 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95075\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0669 - acc: 0.9719 - val_loss: 0.1479 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95075\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 405us/step - loss: 0.0650 - acc: 0.9731 - val_loss: 0.1533 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95075\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 405us/step - loss: 0.0638 - acc: 0.9734 - val_loss: 0.1730 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95075\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0619 - acc: 0.9743 - val_loss: 0.1992 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95075\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 25s 414us/step - loss: 0.0606 - acc: 0.9747 - val_loss: 0.1801 - val_acc: 0.9398\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95075\n",
      "Epoch 15/40\n",
      "44448/60597 [=====================>........] - ETA: 6s - loss: 0.0592 - acc: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 405us/step - loss: 0.0881 - acc: 0.9643 - val_loss: 0.1240 - val_acc: 0.9537\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95005 to 0.95369, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 405us/step - loss: 0.0829 - acc: 0.9664 - val_loss: 0.1429 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95369\n",
      "Epoch 6/40\n",
      "57184/60597 [===========================>..] - ETA: 1s - loss: 0.0792 - acc: 0.9679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0708 - acc: 0.9707 - val_loss: 0.1608 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95369\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.0690 - acc: 0.9716 - val_loss: 0.1938 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95369\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0670 - acc: 0.9722 - val_loss: 0.1617 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95369\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.0646 - acc: 0.9731 - val_loss: 0.1815 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95369\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.0638 - acc: 0.9735 - val_loss: 0.1770 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95369\n",
      "Epoch 14/40\n",
      "57568/60597 [===========================>..] - ETA: 1s - loss: 0.0617 - acc: 0.9742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.0946 - acc: 0.9627 - val_loss: 0.1401 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94796 to 0.95036, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 24s 401us/step - loss: 0.0881 - acc: 0.9648 - val_loss: 0.1381 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.95036 to 0.95441, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 25s 404us/step - loss: 0.0839 - acc: 0.9664 - val_loss: 0.1603 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95441\n",
      "Epoch 7/40\n",
      " 8480/60597 [===>..........................] - ETA: 20s - loss: 0.0798 - acc: 0.9676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0750 - acc: 0.9698 - val_loss: 0.1713 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95441\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0725 - acc: 0.9704 - val_loss: 0.1634 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95441\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 413us/step - loss: 0.0709 - acc: 0.9710 - val_loss: 0.1897 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95441\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0692 - acc: 0.9716 - val_loss: 0.1542 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95441\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 25s 415us/step - loss: 0.0668 - acc: 0.9724 - val_loss: 0.1724 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95441\n",
      "Epoch 14/40\n",
      "22816/60597 [==========>...................] - ETA: 14s - loss: 0.0651 - acc: 0.9727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 403us/step - loss: 0.0996 - acc: 0.9597 - val_loss: 0.1474 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94765\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 24s 403us/step - loss: 0.0902 - acc: 0.9633 - val_loss: 0.1463 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94765 to 0.94822, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "36704/60597 [=================>............] - ETA: 9s - loss: 0.0842 - acc: 0.9656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 403us/step - loss: 0.0744 - acc: 0.9694 - val_loss: 0.1549 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95414\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.0718 - acc: 0.9705 - val_loss: 0.1479 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95414\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0701 - acc: 0.9711 - val_loss: 0.1685 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95414\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.0687 - acc: 0.9717 - val_loss: 0.1715 - val_acc: 0.9421\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95414\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.0667 - acc: 0.9723 - val_loss: 0.1623 - val_acc: 0.9428\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95414\n",
      "Epoch 12/40\n",
      "41024/60597 [===================>..........] - ETA: 7s - loss: 0.0657 - acc: 0.9727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.0612 - acc: 0.9745 - val_loss: 0.1688 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 23:29:06,986 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-15 23:29:06,988 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 23:29:06,990 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 23:29:06,995 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 23:29:07,000 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 23:29:07,004 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 23:29:07,009 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 23:29:07,012 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 23:29:07,015 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 23:29:07,019 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 23:29:07,024 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 23:29:07,029 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 23:29:07,032 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 23:29:07,036 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 23:29:07,040 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 23:29:07,045 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 23:29:07,047 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 23:29:07,052 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 23:29:07,056 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 23:29:07,060 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 23:29:07,064 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 23:29:07,067 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 23:29:07,072 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 23:29:07,074 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 23:29:07,079 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 23:29:07,083 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 23:29:07,087 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 27s 447us/step - loss: 0.1278 - acc: 0.9490 - val_loss: 0.1503 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93968, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 24s 396us/step - loss: 0.1004 - acc: 0.9599 - val_loss: 0.1595 - val_acc: 0.9320\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93968\n",
      "Epoch 3/40\n",
      " 6784/60597 [==>...........................] - ETA: 20s - loss: 0.0910 - acc: 0.9632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0771 - acc: 0.9687 - val_loss: 0.1638 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94582\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0742 - acc: 0.9697 - val_loss: 0.1531 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94582\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 408us/step - loss: 0.0721 - acc: 0.9701 - val_loss: 0.1560 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94582\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0695 - acc: 0.9712 - val_loss: 0.1490 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94582\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.0677 - acc: 0.9718 - val_loss: 0.1533 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.94582 to 0.94857, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 11/40\n",
      "16000/60597 [======>.......................] - ETA: 16s - loss: 0.0635 - acc: 0.9733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0615 - acc: 0.9741 - val_loss: 0.1800 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.94857\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0603 - acc: 0.9749 - val_loss: 0.1825 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.94857\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0592 - acc: 0.9752 - val_loss: 0.1726 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.94857\n",
      "Epoch 17/40\n",
      "17760/60597 [=======>......................] - ETA: 16s - loss: 0.0550 - acc: 0.9766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0556 - acc: 0.9767 - val_loss: 0.2053 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.94857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 23:38:07,060 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-15 23:38:07,061 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 23:38:07,064 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 23:38:07,068 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 23:38:07,073 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 23:38:07,077 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 23:38:07,081 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 23:38:07,085 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 23:38:07,088 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 23:38:07,092 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 23:38:07,096 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 23:38:07,100 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 23:38:07,102 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 23:38:07,106 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 23:38:07,111 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 23:38:07,115 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 23:38:07,117 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 23:38:07,122 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 23:38:07,126 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 23:38:07,130 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 23:38:07,135 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 23:38:07,137 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 23:38:07,141 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 23:38:07,144 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 23:38:07,148 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 23:38:07,153 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 23:38:07,156 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.1288 - acc: 0.9489 - val_loss: 0.1394 - val_acc: 0.9502\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95022, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.1012 - acc: 0.9593 - val_loss: 0.1444 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95022\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0920 - acc: 0.9629 - val_loss: 0.1378 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95022\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 24s 401us/step - loss: 0.0854 - acc: 0.9654 - val_loss: 0.1300 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95022 to 0.95385, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0806 - acc: 0.9669 - val_loss: 0.1508 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95385\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 24s 395us/step - loss: 0.0773 - acc: 0.9680 - val_loss: 0.1500 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95385\n",
      "Epoch 7/40\n",
      "42336/60597 [===================>..........] - ETA: 6s - loss: 0.0745 - acc: 0.9690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 406us/step - loss: 0.0676 - acc: 0.9717 - val_loss: 0.1720 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95385\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0653 - acc: 0.9727 - val_loss: 0.1544 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95385\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.0633 - acc: 0.9733 - val_loss: 0.1661 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95385\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0625 - acc: 0.9738 - val_loss: 0.1543 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95385\n",
      "Epoch 14/40\n",
      " 4960/60597 [=>............................] - ETA: 21s - loss: 0.0569 - acc: 0.9754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.1025 - acc: 0.9589 - val_loss: 0.1375 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95936\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0920 - acc: 0.9631 - val_loss: 0.1352 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95936\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.0860 - acc: 0.9652 - val_loss: 0.1392 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95936\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 24s 401us/step - loss: 0.0820 - acc: 0.9665 - val_loss: 0.1406 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95936\n",
      "Epoch 6/40\n",
      "28544/60597 [=============>................] - ETA: 12s - loss: 0.0765 - acc: 0.9683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0698 - acc: 0.9710 - val_loss: 0.1403 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95936\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.0679 - acc: 0.9718 - val_loss: 0.1669 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95936\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0655 - acc: 0.9728 - val_loss: 0.1490 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 23:50:08,175 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-15 23:50:08,177 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 23:50:08,180 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 23:50:08,185 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 23:50:08,189 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 23:50:08,193 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 23:50:08,197 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 23:50:08,200 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 23:50:08,203 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 23:50:08,208 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 23:50:08,212 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 23:50:08,216 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 23:50:08,218 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 23:50:08,222 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 23:50:08,226 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 23:50:08,230 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 23:50:08,233 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 23:50:08,237 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 23:50:08,241 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 23:50:08,246 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 23:50:08,250 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 23:50:08,253 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 23:50:08,258 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 23:50:08,261 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 23:50:08,265 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 23:50:08,270 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 23:50:08,273 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.1386 - acc: 0.9458 - val_loss: 0.1590 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93602, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      " 4928/60597 [=>............................] - ETA: 21s - loss: 0.1128 - acc: 0.9556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0875 - acc: 0.9646 - val_loss: 0.1417 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95344\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0824 - acc: 0.9663 - val_loss: 0.1459 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95344\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 24s 401us/step - loss: 0.0790 - acc: 0.9678 - val_loss: 0.1552 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95344\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 24s 399us/step - loss: 0.0756 - acc: 0.9689 - val_loss: 0.1402 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95344\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 24s 403us/step - loss: 0.0731 - acc: 0.9702 - val_loss: 0.1521 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95344\n",
      "Epoch 9/40\n",
      "10656/60597 [====>.........................] - ETA: 18s - loss: 0.0687 - acc: 0.9714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 397us/step - loss: 0.0644 - acc: 0.9733 - val_loss: 0.1673 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-15 23:55:56,423 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-15 23:55:56,425 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-15 23:55:56,427 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-15 23:55:56,432 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-15 23:55:56,436 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-15 23:55:56,440 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-15 23:55:56,444 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-15 23:55:56,447 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-15 23:55:56,450 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-15 23:55:56,453 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-15 23:55:56,458 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-15 23:55:56,462 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-15 23:55:56,464 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-15 23:55:56,468 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-15 23:55:56,472 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-15 23:55:56,477 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-15 23:55:56,479 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-15 23:55:56,483 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-15 23:55:56,487 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-15 23:55:56,491 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-15 23:55:56,495 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-15 23:55:56,497 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-15 23:55:56,502 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-15 23:55:56,504 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-15 23:55:56,509 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-15 23:55:56,513 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-15 23:55:56,517 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.1457 - acc: 0.9442 - val_loss: 0.1713 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93208, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 24s 401us/step - loss: 0.1082 - acc: 0.9574 - val_loss: 0.1336 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93208 to 0.95414, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "51264/60597 [========================>.....] - ETA: 3s - loss: 0.0981 - acc: 0.9614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 398us/step - loss: 0.0818 - acc: 0.9671 - val_loss: 0.1307 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95414\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 25s 406us/step - loss: 0.0799 - acc: 0.9676 - val_loss: 0.1288 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95414\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 24s 401us/step - loss: 0.0764 - acc: 0.9691 - val_loss: 0.1657 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95414\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 24s 400us/step - loss: 0.0739 - acc: 0.9698 - val_loss: 0.1668 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95414\n",
      "Epoch 10/40\n",
      "57088/60597 [===========================>..] - ETA: 1s - loss: 0.0716 - acc: 0.9706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.1009 - acc: 0.9595 - val_loss: 0.1434 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94545\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 25s 405us/step - loss: 0.0910 - acc: 0.9632 - val_loss: 0.1395 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94545 to 0.95219, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.0855 - acc: 0.9649 - val_loss: 0.1586 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95219\n",
      "Epoch 5/40\n",
      "50912/60597 [========================>.....] - ETA: 3s - loss: 0.0806 - acc: 0.9669"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 405us/step - loss: 0.0723 - acc: 0.9704 - val_loss: 0.1580 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95219\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.0695 - acc: 0.9711 - val_loss: 0.1629 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95219\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 24s 402us/step - loss: 0.0688 - acc: 0.9712 - val_loss: 0.1461 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95219\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 24s 404us/step - loss: 0.0664 - acc: 0.9724 - val_loss: 0.1624 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95219\n",
      "Epoch 12/40\n",
      "55712/60597 [==========================>...] - ETA: 1s - loss: 0.0652 - acc: 0.9729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 407us/step - loss: 0.0920 - acc: 0.9629 - val_loss: 0.1570 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94251\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.0855 - acc: 0.9651 - val_loss: 0.1292 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94251 to 0.95164, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0815 - acc: 0.9668 - val_loss: 0.1782 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95164\n",
      "Epoch 6/40\n",
      "40160/60597 [==================>...........] - ETA: 7s - loss: 0.0775 - acc: 0.9682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 407us/step - loss: 0.0702 - acc: 0.9707 - val_loss: 0.1522 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95164\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0676 - acc: 0.9720 - val_loss: 0.1651 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95164\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0668 - acc: 0.9720 - val_loss: 0.1861 - val_acc: 0.9269\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95164\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 408us/step - loss: 0.0647 - acc: 0.9728 - val_loss: 0.1542 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95164\n",
      "Epoch 13/40\n",
      "44896/60597 [=====================>........] - ETA: 6s - loss: 0.0625 - acc: 0.9739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 406us/step - loss: 0.1017 - acc: 0.9595 - val_loss: 0.1450 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94120\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 25s 406us/step - loss: 0.0928 - acc: 0.9626 - val_loss: 0.1377 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94120 to 0.94816, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 25s 407us/step - loss: 0.0858 - acc: 0.9651 - val_loss: 0.1409 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94816 to 0.94849, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60256/60597 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 408us/step - loss: 0.0715 - acc: 0.9705 - val_loss: 0.1397 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95034\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0685 - acc: 0.9714 - val_loss: 0.1542 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95034\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0667 - acc: 0.9723 - val_loss: 0.1637 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95034\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0647 - acc: 0.9732 - val_loss: 0.1680 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95034\n",
      "Epoch 12/40\n",
      "23968/60597 [==========>...................] - ETA: 14s - loss: 0.0638 - acc: 0.9732"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0589 - acc: 0.9755 - val_loss: 0.1813 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 00:22:01,247 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 00:22:01,248 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 00:22:01,250 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 00:22:01,255 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 00:22:01,259 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 00:22:01,263 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 00:22:01,268 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 00:22:01,272 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 00:22:01,274 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 00:22:01,279 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 00:22:01,284 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 00:22:01,289 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 00:22:01,291 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 00:22:01,295 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 00:22:01,300 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 00:22:01,305 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 00:22:01,308 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 00:22:01,313 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 00:22:01,317 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 00:22:01,322 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 00:22:01,326 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 00:22:01,329 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 00:22:01,334 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 00:22:01,336 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 00:22:01,341 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 00:22:01,346 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 00:22:01,350 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 29s 477us/step - loss: 0.1358 - acc: 0.9464 - val_loss: 0.1321 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95379, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.1041 - acc: 0.9584 - val_loss: 0.1491 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95379\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 26s 427us/step - loss: 0.0938 - acc: 0.9622 - val_loss: 0.1226 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.95379 to 0.95443, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.0867 - acc: 0.9648 - val_loss: 0.1437 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95443\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 408us/step - loss: 0.0819 - acc: 0.9666 - val_loss: 0.1556 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95443\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0776 - acc: 0.9678 - val_loss: 0.1632 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95443\n",
      "Epoch 7/40\n",
      "31328/60597 [==============>...............] - ETA: 11s - loss: 0.0752 - acc: 0.9694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0621 - acc: 0.9739 - val_loss: 0.1631 - val_acc: 0.9401\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 00:28:28,963 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 00:28:28,964 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 00:28:28,966 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 00:28:28,971 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 00:28:28,975 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 00:28:28,980 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 00:28:28,984 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 00:28:28,988 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 00:28:28,991 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 00:28:28,995 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 00:28:29,000 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 00:28:29,004 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 00:28:29,007 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 00:28:29,011 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 00:28:29,016 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 00:28:29,021 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 00:28:29,023 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 00:28:29,028 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 00:28:29,032 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 00:28:29,037 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 00:28:29,041 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 00:28:29,044 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 00:28:29,049 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 00:28:29,051 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 00:28:29,056 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 00:28:29,060 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 00:28:29,064 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 29s 479us/step - loss: 0.1381 - acc: 0.9460 - val_loss: 0.1321 - val_acc: 0.9520\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95196, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 27s 439us/step - loss: 0.1050 - acc: 0.9582 - val_loss: 0.1441 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95196\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 25s 406us/step - loss: 0.0947 - acc: 0.9621 - val_loss: 0.1575 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95196\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 25s 408us/step - loss: 0.0882 - acc: 0.9643 - val_loss: 0.1349 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95196\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0838 - acc: 0.9658 - val_loss: 0.1321 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95196\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 26s 427us/step - loss: 0.0792 - acc: 0.9676 - val_loss: 0.1394 - val_acc: 0.9480\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95196\n",
      "Epoch 7/40\n",
      "18976/60597 [========>.....................] - ETA: 17s - loss: 0.0758 - acc: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.0637 - acc: 0.9734 - val_loss: 0.1599 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95238\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.0620 - acc: 0.9741 - val_loss: 0.1567 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95238\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 25s 408us/step - loss: 0.0603 - acc: 0.9748 - val_loss: 0.1728 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95238\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 25s 407us/step - loss: 0.0593 - acc: 0.9752 - val_loss: 0.1752 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95238\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0582 - acc: 0.9758 - val_loss: 0.1746 - val_acc: 0.9421\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95238\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.0572 - acc: 0.9762 - val_loss: 0.1839 - val_acc: 0.9398\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95238\n",
      "Epoch 19/40\n",
      "60597/60597 [==============================] - 25s 407us/step - loss: 0.0563 - acc: 0.9764 - val_loss: 0.1714 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.95238\n",
      "Epoch 20/40\n",
      "45248/60597 [=====================>........] - ETA: 5s - loss: 0.0551 - acc: 0.9769"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0883 - acc: 0.9646 - val_loss: 0.1392 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95340\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 25s 408us/step - loss: 0.0837 - acc: 0.9661 - val_loss: 0.1595 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95340\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0798 - acc: 0.9677 - val_loss: 0.1456 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95340\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0764 - acc: 0.9689 - val_loss: 0.1398 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95340\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 408us/step - loss: 0.0747 - acc: 0.9695 - val_loss: 0.1634 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95340\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 408us/step - loss: 0.0722 - acc: 0.9705 - val_loss: 0.1650 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95340\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0701 - acc: 0.9712 - val_loss: 0.1505 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95340\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0683 - acc: 0.9719 - val_loss: 0.1578 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 00:44:08,809 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 00:44:08,810 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 00:44:08,813 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 00:44:08,818 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 00:44:08,823 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 00:44:08,827 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 00:44:08,832 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 00:44:08,836 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 00:44:08,839 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 00:44:08,843 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 00:44:08,848 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 00:44:08,853 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 407us/step - loss: 0.0752 - acc: 0.9691 - val_loss: 0.1353 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95237\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0736 - acc: 0.9701 - val_loss: 0.1522 - val_acc: 0.9310\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95237\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0714 - acc: 0.9706 - val_loss: 0.1446 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95237\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 414us/step - loss: 0.0685 - acc: 0.9719 - val_loss: 0.1510 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95237\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0674 - acc: 0.9724 - val_loss: 0.1439 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95237\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0656 - acc: 0.9728 - val_loss: 0.1568 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95237\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0642 - acc: 0.9735 - val_loss: 0.1541 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95237\n",
      "Epoch 14/40\n",
      "41024/60597 [===================>..........] - ETA: 7s - loss: 0.0622 - acc: 0.9741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 414us/step - loss: 0.0866 - acc: 0.9649 - val_loss: 0.1404 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94995\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0815 - acc: 0.9671 - val_loss: 0.1579 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94995\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0779 - acc: 0.9681 - val_loss: 0.1441 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94995\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0747 - acc: 0.9692 - val_loss: 0.1469 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94995\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.0726 - acc: 0.9705 - val_loss: 0.1603 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94995\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 409us/step - loss: 0.0706 - acc: 0.9711 - val_loss: 0.1652 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94995\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 415us/step - loss: 0.0692 - acc: 0.9717 - val_loss: 0.1569 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.94995\n",
      "Epoch 11/40\n",
      "47424/60597 [======================>.......] - ETA: 5s - loss: 0.0669 - acc: 0.9721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 414us/step - loss: 0.0868 - acc: 0.9649 - val_loss: 0.1530 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95053\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0818 - acc: 0.9667 - val_loss: 0.1711 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95053\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0779 - acc: 0.9683 - val_loss: 0.1511 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95053\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 25s 414us/step - loss: 0.0743 - acc: 0.9696 - val_loss: 0.1676 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95053\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0729 - acc: 0.9702 - val_loss: 0.1633 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95053\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 410us/step - loss: 0.0694 - acc: 0.9713 - val_loss: 0.1578 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95053\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 414us/step - loss: 0.0675 - acc: 0.9720 - val_loss: 0.1839 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95053\n",
      "Epoch 11/40\n",
      "11552/60597 [====>.........................] - ETA: 19s - loss: 0.0652 - acc: 0.9729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0791 - acc: 0.9678 - val_loss: 0.1440 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95412\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 25s 413us/step - loss: 0.0756 - acc: 0.9690 - val_loss: 0.1421 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95412\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 413us/step - loss: 0.0737 - acc: 0.9701 - val_loss: 0.1492 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95412\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 426us/step - loss: 0.0704 - acc: 0.9710 - val_loss: 0.1357 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95412\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 413us/step - loss: 0.0690 - acc: 0.9716 - val_loss: 0.1756 - val_acc: 0.9421\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95412\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.0670 - acc: 0.9724 - val_loss: 0.1540 - val_acc: 0.9439\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95412\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0655 - acc: 0.9728 - val_loss: 0.1752 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 01:09:46,470 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 01:09:46,472 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 01:09:46,474 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 01:09:46,479 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 01:09:46,484 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 01:09:46,489 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 01:09:46,493 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 01:09:46,497 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 01:09:46,500 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 01:09:46,504 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 01:09:46,509 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 01:09:46,514 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 01:09:46,516 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 01:09:46,520 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 01:09:46,525 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 01:09:46,530 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 01:09:46,532 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 01:09:46,537 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 01:09:46,541 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 01:09:46,545 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 01:09:46,549 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 01:09:46,551 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 01:09:46,556 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 01:09:46,558 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 01:09:46,562 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 01:09:46,566 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 01:09:46,570 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      " 6400/60597 [==>...........................] - ETA: 37s - loss: 0.2188 - acc: 0.9182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0770 - acc: 0.9689 - val_loss: 0.1668 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95457\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 412us/step - loss: 0.0742 - acc: 0.9697 - val_loss: 0.1417 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95457\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 413us/step - loss: 0.0721 - acc: 0.9705 - val_loss: 0.1690 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95457\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.0691 - acc: 0.9713 - val_loss: 0.1720 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95457\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 414us/step - loss: 0.0672 - acc: 0.9725 - val_loss: 0.1430 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95457\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 411us/step - loss: 0.0655 - acc: 0.9727 - val_loss: 0.1557 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95457\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 25s 414us/step - loss: 0.0644 - acc: 0.9732 - val_loss: 0.1769 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95457\n",
      "Epoch 14/40\n",
      "10496/60597 [====>.........................] - ETA: 19s - loss: 0.0597 - acc: 0.9752"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 470us/step - loss: 0.1537 - acc: 0.9409 - val_loss: 0.1495 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93929, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.1138 - acc: 0.9553 - val_loss: 0.1370 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93929 to 0.94525, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.1022 - acc: 0.9592 - val_loss: 0.1287 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94525 to 0.95420, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0952 - acc: 0.9621 - val_loss: 0.1456 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95420\n",
      "Epoch 5/40\n",
      "33888/60597 [===============>..............] - ETA: 10s - loss: 0.0893 - acc: 0.9638"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.0761 - acc: 0.9690 - val_loss: 0.1733 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95420\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0734 - acc: 0.9697 - val_loss: 0.1520 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95420\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0711 - acc: 0.9710 - val_loss: 0.1608 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95420\n",
      "Epoch 12/40\n",
      "27488/60597 [============>.................] - ETA: 12s - loss: 0.0693 - acc: 0.9716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 29s 474us/step - loss: 0.1329 - acc: 0.9476 - val_loss: 0.1390 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94703, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.1033 - acc: 0.9590 - val_loss: 0.1418 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94703 to 0.94765, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0945 - acc: 0.9625 - val_loss: 0.1677 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94765\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.0876 - acc: 0.9649 - val_loss: 0.1618 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94765\n",
      "Epoch 5/40\n",
      "16256/60597 [=======>......................] - ETA: 17s - loss: 0.0829 - acc: 0.9665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 415us/step - loss: 0.0741 - acc: 0.9698 - val_loss: 0.1569 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95336\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0719 - acc: 0.9707 - val_loss: 0.1605 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95336\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.0699 - acc: 0.9717 - val_loss: 0.1462 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95336\n",
      "Epoch 11/40\n",
      "55488/60597 [==========================>...] - ETA: 1s - loss: 0.0677 - acc: 0.9724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 414us/step - loss: 0.0633 - acc: 0.9739 - val_loss: 0.1606 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95336\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 25s 415us/step - loss: 0.0622 - acc: 0.9744 - val_loss: 0.1765 - val_acc: 0.9317\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95336\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0604 - acc: 0.9749 - val_loss: 0.1646 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95336\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0603 - acc: 0.9754 - val_loss: 0.1536 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 418us/step - loss: 0.0867 - acc: 0.9651 - val_loss: 0.1577 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94648\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0828 - acc: 0.9664 - val_loss: 0.1385 - val_acc: 0.9436\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94648\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0786 - acc: 0.9681 - val_loss: 0.1389 - val_acc: 0.9468\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94648 to 0.94675, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "49088/60597 [=======================>......] - ETA: 4s - loss: 0.0759 - acc: 0.9689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0709 - acc: 0.9708 - val_loss: 0.1552 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95018\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0686 - acc: 0.9718 - val_loss: 0.1665 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95018\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0671 - acc: 0.9720 - val_loss: 0.1542 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95018\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0655 - acc: 0.9731 - val_loss: 0.1725 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95018\n",
      "Epoch 13/40\n",
      "41888/60597 [===================>..........] - ETA: 7s - loss: 0.0634 - acc: 0.9741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0589 - acc: 0.9754 - val_loss: 0.1570 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95018\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0580 - acc: 0.9759 - val_loss: 0.1824 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 01:40:17,344 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 01:40:17,345 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 01:40:17,347 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 01:40:17,352 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 01:40:17,356 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 01:40:17,361 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 01:40:17,366 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 01:40:17,370 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 01:40:17,373 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 01:40:17,377 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 01:40:17,382 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 01:40:17,387 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 01:40:17,390 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 01:40:17,395 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 01:40:17,400 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 01:40:17,405 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 01:40:17,407 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 01:40:17,412 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 01:40:17,417 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 01:40:17,421 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 01:40:17,426 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 01:40:17,428 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 01:40:17,433 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 01:40:17,435 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 01:40:17,440 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 01:40:17,445 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 01:40:17,449 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 29s 478us/step - loss: 0.1406 - acc: 0.9446 - val_loss: 0.1732 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93232, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "23648/60597 [==========>...................] - ETA: 14s - loss: 0.1088 - acc: 0.9568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 418us/step - loss: 0.0895 - acc: 0.9641 - val_loss: 0.1603 - val_acc: 0.9351\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.93555\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.0842 - acc: 0.9662 - val_loss: 0.1429 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.93555 to 0.94181, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0807 - acc: 0.9675 - val_loss: 0.1578 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94181\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0768 - acc: 0.9685 - val_loss: 0.1530 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94181\n",
      "Epoch 8/40\n",
      "44800/60597 [=====================>........] - ETA: 6s - loss: 0.0728 - acc: 0.9699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 422us/step - loss: 0.0652 - acc: 0.9731 - val_loss: 0.1614 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95178\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0633 - acc: 0.9738 - val_loss: 0.1803 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95178\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0617 - acc: 0.9746 - val_loss: 0.1518 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95178\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0606 - acc: 0.9750 - val_loss: 0.1703 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95178\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0597 - acc: 0.9753 - val_loss: 0.1774 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95178\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0585 - acc: 0.9759 - val_loss: 0.1856 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95178\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 25s 421us/step - loss: 0.0564 - acc: 0.9765 - val_loss: 0.1802 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 01:48:54,365 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 01:48:54,366 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 01:48:54,369 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 01:48:54,374 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 01:48:54,378 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 01:48:54,383 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 01:48:54,388 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 01:48:54,391 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 01:48:54,394 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 01:48:54,399 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 01:48:54,404 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 01:48:54,409 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 01:48:54,412 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 01:48:54,415 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 01:48:54,420 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 01:48:54,424 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 01:48:54,427 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 01:48:54,431 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 01:48:54,435 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 01:48:54,440 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 01:48:54,444 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 01:48:54,447 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 01:48:54,452 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 01:48:54,454 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 01:48:54,459 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 01:48:54,464 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 01:48:54,467 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "25568/60597 [===========>..................] - ETA: 16s - loss: 0.1659 - acc: 0.9347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0775 - acc: 0.9683 - val_loss: 0.1589 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94749\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 416us/step - loss: 0.0745 - acc: 0.9695 - val_loss: 0.1410 - val_acc: 0.9438\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94749\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0720 - acc: 0.9704 - val_loss: 0.1466 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94749\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0695 - acc: 0.9715 - val_loss: 0.2004 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.94749\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0682 - acc: 0.9720 - val_loss: 0.1904 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.94749\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0663 - acc: 0.9729 - val_loss: 0.1645 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.94749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 01:55:01,800 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 01:55:01,801 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 01:55:01,803 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 01:55:01,809 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 01:55:01,813 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 01:55:01,817 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 01:55:01,822 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 01:55:01,826 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 01:55:01,828 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 01:55:01,833 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 01:55:01,837 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 01:55:01,842 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 01:55:01,845 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 01:55:01,849 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 01:55:01,853 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 01:55:01,858 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 01:55:01,861 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 01:55:01,865 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 01:55:01,869 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 01:55:01,874 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 01:55:01,879 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 01:55:01,881 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 01:55:01,886 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 01:55:01,889 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 01:55:01,894 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 01:55:01,898 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 01:55:01,903 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 29s 477us/step - loss: 0.1503 - acc: 0.9412 - val_loss: 0.1477 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94027, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      " 4096/60597 [=>............................] - ETA: 23s - loss: 0.1228 - acc: 0.9514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 25s 418us/step - loss: 0.0794 - acc: 0.9679 - val_loss: 0.1431 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95338\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0769 - acc: 0.9690 - val_loss: 0.1609 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95338\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0742 - acc: 0.9702 - val_loss: 0.1594 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95338\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0721 - acc: 0.9707 - val_loss: 0.1538 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95338\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 26s 424us/step - loss: 0.0702 - acc: 0.9713 - val_loss: 0.1711 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95338\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0670 - acc: 0.9727 - val_loss: 0.1821 - val_acc: 0.9351\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 02:01:08,999 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 02:01:09,000 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 02:01:09,002 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 02:01:09,007 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 02:01:09,011 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 02:01:09,015 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 02:01:09,020 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 02:01:09,023 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 02:01:09,025 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 02:01:09,029 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 02:01:09,034 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 02:01:09,038 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 02:01:09,041 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 02:01:09,045 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 02:01:09,049 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 02:01:09,054 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 02:01:09,056 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 02:01:09,061 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 02:01:09,065 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 02:01:09,069 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 02:01:09,073 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 02:01:09,075 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 02:01:09,079 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 02:01:09,082 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 02:01:09,086 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 02:01:09,090 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 02:01:09,094 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 29s 480us/step - loss: 0.1628 - acc: 0.9372 - val_loss: 0.1447 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95053, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "29280/60597 [=============>................] - ETA: 12s - loss: 0.1249 - acc: 0.9515"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 423us/step - loss: 0.0816 - acc: 0.9673 - val_loss: 0.1570 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95096\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 424us/step - loss: 0.0789 - acc: 0.9684 - val_loss: 0.1403 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.95096 to 0.95326, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0770 - acc: 0.9690 - val_loss: 0.1690 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95326\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 26s 422us/step - loss: 0.0747 - acc: 0.9699 - val_loss: 0.1533 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95326\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0733 - acc: 0.9705 - val_loss: 0.1808 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95326\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 26s 424us/step - loss: 0.0709 - acc: 0.9711 - val_loss: 0.1867 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95326\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 25s 420us/step - loss: 0.0694 - acc: 0.9720 - val_loss: 0.1692 - val_acc: 0.9438\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95326\n",
      "Epoch 15/40\n",
      "23616/60597 [==========>...................] - ETA: 14s - loss: 0.0683 - acc: 0.9726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 29s 477us/step - loss: 0.1392 - acc: 0.9444 - val_loss: 0.1509 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94029, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 423us/step - loss: 0.1057 - acc: 0.9580 - val_loss: 0.1468 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94029 to 0.94294, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0964 - acc: 0.9616 - val_loss: 0.1496 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94294 to 0.94430, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0911 - acc: 0.9638 - val_loss: 0.1410 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94430 to 0.94765, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 418us/step - loss: 0.0861 - acc: 0.9655 - val_loss: 0.1294 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94765 to 0.95496, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 26s 426us/step - loss: 0.0819 - acc: 0.9673 - val_loss: 0.1547 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95496\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0789 - acc: 0.9684 - val_loss: 0.1466 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95496\n",
      "Epoch 8/40\n",
      "38400/60597 [==================>...........] - ETA: 8s - loss: 0.0767 - acc: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0645 - acc: 0.9737 - val_loss: 0.1802 - val_acc: 0.9313\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95496\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 26s 423us/step - loss: 0.0633 - acc: 0.9738 - val_loss: 0.1568 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 02:17:41,503 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 02:17:41,505 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 02:17:41,507 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 02:17:41,512 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 02:17:41,516 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 02:17:41,521 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 02:17:41,526 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 02:17:41,529 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 02:17:41,532 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 02:17:41,536 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 02:17:41,541 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 02:17:41,546 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 02:17:41,548 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 02:17:41,552 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 02:17:41,557 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 02:17:41,561 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 02:17:41,564 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 02:17:41,568 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 02:17:41,573 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 02:17:41,577 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 02:17:41,582 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 02:17:41,584 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 02:17:41,589 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 02:17:41,592 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 02:17:41,596 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 02:17:41,601 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 02:17:41,605 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 29s 473us/step - loss: 0.1453 - acc: 0.9421 - val_loss: 0.1563 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93931, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 426us/step - loss: 0.1089 - acc: 0.9563 - val_loss: 0.1377 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93931 to 0.94818, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 25s 419us/step - loss: 0.0989 - acc: 0.9608 - val_loss: 0.1366 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94818 to 0.94923, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0922 - acc: 0.9632 - val_loss: 0.1280 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94923 to 0.95124, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 26s 422us/step - loss: 0.0867 - acc: 0.9651 - val_loss: 0.1366 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95124\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 26s 422us/step - loss: 0.0826 - acc: 0.9669 - val_loss: 0.1518 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95124\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 26s 424us/step - loss: 0.0793 - acc: 0.9679 - val_loss: 0.1529 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95124\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 25s 418us/step - loss: 0.0766 - acc: 0.9693 - val_loss: 0.1471 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95124\n",
      "Epoch 9/40\n",
      "24256/60597 [===========>..................] - ETA: 14s - loss: 0.0725 - acc: 0.9710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 31s 517us/step - loss: 0.1451 - acc: 0.9428 - val_loss: 0.1768 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93290, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.1093 - acc: 0.9562 - val_loss: 0.1507 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93290 to 0.94204, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 25s 417us/step - loss: 0.0991 - acc: 0.9602 - val_loss: 0.1351 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94204 to 0.94225, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0916 - acc: 0.9635 - val_loss: 0.1501 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94225\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 26s 426us/step - loss: 0.0865 - acc: 0.9653 - val_loss: 0.1602 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94225\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 28s 463us/step - loss: 0.0826 - acc: 0.9667 - val_loss: 0.1440 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94225 to 0.94307, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "45632/60597 [=====================>........] - ETA: 6s - loss: 0.0786 - acc: 0.9687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0670 - acc: 0.9732 - val_loss: 0.1677 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94527\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 27s 437us/step - loss: 0.0655 - acc: 0.9733 - val_loss: 0.1467 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.94527 to 0.94870, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 27s 447us/step - loss: 0.0644 - acc: 0.9737 - val_loss: 0.1396 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.94870 to 0.95219, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0626 - acc: 0.9746 - val_loss: 0.1706 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95219\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 26s 437us/step - loss: 0.0617 - acc: 0.9748 - val_loss: 0.1852 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95219\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 26s 431us/step - loss: 0.0606 - acc: 0.9753 - val_loss: 0.1562 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95219\n",
      "Epoch 19/40\n",
      "46336/60597 [=====================>........] - ETA: 5s - loss: 0.0589 - acc: 0.9757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 29s 481us/step - loss: 0.0558 - acc: 0.9771 - val_loss: 0.1763 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.95219\n",
      "Epoch 25/40\n",
      "60597/60597 [==============================] - 34s 565us/step - loss: 0.0552 - acc: 0.9774 - val_loss: 0.1695 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.95219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 02:37:03,400 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 02:37:03,401 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 02:37:03,402 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 02:37:03,407 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 02:37:03,411 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 02:37:03,415 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 02:37:03,419 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 02:37:03,422 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 02:37:03,424 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 02:37:03,428 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 02:37:03,433 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 02:37:03,437 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 02:37:03,439 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 02:37:03,443 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 02:37:03,447 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 02:37:03,451 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 02:37:03,454 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 02:37:03,458 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 02:37:03,462 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 02:37:03,467 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 02:37:03,471 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 02:37:03,474 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 02:37:03,480 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 02:37:03,483 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 02:37:03,488 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 02:37:03,492 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 02:37:03,496 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 32s 534us/step - loss: 0.1617 - acc: 0.9373 - val_loss: 0.1536 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94001, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 424us/step - loss: 0.1165 - acc: 0.9547 - val_loss: 0.1394 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94001 to 0.94574, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.1064 - acc: 0.9588 - val_loss: 0.1440 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94574\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 26s 426us/step - loss: 0.0998 - acc: 0.9613 - val_loss: 0.1440 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94574\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 25s 415us/step - loss: 0.0938 - acc: 0.9639 - val_loss: 0.1480 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94574\n",
      "Epoch 6/40\n",
      " 4800/60597 [=>............................] - ETA: 22s - loss: 0.0937 - acc: 0.9634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 436us/step - loss: 0.0772 - acc: 0.9701 - val_loss: 0.1386 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.94808 to 0.94929, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 29s 477us/step - loss: 0.0753 - acc: 0.9709 - val_loss: 0.1589 - val_acc: 0.9384\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.94929\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 29s 474us/step - loss: 0.0740 - acc: 0.9714 - val_loss: 0.1642 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94929\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 27s 448us/step - loss: 0.0727 - acc: 0.9718 - val_loss: 0.1724 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.94929\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0716 - acc: 0.9722 - val_loss: 0.1588 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.94929\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 27s 454us/step - loss: 0.0701 - acc: 0.9731 - val_loss: 0.1466 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.94929\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0689 - acc: 0.9736 - val_loss: 0.1654 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.94929\n",
      "Epoch 18/40\n",
      " 4160/60597 [=>............................] - ETA: 23s - loss: 0.0652 - acc: 0.9754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 432us/step - loss: 0.0633 - acc: 0.9755 - val_loss: 0.1512 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.94956\n",
      "Epoch 24/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.0631 - acc: 0.9755 - val_loss: 0.1781 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.94956\n",
      "Epoch 25/40\n",
      "60597/60597 [==============================] - 26s 422us/step - loss: 0.0628 - acc: 0.9759 - val_loss: 0.1665 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.94956\n",
      "Epoch 26/40\n",
      "60597/60597 [==============================] - 26s 426us/step - loss: 0.0620 - acc: 0.9761 - val_loss: 0.1775 - val_acc: 0.9401\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.94956\n",
      "Epoch 27/40\n",
      "60597/60597 [==============================] - 26s 422us/step - loss: 0.0606 - acc: 0.9765 - val_loss: 0.1695 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.94956\n",
      "Epoch 28/40\n",
      "60597/60597 [==============================] - 30s 498us/step - loss: 0.0600 - acc: 0.9770 - val_loss: 0.1812 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.94956\n",
      "Epoch 29/40\n",
      "60597/60597 [==============================] - 30s 496us/step - loss: 0.0600 - acc: 0.9770 - val_loss: 0.1757 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.94956\n",
      "Epoch 30/40\n",
      "21728/60597 [=========>....................] - ETA: 16s - loss: 0.0588 - acc: 0.9772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 439us/step - loss: 0.0933 - acc: 0.9635 - val_loss: 0.1614 - val_acc: 0.9421\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95100\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0890 - acc: 0.9651 - val_loss: 0.1379 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95100\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0851 - acc: 0.9664 - val_loss: 0.1297 - val_acc: 0.9548\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95100 to 0.95476, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 31s 515us/step - loss: 0.0818 - acc: 0.9673 - val_loss: 0.1387 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95476\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 32s 534us/step - loss: 0.0805 - acc: 0.9677 - val_loss: 0.1460 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95476\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0769 - acc: 0.9693 - val_loss: 0.1447 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95476\n",
      "Epoch 11/40\n",
      "36928/60597 [=================>............] - ETA: 9s - loss: 0.0747 - acc: 0.9702 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 32s 535us/step - loss: 0.0675 - acc: 0.9728 - val_loss: 0.1680 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95716\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 30s 500us/step - loss: 0.0657 - acc: 0.9734 - val_loss: 0.1650 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95716\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 27s 449us/step - loss: 0.0653 - acc: 0.9736 - val_loss: 0.1531 - val_acc: 0.9520\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95716\n",
      "Epoch 19/40\n",
      "60597/60597 [==============================] - 26s 435us/step - loss: 0.0637 - acc: 0.9743 - val_loss: 0.1547 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.95716\n",
      "Epoch 20/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0629 - acc: 0.9745 - val_loss: 0.1661 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.95716\n",
      "Epoch 21/40\n",
      "60597/60597 [==============================] - 26s 431us/step - loss: 0.0614 - acc: 0.9749 - val_loss: 0.1740 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.95716\n",
      "Epoch 22/40\n",
      "17152/60597 [=======>......................] - ETA: 17s - loss: 0.0618 - acc: 0.9749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 446us/step - loss: 0.1010 - acc: 0.9602 - val_loss: 0.1408 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94699 to 0.95404, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 27s 449us/step - loss: 0.0955 - acc: 0.9621 - val_loss: 0.1558 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95404\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 29s 475us/step - loss: 0.0919 - acc: 0.9637 - val_loss: 0.1493 - val_acc: 0.9502\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95404\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0896 - acc: 0.9647 - val_loss: 0.1713 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95404\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0857 - acc: 0.9659 - val_loss: 0.1563 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95404\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 26s 424us/step - loss: 0.0843 - acc: 0.9664 - val_loss: 0.1707 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95404\n",
      "Epoch 11/40\n",
      "56512/60597 [==========================>...] - ETA: 1s - loss: 0.0816 - acc: 0.9677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.1003 - acc: 0.9596 - val_loss: 0.1445 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94167 to 0.94557, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 26s 424us/step - loss: 0.0922 - acc: 0.9624 - val_loss: 0.1436 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94557\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0868 - acc: 0.9646 - val_loss: 0.1514 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94557 to 0.94835, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0825 - acc: 0.9662 - val_loss: 0.1625 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94835\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 26s 422us/step - loss: 0.0794 - acc: 0.9678 - val_loss: 0.1557 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94835\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 26s 421us/step - loss: 0.0760 - acc: 0.9688 - val_loss: 0.1733 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94835\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0749 - acc: 0.9694 - val_loss: 0.1593 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94835\n",
      "Epoch 9/40\n",
      "17120/60597 [=======>......................] - ETA: 17s - loss: 0.0717 - acc: 0.9703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "2019-01-16 03:17:32,801 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 03:17:32,806 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 03:17:32,809 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 03:17:32,814 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 03:17:32,819 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 03:17:32,824 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 29s 479us/step - loss: 0.1267 - acc: 0.9496 - val_loss: 0.1522 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93577, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.1005 - acc: 0.9597 - val_loss: 0.1387 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93577 to 0.95131, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0915 - acc: 0.9629 - val_loss: 0.1427 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95131\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0864 - acc: 0.9645 - val_loss: 0.1534 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95131\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 26s 427us/step - loss: 0.0815 - acc: 0.9668 - val_loss: 0.1365 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.95131 to 0.95219, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 26s 430us/step - loss: 0.0788 - acc: 0.9677 - val_loss: 0.1327 - val_acc: 0.9478\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95219\n",
      "Epoch 7/40\n",
      "40992/60597 [===================>..........] - ETA: 7s - loss: 0.0771 - acc: 0.9684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0659 - acc: 0.9726 - val_loss: 0.1560 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95219\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 26s 428us/step - loss: 0.0644 - acc: 0.9733 - val_loss: 0.1648 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95219\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 26s 427us/step - loss: 0.0637 - acc: 0.9734 - val_loss: 0.1694 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 03:25:03,123 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 03:25:03,125 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 03:25:03,127 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 03:25:03,132 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 03:25:03,137 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 03:25:03,142 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 03:25:03,147 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 03:25:03,150 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 03:25:03,153 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 03:25:03,157 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 03:25:03,162 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 03:25:03,167 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 03:25:03,169 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 03:25:03,173 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 03:25:03,178 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 03:25:03,183 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 03:25:03,185 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 03:25:03,190 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 03:25:03,194 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 03:25:03,199 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 03:25:03,203 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 03:25:03,206 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 03:25:03,210 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 03:25:03,213 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 03:25:03,217 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 03:25:03,222 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 03:25:03,226 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 29s 485us/step - loss: 0.1270 - acc: 0.9491 - val_loss: 0.1238 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95498, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 435us/step - loss: 0.1008 - acc: 0.9595 - val_loss: 0.1460 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95498\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0915 - acc: 0.9630 - val_loss: 0.1374 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95498\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0856 - acc: 0.9653 - val_loss: 0.1486 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95498\n",
      "Epoch 5/40\n",
      " 3872/60597 [>.............................] - ETA: 23s - loss: 0.0809 - acc: 0.9665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 430us/step - loss: 0.0685 - acc: 0.9719 - val_loss: 0.1855 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95498\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 26s 431us/step - loss: 0.0674 - acc: 0.9722 - val_loss: 0.1811 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 03:30:52,254 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 03:30:52,256 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 03:30:52,258 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 03:30:52,264 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 03:30:52,268 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 03:30:52,273 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 03:30:52,277 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 03:30:52,281 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 03:30:52,284 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 03:30:52,289 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 03:30:52,294 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 03:30:52,299 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 03:30:52,301 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 03:30:52,305 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 03:30:52,310 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 03:30:52,315 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 03:30:52,317 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 03:30:52,322 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 03:30:52,326 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 03:30:52,331 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 03:30:52,335 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 03:30:52,338 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 03:30:52,342 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 03:30:52,345 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 03:30:52,351 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 03:30:52,356 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 03:30:52,360 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 29s 486us/step - loss: 0.1299 - acc: 0.9482 - val_loss: 0.1487 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94444, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.1029 - acc: 0.9589 - val_loss: 0.1628 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94444\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 26s 433us/step - loss: 0.0931 - acc: 0.9623 - val_loss: 0.1438 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94444\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 26s 426us/step - loss: 0.0874 - acc: 0.9644 - val_loss: 0.1476 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94444 to 0.94553, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "56576/60597 [===========================>..] - ETA: 1s - loss: 0.0830 - acc: 0.9665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 427us/step - loss: 0.0673 - acc: 0.9722 - val_loss: 0.1564 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95096\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 26s 427us/step - loss: 0.0661 - acc: 0.9727 - val_loss: 0.1536 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95096\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 26s 426us/step - loss: 0.0651 - acc: 0.9728 - val_loss: 0.1585 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95096\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0634 - acc: 0.9733 - val_loss: 0.1837 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95096\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0621 - acc: 0.9737 - val_loss: 0.1936 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95096\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 26s 424us/step - loss: 0.0611 - acc: 0.9746 - val_loss: 0.1877 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95096\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 26s 425us/step - loss: 0.0599 - acc: 0.9746 - val_loss: 0.1704 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 03:39:15,647 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 03:39:15,649 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 03:39:15,651 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 03:39:15,656 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 03:39:15,660 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 03:39:15,665 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 03:39:15,669 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 03:39:15,673 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 03:39:15,676 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 03:39:15,680 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 03:39:15,685 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 03:39:15,689 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 03:39:15,691 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 03:39:15,695 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 03:39:15,700 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 03:39:15,705 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 03:39:15,707 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 03:39:15,712 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 03:39:15,716 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 03:39:15,720 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 03:39:15,725 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 03:39:15,727 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 03:39:15,732 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 03:39:15,735 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 03:39:15,740 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 03:39:15,745 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 03:39:15,749 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "57120/60597 [===========================>..] - ETA: 1s - loss: 0.1389 - acc: 0.9453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 430us/step - loss: 0.0783 - acc: 0.9681 - val_loss: 0.1500 - val_acc: 0.9456\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95365\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.0750 - acc: 0.9694 - val_loss: 0.1849 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95365\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 430us/step - loss: 0.0730 - acc: 0.9701 - val_loss: 0.1836 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95365\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.0713 - acc: 0.9706 - val_loss: 0.1579 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95365\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 26s 431us/step - loss: 0.0690 - acc: 0.9716 - val_loss: 0.1694 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 03:45:05,033 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 03:45:05,034 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 03:45:05,036 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 03:45:05,041 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 03:45:05,044 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 03:45:05,048 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 03:45:05,053 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 03:45:05,057 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 03:45:05,059 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 03:45:05,063 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 03:45:05,068 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 03:45:05,072 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 03:45:05,074 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 03:45:05,078 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 03:45:05,083 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 03:45:05,087 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 03:45:05,089 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 03:45:05,094 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 03:45:05,098 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 03:45:05,101 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 03:45:05,106 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 03:45:05,108 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 03:45:05,112 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 03:45:05,115 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 03:45:05,119 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 03:45:05,123 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 03:45:05,127 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 30s 493us/step - loss: 0.1439 - acc: 0.9439 - val_loss: 0.1594 - val_acc: 0.9402\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94023, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "32384/60597 [===============>..............] - ETA: 11s - loss: 0.1104 - acc: 0.9556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 433us/step - loss: 0.0785 - acc: 0.9679 - val_loss: 0.1718 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94938\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 432us/step - loss: 0.0758 - acc: 0.9691 - val_loss: 0.1602 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94938\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 26s 432us/step - loss: 0.0744 - acc: 0.9697 - val_loss: 0.1653 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.94938\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 27s 438us/step - loss: 0.0721 - acc: 0.9701 - val_loss: 0.1650 - val_acc: 0.9428\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.94938\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 27s 438us/step - loss: 0.0702 - acc: 0.9712 - val_loss: 0.1715 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.94938\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0690 - acc: 0.9711 - val_loss: 0.2002 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 03:51:53,933 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 03:51:53,934 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 03:51:53,936 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 03:51:53,941 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 03:51:53,945 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 03:51:53,950 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 03:51:53,955 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 03:51:53,959 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 03:51:53,961 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 03:51:53,966 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 03:51:53,971 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 03:51:53,975 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 03:51:53,978 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 03:51:53,982 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 03:51:53,986 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 03:51:53,991 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 03:51:53,994 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 03:51:53,998 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 03:51:54,003 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 03:51:54,008 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 03:51:54,013 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 03:51:54,015 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 03:51:54,020 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 03:51:54,023 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 03:51:54,028 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 03:51:54,033 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 03:51:54,037 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "29920/60597 [=============>................] - ETA: 14s - loss: 0.1397 - acc: 0.9445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 431us/step - loss: 0.0790 - acc: 0.9677 - val_loss: 0.1607 - val_acc: 0.9398\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95170\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.0763 - acc: 0.9687 - val_loss: 0.1454 - val_acc: 0.9480\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95170\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.0748 - acc: 0.9692 - val_loss: 0.1590 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95170\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.0726 - acc: 0.9702 - val_loss: 0.1414 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95170\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 26s 427us/step - loss: 0.0704 - acc: 0.9706 - val_loss: 0.1407 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95170\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.0693 - acc: 0.9715 - val_loss: 0.1680 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95170\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 26s 429us/step - loss: 0.0670 - acc: 0.9722 - val_loss: 0.1592 - val_acc: 0.9394\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95170\n",
      "Epoch 13/40\n",
      " 2848/60597 [>.............................] - ETA: 23s - loss: 0.0618 - acc: 0.9738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0866 - acc: 0.9649 - val_loss: 0.1384 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94995 to 0.95069, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 26s 435us/step - loss: 0.0820 - acc: 0.9666 - val_loss: 0.1555 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95069\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 26s 432us/step - loss: 0.0788 - acc: 0.9679 - val_loss: 0.1509 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95069\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 26s 432us/step - loss: 0.0757 - acc: 0.9686 - val_loss: 0.1285 - val_acc: 0.9537\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95069 to 0.95367, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0735 - acc: 0.9697 - val_loss: 0.1447 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95367\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 432us/step - loss: 0.0715 - acc: 0.9703 - val_loss: 0.1813 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95367\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 26s 433us/step - loss: 0.0689 - acc: 0.9714 - val_loss: 0.1681 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95367\n",
      "Epoch 11/40\n",
      "13888/60597 [=====>........................] - ETA: 19s - loss: 0.0675 - acc: 0.9726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 430us/step - loss: 0.0616 - acc: 0.9741 - val_loss: 0.1784 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95367\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 26s 430us/step - loss: 0.0606 - acc: 0.9747 - val_loss: 0.1924 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 04:07:08,451 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 04:07:08,453 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 04:07:08,455 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 04:07:08,460 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 04:07:08,464 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 04:07:08,468 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 04:07:08,473 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 04:07:08,476 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 04:07:08,479 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 04:07:08,483 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 04:07:08,488 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 04:07:08,492 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 04:07:08,494 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 04:07:08,499 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 04:07:08,503 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 04:07:08,507 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 04:07:08,510 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 04:07:08,514 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 04:07:08,518 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 04:07:08,522 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 04:07:08,527 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 04:07:08,530 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 04:07:08,535 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 04:07:08,537 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 04:07:08,541 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 04:07:08,546 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 04:07:08,549 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 30s 487us/step - loss: 0.1305 - acc: 0.9480 - val_loss: 0.1470 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94481, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.1026 - acc: 0.9587 - val_loss: 0.1514 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94481\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 26s 432us/step - loss: 0.0932 - acc: 0.9625 - val_loss: 0.1341 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94481 to 0.94835, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 26s 435us/step - loss: 0.0873 - acc: 0.9645 - val_loss: 0.1340 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94835\n",
      "Epoch 5/40\n",
      "28000/60597 [============>.................] - ETA: 13s - loss: 0.0817 - acc: 0.9668"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 430us/step - loss: 0.0687 - acc: 0.9716 - val_loss: 0.1723 - val_acc: 0.9281\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95229\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 26s 431us/step - loss: 0.0673 - acc: 0.9719 - val_loss: 0.1790 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95229\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0657 - acc: 0.9726 - val_loss: 0.1482 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95229\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 26s 432us/step - loss: 0.0648 - acc: 0.9730 - val_loss: 0.1775 - val_acc: 0.9349\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95229\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 26s 433us/step - loss: 0.0630 - acc: 0.9737 - val_loss: 0.1653 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95229\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 26s 431us/step - loss: 0.0619 - acc: 0.9740 - val_loss: 0.1810 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95229\n",
      "Epoch 16/40\n",
      "58080/60597 [===========================>..] - ETA: 1s - loss: 0.0605 - acc: 0.9747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 433us/step - loss: 0.0793 - acc: 0.9677 - val_loss: 0.1454 - val_acc: 0.9498\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94391 to 0.94979, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 26s 433us/step - loss: 0.0762 - acc: 0.9689 - val_loss: 0.1489 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94979\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0731 - acc: 0.9697 - val_loss: 0.1722 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94979\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0717 - acc: 0.9705 - val_loss: 0.1794 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94979\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 26s 435us/step - loss: 0.0695 - acc: 0.9713 - val_loss: 0.1517 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.94979\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0679 - acc: 0.9717 - val_loss: 0.1645 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.94979\n",
      "Epoch 12/40\n",
      "36096/60597 [================>.............] - ETA: 10s - loss: 0.0652 - acc: 0.9730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 30s 502us/step - loss: 0.1380 - acc: 0.9456 - val_loss: 0.1565 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93123, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 27s 448us/step - loss: 0.1053 - acc: 0.9583 - val_loss: 0.1360 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93123 to 0.94771, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0957 - acc: 0.9615 - val_loss: 0.1452 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94771 to 0.95028, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 447us/step - loss: 0.0890 - acc: 0.9642 - val_loss: 0.1323 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95028\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0849 - acc: 0.9657 - val_loss: 0.1449 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95028\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 28s 454us/step - loss: 0.0812 - acc: 0.9668 - val_loss: 0.1293 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95028 to 0.95182, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "42400/60597 [===================>..........] - ETA: 7s - loss: 0.0779 - acc: 0.9681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 447us/step - loss: 0.0682 - acc: 0.9719 - val_loss: 0.1652 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95182\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 27s 438us/step - loss: 0.0658 - acc: 0.9725 - val_loss: 0.1637 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95182\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0651 - acc: 0.9728 - val_loss: 0.1592 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95182\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 26s 435us/step - loss: 0.0632 - acc: 0.9734 - val_loss: 0.1963 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95182\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 27s 438us/step - loss: 0.0626 - acc: 0.9741 - val_loss: 0.1836 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 04:31:38,884 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 04:31:38,885 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 04:31:38,887 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 04:31:38,892 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 04:31:38,896 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 04:31:38,900 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 04:31:38,904 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 04:31:38,908 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 04:31:38,910 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 04:31:38,915 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 04:31:38,919 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 04:31:38,923 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 04:31:38,926 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 04:31:38,930 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 04:31:38,934 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 04:31:38,938 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 04:31:38,940 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 04:31:38,945 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 04:31:38,948 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 04:31:38,953 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 04:31:38,957 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 04:31:38,959 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 04:31:38,964 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 04:31:38,966 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 04:31:38,971 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 04:31:38,975 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 04:31:38,979 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 30s 492us/step - loss: 0.1538 - acc: 0.9407 - val_loss: 0.1661 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93690, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.1151 - acc: 0.9548 - val_loss: 0.1510 - val_acc: 0.9351\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93690\n",
      "Epoch 3/40\n",
      "20960/60597 [=========>....................] - ETA: 16s - loss: 0.1043 - acc: 0.9589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0807 - acc: 0.9674 - val_loss: 0.1538 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95275\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.0787 - acc: 0.9685 - val_loss: 0.1555 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95275\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 26s 432us/step - loss: 0.0754 - acc: 0.9694 - val_loss: 0.1636 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95275\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 26s 436us/step - loss: 0.0738 - acc: 0.9697 - val_loss: 0.1675 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95275\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 26s 436us/step - loss: 0.0728 - acc: 0.9699 - val_loss: 0.1673 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95275\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 26s 433us/step - loss: 0.0702 - acc: 0.9710 - val_loss: 0.1441 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95275\n",
      "Epoch 14/40\n",
      "45664/60597 [=====================>........] - ETA: 6s - loss: 0.0693 - acc: 0.9715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 437us/step - loss: 0.0933 - acc: 0.9622 - val_loss: 0.1556 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94898\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 438us/step - loss: 0.0877 - acc: 0.9643 - val_loss: 0.1513 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94898\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 26s 437us/step - loss: 0.0839 - acc: 0.9661 - val_loss: 0.1381 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94898\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 26s 435us/step - loss: 0.0800 - acc: 0.9673 - val_loss: 0.1308 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94898 to 0.95069, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 26s 435us/step - loss: 0.0765 - acc: 0.9689 - val_loss: 0.1716 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95069\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 26s 436us/step - loss: 0.0744 - acc: 0.9697 - val_loss: 0.1599 - val_acc: 0.9436\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95069\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 26s 435us/step - loss: 0.0727 - acc: 0.9701 - val_loss: 0.1562 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95069\n",
      "Epoch 10/40\n",
      "12576/60597 [=====>........................] - ETA: 19s - loss: 0.0711 - acc: 0.9708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0642 - acc: 0.9736 - val_loss: 0.1566 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95069\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 27s 439us/step - loss: 0.0620 - acc: 0.9740 - val_loss: 0.1534 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.95069 to 0.95149, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0621 - acc: 0.9740 - val_loss: 0.1616 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95149\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 26s 436us/step - loss: 0.0606 - acc: 0.9746 - val_loss: 0.1758 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95149\n",
      "Epoch 19/40\n",
      "60597/60597 [==============================] - 26s 436us/step - loss: 0.0613 - acc: 0.9746 - val_loss: 0.1881 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.95149\n",
      "Epoch 20/40\n",
      "60597/60597 [==============================] - 27s 438us/step - loss: 0.0592 - acc: 0.9752 - val_loss: 0.1837 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.95149\n",
      "Epoch 21/40\n",
      "34496/60597 [================>.............] - ETA: 10s - loss: 0.0588 - acc: 0.9754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 26s 437us/step - loss: 0.0555 - acc: 0.9767 - val_loss: 0.1891 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.95149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 04:52:22,162 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 04:52:22,164 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 04:52:22,166 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 04:52:22,171 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 04:52:22,175 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 04:52:22,179 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 04:52:22,184 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 04:52:22,188 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 04:52:22,191 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 04:52:22,195 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 04:52:22,201 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 04:52:22,205 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 04:52:22,208 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 04:52:22,212 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 04:52:22,217 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 04:52:22,221 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 04:52:22,224 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 04:52:22,228 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 04:52:22,233 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 04:52:22,237 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 04:52:22,242 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 04:52:22,245 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 04:52:22,249 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 04:52:22,252 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 04:52:22,257 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 04:52:22,262 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 04:52:22,266 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 30s 499us/step - loss: 0.1298 - acc: 0.9482 - val_loss: 0.1633 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93505, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 436us/step - loss: 0.1023 - acc: 0.9587 - val_loss: 0.1306 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93505 to 0.95383, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0934 - acc: 0.9621 - val_loss: 0.1496 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95383\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 441us/step - loss: 0.0877 - acc: 0.9643 - val_loss: 0.1363 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95383\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0837 - acc: 0.9661 - val_loss: 0.1408 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95383\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 27s 437us/step - loss: 0.0802 - acc: 0.9672 - val_loss: 0.1584 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95383\n",
      "Epoch 7/40\n",
      " 1952/60597 [..............................] - ETA: 24s - loss: 0.0781 - acc: 0.9666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 29s 473us/step - loss: 0.0673 - acc: 0.9720 - val_loss: 0.1641 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 04:58:49,145 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 04:58:49,147 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 04:58:49,148 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 04:58:49,154 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 04:58:49,158 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 04:58:49,162 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 04:58:49,167 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 04:58:49,170 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 04:58:49,173 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 04:58:49,177 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 04:58:49,182 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 04:58:49,186 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 04:58:49,188 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 04:58:49,192 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 04:58:49,197 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 04:58:49,201 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 04:58:49,203 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 04:58:49,208 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 04:58:49,212 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 04:58:49,216 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 04:58:49,220 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 04:58:49,222 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 04:58:49,227 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 04:58:49,229 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 04:58:49,234 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 04:58:49,238 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 04:58:49,242 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 30s 495us/step - loss: 0.1329 - acc: 0.9469 - val_loss: 0.1445 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94749, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 26s 434us/step - loss: 0.1032 - acc: 0.9588 - val_loss: 0.1278 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94749 to 0.95494, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 27s 439us/step - loss: 0.0936 - acc: 0.9621 - val_loss: 0.1505 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95494\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0877 - acc: 0.9649 - val_loss: 0.1444 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95494\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 441us/step - loss: 0.0831 - acc: 0.9662 - val_loss: 0.1611 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95494\n",
      "Epoch 6/40\n",
      "57984/60597 [===========================>..] - ETA: 1s - loss: 0.0794 - acc: 0.9679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0661 - acc: 0.9723 - val_loss: 0.1620 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 05:05:16,913 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 05:05:16,915 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 05:05:16,918 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 05:05:16,922 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 05:05:16,926 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 05:05:16,930 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 05:05:16,934 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 05:05:16,938 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 05:05:16,941 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 05:05:16,945 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 05:05:16,950 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 05:05:16,954 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 05:05:16,957 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 05:05:16,960 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 05:05:16,965 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 05:05:16,969 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 05:05:16,972 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 05:05:16,975 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 05:05:16,979 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 05:05:16,984 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 05:05:16,988 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 05:05:16,991 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 05:05:16,995 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 05:05:16,998 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 05:05:17,002 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 05:05:17,006 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 05:05:17,010 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 31s 510us/step - loss: 0.1360 - acc: 0.9463 - val_loss: 0.1557 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93890, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.1052 - acc: 0.9573 - val_loss: 0.1673 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93890\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0958 - acc: 0.9616 - val_loss: 0.1289 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93890 to 0.95277, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0897 - acc: 0.9637 - val_loss: 0.1404 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95277\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0855 - acc: 0.9655 - val_loss: 0.1306 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95277\n",
      "Epoch 6/40\n",
      "41152/60597 [===================>..........] - ETA: 8s - loss: 0.0803 - acc: 0.9671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0667 - acc: 0.9721 - val_loss: 0.1555 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95277\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0655 - acc: 0.9729 - val_loss: 0.1669 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 05:12:12,801 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 05:12:12,802 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 05:12:12,804 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 05:12:12,809 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 05:12:12,813 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 05:12:12,817 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 05:12:12,822 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 05:12:12,825 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 05:12:12,828 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 05:12:12,833 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 05:12:12,837 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 05:12:12,842 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 05:12:12,844 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 05:12:12,848 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 05:12:12,853 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 05:12:12,857 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 05:12:12,860 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 05:12:12,865 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 05:12:12,869 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 05:12:12,873 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 05:12:12,877 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 05:12:12,880 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 05:12:12,884 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 05:12:12,886 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 05:12:12,891 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 05:12:12,895 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 05:12:12,899 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 30s 502us/step - loss: 0.1410 - acc: 0.9445 - val_loss: 0.1480 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94286, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.1071 - acc: 0.9574 - val_loss: 0.1342 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94286 to 0.94767, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0973 - acc: 0.9610 - val_loss: 0.1517 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94767\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0906 - acc: 0.9636 - val_loss: 0.1572 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94767\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0853 - acc: 0.9658 - val_loss: 0.1491 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94767\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0819 - acc: 0.9673 - val_loss: 0.1453 - val_acc: 0.9468\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94767\n",
      "Epoch 7/40\n",
      "46624/60597 [======================>.......] - ETA: 5s - loss: 0.0786 - acc: 0.9682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 439us/step - loss: 0.0676 - acc: 0.9719 - val_loss: 0.1547 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95277\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 27s 439us/step - loss: 0.0660 - acc: 0.9731 - val_loss: 0.1470 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95277\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 27s 439us/step - loss: 0.0649 - acc: 0.9732 - val_loss: 0.1770 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95277\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 26s 437us/step - loss: 0.0633 - acc: 0.9738 - val_loss: 0.1655 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95277\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 27s 439us/step - loss: 0.0621 - acc: 0.9740 - val_loss: 0.1620 - val_acc: 0.9402\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95277\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0616 - acc: 0.9743 - val_loss: 0.1517 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95277\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0600 - acc: 0.9750 - val_loss: 0.1663 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 05:21:22,207 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 05:21:22,209 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 05:21:22,211 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 05:21:22,215 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 05:21:22,219 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 05:21:22,224 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 05:21:22,229 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 05:21:22,232 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 05:21:22,234 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 05:21:22,238 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 05:21:22,243 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 05:21:22,247 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 05:21:22,249 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 05:21:22,253 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 05:21:22,258 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 05:21:22,263 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 05:21:22,265 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 05:21:22,270 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 05:21:22,274 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 05:21:22,278 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 05:21:22,282 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 05:21:22,285 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 05:21:22,289 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 05:21:22,292 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 05:21:22,296 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 05:21:22,300 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 05:21:22,304 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      " 1824/60597 [..............................] - ETA: 1:30 - loss: 0.2831 - acc: 0.9019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0858 - acc: 0.9657 - val_loss: 0.1473 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94759 to 0.94861, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0821 - acc: 0.9670 - val_loss: 0.1366 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94861\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 27s 441us/step - loss: 0.0793 - acc: 0.9679 - val_loss: 0.1376 - val_acc: 0.9529\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.94861 to 0.95291, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0775 - acc: 0.9684 - val_loss: 0.1504 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95291\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0747 - acc: 0.9696 - val_loss: 0.1623 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95291\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0730 - acc: 0.9703 - val_loss: 0.1445 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95291\n",
      "Epoch 12/40\n",
      "43584/60597 [====================>.........] - ETA: 7s - loss: 0.0701 - acc: 0.9714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 438us/step - loss: 0.0648 - acc: 0.9733 - val_loss: 0.1729 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95291\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0628 - acc: 0.9739 - val_loss: 0.1684 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 05:30:31,070 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 05:30:31,071 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 05:30:31,073 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 05:30:31,078 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 05:30:31,081 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 05:30:31,085 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 05:30:31,090 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 05:30:31,093 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 05:30:31,096 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 05:30:31,100 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 05:30:31,104 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 05:30:31,109 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 05:30:31,111 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 05:30:31,115 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 05:30:31,119 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 05:30:31,123 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 05:30:31,125 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 05:30:31,130 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 05:30:31,134 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 05:30:31,138 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 05:30:31,142 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 05:30:31,145 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 05:30:31,149 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 05:30:31,152 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 05:30:31,156 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 05:30:31,160 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 05:30:31,163 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 30s 503us/step - loss: 0.1310 - acc: 0.9475 - val_loss: 0.1421 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94590, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.1036 - acc: 0.9584 - val_loss: 0.1452 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94590 to 0.94765, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0940 - acc: 0.9621 - val_loss: 0.1425 - val_acc: 0.9468\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94765\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0883 - acc: 0.9642 - val_loss: 0.1808 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94765\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0836 - acc: 0.9660 - val_loss: 0.1473 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94765\n",
      "Epoch 6/40\n",
      " 9856/60597 [===>..........................] - ETA: 21s - loss: 0.0810 - acc: 0.9674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0691 - acc: 0.9716 - val_loss: 0.1369 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.94765 to 0.94913, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0671 - acc: 0.9723 - val_loss: 0.1458 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.94913\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0662 - acc: 0.9727 - val_loss: 0.1476 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94913\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0653 - acc: 0.9732 - val_loss: 0.1590 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.94913\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 27s 440us/step - loss: 0.0629 - acc: 0.9736 - val_loss: 0.1700 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.94913\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 27s 439us/step - loss: 0.0620 - acc: 0.9743 - val_loss: 0.1670 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.94913\n",
      "Epoch 17/40\n",
      "23584/60597 [==========>...................] - ETA: 15s - loss: 0.0605 - acc: 0.9747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 31s 511us/step - loss: 0.1330 - acc: 0.9468 - val_loss: 0.1463 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94757, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 27s 446us/step - loss: 0.1028 - acc: 0.9586 - val_loss: 0.1327 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94757 to 0.94876, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 27s 447us/step - loss: 0.0939 - acc: 0.9622 - val_loss: 0.1523 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94876\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 448us/step - loss: 0.0885 - acc: 0.9644 - val_loss: 0.1447 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94876\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0832 - acc: 0.9661 - val_loss: 0.1699 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94876\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0797 - acc: 0.9678 - val_loss: 0.1526 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94876\n",
      "Epoch 7/40\n",
      "58656/60597 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0658 - acc: 0.9725 - val_loss: 0.1639 - val_acc: 0.9401\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95018\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 27s 446us/step - loss: 0.0650 - acc: 0.9732 - val_loss: 0.1821 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95018\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0637 - acc: 0.9736 - val_loss: 0.1479 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95018\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0628 - acc: 0.9738 - val_loss: 0.1555 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95018\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0610 - acc: 0.9745 - val_loss: 0.1787 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95018\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 27s 447us/step - loss: 0.0609 - acc: 0.9748 - val_loss: 0.1785 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95018\n",
      "Epoch 19/40\n",
      "32416/60597 [===============>..............] - ETA: 11s - loss: 0.0590 - acc: 0.9751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0842 - acc: 0.9659 - val_loss: 0.1490 - val_acc: 0.9401\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94841\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0804 - acc: 0.9672 - val_loss: 0.1380 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94841 to 0.94874, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 27s 441us/step - loss: 0.0778 - acc: 0.9682 - val_loss: 0.1380 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.94874 to 0.94946, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0752 - acc: 0.9694 - val_loss: 0.1430 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94946\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 27s 441us/step - loss: 0.0715 - acc: 0.9704 - val_loss: 0.1352 - val_acc: 0.9564\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.94946 to 0.95636, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0702 - acc: 0.9710 - val_loss: 0.1662 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95636\n",
      "Epoch 11/40\n",
      "29280/60597 [=============>................] - ETA: 12s - loss: 0.0679 - acc: 0.9718"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 441us/step - loss: 0.0618 - acc: 0.9742 - val_loss: 0.1597 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95636\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0611 - acc: 0.9744 - val_loss: 0.1519 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95636\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 27s 442us/step - loss: 0.0597 - acc: 0.9751 - val_loss: 0.1647 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95636\n",
      "Epoch 19/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0590 - acc: 0.9756 - val_loss: 0.1546 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.95636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 06:00:22,961 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 06:00:22,963 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 06:00:22,964 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 06:00:22,969 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 06:00:22,973 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 06:00:22,978 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 06:00:22,982 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 06:00:22,986 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 06:00:22,989 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 06:00:22,993 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 06:00:22,997 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 06:00:23,002 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 06:00:23,004 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 06:00:23,009 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 06:00:23,014 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 06:00:23,018 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 06:00:23,021 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 06:00:23,025 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 06:00:23,029 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 06:00:23,033 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 06:00:23,038 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 06:00:23,040 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 06:00:23,044 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 06:00:23,047 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 06:00:23,051 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 06:00:23,055 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 06:00:23,059 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 31s 515us/step - loss: 0.1411 - acc: 0.9444 - val_loss: 0.1340 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95272, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 27s 450us/step - loss: 0.1061 - acc: 0.9575 - val_loss: 0.1342 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95272 to 0.95439, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "58144/60597 [===========================>..] - ETA: 1s - loss: 0.0966 - acc: 0.9613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0750 - acc: 0.9695 - val_loss: 0.1362 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95529\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0727 - acc: 0.9702 - val_loss: 0.1688 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95529\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0712 - acc: 0.9709 - val_loss: 0.1479 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95529\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0692 - acc: 0.9717 - val_loss: 0.1516 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95529\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 27s 444us/step - loss: 0.0672 - acc: 0.9722 - val_loss: 0.1851 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95529\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 27s 445us/step - loss: 0.0657 - acc: 0.9726 - val_loss: 0.1580 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95529\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 27s 443us/step - loss: 0.0645 - acc: 0.9733 - val_loss: 0.1552 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 06:07:48,555 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 06:07:48,556 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 06:07:48,558 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 06:07:48,562 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 06:07:48,566 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 06:07:48,570 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 06:07:48,575 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 06:07:48,579 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 06:07:48,581 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 06:07:48,585 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 06:07:48,589 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 06:07:48,594 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 06:07:48,596 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 06:07:48,600 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 06:07:48,604 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 06:07:48,609 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 06:07:48,611 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 06:07:48,616 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 06:07:48,620 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 06:07:48,624 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 06:07:48,628 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 06:07:48,630 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 06:07:48,635 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 06:07:48,637 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 06:07:48,641 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 06:07:48,645 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 06:07:48,649 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "13856/60597 [=====>........................] - ETA: 26s - loss: 0.1960 - acc: 0.9255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 451us/step - loss: 0.0841 - acc: 0.9662 - val_loss: 0.1489 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95316\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 27s 452us/step - loss: 0.0803 - acc: 0.9674 - val_loss: 0.1424 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95316\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 27s 449us/step - loss: 0.0776 - acc: 0.9686 - val_loss: 0.1349 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95316\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 27s 449us/step - loss: 0.0752 - acc: 0.9691 - val_loss: 0.1523 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95316\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 27s 449us/step - loss: 0.0723 - acc: 0.9702 - val_loss: 0.1526 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95316\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 27s 450us/step - loss: 0.0710 - acc: 0.9709 - val_loss: 0.1560 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95316\n",
      "Epoch 12/40\n",
      "56960/60597 [===========================>..] - ETA: 1s - loss: 0.0694 - acc: 0.9713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 451us/step - loss: 0.0913 - acc: 0.9638 - val_loss: 0.1343 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95741\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.0879 - acc: 0.9652 - val_loss: 0.1695 - val_acc: 0.9366\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95741\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.0838 - acc: 0.9662 - val_loss: 0.1489 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95741\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 28s 458us/step - loss: 0.0821 - acc: 0.9674 - val_loss: 0.1334 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95741\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 28s 461us/step - loss: 0.0789 - acc: 0.9681 - val_loss: 0.1474 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95741\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 28s 459us/step - loss: 0.0767 - acc: 0.9690 - val_loss: 0.1577 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95741\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0750 - acc: 0.9697 - val_loss: 0.1534 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95741\n",
      "Epoch 12/40\n",
      "16160/60597 [=======>......................] - ETA: 19s - loss: 0.0733 - acc: 0.9702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.0843 - acc: 0.9662 - val_loss: 0.1461 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95221\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 28s 454us/step - loss: 0.0801 - acc: 0.9679 - val_loss: 0.1484 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95221\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0776 - acc: 0.9687 - val_loss: 0.1407 - val_acc: 0.9478\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95221\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 28s 459us/step - loss: 0.0753 - acc: 0.9699 - val_loss: 0.1573 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95221\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 28s 458us/step - loss: 0.0724 - acc: 0.9703 - val_loss: 0.1615 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95221\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 29s 473us/step - loss: 0.0707 - acc: 0.9711 - val_loss: 0.1392 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95221\n",
      "Epoch 11/40\n",
      "40000/60597 [==================>...........] - ETA: 8s - loss: 0.0707 - acc: 0.9711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 454us/step - loss: 0.0843 - acc: 0.9660 - val_loss: 0.1393 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95016\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 27s 452us/step - loss: 0.0808 - acc: 0.9675 - val_loss: 0.1336 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95016\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0778 - acc: 0.9685 - val_loss: 0.1352 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95016 to 0.95392, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0752 - acc: 0.9694 - val_loss: 0.1318 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95392\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 27s 451us/step - loss: 0.0726 - acc: 0.9702 - val_loss: 0.1392 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95392\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0709 - acc: 0.9710 - val_loss: 0.1349 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95392\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0690 - acc: 0.9717 - val_loss: 0.1423 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95392\n",
      "Epoch 12/40\n",
      "17600/60597 [=======>......................] - ETA: 18s - loss: 0.0673 - acc: 0.9721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.0612 - acc: 0.9747 - val_loss: 0.1482 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 06:36:12,110 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 06:36:12,111 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 06:36:12,113 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 06:36:12,117 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 06:36:12,121 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 06:36:12,126 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 06:36:12,131 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 06:36:12,134 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 06:36:12,137 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 06:36:12,141 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 06:36:12,146 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 06:36:12,151 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 06:36:12,153 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 06:36:12,157 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 06:36:12,163 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 06:36:12,168 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 06:36:12,171 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 06:36:12,176 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 06:36:12,180 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 06:36:12,185 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 06:36:12,189 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 06:36:12,192 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 06:36:12,196 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 06:36:12,198 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 06:36:12,203 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 06:36:12,207 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 06:36:12,211 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 33s 540us/step - loss: 0.1402 - acc: 0.9441 - val_loss: 0.1789 - val_acc: 0.9310\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93099, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 28s 462us/step - loss: 0.1059 - acc: 0.9576 - val_loss: 0.1463 - val_acc: 0.9415\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93099 to 0.94145, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 27s 451us/step - loss: 0.0955 - acc: 0.9614 - val_loss: 0.1353 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94145 to 0.95071, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0892 - acc: 0.9636 - val_loss: 0.1423 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95071\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 454us/step - loss: 0.0843 - acc: 0.9658 - val_loss: 0.1433 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95071\n",
      "Epoch 6/40\n",
      "60416/60597 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 30s 490us/step - loss: 0.0691 - acc: 0.9714 - val_loss: 0.1448 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95519\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.0670 - acc: 0.9725 - val_loss: 0.1451 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95519\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 28s 469us/step - loss: 0.0656 - acc: 0.9731 - val_loss: 0.1572 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95519\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 28s 462us/step - loss: 0.0646 - acc: 0.9734 - val_loss: 0.1493 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95519\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 28s 459us/step - loss: 0.0633 - acc: 0.9740 - val_loss: 0.1530 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 06:44:50,404 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 06:44:50,406 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 06:44:50,408 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 06:44:50,413 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 06:44:50,418 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 06:44:50,422 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 06:44:50,427 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 06:44:50,430 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 06:44:50,433 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 06:44:50,438 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 06:44:50,442 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 06:44:50,447 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 06:44:50,449 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 06:44:50,453 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 06:44:50,458 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 06:44:50,463 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 06:44:50,466 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 06:44:50,470 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 06:44:50,475 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 06:44:50,479 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 06:44:50,484 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 06:44:50,487 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 06:44:50,491 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 06:44:50,494 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 06:44:50,499 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 06:44:50,503 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 06:44:50,507 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 32s 521us/step - loss: 0.1465 - acc: 0.9424 - val_loss: 0.1596 - val_acc: 0.9351\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93512, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "39552/60597 [==================>...........] - ETA: 9s - loss: 0.1106 - acc: 0.9561"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.0795 - acc: 0.9679 - val_loss: 0.1307 - val_acc: 0.9529\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95172 to 0.95295, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0771 - acc: 0.9685 - val_loss: 0.1469 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95295\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.0748 - acc: 0.9695 - val_loss: 0.1557 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95295\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0728 - acc: 0.9702 - val_loss: 0.1287 - val_acc: 0.9537\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.95295 to 0.95365, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 27s 454us/step - loss: 0.0704 - acc: 0.9711 - val_loss: 0.1517 - val_acc: 0.9485\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95365\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.0688 - acc: 0.9719 - val_loss: 0.1703 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95365\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 27s 454us/step - loss: 0.0676 - acc: 0.9722 - val_loss: 0.1543 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95365\n",
      "Epoch 14/40\n",
      "11264/60597 [====>.........................] - ETA: 21s - loss: 0.0675 - acc: 0.9723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.0606 - acc: 0.9746 - val_loss: 0.1731 - val_acc: 0.9428\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.95365\n",
      "Epoch 20/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0595 - acc: 0.9750 - val_loss: 0.1535 - val_acc: 0.9466\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.95365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 06:55:12,114 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 06:55:12,115 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 06:55:12,118 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 06:55:12,122 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 06:55:12,126 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 06:55:12,131 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 06:55:12,136 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 06:55:12,140 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 06:55:12,143 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 06:55:12,148 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 06:55:12,152 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 06:55:12,158 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 06:55:12,160 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 06:55:12,165 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 06:55:12,170 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 06:55:12,175 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 06:55:12,177 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 06:55:12,182 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 06:55:12,186 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 06:55:12,191 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 06:55:12,196 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 06:55:12,198 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 06:55:12,203 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 06:55:12,205 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 06:55:12,210 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 06:55:12,214 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 06:55:12,218 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 32s 521us/step - loss: 0.1527 - acc: 0.9407 - val_loss: 0.1482 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94447, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 28s 458us/step - loss: 0.1118 - acc: 0.9564 - val_loss: 0.1365 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94447 to 0.95012, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.1003 - acc: 0.9603 - val_loss: 0.1410 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95012\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0939 - acc: 0.9628 - val_loss: 0.1411 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95012\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0889 - acc: 0.9646 - val_loss: 0.1472 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95012\n",
      "Epoch 6/40\n",
      " 4000/60597 [>.............................] - ETA: 24s - loss: 0.0808 - acc: 0.9682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 450us/step - loss: 0.0736 - acc: 0.9699 - val_loss: 0.1434 - val_acc: 0.9526\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95501\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.0726 - acc: 0.9710 - val_loss: 0.1443 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95501\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.0704 - acc: 0.9714 - val_loss: 0.1610 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95501\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.0691 - acc: 0.9718 - val_loss: 0.1458 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95501\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 28s 454us/step - loss: 0.0675 - acc: 0.9723 - val_loss: 0.1694 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95501\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.0658 - acc: 0.9730 - val_loss: 0.1931 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95501\n",
      "Epoch 16/40\n",
      "60160/60597 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9735"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 463us/step - loss: 0.0899 - acc: 0.9647 - val_loss: 0.1508 - val_acc: 0.9498\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94722 to 0.94981, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0862 - acc: 0.9657 - val_loss: 0.1573 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94981\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 28s 462us/step - loss: 0.0835 - acc: 0.9668 - val_loss: 0.1456 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94981\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.0803 - acc: 0.9681 - val_loss: 0.1667 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94981\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.0783 - acc: 0.9687 - val_loss: 0.1950 - val_acc: 0.9366\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.94981\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 29s 473us/step - loss: 0.0763 - acc: 0.9693 - val_loss: 0.1521 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.94981\n",
      "Epoch 12/40\n",
      "49312/60597 [=======================>......] - ETA: 4s - loss: 0.0743 - acc: 0.9700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 31s 516us/step - loss: 0.1400 - acc: 0.9437 - val_loss: 0.1647 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93709, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 27s 452us/step - loss: 0.1083 - acc: 0.9567 - val_loss: 0.1285 - val_acc: 0.9555\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93709 to 0.95548, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 28s 458us/step - loss: 0.0978 - acc: 0.9609 - val_loss: 0.1319 - val_acc: 0.9510\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95548\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 28s 465us/step - loss: 0.0919 - acc: 0.9631 - val_loss: 0.1227 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95548 to 0.95805, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 30s 491us/step - loss: 0.0871 - acc: 0.9652 - val_loss: 0.1574 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95805\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.0835 - acc: 0.9662 - val_loss: 0.1489 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95805\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 28s 462us/step - loss: 0.0810 - acc: 0.9674 - val_loss: 0.1274 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95805\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0781 - acc: 0.9685 - val_loss: 0.1319 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95805\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0756 - acc: 0.9695 - val_loss: 0.1435 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95805\n",
      "Epoch 10/40\n",
      "58080/60597 [===========================>..] - ETA: 1s - loss: 0.0742 - acc: 0.9698"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.1084 - acc: 0.9570 - val_loss: 0.1337 - val_acc: 0.9537\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94859 to 0.95375, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0984 - acc: 0.9607 - val_loss: 0.1385 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95375\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.0917 - acc: 0.9637 - val_loss: 0.1399 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95375\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 27s 451us/step - loss: 0.0875 - acc: 0.9654 - val_loss: 0.1398 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95375\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 27s 453us/step - loss: 0.0833 - acc: 0.9669 - val_loss: 0.1489 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95375\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.0801 - acc: 0.9678 - val_loss: 0.1292 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95375\n",
      "Epoch 8/40\n",
      "21280/60597 [=========>....................] - ETA: 16s - loss: 0.0762 - acc: 0.9693"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 32s 526us/step - loss: 0.1431 - acc: 0.9431 - val_loss: 0.1356 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94989, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 28s 458us/step - loss: 0.1097 - acc: 0.9567 - val_loss: 0.1363 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94989 to 0.95157, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 28s 454us/step - loss: 0.0998 - acc: 0.9605 - val_loss: 0.1384 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95157\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.0931 - acc: 0.9629 - val_loss: 0.1431 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95157\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.0886 - acc: 0.9646 - val_loss: 0.1469 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95157\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.0842 - acc: 0.9661 - val_loss: 0.1350 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95157 to 0.95470, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "52864/60597 [=========================>....] - ETA: 3s - loss: 0.0814 - acc: 0.9672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 27s 454us/step - loss: 0.0707 - acc: 0.9710 - val_loss: 0.1450 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95470\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 28s 458us/step - loss: 0.0691 - acc: 0.9716 - val_loss: 0.1565 - val_acc: 0.9400\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95470\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0682 - acc: 0.9721 - val_loss: 0.1713 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95470\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.0661 - acc: 0.9730 - val_loss: 0.1494 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95470\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 28s 454us/step - loss: 0.0653 - acc: 0.9732 - val_loss: 0.1660 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 07:35:17,623 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 07:35:17,625 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 07:35:17,627 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 07:35:17,632 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 07:35:17,636 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 07:35:17,641 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 07:35:17,646 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 07:35:17,650 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 07:35:17,652 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 07:35:17,656 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 07:35:17,660 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 07:35:17,665 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 07:35:17,668 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 07:35:17,671 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 07:35:17,676 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 07:35:17,681 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 07:35:17,683 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 07:35:17,688 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 07:35:17,692 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 07:35:17,696 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 07:35:17,701 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 07:35:17,703 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 07:35:17,708 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 07:35:17,711 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 07:35:17,715 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 07:35:17,720 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 07:35:17,724 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 34s 558us/step - loss: 0.1595 - acc: 0.9382 - val_loss: 0.1572 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94216, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 28s 466us/step - loss: 0.1140 - acc: 0.9548 - val_loss: 0.1438 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94216 to 0.94673, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      " 8832/60597 [===>..........................] - ETA: 22s - loss: 0.1030 - acc: 0.9578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 463us/step - loss: 0.0795 - acc: 0.9680 - val_loss: 0.1442 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95085\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 28s 466us/step - loss: 0.0764 - acc: 0.9689 - val_loss: 0.1488 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95085\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 28s 467us/step - loss: 0.0745 - acc: 0.9702 - val_loss: 0.1645 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95085\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 29s 472us/step - loss: 0.0734 - acc: 0.9706 - val_loss: 0.1628 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95085\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 28s 470us/step - loss: 0.0715 - acc: 0.9712 - val_loss: 0.1416 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95085\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 28s 465us/step - loss: 0.0702 - acc: 0.9713 - val_loss: 0.1644 - val_acc: 0.9401\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95085\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 29s 471us/step - loss: 0.0688 - acc: 0.9716 - val_loss: 0.1383 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.95085 to 0.95207, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 28s 467us/step - loss: 0.0674 - acc: 0.9727 - val_loss: 0.1503 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95207\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 29s 471us/step - loss: 0.0658 - acc: 0.9732 - val_loss: 0.1392 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95207\n",
      "Epoch 17/40\n",
      "19072/60597 [========>.....................] - ETA: 18s - loss: 0.0629 - acc: 0.9743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 469us/step - loss: 0.0615 - acc: 0.9747 - val_loss: 0.1616 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.95207\n",
      "Epoch 22/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0607 - acc: 0.9751 - val_loss: 0.1548 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.95207\n",
      "Epoch 23/40\n",
      "60597/60597 [==============================] - 28s 468us/step - loss: 0.0595 - acc: 0.9757 - val_loss: 0.1851 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.95207\n",
      "Epoch 24/40\n",
      "60597/60597 [==============================] - 28s 462us/step - loss: 0.0588 - acc: 0.9760 - val_loss: 0.1683 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.95207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 07:47:54,364 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 07:47:54,365 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 07:47:54,367 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 07:47:54,372 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 07:47:54,376 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 07:47:54,381 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 07:47:54,386 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 07:47:54,390 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 07:47:54,393 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 07:47:54,398 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 07:47:54,402 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 07:47:54,406 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 07:47:54,409 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 07:47:54,413 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 07:47:54,417 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 07:47:54,422 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 07:47:54,424 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 07:47:54,429 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 07:47:54,433 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 07:47:54,437 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 07:47:54,441 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 07:47:54,443 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 07:47:54,448 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 07:47:54,451 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 07:47:54,455 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 07:47:54,459 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 07:47:54,463 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 32s 528us/step - loss: 0.1604 - acc: 0.9368 - val_loss: 0.1508 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94247, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 28s 465us/step - loss: 0.1189 - acc: 0.9533 - val_loss: 0.1474 - val_acc: 0.9478\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94247 to 0.94779, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.1062 - acc: 0.9582 - val_loss: 0.1449 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94779\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 28s 462us/step - loss: 0.0994 - acc: 0.9606 - val_loss: 0.1384 - val_acc: 0.9503\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94779 to 0.95032, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 28s 463us/step - loss: 0.0934 - acc: 0.9629 - val_loss: 0.1465 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95032\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 28s 459us/step - loss: 0.0888 - acc: 0.9648 - val_loss: 0.1387 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95032 to 0.95223, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 29s 478us/step - loss: 0.0861 - acc: 0.9656 - val_loss: 0.1469 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95223\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 29s 475us/step - loss: 0.0835 - acc: 0.9664 - val_loss: 0.1568 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95223\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 29s 474us/step - loss: 0.0808 - acc: 0.9675 - val_loss: 0.1459 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95223\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 28s 459us/step - loss: 0.0785 - acc: 0.9683 - val_loss: 0.1535 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95223\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.0773 - acc: 0.9690 - val_loss: 0.1555 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95223\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.0761 - acc: 0.9692 - val_loss: 0.1525 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95223\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0743 - acc: 0.9701 - val_loss: 0.1596 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95223\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0722 - acc: 0.9705 - val_loss: 0.1618 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95223\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.0705 - acc: 0.9714 - val_loss: 0.1541 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95223\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 28s 461us/step - loss: 0.0699 - acc: 0.9714 - val_loss: 0.1495 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 07:56:35,207 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 07:56:35,209 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 07:56:35,210 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 07:56:35,214 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 07:56:35,218 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 07:56:35,223 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 07:56:35,227 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 07:56:35,231 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 07:56:35,233 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 07:56:35,237 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 07:56:35,242 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 07:56:35,246 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 07:56:35,249 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 07:56:35,253 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 07:56:35,258 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 07:56:35,262 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 07:56:35,265 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 07:56:35,269 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 07:56:35,273 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 07:56:35,277 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 07:56:35,282 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 07:56:35,284 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 07:56:35,289 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 07:56:35,291 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 07:56:35,296 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 07:56:35,300 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 07:56:35,304 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 32s 525us/step - loss: 0.1761 - acc: 0.9320 - val_loss: 0.1560 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93974, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 28s 459us/step - loss: 0.1265 - acc: 0.9502 - val_loss: 0.1656 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.93974\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 28s 460us/step - loss: 0.1135 - acc: 0.9552 - val_loss: 0.1776 - val_acc: 0.9327\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.93974\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 28s 455us/step - loss: 0.1065 - acc: 0.9583 - val_loss: 0.1627 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.93974 to 0.94177, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 28s 456us/step - loss: 0.1005 - acc: 0.9604 - val_loss: 0.1560 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94177 to 0.94294, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 27s 449us/step - loss: 0.0964 - acc: 0.9620 - val_loss: 0.1569 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94294 to 0.94422, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 28s 463us/step - loss: 0.0927 - acc: 0.9631 - val_loss: 0.1707 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94422\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 28s 463us/step - loss: 0.0898 - acc: 0.9640 - val_loss: 0.1541 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.94422 to 0.95108, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 28s 465us/step - loss: 0.0876 - acc: 0.9650 - val_loss: 0.1696 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95108\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 29s 472us/step - loss: 0.0852 - acc: 0.9659 - val_loss: 0.1499 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95108\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 28s 470us/step - loss: 0.0835 - acc: 0.9668 - val_loss: 0.1644 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95108\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 29s 472us/step - loss: 0.0819 - acc: 0.9672 - val_loss: 0.1978 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95108\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 29s 472us/step - loss: 0.0796 - acc: 0.9682 - val_loss: 0.1734 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.95108\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 28s 470us/step - loss: 0.0776 - acc: 0.9687 - val_loss: 0.1657 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95108\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 29s 472us/step - loss: 0.0763 - acc: 0.9694 - val_loss: 0.1741 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95108\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 29s 472us/step - loss: 0.0752 - acc: 0.9703 - val_loss: 0.1650 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95108\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 29s 474us/step - loss: 0.0735 - acc: 0.9707 - val_loss: 0.1802 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95108\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 28s 468us/step - loss: 0.0731 - acc: 0.9705 - val_loss: 0.1881 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.95108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 08:06:13,033 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 08:06:13,035 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 08:06:13,038 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 08:06:13,044 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 08:06:13,049 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 08:06:13,054 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 08:06:13,059 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 08:06:13,064 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 08:06:13,067 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 08:06:13,072 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 08:06:13,076 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 08:06:13,081 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 08:06:13,085 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 08:06:13,089 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 08:06:13,093 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 08:06:13,098 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 08:06:13,100 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 08:06:13,105 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 08:06:13,109 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 08:06:13,114 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 08:06:13,118 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 08:06:13,120 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 08:06:13,124 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 08:06:13,127 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 08:06:13,131 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 08:06:13,135 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 08:06:13,139 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 33s 540us/step - loss: 0.1276 - acc: 0.9490 - val_loss: 0.1313 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95063, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 28s 466us/step - loss: 0.1027 - acc: 0.9585 - val_loss: 0.1447 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95063\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 28s 463us/step - loss: 0.0939 - acc: 0.9620 - val_loss: 0.1449 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.95063\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 28s 467us/step - loss: 0.0884 - acc: 0.9640 - val_loss: 0.1543 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95063\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 28s 468us/step - loss: 0.0849 - acc: 0.9657 - val_loss: 0.1579 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95063\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 28s 466us/step - loss: 0.0816 - acc: 0.9664 - val_loss: 0.1737 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95063\n",
      "Epoch 7/40\n",
      "17024/60597 [=======>......................] - ETA: 18s - loss: 0.0769 - acc: 0.9682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 33s 540us/step - loss: 0.1272 - acc: 0.9487 - val_loss: 0.1423 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94498, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 28s 467us/step - loss: 0.1022 - acc: 0.9588 - val_loss: 0.1470 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.94498\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 29s 471us/step - loss: 0.0939 - acc: 0.9620 - val_loss: 0.1486 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94498 to 0.94633, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 29s 474us/step - loss: 0.0883 - acc: 0.9640 - val_loss: 0.1535 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94633\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 28s 469us/step - loss: 0.0844 - acc: 0.9657 - val_loss: 0.1588 - val_acc: 0.9334\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94633\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 28s 467us/step - loss: 0.0809 - acc: 0.9670 - val_loss: 0.1517 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.94633\n",
      "Epoch 7/40\n",
      "55360/60597 [==========================>...] - ETA: 2s - loss: 0.0787 - acc: 0.9679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 469us/step - loss: 0.0682 - acc: 0.9716 - val_loss: 0.1723 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94720\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 29s 486us/step - loss: 0.0675 - acc: 0.9716 - val_loss: 0.1774 - val_acc: 0.9345\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.94720\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 30s 490us/step - loss: 0.0672 - acc: 0.9721 - val_loss: 0.1693 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.94720\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 29s 485us/step - loss: 0.0650 - acc: 0.9727 - val_loss: 0.1859 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.94720\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 29s 477us/step - loss: 0.0643 - acc: 0.9731 - val_loss: 0.1585 - val_acc: 0.9470\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.94720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 08:22:02,844 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 08:22:02,846 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 08:22:02,848 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 08:22:02,853 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 08:22:02,857 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 08:22:02,861 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 08:22:02,865 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 08:22:02,868 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 08:22:02,870 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 08:22:02,874 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 08:22:02,878 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 08:22:02,882 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 08:22:02,885 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 08:22:02,888 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 08:22:02,892 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 08:22:02,896 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 08:22:02,898 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 08:22:02,903 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 08:22:02,907 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 08:22:02,911 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 08:22:02,916 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 08:22:02,919 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 08:22:02,923 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 08:22:02,925 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 08:22:02,930 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 08:22:02,934 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 08:22:02,938 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 33s 552us/step - loss: 0.1285 - acc: 0.9485 - val_loss: 0.1445 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94570, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "23008/60597 [==========>...................] - ETA: 17s - loss: 0.1018 - acc: 0.9584"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 29s 475us/step - loss: 0.0786 - acc: 0.9678 - val_loss: 0.1392 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95145\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 29s 479us/step - loss: 0.0767 - acc: 0.9683 - val_loss: 0.1445 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95145\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 28s 470us/step - loss: 0.0742 - acc: 0.9693 - val_loss: 0.1405 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95145\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 29s 471us/step - loss: 0.0729 - acc: 0.9696 - val_loss: 0.1504 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95145\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 28s 467us/step - loss: 0.0715 - acc: 0.9704 - val_loss: 0.1474 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.95145\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 28s 468us/step - loss: 0.0698 - acc: 0.9710 - val_loss: 0.1497 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.95145\n",
      "Epoch 13/40\n",
      "60224/60597 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9720"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 29s 475us/step - loss: 0.0626 - acc: 0.9738 - val_loss: 0.1587 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.95852\n",
      "Epoch 20/40\n",
      "60597/60597 [==============================] - 29s 480us/step - loss: 0.0616 - acc: 0.9741 - val_loss: 0.1945 - val_acc: 0.9337\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.95852\n",
      "Epoch 21/40\n",
      "60597/60597 [==============================] - 29s 483us/step - loss: 0.0605 - acc: 0.9746 - val_loss: 0.1737 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.95852\n",
      "Epoch 22/40\n",
      "60597/60597 [==============================] - 29s 480us/step - loss: 0.0605 - acc: 0.9747 - val_loss: 0.1683 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.95852\n",
      "Epoch 23/40\n",
      "60597/60597 [==============================] - 29s 482us/step - loss: 0.0606 - acc: 0.9749 - val_loss: 0.1641 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.95852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 08:34:24,253 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 08:34:24,254 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 08:34:24,257 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 08:34:24,261 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 08:34:24,266 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 08:34:24,270 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 08:34:24,275 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 08:34:24,278 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 08:34:24,280 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 08:34:24,285 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 08:34:24,289 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 08:34:24,294 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 08:34:24,296 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 08:34:24,300 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 08:34:24,305 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 08:34:24,309 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 08:34:24,312 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 08:34:24,317 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 08:34:24,321 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 08:34:24,326 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 08:34:24,330 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 08:34:24,333 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 08:34:24,338 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 08:34:24,340 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 08:34:24,345 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 08:34:24,349 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 08:34:24,353 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 33s 538us/step - loss: 0.1324 - acc: 0.9475 - val_loss: 0.1423 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94989, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "47520/60597 [======================>.......] - ETA: 5s - loss: 0.1060 - acc: 0.9573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60597/60597 [==============================] - 28s 457us/step - loss: 0.0773 - acc: 0.9684 - val_loss: 0.1417 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.95537\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 28s 459us/step - loss: 0.0757 - acc: 0.9690 - val_loss: 0.1445 - val_acc: 0.9498\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.95537\n",
      "Epoch 10/40\n",
      "59520/60597 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9698"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-d94e87965269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mfit_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/seals/deepvideoclassification/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, path_model, learning_rate, epochs, batch_size, patience, verbose)\u001b[0m\n\u001b[1;32m    794\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m               verbose=verbose)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layer_1_sizes = [512,256,128,64,32,16]\n",
    "layer_2_sizes = [512,256,128,64,32,16]\n",
    "layer_3_sizes = [512,256,128,64,32,16]\n",
    "dropouts = [0.2]\n",
    "\n",
    "# IMAGE_MLP_FROZEN\n",
    "model_id = 0\n",
    "for pretrained_model_name in pretrained_model_names:\n",
    "    for layer_1_size in layer_1_sizes:\n",
    "        for layer_2_size in layer_2_sizes:\n",
    "            for layer_3_size in layer_3_sizes:\n",
    "                for dropout in dropouts:\n",
    "                    \n",
    "                    data = Data(sequence_length = 1, \n",
    "                                return_CNN_features = True, \n",
    "                                pretrained_model_name=pretrained_model_name,\n",
    "                                pooling = pooling)\n",
    "\n",
    "                    architecture = Architecture(architecture=\"image_MLP_frozen\", \n",
    "                                                sequence_length = 1,\n",
    "                                                num_classes = data.num_classes, \n",
    "                                                frame_size = data.frame_size, \n",
    "                                                pretrained_model_name=pretrained_model_name, \n",
    "                                                pooling='max',\n",
    "                                                layer_1_size=layer_1_size, \n",
    "                                                layer_2_size=layer_2_size, \n",
    "                                                layer_3_size=layer_3_size, \n",
    "                                                dropout=dropout)\n",
    "\n",
    "                    path_model = pwd+'models/' + str(model_id) + '_'\n",
    "\n",
    "                    # train model\n",
    "                    fit_history = train(architecture.model, data, path_model = path_model, learning_rate = 0.001, epochs = 40)\n",
    "\n",
    "                    results = {}\n",
    "                    results['fit_val_acc'] = fit_history.history['val_acc'][-1]\n",
    "                    results['fit_train_acc'] = fit_history.history['acc'][-1]\n",
    "                    results['fit_val_loss'] = fit_history.history['val_loss'][-1]\n",
    "                    results['fit_train_loss'] = fit_history.history['loss'][-1]\n",
    "                    results['model_id'] = str(model_id)\n",
    "\n",
    "                    results['pretrained_model_name'] = pretrained_model_name\n",
    "                    results['layer_1_size'] = layer_1_size\n",
    "                    results['layer_2_size'] = layer_2_size\n",
    "                    results['layer_3_size'] = layer_3_size\n",
    "                    results['dropout'] = dropout\n",
    "\n",
    "                    with open(path_model + 'results.json', 'w') as fp:\n",
    "                        json.dump(results, fp)\n",
    "                        \n",
    "                    model_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T08:40:16.422639Z",
     "start_time": "2019-01-15T22:39:46.797Z"
    }
   },
   "outputs": [],
   "source": [
    "# VIDEO_LRCNN_FROZEN\n",
    "# IMAGE_MLP_FROZEN\n",
    "\n",
    "\n",
    "\n",
    "layer_1_sizes = [512,256,128,64,32,16]\n",
    "layer_2_sizes = [512,256,128,64,32,16]\n",
    "layer_3_sizes = [512,256,128,64,32,16]\n",
    "dropouts = [0.2]\n",
    "sequence_model_layers = [1,2,3]\n",
    "sequence_lengths = [3,5,10,20]\n",
    "sequence_models = ['LSTM', 'SimpleRNN', 'GRU', 'Convolution1D']\n",
    "\n",
    "# for pretrained_model_name in pretrained_model_names:\n",
    "pretrained_model_name = 'vgg16'\n",
    "for layer_1_size in layer_1_sizes:\n",
    "    for layer_2_size in layer_2_sizes:\n",
    "        for layer_3_size in layer_3_sizes:\n",
    "            for dropout in dropouts:\n",
    "                for sequence_model in sequence_models:\n",
    "                    for sequence_model_layer in sequence_model_layers:\n",
    "                        for sequence_length in sequence_lengths:\n",
    "\n",
    "                            data = Data(sequence_length = sequence_length, \n",
    "                                        return_CNN_features = True, \n",
    "                                        pretrained_model_name=pretrained_model_name,\n",
    "                                        pooling = pooling)\n",
    "\n",
    "                            architecture = Architecture(architecture=\"video_LRCNN_frozen\", \n",
    "                                                        sequence_model = 'LSTM',\n",
    "                                                        sequence_model_layers = 1,\n",
    "                                                        sequence_length = sequence_length,\n",
    "                                                        num_classes = data.num_classes, \n",
    "                                                        frame_size = data.frame_size, \n",
    "                                                        pretrained_model_name='vgg16', \n",
    "                                                        pooling='max',\n",
    "                                                        layer_1_size=64, \n",
    "                                                        layer_2_size=32, \n",
    "                                                        layer_3_size=8, \n",
    "                                                        dropout=0.2,\n",
    "                                                        convolution_kernel_size=3)\n",
    "\n",
    "                            path_model = pwd+'models/' + str(model_id) + '_'\n",
    "                            \n",
    "                            # train model\n",
    "                            fit_history = train(architecture.model, data, path_model = path_model, learning_rate = 0.001, epochs = 40)\n",
    "                            \n",
    "                            results = {}\n",
    "                            results['fit_val_acc'] = fit_history.history['val_acc'][-1]\n",
    "                            results['fit_train_acc'] = fit_history.history['acc'][-1]\n",
    "                            results['fit_val_loss'] = fit_history.history['val_loss'][-1]\n",
    "                            results['fit_train_loss'] = fit_history.history['loss'][-1]\n",
    "                            results['model_id'] = str(model_id)\n",
    "                            \n",
    "                            results['pretrained_model_name'] = pretrained_model_name\n",
    "                            results['layer_1_size'] = layer_1_size\n",
    "                            results['layer_2_size'] = layer_2_size\n",
    "                            results['layer_3_size'] = layer_3_size\n",
    "                            results['dropout'] = dropout\n",
    "                            results['sequence_model'] = sequence_model\n",
    "                            results['sequence_length'] = sequence_length\n",
    "                            results['sequence_model_layer'] = sequence_model_layer\n",
    "\n",
    "                            with open(path_model + 'results.json', 'w') as fp:\n",
    "                                json.dump(results, fp)\n",
    "                                \n",
    "                            model_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T08:58:24.481548Z",
     "start_time": "2019-01-16T08:46:31.497648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-16 08:46:32,464 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/avg/\n",
      "2019-01-16 08:46:32,465 [MainThread  ] [INFO ]  Loading features data into memory [may take a few minutes]\n",
      "2019-01-16 08:46:32,468 [MainThread  ] [INFO ]  Loading features data into memory: 1/25\n",
      "2019-01-16 08:46:32,473 [MainThread  ] [INFO ]  Loading features data into memory: 2/25\n",
      "2019-01-16 08:46:32,477 [MainThread  ] [INFO ]  Loading features data into memory: 3/25\n",
      "2019-01-16 08:46:32,482 [MainThread  ] [INFO ]  Loading features data into memory: 4/25\n",
      "2019-01-16 08:46:32,486 [MainThread  ] [INFO ]  Loading features data into memory: 5/25\n",
      "2019-01-16 08:46:32,490 [MainThread  ] [INFO ]  Loading features data into memory: 6/25\n",
      "2019-01-16 08:46:32,493 [MainThread  ] [INFO ]  Loading features data into memory: 7/25\n",
      "2019-01-16 08:46:32,498 [MainThread  ] [INFO ]  Loading features data into memory: 8/25\n",
      "2019-01-16 08:46:32,502 [MainThread  ] [INFO ]  Loading features data into memory: 9/25\n",
      "2019-01-16 08:46:32,507 [MainThread  ] [INFO ]  Loading features data into memory: 10/25\n",
      "2019-01-16 08:46:32,510 [MainThread  ] [INFO ]  Loading features data into memory: 11/25\n",
      "2019-01-16 08:46:32,514 [MainThread  ] [INFO ]  Loading features data into memory: 12/25\n",
      "2019-01-16 08:46:32,519 [MainThread  ] [INFO ]  Loading features data into memory: 13/25\n",
      "2019-01-16 08:46:32,525 [MainThread  ] [INFO ]  Loading features data into memory: 14/25\n",
      "2019-01-16 08:46:32,528 [MainThread  ] [INFO ]  Loading features data into memory: 15/25\n",
      "2019-01-16 08:46:32,532 [MainThread  ] [INFO ]  Loading features data into memory: 16/25\n",
      "2019-01-16 08:46:32,537 [MainThread  ] [INFO ]  Loading features data into memory: 17/25\n",
      "2019-01-16 08:46:32,541 [MainThread  ] [INFO ]  Loading features data into memory: 18/25\n",
      "2019-01-16 08:46:32,546 [MainThread  ] [INFO ]  Loading features data into memory: 19/25\n",
      "2019-01-16 08:46:32,549 [MainThread  ] [INFO ]  Loading features data into memory: 20/25\n",
      "2019-01-16 08:46:32,554 [MainThread  ] [INFO ]  Loading features data into memory: 21/25\n",
      "2019-01-16 08:46:32,557 [MainThread  ] [INFO ]  Loading features data into memory: 22/25\n",
      "2019-01-16 08:46:32,562 [MainThread  ] [INFO ]  Loading features data into memory: 23/25\n",
      "2019-01-16 08:46:32,566 [MainThread  ] [INFO ]  Loading features data into memory: 24/25\n",
      "2019-01-16 08:46:32,574 [MainThread  ] [INFO ]  Loading features data into memory: 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60597, 512) (60597, 8) 60597\n",
      "Train on 60597 samples, validate on 6416 samples\n",
      "Epoch 1/40\n",
      "60597/60597 [==============================] - 33s 541us/step - loss: 0.1694 - acc: 0.9350 - val_loss: 0.1695 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.93434, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 2/40\n",
      "60597/60597 [==============================] - 28s 463us/step - loss: 0.1271 - acc: 0.9506 - val_loss: 0.1524 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.93434 to 0.94407, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 3/40\n",
      "60597/60597 [==============================] - 28s 463us/step - loss: 0.1156 - acc: 0.9549 - val_loss: 0.1749 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.94407\n",
      "Epoch 4/40\n",
      "60597/60597 [==============================] - 28s 464us/step - loss: 0.1091 - acc: 0.9577 - val_loss: 0.1614 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.94407\n",
      "Epoch 5/40\n",
      "60597/60597 [==============================] - 29s 471us/step - loss: 0.1054 - acc: 0.9591 - val_loss: 0.1589 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.94407\n",
      "Epoch 6/40\n",
      "60597/60597 [==============================] - 30s 492us/step - loss: 0.1014 - acc: 0.9603 - val_loss: 0.1415 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.94407 to 0.94866, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 7/40\n",
      "60597/60597 [==============================] - 29s 474us/step - loss: 0.0984 - acc: 0.9615 - val_loss: 0.1580 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94866\n",
      "Epoch 8/40\n",
      "60597/60597 [==============================] - 29s 473us/step - loss: 0.0967 - acc: 0.9621 - val_loss: 0.1763 - val_acc: 0.9313\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94866\n",
      "Epoch 9/40\n",
      "60597/60597 [==============================] - 29s 480us/step - loss: 0.0942 - acc: 0.9630 - val_loss: 0.1548 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.94866\n",
      "Epoch 10/40\n",
      "60597/60597 [==============================] - 29s 479us/step - loss: 0.0931 - acc: 0.9633 - val_loss: 0.1668 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.94866\n",
      "Epoch 11/40\n",
      "60597/60597 [==============================] - 30s 488us/step - loss: 0.0920 - acc: 0.9636 - val_loss: 0.1557 - val_acc: 0.9439\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.94866\n",
      "Epoch 12/40\n",
      "60597/60597 [==============================] - 31s 504us/step - loss: 0.0899 - acc: 0.9644 - val_loss: 0.1494 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.94866 to 0.94901, saving model to /mnt/seals/models/model.h5\n",
      "Epoch 13/40\n",
      "60597/60597 [==============================] - 30s 489us/step - loss: 0.0887 - acc: 0.9647 - val_loss: 0.1575 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94901\n",
      "Epoch 14/40\n",
      "60597/60597 [==============================] - 29s 485us/step - loss: 0.0886 - acc: 0.9649 - val_loss: 0.1742 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.94901\n",
      "Epoch 15/40\n",
      "60597/60597 [==============================] - 29s 479us/step - loss: 0.0869 - acc: 0.9654 - val_loss: 0.1811 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.94901\n",
      "Epoch 16/40\n",
      "60597/60597 [==============================] - 29s 473us/step - loss: 0.0860 - acc: 0.9658 - val_loss: 0.1693 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.94901\n",
      "Epoch 17/40\n",
      "60597/60597 [==============================] - 29s 474us/step - loss: 0.0848 - acc: 0.9663 - val_loss: 0.1717 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.94901\n",
      "Epoch 18/40\n",
      "60597/60597 [==============================] - 29s 475us/step - loss: 0.0846 - acc: 0.9662 - val_loss: 0.1868 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.94901\n",
      "Epoch 19/40\n",
      "60597/60597 [==============================] - 29s 472us/step - loss: 0.0838 - acc: 0.9665 - val_loss: 0.1560 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.94901\n",
      "Epoch 20/40\n",
      "60597/60597 [==============================] - 28s 459us/step - loss: 0.0826 - acc: 0.9672 - val_loss: 0.1706 - val_acc: 0.9345\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.94901\n",
      "Epoch 21/40\n",
      "60597/60597 [==============================] - 28s 468us/step - loss: 0.0833 - acc: 0.9666 - val_loss: 0.1786 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.94901\n",
      "Epoch 22/40\n",
      "60597/60597 [==============================] - 29s 473us/step - loss: 0.0821 - acc: 0.9672 - val_loss: 0.1861 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.94901\n"
     ]
    }
   ],
   "source": [
    "data = Data(sequence_length = 1, \n",
    "            return_CNN_features = True, \n",
    "            pretrained_model_name=pretrained_model_name,\n",
    "            pooling = pooling)\n",
    "\n",
    "architecture = Architecture(architecture=\"image_MLP_frozen\", \n",
    "                            sequence_length = 1,\n",
    "                            num_classes = data.num_classes, \n",
    "                            frame_size = data.frame_size, \n",
    "                            pretrained_model_name=pretrained_model_name, \n",
    "                            pooling='max',\n",
    "                            layer_1_size=64, \n",
    "                            layer_2_size=32, \n",
    "                            layer_3_size=16, \n",
    "                            dropout=dropout)\n",
    "\n",
    "fit_history = train(architecture.model, data, path_model = path_model, learning_rate = 0.001, epochs = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T08:44:04.283348Z",
     "start_time": "2019-01-16T08:44:04.247241Z"
    }
   },
   "outputs": [],
   "source": [
    "path_models = pwd + 'models/'\n",
    "\n",
    "results = []\n",
    "\n",
    "for folder, subs, files in os.walk(path_models):        \n",
    "    for filename in files:\n",
    "        if 'results.json' in filename:\n",
    "            with open(os.path.abspath(os.path.join(folder, filename))) as f:\n",
    "                data = json.load(f)\n",
    "            results.append(data)\n",
    "\n",
    "results = pd.DataFrame(results)        \n",
    "results.sort_values(\"fit_val_acc\", inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T08:44:10.870834Z",
     "start_time": "2019-01-16T08:44:10.851535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>fit_train_acc</th>\n",
       "      <th>fit_train_loss</th>\n",
       "      <th>fit_val_acc</th>\n",
       "      <th>fit_val_loss</th>\n",
       "      <th>layer_1_size</th>\n",
       "      <th>layer_2_size</th>\n",
       "      <th>layer_3_size</th>\n",
       "      <th>model_id</th>\n",
       "      <th>pretrained_model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.971226</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.952638</td>\n",
       "      <td>0.134846</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.974475</td>\n",
       "      <td>0.061214</td>\n",
       "      <td>0.951761</td>\n",
       "      <td>0.168835</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>6</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.971946</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.951488</td>\n",
       "      <td>0.157837</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.975558</td>\n",
       "      <td>0.059033</td>\n",
       "      <td>0.951488</td>\n",
       "      <td>0.154643</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>56</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.971962</td>\n",
       "      <td>0.068007</td>\n",
       "      <td>0.950261</td>\n",
       "      <td>0.159397</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.972552</td>\n",
       "      <td>0.067255</td>\n",
       "      <td>0.949306</td>\n",
       "      <td>0.143501</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>512</td>\n",
       "      <td>66</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.972012</td>\n",
       "      <td>0.067722</td>\n",
       "      <td>0.948878</td>\n",
       "      <td>0.156286</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.971412</td>\n",
       "      <td>0.069901</td>\n",
       "      <td>0.948819</td>\n",
       "      <td>0.149474</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>70</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.977249</td>\n",
       "      <td>0.058907</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.175842</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.972045</td>\n",
       "      <td>0.068718</td>\n",
       "      <td>0.947767</td>\n",
       "      <td>0.171876</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dropout  fit_train_acc  fit_train_loss  fit_val_acc  fit_val_loss  \\\n",
       "38      0.2       0.971226        0.069500     0.952638      0.134846   \n",
       "53      0.2       0.974475        0.061214     0.951761      0.168835   \n",
       "33      0.2       0.971946        0.068300     0.951488      0.157837   \n",
       "12      0.2       0.975558        0.059033     0.951488      0.154643   \n",
       "50      0.2       0.971962        0.068007     0.950261      0.159397   \n",
       "66      0.2       0.972552        0.067255     0.949306      0.143501   \n",
       "0       0.2       0.972012        0.067722     0.948878      0.156286   \n",
       "9       0.2       0.971412        0.069901     0.948819      0.149474   \n",
       "74      0.2       0.977249        0.058907     0.947826      0.175842   \n",
       "32      0.2       0.972045        0.068718     0.947767      0.171876   \n",
       "\n",
       "    layer_1_size  layer_2_size  layer_3_size model_id pretrained_model_name  \n",
       "38           256            64            32       58                 vgg16  \n",
       "53           512           256           512        6                 vgg16  \n",
       "33           512           128            16       17                 vgg16  \n",
       "12           256            64           128       56                 vgg16  \n",
       "50           512           256            16       11                 vgg16  \n",
       "66           256            16           512       66                 vgg16  \n",
       "0            512            64            16       23                 vgg16  \n",
       "9            256            16            32       70                 vgg16  \n",
       "74           512            16            64       33                 vgg16  \n",
       "32           256            32            16       65                 vgg16  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T08:44:15.474978Z",
     "start_time": "2019-01-16T08:44:15.456761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>fit_train_acc</th>\n",
       "      <th>fit_train_loss</th>\n",
       "      <th>fit_val_acc</th>\n",
       "      <th>fit_val_loss</th>\n",
       "      <th>layer_1_size</th>\n",
       "      <th>layer_2_size</th>\n",
       "      <th>layer_3_size</th>\n",
       "      <th>model_id</th>\n",
       "      <th>pretrained_model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.975151</td>\n",
       "      <td>0.061158</td>\n",
       "      <td>0.936428</td>\n",
       "      <td>0.198180</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.972026</td>\n",
       "      <td>0.067342</td>\n",
       "      <td>0.936370</td>\n",
       "      <td>0.164086</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>49</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.975968</td>\n",
       "      <td>0.058809</td>\n",
       "      <td>0.936370</td>\n",
       "      <td>0.168331</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.972651</td>\n",
       "      <td>0.066966</td>\n",
       "      <td>0.935084</td>\n",
       "      <td>0.182124</td>\n",
       "      <td>512</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.970487</td>\n",
       "      <td>0.073108</td>\n",
       "      <td>0.934987</td>\n",
       "      <td>0.188097</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>71</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.972385</td>\n",
       "      <td>0.066343</td>\n",
       "      <td>0.934285</td>\n",
       "      <td>0.170115</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>42</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.975663</td>\n",
       "      <td>0.058246</td>\n",
       "      <td>0.931811</td>\n",
       "      <td>0.228911</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>54</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.972837</td>\n",
       "      <td>0.065532</td>\n",
       "      <td>0.929668</td>\n",
       "      <td>0.175158</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>21</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.977093</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.928480</td>\n",
       "      <td>0.199443</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.974634</td>\n",
       "      <td>0.060648</td>\n",
       "      <td>0.926395</td>\n",
       "      <td>0.222550</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dropout  fit_train_acc  fit_train_loss  fit_val_acc  fit_val_loss  \\\n",
       "62      0.2       0.975151        0.061158     0.936428      0.198180   \n",
       "72      0.2       0.972026        0.067342     0.936370      0.164086   \n",
       "47      0.2       0.975968        0.058809     0.936370      0.168331   \n",
       "69      0.2       0.972651        0.066966     0.935084      0.182124   \n",
       "41      0.2       0.970487        0.073108     0.934987      0.188097   \n",
       "55      0.2       0.972385        0.066343     0.934285      0.170115   \n",
       "7       0.2       0.975663        0.058246     0.931811      0.228911   \n",
       "26      0.2       0.972837        0.065532     0.929668      0.175158   \n",
       "43      0.2       0.977093        0.054135     0.928480      0.199443   \n",
       "39      0.2       0.974634        0.060648     0.926395      0.222550   \n",
       "\n",
       "    layer_1_size  layer_2_size  layer_3_size model_id pretrained_model_name  \n",
       "62           512            16            32       34                 vgg16  \n",
       "72           256           128           256       49                 vgg16  \n",
       "47           256            16            64       69                 vgg16  \n",
       "69           512            32            32       28                 vgg16  \n",
       "41           256            16            16       71                 vgg16  \n",
       "55           256           256           512       42                 vgg16  \n",
       "7            256            64           512       54                 vgg16  \n",
       "26           512            64            64       21                 vgg16  \n",
       "43           512           128            32       16                 vgg16  \n",
       "39           512           256           128        8                 vgg16  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
