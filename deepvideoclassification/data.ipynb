{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:59:33.995413Z",
     "start_time": "2019-01-05T23:59:33.991339Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:07:16.372514Z",
     "start_time": "2019-01-05T23:07:15.575792Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T22:05:26.922264Z",
     "start_time": "2019-01-05T22:05:26.918661Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T22:05:27.245492Z",
     "start_time": "2019-01-05T22:05:27.241046Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T22:06:51.345073Z",
     "start_time": "2019-01-05T22:06:51.326801Z"
    }
   },
   "outputs": [],
   "source": [
    "# read vid folders\n",
    "def get_video_paths():\n",
    "    \"\"\"\n",
    "    Return list of video paths \n",
    "\n",
    "    Videos should be in /data/video_1/, /data/video_2/ style folders \n",
    "    with sequentially numbered frame images e.g. /data/video_1/frame00001.jpg\n",
    "\n",
    "    There should be at least 3 videos, 1 for each of train/test/valid splits\n",
    "    Split assignment is given in /data/labels.csv (also to be provided by user)\n",
    "\n",
    "    Functionality to use different parts of a video as train/valid/test \n",
    "    not currently implemented.\n",
    "    \"\"\"\n",
    "    path_videos = []\n",
    "    for filename in os.listdir(path_data):\n",
    "        if os.path.isdir(os.path.join(path_data, filename)):\n",
    "            path_videos.append(filename)\n",
    "\n",
    "    path_videos = [path_data + v + '/' for v in path_videos]\n",
    "\n",
    "    # make sure that there is video data in /data/ and give instructions if not done correctly\n",
    "    assert len(path_videos)>0, \"There need to be at least 3 video folders (at least 1 for each of train, valid, \\\n",
    "    and test splits) in /data/ - each video should be its own folder of frame images with ascending time-ordered \\\n",
    "    filenames e.g. /data/vid1/frame00001.jpg ... videos assignment to train/valid/test split should be given in \\\n",
    "    /data/labels.csv ... cross-validation or train/valid/test splits within a single long video not currently implemented\"\n",
    "\n",
    "    return path_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:59:40.242433Z",
     "start_time": "2019-01-05T23:59:40.233479Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_frames(target_size):\n",
    "    \"\"\"\n",
    "    Resize the frames of all videos and save them to /cache/ \n",
    "    to make model fitting faster .\n",
    "\n",
    "    We resize once upfront rather than each we use a pretrained model or architecture.\n",
    "\n",
    "    Our models require inputs resized to:\n",
    "    * 224 x 224 VGG16, ResNet50, DenseNet, MobileNet\n",
    "    * 299 x 299 XCeption, InceptionV3, InceptionResNetV2\n",
    "    * 112 x 112 3D CNN \n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path_cache + 'frames/' + str(target_size[0]) + \"_\" + str(target_size[1]) + '/'):\n",
    "\n",
    "        # read vid paths\n",
    "        path_videos = get_video_paths()\n",
    "\n",
    "        # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "        for c,path_video in enumerate(path_videos):\n",
    "\n",
    "            logger.info(\"resizing vid {}/{} to {}x{}\".format(c+1,len(path_videos),target_size[0], target_size[1]))\n",
    "\n",
    "            # get vid name from path\n",
    "            video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "            # create directory for resized frames\n",
    "            # e.g. path_vid_resized = /cache/frames/224_224/s23-4847/\n",
    "            path_vid_resized = path_cache + 'frames/'\n",
    "            path_vid_resized += str(target_size[0]) + \"_\" + str(target_size[1]) + '/' \n",
    "            path_vid_resized += video_name + '/'\n",
    "            if not os.path.exists(path_vid_resized):\n",
    "                os.makedirs(path_vid_resized)\n",
    "\n",
    "            # load frame paths for vid\n",
    "            path_frames = os.listdir(path_vid)\n",
    "            path_frames = [path_video + f for f in path_frames if f != '.DS_Store']\n",
    "            path_frames.sort()\n",
    "\n",
    "            # load frames\n",
    "            frames = []\n",
    "            for path_frame in path_frames:\n",
    "\n",
    "                # open image and resize\n",
    "                filename = path_frame.split(\"/\").pop()\n",
    "                img_frame = Image.open(path_frame)\n",
    "                img_frame = img_frame.resize(target_size)\n",
    "                # img_frame.save(path_vid_resized + filename, \"JPEG\", quality = 100)\n",
    "\n",
    "                # convert to array and append to list\n",
    "                img_frame = np.array(img_frame)\n",
    "                frames.append(img_frame)\n",
    "\n",
    "            # save array of resized frames\n",
    "            np.save(\"/mnt/seals/cache/frames/\" + str(target_size[0]) + \"_\" + str(target_size[1]) + \"/\" + video_name, np.array(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:59:42.855180Z",
     "start_time": "2019-01-05T23:59:42.850066Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    # read labels - should be CSV with columns \"video\",\"frame\",\"label\",\"split\"\n",
    "    # e.g. \"s1-218\", \"s1-218-00001.jpeg\", \"noseal\", \"train\"\n",
    "    labels = None\n",
    "    try:\n",
    "        labels = pd.read_csv(path_data + 'labels.csv', usecols=['video','frame','label','split'])\n",
    "    except ValueError as e:\n",
    "        raise Exception(\"Labels file must contain columns ['video','frame','label','split'] - if you only have ['video','frame','label'], use the helper function add_splits_to_labels_file to add train/valid/test splits to your labels file\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise Exception(\"No labels found - please save labels file to /data/labels.csv\") from e\n",
    "\n",
    "    return labels.sort_values([\"video\",\"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:59:43.291872Z",
     "start_time": "2019-01-05T23:59:43.282633Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_video_label_arrays():\n",
    "    \"\"\"\n",
    "    Create numpy array with labels for each vid and a label_map.json file\n",
    "    in /cache/labels/\n",
    "    \"\"\"\n",
    "\n",
    "    # create folder for labels\n",
    "    if not os.path.exists(path_cache + 'labels/'):\n",
    "        os.makedirs(path_cache + 'labels/')\n",
    "\n",
    "    # load labels\n",
    "    labels = get_labels()\n",
    "\n",
    "    # build label_map\n",
    "    label_dummies = pd.get_dummies(labels, columns = ['label'])\n",
    "\n",
    "    # get label columns list and build label map dict\n",
    "    label_columns = []\n",
    "    label_map = {}\n",
    "    label_map_idx = 0\n",
    "    for i, col in enumerate(label_dummies.columns):\n",
    "        if col[:6] == 'label_':\n",
    "            label_columns.append(col)\n",
    "            label_map[label_map_idx] = col\n",
    "            label_map_idx+=1\n",
    "\n",
    "    # save label map to json\n",
    "    with open(path_cache + 'labels/label_map.json', 'w') as fp:\n",
    "        json.dump(label_map, fp)\n",
    "\n",
    "    # get video paths\n",
    "    path_videos = get_video_paths()\n",
    "\n",
    "    # save numpy array of labels for each vid\n",
    "    for path_video in path_videos:\n",
    "\n",
    "        # get vid name from path\n",
    "        video_name = path_video.split(\"/\")[-2]\n",
    "\n",
    "        vid_labels = np.array(label_dummies[label_dummies['video'] == video_name][label_columns])\n",
    "\n",
    "        # save labels array for this vid\n",
    "        np.save(\"/mnt/seals/cache/labels/\" + video_name, np.array(vid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:59:43.772621Z",
     "start_time": "2019-01-05T23:59:43.766844Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_label_map():\n",
    "    \"\"\"\n",
    "    Returns label map - read from disk\n",
    "    \"\"\"\n",
    "\n",
    "    # load label map from disk\n",
    "    label_map = None\n",
    "    try:\n",
    "        if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "            with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                label_map = json.load(fp)\n",
    "        else:\n",
    "            # build labels and label map\n",
    "            create_video_label_arrays()\n",
    "            if os.path.exists(path_cache + 'labels/label_map.json'):\n",
    "                with open(path_cache + 'labels/label_map.json', 'r') as fp:\n",
    "                    label_map = json.load(fp)\n",
    "    except Exception as e:\n",
    "        logger.error ('label map not found - make sure /data/labels.csv exists and data cache has been built')\n",
    "\n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:59:44.373565Z",
     "start_time": "2019-01-05T23:59:44.365973Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_model(pretrained_model_name, pooling):\n",
    "    \"\"\" Load pretrained model with given pooling applied\n",
    "    \n",
    "    Args:\n",
    "        pretrained_model: name of pretrained model [\"Xception\", \"VGG16\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNetV2\"]\n",
    "        pooling: pooling strategy for final pretrained model layer [\"max\",\"avg\"]\n",
    "    \n",
    "    Returns:\n",
    "        Pretrained model object (excluding dense softmax 1000 ImageNet classes layer)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize output\n",
    "    model = None\n",
    "    \n",
    "    ###########################\n",
    "    ### import pretrained model\n",
    "    ###########################\n",
    "    if pretrained_model_name == \"xception\":   \n",
    "        from keras.applications.xception import Xception\n",
    "        model = Xception(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"vgg16\":   \n",
    "        from keras.applications.vgg16 import VGG16\n",
    "        model = VGG16(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"resnet50\":   \n",
    "        from keras.applications.resnet50 import ResNet50\n",
    "        model = ResNet50(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"inception_v3\":   \n",
    "        from keras.applications.inception_v3 import InceptionV3\n",
    "        model = InceptionV3(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"inception_resnet_v2\":   \n",
    "        from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "        model = InceptionResNetV2(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    elif pretrained_model_name == \"mobilenetv2_1.00_224\":   \n",
    "        from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "        model = MobileNetV2(include_top=False, weights='imagenet', pooling=pooling)\n",
    "    else:\n",
    "        raise NameError('Invalid pretrained model name - must be one of [\"Xception\", \"VGG16\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNetV2\"]')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:59:45.493545Z",
     "start_time": "2019-01-05T23:59:45.488365Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_model_preprocessor(pretrained_model_name):\n",
    "    \"\"\"\n",
    "    Return preprocessing function for a given pretrained model\n",
    "    \"\"\"\n",
    "\n",
    "    preprocess_input = None\n",
    "    \n",
    "    if pretrained_model_name == \"xception\":   \n",
    "        from keras.applications.xception import preprocess_input\n",
    "    elif pretrained_model_name == \"vgg16\":   \n",
    "        from keras.applications.vgg16 import preprocess_input\n",
    "    elif pretrained_model_name == \"resnet50\":   \n",
    "        from keras.applications.resnet50 import preprocess_input\n",
    "    elif pretrained_model_name == \"inception_v3\":   \n",
    "        from keras.applications.inception_v3 import preprocess_input\n",
    "    elif pretrained_model_name == \"inception_resnet_v2\":   \n",
    "        from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "    elif pretrained_model_name == \"mobilenetv2_1.00_224\":   \n",
    "        from keras.applications.mobilenet_v2 import preprocess_input\n",
    "    else:\n",
    "        raise NameError('Invalid pretrained model name - must be one of [\"Xception\", \"VGG16\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNetV2\"]')\n",
    "        \n",
    "    return preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:59:46.235218Z",
     "start_time": "2019-01-05T23:59:46.230195Z"
    }
   },
   "outputs": [],
   "source": [
    "# define pretrained model shapes\n",
    "pretrained_model_shapes = {}\n",
    "#\n",
    "pretrained_model_shapes['vgg16'] = (224,224)\n",
    "pretrained_model_shapes['resnet50'] = (224,224)\n",
    "pretrained_model_shapes['mobilenetv2_1.00_224'] = (224,224)\n",
    "#\n",
    "pretrained_model_shapes['xception'] = (299,299)\n",
    "pretrained_model_shapes['inception_v3'] = (299,299)\n",
    "pretrained_model_shapes['inception_resnet_v2'] = (299,299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T23:31:03.924575Z",
     "start_time": "2019-01-05T23:31:03.914482Z"
    }
   },
   "outputs": [],
   "source": [
    "def precompute_CNN_features(pretrained_model_name, pooling):\n",
    "    \"\"\" Save pretrained features array computed over all frames of each video using given pretrained model and pooling method\n",
    "    \n",
    "    Args:\n",
    "        pretrained_model_name: pretrained model object loaded using `load_pretrained_model`\n",
    "        pooling: pooling method used with pretrained model\n",
    "    \n",
    "    Returns:\n",
    "        None. Saves pretrained frames to `/cache/features/*pretrained_model_name*/*pooling*/*video_name*.npy`\n",
    "    \"\"\"\n",
    "    \n",
    "    # load pretrained model\n",
    "    pretrained_model = load_pretrained_model(pretrained_model_name, pooling)\n",
    "    \n",
    "    # load preprocessing function\n",
    "    preprocess_input = load_pretrained_model_preprocessor(pretrained_model_name)\n",
    "    \n",
    "    # lookup pretrained model input shape\n",
    "    model_input_shape = pretrained_model_shapes[pretrained_model_name]\n",
    "    \n",
    "    # setup path to save featuers\n",
    "    path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "    if not os.path.exists(path_features):\n",
    "        os.makedirs(path_features)\n",
    "        \n",
    "    path_videos = get_video_paths()\n",
    "    \n",
    "    for c, path_video in enumerate(path_videos):\n",
    "        \n",
    "        if verbose:\n",
    "            logging.info(\"Computing pretrained model features for video {}/{} using pretrained model: {}, pooling: {}\".format(c+1,len(path_videos),pretrained_model_name, pooling))\n",
    "        \n",
    "        # get video name from video path\n",
    "        video_name = path_video.split(\"/\")[-2]\n",
    "    \n",
    "        # build output path\n",
    "        path_output = path_features + video_name\n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(path_output + '.npy'):\n",
    "\n",
    "                path_frames = path_data + video_name + \"/\"\n",
    "\n",
    "                # initialize features list\n",
    "                features = []\n",
    "\n",
    "                frame_paths = os.listdir(path_frames)\n",
    "                frame_paths = [path_frames + f for f in frame_paths if f != '.DS_Store']\n",
    "\n",
    "                # sort paths in sequence (they were created with incrementing filenames through time)\n",
    "                frame_paths.sort()\n",
    "\n",
    "                # load each frame in vid and get features\n",
    "                for j, frame_path in enumerate(frame_paths):\n",
    "\n",
    "                    # load image & preprocess\n",
    "                    image = cv2.imread(frame_path, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(image, model_input_shape, interpolation=cv2.INTER_AREA)\n",
    "                    img = img_to_array(img)\n",
    "                    img = np.expand_dims(img, axis=0)\n",
    "                    img = preprocess_input(img)\n",
    "\n",
    "                    # get features from pretrained model\n",
    "                    feature = pretrained_model.predict(img).ravel()\n",
    "                    features.append(feature)\n",
    "\n",
    "                # convert to arrays\n",
    "                features = np.array(features)\n",
    "\n",
    "                np.save(path_output, features)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    logger.info(\"Features already cached: {}\".format(path_output))\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(\"Error precomputing features {} / {},{}\".format(video_namepretrained_model_name, pooling))\n",
    "            logging.fatal(e, exc_info=True)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T00:18:05.456865Z",
     "start_time": "2019-01-06T00:18:05.428142Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \n",
    "    def __init__(self, sequence_length, target_size, return_CNN_features = False, \n",
    "                 pretrained_model_name = None, pooling = None, augmentation = False, oversampling = False):\n",
    "        \"\"\"\n",
    "        Data object constructor\n",
    "        \n",
    "        :sequence_length: number of frames in sequence to be returned by Data object\n",
    "        :target_size: size that frames are resized to (different models / architectures accept different input sizes)\n",
    "\n",
    "        :pretrained_model_name: name of pretrained model (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :pooling: name of pooling variant (or None if not using pretrained model e.g. for 3D-CNN)\n",
    "        :return_features: if True then return features (or sequences of feature) from pretrained model, if False then return frames (or sequences of frames)        \n",
    "        :augmentation: whether to apply data augmentation (horizontal flips)\n",
    "        :oversampling: whether to apply oversampling to create class balance\n",
    "        \"\"\"\n",
    "    \n",
    "        # required params\n",
    "        self.sequence_length = sequence_length\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # optional params\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pooling = pooling\n",
    "        self.return_CNN_features = return_CNN_features\n",
    "        self.augmentation = augmentation\n",
    "        self.oversampling = oversampling\n",
    "        \n",
    "        # model data\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_valid = []\n",
    "        self.y_valid = []\n",
    "        # \n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        \n",
    "        ################\n",
    "        ### Prepare data\n",
    "        ################\n",
    "        \n",
    "        # get video paths\n",
    "        self.path_videos = get_video_paths()\n",
    "        \n",
    "        # create label array for each video and load label map\n",
    "        create_video_label_arrays()\n",
    "        self.label_map = load_label_map()\n",
    "        \n",
    "        # get labels\n",
    "        self.labels = get_labels()\n",
    "        \n",
    "        # create dict mapping video to train/valid/test split assignment\n",
    "        video_splits = d.labels[['video','split']].drop_duplicates()\n",
    "        video_splits.set_index(\"video\", inplace=True)\n",
    "        video_splits = video_splits.to_dict()['split']\n",
    "        self.video_splits = video_splits\n",
    "        \n",
    "        # resize frames to correct size if not already resized\n",
    "        resize_frames(target_size)\n",
    "\n",
    "        # pre compute CNN features if not already computed\n",
    "        if return_CNN_features and pretrained_model_name is not None:\n",
    "            precompute_CNN_features(self.pretrained_model_name, self.pooling)\n",
    "        \n",
    "        # load features/frames from all videos and concat into big array for each of train, valid and test\n",
    "        if self.sequence_length > 1:\n",
    "            \n",
    "            ###################\n",
    "            ### frame sequences\n",
    "            ###################\n",
    "            \n",
    "            if return_CNN_features:\n",
    "                \n",
    "                #####################\n",
    "                ### feature sequences\n",
    "                #####################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    features = np.load(path_features + video_name + '.npy')\n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(features) + 1):\n",
    "                        x.append(features[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                        \n",
    "            else:\n",
    "\n",
    "                ###################\n",
    "                ### frame sequences\n",
    "                ###################\n",
    "                \n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.target_size[0]) + \"_\" + str(self.target_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    frames = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    # build sequences\n",
    "                    x = []\n",
    "                    for i in range(sequence_length, len(frames) + 1):\n",
    "                        x.append(frames[i-sequence_length:i])\n",
    "                    x = np.array(x)\n",
    "                    \n",
    "                    \n",
    "                    ### create sequence: features\n",
    "                    # load precomputed features\n",
    "                    labels = np.load(path_labels + video_name + '.npy')     \n",
    "\n",
    "                    # temp lists to store sequences\n",
    "                    y = []\n",
    "                    for i in range(sequence_length, len(labels) + 1):\n",
    "                        y.append(labels[i-1])\n",
    "                    y = (np.array(y))\n",
    "\n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            ###############\n",
    "            ### no sequence\n",
    "            ###############\n",
    "            if return_CNN_features:\n",
    "                \n",
    "                ###################\n",
    "                ### feature vectors\n",
    "                ###################\n",
    "                \n",
    "                path_features = path_cache + 'features/' + pretrained_model_name + \"/\" + pooling + '/'\n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    ### load precomputed features\n",
    "                    x = np.load(path_features + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                    \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            else:\n",
    "                \n",
    "                #################\n",
    "                ### single frames\n",
    "                #################\n",
    "                \n",
    "                path_vid_resized = path_cache + 'frames/'\n",
    "                path_vid_resized += str(self.target_size[0]) + \"_\" + str(self.target_size[1]) + '/' \n",
    "                \n",
    "                path_labels = path_cache + 'labels/'\n",
    "                \n",
    "                # read vid paths\n",
    "                path_videos = get_video_paths()\n",
    "\n",
    "                # loop over all vids and resize frames, saving to new folder in /cache/frames/\n",
    "                for c, path_video in enumerate(path_videos):\n",
    "\n",
    "                    # get vid name from path\n",
    "                    video_name = path_video.split(\"/\")[-2]\n",
    "                    \n",
    "                    # load precomputed numpy arrays for frames and labels\n",
    "                    x = np.load(path_vid_resized  + video_name + '.npy')\n",
    "                    y = np.load(path_labels + video_name + '.npy')\n",
    "                \n",
    "                    ### build output\n",
    "                    if self.video_splits[video_name] == \"train\":\n",
    "                        self.x_train.append(x)\n",
    "                        self.y_train.append(y)\n",
    "                    if self.video_splits[video_name] == \"valid\":\n",
    "                        self.x_valid.append(x)\n",
    "                        self.y_valid.append(y)\n",
    "                    if self.video_splits[video_name] == \"test\":\n",
    "                        self.x_test.append(x)\n",
    "                        self.y_test.append(y)\n",
    "            \n",
    "        ########################\n",
    "        ### reshape list outputs\n",
    "        ########################\n",
    "        ## e.g. (9846, 224, 224, 3) for frames [return_CNN_features=True]\n",
    "        ## or  (9846, 512) for features [return_CNN_features=False]\n",
    "        self.x_train = np.concatenate(self.x_train, axis=0)\n",
    "        self.y_train = np.concatenate(self.y_train, axis=0)\n",
    "        self.x_valid = np.concatenate(self.x_valid, axis=0)\n",
    "        self.y_valid = np.concatenate(self.y_valid, axis=0)\n",
    "        self.x_test = np.concatenate(self.x_test, axis=0)\n",
    "        self.y_test = np.concatenate(self.y_test, axis=0)\n",
    "            \n",
    "\n",
    "        ###########\n",
    "        ### shuffle\n",
    "        ###########\n",
    "        self.x_train, self.y_train = shuffle(self.x_train, self.y_train)\n",
    "        self.x_valid, self.y_valid = shuffle(self.x_valid, self.y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> refactor pretrained model into models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> make sure don't recompute sequences if inputs don't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
