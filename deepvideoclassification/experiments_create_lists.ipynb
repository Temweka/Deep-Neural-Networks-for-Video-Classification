{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:51:14.692911Z",
     "start_time": "2019-01-20T09:51:14.689522Z"
    }
   },
   "outputs": [],
   "source": [
    "WORKER_COUNT = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:45:41.386076Z",
     "start_time": "2019-01-20T09:45:41.382778Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:49:52.619605Z",
     "start_time": "2019-01-20T09:49:52.615287Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:45:42.033749Z",
     "start_time": "2019-01-20T09:45:42.030794Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"deepvideoclassification\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:45:42.686998Z",
     "start_time": "2019-01-20T09:45:42.682022Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:45:45.416064Z",
     "start_time": "2019-01-20T09:45:43.632363Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from deepvideoclassification.architectures import Architecture\n",
    "from deepvideoclassification.pretrained_CNNs import pretrained_model_names, pretrained_model_names_bucketed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create experiments lists and run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* batch 1 = run frozen image MLP, LRCNNs and concat models on 1 of each pretrained_model_name in buckets (bucketed on feature sizes and limited to max sequence_length of 10)\n",
    "\n",
    "* batch 2 = for best configurations from batch 1, run other pretrained models in buckets and run longer sequence lengths\n",
    "\n",
    "* batch 3 = run trainable MLP and LRCNN on best performing frozen variants\n",
    "\n",
    "* batch 4 = run trainable but initializing with best CNN weights\n",
    "\n",
    "* batch 5 = run C3D models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:48:38.803707Z",
     "start_time": "2019-01-20T09:48:38.800613Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_batch_name = 'experiment_batch_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:48:39.107652Z",
     "start_time": "2019-01-20T09:48:39.105052Z"
    }
   },
   "outputs": [],
   "source": [
    "# init list of experiments\n",
    "experiments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:48:39.480232Z",
     "start_time": "2019-01-20T09:48:39.477036Z"
    }
   },
   "outputs": [],
   "source": [
    "pooling = 'max'\n",
    "layer_sizes = [512, 256, 128, 0]\n",
    "dropouts = [0.2]\n",
    "sequence_lengths = [3,5,10]\n",
    "sequence_models = [\"LSTM\", \"SimpleRNN\", \"GRU\", \"Convolution1D\"]\n",
    "sequence_model_layer_counts = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:48:40.492136Z",
     "start_time": "2019-01-20T09:48:40.487109Z"
    }
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### image_MLP_frozen \n",
    "####################\n",
    "\n",
    "for pretrained_model_name in pretrained_model_names_bucketed:\n",
    "    for layer_1_size in layer_sizes:\n",
    "        for layer_2_size in layer_sizes:\n",
    "            for layer_3_size in layer_sizes:\n",
    "                for dropout in dropouts:\n",
    "\n",
    "                    # build experiment parameters\n",
    "                    experiment = {}\n",
    "                    \n",
    "                    experiment['architecture'] = 'image_MLP_frozen'\n",
    "                    experiment['sequence_length'] = 1\n",
    "                    experiment['pretrained_model_name'] = pretrained_model_name\n",
    "                    experiment['layer_1_size'] = layer_1_size\n",
    "                    experiment['layer_2_size'] = layer_2_size\n",
    "                    experiment['layer_3_size'] = layer_3_size\n",
    "                    experiment['dropout'] = dropout\n",
    "                    experiment['pooling'] = 'max' # outperforms avg across all parameters\n",
    "                    \n",
    "                    # add to list of experiments\n",
    "                    experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:48:41.855247Z",
     "start_time": "2019-01-20T09:48:41.849536Z"
    }
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### video_MLP_concat\n",
    "####################\n",
    "\n",
    "for sequence_length in sequence_lengths:\n",
    "    for pretrained_model_name in pretrained_model_names_bucketed:\n",
    "        for layer_1_size in layer_sizes:\n",
    "            for layer_2_size in layer_sizes:\n",
    "                for layer_3_size in layer_sizes:\n",
    "                    for dropout in dropouts:\n",
    "\n",
    "                        # build experiment parameters\n",
    "                        experiment = {}\n",
    "\n",
    "                        experiment['architecture'] = 'video_MLP_concat'\n",
    "                        experiment['pretrained_model_name'] = pretrained_model_name\n",
    "                        experiment['layer_1_size'] = layer_1_size\n",
    "                        experiment['layer_2_size'] = layer_2_size\n",
    "                        experiment['layer_3_size'] = layer_3_size\n",
    "                        experiment['dropout'] = dropout\n",
    "                        experiment['pooling'] = 'max' # outperforms avg across all parameters\n",
    "\n",
    "                        # add to list of experiments\n",
    "                        experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:48:48.533676Z",
     "start_time": "2019-01-20T09:48:48.523899Z"
    }
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### video_LRCNN_frozen\n",
    "######################\n",
    "\n",
    "for sequence_length in sequence_lengths:\n",
    "    for pretrained_model_name in pretrained_model_names_bucketed:\n",
    "        for layer_1_size in layer_sizes:\n",
    "            for layer_2_size in layer_sizes:\n",
    "                for layer_3_size in layer_sizes:\n",
    "                    for dropout in dropouts:\n",
    "                        for sequence_model in sequence_models:\n",
    "                            for sequence_model_layers in sequence_model_layer_counts:\n",
    "\n",
    "                                # build experiment parameters\n",
    "                                experiment = {}\n",
    "\n",
    "                                experiment['architecture'] = 'video_LRCNN_frozen'\n",
    "                                experiment['pretrained_model_name'] = pretrained_model_name\n",
    "                                experiment['layer_1_size'] = layer_1_size\n",
    "                                experiment['layer_2_size'] = layer_2_size\n",
    "                                experiment['layer_3_size'] = layer_3_size\n",
    "                                experiment['dropout'] = dropout\n",
    "                                experiment['pooling'] = 'max' # outperforms avg across all parameters\n",
    "                                experiment['sequence_model'] = sequence_model\n",
    "                                experiment['sequence_model_layers'] = sequence_model_layers\n",
    "\n",
    "                                # add to list of experiments\n",
    "                                experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:48:53.699120Z",
     "start_time": "2019-01-20T09:48:53.680342Z"
    }
   },
   "outputs": [],
   "source": [
    "########################\n",
    "### convert to dataframe\n",
    "########################\n",
    "\n",
    "experiments = pd.DataFrame(experiments)\n",
    "experiments['model_id'] = experiments.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:48:55.005505Z",
     "start_time": "2019-01-20T09:48:54.998010Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments['WORKER'] = experiments['model_id'].apply(lambda x: x % WORKER_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:55:33.090132Z",
     "start_time": "2019-01-20T09:55:33.030523Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments.to_csv(pwd + \"experiments/\" + experiment_batch_name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-20T01:54:17.546Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "### Run experiments\n",
    "###################\n",
    "\n",
    "for row in experiments.values:\n",
    "    \n",
    "    # get experiment params from dataframe row\n",
    "    experiment = dict(zip(experiments.columns, row))\n",
    "    print(experiment)\n",
    "    \n",
    "    # only run experiment if not already run\n",
    "    if not os.path.exists(pwd + 'models/' + str(model_id) + '/results.json'):\n",
    "\n",
    "        logging.info(\"Begin experiment for model_id={}\".format(experiment['model_id']))\n",
    "\n",
    "        architecture = Architecture(model_id = experiment['model_id'], \n",
    "                                    architecture = experiment['architecture'], \n",
    "                                    sequence_length = experiment['sequence_length'], \n",
    "                                    pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                                    pooling = experiment['pooling'],\n",
    "                                    sequence_model = experiment['sequence_model'],\n",
    "                                    sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                                    layer_1_size = experiment['layer_1_size'],\n",
    "                                    layer_2_size = experiment['layer_2_size'],\n",
    "                                    layer_3_size = experiment['layer_3_size'],\n",
    "                                    dropout = experiment['dropout'],\n",
    "                                    verbose=True)\n",
    "\n",
    "        architecture.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T09:54:14.363139Z",
     "start_time": "2019-01-20T09:54:14.359514Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for best configurations from batch 1, run other pretrained models \n",
    "# in buckets and run longer sequence lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run trainable MLP and LRCNN on best performing frozen variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "### image_MLP_trainable\n",
    "#######################\n",
    "\n",
    "architecture = 'video_LRCNN_trainable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "### video_LRCNN_trainable\n",
    "#########################\n",
    "\n",
    "architecture = 'video_LRCNN_trainable'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Batch 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run trainable but initializing with best CNN weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Batch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#######\n",
    "### C3D\n",
    "#######\n",
    "\n",
    "architecture = 'C3D'\n",
    "\n",
    "############\n",
    "### C3Dsmall\n",
    "############\n",
    "\n",
    "architecture = 'C3Dsmall' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.908895Z",
     "start_time": "2019-01-20T00:01:43.447Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_models = pwd + 'models/'\n",
    "\n",
    "results = []\n",
    "\n",
    "for folder, subs, files in os.walk(path_models):\n",
    "    for filename in files:\n",
    "        if 'results.json' in filename:\n",
    "            with open(os.path.abspath(os.path.join(folder, filename))) as f:\n",
    "                data = json.load(f)\n",
    "            results.append(data)\n",
    "\n",
    "results = pd.DataFrame(results)        \n",
    "results.sort_values(\"fit_val_acc\", inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T00:01:47.910098Z",
     "start_time": "2019-01-20T00:01:43.449Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
