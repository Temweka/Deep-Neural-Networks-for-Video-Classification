{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:51:58.953507Z",
     "start_time": "2020-04-14T06:51:58.950801Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:01.107751Z",
     "start_time": "2020-04-14T06:52:00.501570Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "from shutil import rmtree\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:03.214666Z",
     "start_time": "2020-04-14T06:52:01.991546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:03.588456Z",
     "start_time": "2020-04-14T06:52:03.584465Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"notebooks\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:03.598821Z",
     "start_time": "2020-04-14T06:52:03.592099Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:05.766399Z",
     "start_time": "2020-04-14T06:52:03.601834Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.architectures import Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:05.772697Z",
     "start_time": "2020-04-14T06:52:05.769082Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model weights from file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e.g. /models/123/model_best.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:07.623729Z",
     "start_time": "2020-04-14T06:52:07.620220Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 1,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'vgg16',\n",
    "             'sequence_length': 20,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:13.169504Z",
     "start_time": "2020-04-14T06:52:10.780763Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 06:52:10,790 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 256, 'model_id': 1, 'dropout': 0.2, 'sequence_model_layers': 2, 'sequence_length': 20, 'layer_2_size': 512, 'layer_1_size': 256, 'pretrained_model_name': 'vgg16', 'sequence_model': 'LSTM', 'architecture': 'video_lrcnn_frozen', 'pooling': 'max'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 06:52:11,283 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/max/\n",
      "2020-04-14 06:52:11,284 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10034, valid=1285, test=265\n"
     ]
    }
   ],
   "source": [
    "print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "print(experiment)\n",
    "\n",
    "architecture = Architecture(model_id = experiment['model_id'], \n",
    "                            architecture = experiment['architecture'], \n",
    "                            sequence_length = experiment['sequence_length'], \n",
    "                            pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                            pooling = experiment['pooling'],\n",
    "                            sequence_model = experiment['sequence_model'],\n",
    "                            sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                            layer_1_size = experiment['layer_1_size'],\n",
    "                            layer_2_size = experiment['layer_2_size'],\n",
    "                            layer_3_size = experiment['layer_3_size'],\n",
    "                            dropout = experiment['dropout'],\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:13.312781Z",
     "start_time": "2020-04-14T06:52:13.309325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/seals/models/1/model_best.h5\n"
     ]
    }
   ],
   "source": [
    "print(architecture.path_model + \"model_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:28.046674Z",
     "start_time": "2020-04-14T06:52:18.392559Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model weights\n",
    "architecture.model = load_model(architecture.path_model + \"model_best.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and predict on test frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:33.775140Z",
     "start_time": "2020-04-14T06:52:33.771428Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_length = experiment['sequence_length']\n",
    "pretrained_model_name = experiment['pretrained_model_name']\n",
    "pooling = experiment['pooling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:35.417887Z",
     "start_time": "2020-04-14T06:52:34.503880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 06:52:34,781 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/max/\n",
      "2020-04-14 06:52:34,782 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10034, valid=1285, test=265\n"
     ]
    }
   ],
   "source": [
    "# build feature cache if it doesn't already exist\n",
    "data = Data(sequence_length=sequence_length, \n",
    "            return_CNN_features=True,\n",
    "            pretrained_model_name = pretrained_model_name,\n",
    "            pooling=pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:35.424404Z",
     "start_time": "2020-04-14T06:52:35.420855Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:01:05.935907Z",
     "start_time": "2020-04-14T07:01:05.930863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noseal', 'seal']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get class names from data object\n",
    "class_names = []\n",
    "for k in sorted(data.label_map.keys()):\n",
    "    class_names.append(data.label_map[k])\n",
    "class_names = [c.replace(\"label_\",\"\") for c in class_names]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:01:08.628935Z",
     "start_time": "2020-04-14T07:01:08.625010Z"
    }
   },
   "outputs": [],
   "source": [
    "# get list of videos\n",
    "videos = list(labels['video'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:01:09.194671Z",
     "start_time": "2020-04-14T07:01:09.190786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/seals/cache/features/vgg16/max/s1-218.npy\n"
     ]
    }
   ],
   "source": [
    "def get_features_path(video):\n",
    "    return pwd + 'cache/features/' + experiment['pretrained_model_name'] + '/' + experiment['pooling'] + '/' + video + '.npy'\n",
    "print(get_features_path(videos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T07:02:21.805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing frame predictions for video 1/46: s1-218\n",
      "Computing frame predictions for video 2/46: s10-6558\n",
      "Computing frame predictions for video 3/46: s11-7363\n"
     ]
    }
   ],
   "source": [
    "# collect predictions for each video\n",
    "y_preds = []\n",
    "\n",
    "for c, video in enumerate(videos):\n",
    "    print(\"Computing frame predictions for video {}/{}: {}\".format(c+1,len(videos),video))\n",
    "    \n",
    "    # load features from disk\n",
    "    features = np.load(get_features_path(video))\n",
    "\n",
    "    dfs = []\n",
    "    for i in range(sequence_length-1, len(features)):\n",
    "\n",
    "        # get features for the clip\n",
    "        features_frames = features[i-sequence_length+1:i+1,]\n",
    "        features_frames = np.expand_dims(features_frames, axis=0)\n",
    "\n",
    "        # run through model\n",
    "        y_pred = architecture.model.predict(features_frames)\n",
    "\n",
    "        # create pred dataframe\n",
    "        df_pred = pd.DataFrame(y_pred[0]).T\n",
    "        df_pred.columns = class_names\n",
    "        df_pred.index = [i]\n",
    "        dfs.append(df_pred)\n",
    "\n",
    "    # join pred dataframe onto labels\n",
    "    y_pred = pd.concat(dfs)\n",
    "    y_pred['pred'] = y_pred.idxmax(axis=1)\n",
    "    # align labels index\n",
    "    y_labs = labels[labels['video']==video]\n",
    "    y_labs.reset_index(inplace=True,drop=True)\n",
    "    # join predictions on labels\n",
    "    y_pred = pd.merge(y_pred, y_labs, left_index=True,right_index=True,how='left')\n",
    "    y_pred['error'] = (y_pred['label'] != y_pred['pred']).astype(int)\n",
    "    \n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "preds_all = pd.concat(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
