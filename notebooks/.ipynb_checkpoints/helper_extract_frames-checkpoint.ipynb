{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T13:50:12.447437Z",
     "start_time": "2019-01-12T13:50:12.442304Z"
    }
   },
   "source": [
    "Create `data/*vid_name*/` folder with frames for each video in videos and verify the created frames match your `data/labels.csv` file.\n",
    "\n",
    "e.g. `/videos/video_1.MOV` will be converted to `/data/video_1_000001.jpg`, etc.\n",
    "\n",
    "Note: depending on chosen `FPS_OUTPUT`, you may have to extend the number \n",
    "of digits in filename from 06 to something bigger like 09, just update the line in this script that says `_%06d.jpg`\n",
    "\n",
    "Your `labels.csv` file must have frame filenames at the same FPS as the frame files in `/data/`.\n",
    "You can use `notebooks/helper_convert_timestamps_file_to_labels.ipynb` to assist in converting `video,timestamp1,timestamp2,label` style data into `labels.csv`\n",
    "\n",
    "You can use `notebooks/helper_check_frames_against_labels.ipynb` to investigate any mismatch between frame files and `labels.csv`...\n",
    "\n",
    "(You could alternatively use the command line tool `ffmpeg` to extract frames instead of this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:02:57.907515Z",
     "start_time": "2019-01-14T13:02:57.903386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define FPS to extract frames at\n",
    "FPS_OUTPUT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:02:58.119628Z",
     "start_time": "2019-01-14T13:02:58.113101Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from time import time as timer\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:02:58.301286Z",
     "start_time": "2019-01-14T13:02:58.296694Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"notebooks\",\"\")\n",
    "path_videos = pwd + 'videos/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:02:58.470911Z",
     "start_time": "2019-01-14T13:02:58.462621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20150807_no8B_1.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20150820_no8B_2.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20150820_no8B_3.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20150820_no9W_3.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160801_no9_1.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160801_no9_2.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160802_no8_1.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160802_no8_3.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160812_no9_1.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160812_no9_2.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160812_no9_3.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160819_no9_1.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160819_no9_2.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160819_no9_3.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160819_no9_4.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160819_no9_5.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160930_no8_1.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160930_no8_3.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20160930_no8_4.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20161005_no9_1.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20161005_no9_2.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20161005_no9_3.MOV',\n",
       " '/Users/alex/Documents/Work/Thesis/_Video/Deep-Neural-Networks-for-Video-Classification/videos/20161005_no9_4.MOV']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read video paths\n",
    "paths = os.listdir(path_videos)\n",
    "paths = [path_videos + v for v in paths if v != '.DS_Store']\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Frames from Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T13:03:16.220331Z",
     "start_time": "2019-01-14T13:03:03.364315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150807_no8B_1\n",
      "Frames already extracted from video 1/23\n",
      "20150820_no8B_2\n",
      "Frames already extracted from video 2/23\n",
      "20150820_no8B_3\n",
      "Frames already extracted from video 3/23\n",
      "20150820_no9W_3\n",
      "Frames already extracted from video 4/23\n",
      "20160801_no9_1\n",
      "Frames already extracted from video 5/23\n",
      "20160801_no9_2\n",
      "Frames already extracted from video 6/23\n",
      "20160802_no8_1\n",
      "Frames already extracted from video 7/23\n",
      "20160802_no8_3\n",
      "Frames already extracted from video 8/23\n",
      "20160812_no9_1\n",
      "Frames already extracted from video 9/23\n",
      "20160812_no9_2\n",
      "Frames already extracted from video 10/23\n",
      "20160812_no9_3\n",
      "Frames already extracted from video 11/23\n",
      "20160819_no9_1\n",
      "Frames already extracted from video 12/23\n",
      "20160819_no9_2\n",
      "Frames already extracted from video 13/23\n",
      "20160819_no9_3\n",
      "Frames already extracted from video 14/23\n",
      "20160819_no9_4\n",
      "Frames already extracted from video 15/23\n",
      "20160819_no9_5\n",
      "Frames already extracted from video 16/23\n",
      "20160930_no8_1\n",
      "Frames already extracted from video 17/23\n",
      "20160930_no8_3\n",
      "Extracting frames from video 18/23: 20160930_no8_3\n",
      "video FPS 29.819054550303058\n",
      "20160930_no8_4\n",
      "Extracting frames from video 19/23: 20160930_no8_4\n",
      "video FPS 29.81943672897608\n",
      "20161005_no9_1\n",
      "Frames already extracted from video 20/23\n",
      "20161005_no9_2\n",
      "Frames already extracted from video 21/23\n",
      "20161005_no9_3\n",
      "Frames already extracted from video 22/23\n",
      "20161005_no9_4\n",
      "Frames already extracted from video 23/23\n",
      "Done extracting frames from 23 videos\n"
     ]
    }
   ],
   "source": [
    "# create data folder\n",
    "if not os.path.exists(path_data):\n",
    "    os.makedirs(path_data)\n",
    "\n",
    "for c, path in enumerate(paths):\n",
    "\n",
    "    # extract video filename from path\n",
    "    filename = path.split(\"/\")[-1].split(\".\")[0]\n",
    "    print(filename)\n",
    "\n",
    "    if not os.path.exists(path_data + filename):\n",
    "\n",
    "        print(\"Extracting frames from video {}/{}: {}\".format(c+1,len(paths),filename))\n",
    "\n",
    "        # create directory for this video's frames\n",
    "        os.makedirs(path_data + filename)\n",
    "\n",
    "        # open video\n",
    "        vidcap = cv2.VideoCapture(path)\n",
    "\n",
    "        # get fps\n",
    "        print(\"video FPS {}\".format(vidcap.get(cv2.CAP_PROP_FPS)))\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "        fps_savecheck = fps/FPS_OUTPUT\n",
    "\n",
    "        # read frames and save to images at fps_save\n",
    "        success,image = vidcap.read()\n",
    "        count_frame = 0\n",
    "        count_saved = 0\n",
    "        success = True\n",
    "\n",
    "        fps_savecheck_progress = 0\n",
    "\n",
    "        # only extract a subset of frames\n",
    "        while success and count_saved<=100:\n",
    "        # extract all frames\n",
    "            # save frame at desired framerate, indexing filename from 0\n",
    "            if count_frame > fps_savecheck_progress:\n",
    "                cv2.imwrite(path_data + filename + '/' + filename + \"_%06d.jpg\" % count_saved, image)\n",
    "                fps_savecheck_progress += fps_savecheck\n",
    "                count_saved += 1\n",
    "            success,image = vidcap.read()\n",
    "            count_frame += 1\n",
    "\n",
    "        # close video file\n",
    "        vidcap.release()\n",
    "        \n",
    "    else:\n",
    "        print(\"Frames already extracted from video {}/{}\".format(c+1,len(paths)))\n",
    "\n",
    "# Done\n",
    "print(\"Done extracting frames from {} videos\".format(len(paths)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
