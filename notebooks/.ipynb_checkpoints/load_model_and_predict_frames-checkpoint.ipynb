{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:51:58.953507Z",
     "start_time": "2020-04-14T06:51:58.950801Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:01.107751Z",
     "start_time": "2020-04-14T06:52:00.501570Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "from shutil import rmtree\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:03.214666Z",
     "start_time": "2020-04-14T06:52:01.991546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:03.588456Z",
     "start_time": "2020-04-14T06:52:03.584465Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"notebooks\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:03.598821Z",
     "start_time": "2020-04-14T06:52:03.592099Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:05.766399Z",
     "start_time": "2020-04-14T06:52:03.601834Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.architectures import Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:05.772697Z",
     "start_time": "2020-04-14T06:52:05.769082Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model weights from file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e.g. /models/123/model_best.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> enter your experiment parameters below - the trained model and associated parameter files must be in /models/model_id/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:57:51.853484Z",
     "start_time": "2020-04-14T07:57:51.849483Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 1,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'vgg16',\n",
    "             'sequence_length': 20,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:19:53.789639Z",
     "start_time": "2020-04-14T07:19:53.785759Z"
    }
   },
   "outputs": [],
   "source": [
    "# experiment = {\n",
    "#              'architecture': 'image_mlp_frozen',\n",
    "#              'dropout': 0.2,\n",
    "#              'layer_1_size': 128,\n",
    "#              'layer_2_size': 0,\n",
    "#              'layer_3_size': 0,\n",
    "#              'model_id': 6,\n",
    "#              'pooling': 'max',\n",
    "#              'pretrained_model_name': 'resnet50',\n",
    "#              'sequence_length': 1,\n",
    "#              'sequence_model': \"\",\n",
    "#              'sequence_model_layers': \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:54:32.948367Z",
     "start_time": "2020-04-14T07:54:32.944477Z"
    }
   },
   "outputs": [],
   "source": [
    "# experiment = {\n",
    "#              'architecture': 'video_mlp_concat',\n",
    "#              'dropout': 0.2,\n",
    "#              'layer_1_size': 128,\n",
    "#              'layer_2_size': 128,\n",
    "#              'layer_3_size': 512,\n",
    "#              'model_id': 7,\n",
    "#              'pooling': 'max',\n",
    "#              'pretrained_model_name': 'resnet50',\n",
    "#              'sequence_length': 3,\n",
    "#              'sequence_model': \"\",\n",
    "#              'sequence_model_layers': \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:57:57.397975Z",
     "start_time": "2020-04-14T07:57:55.643260Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 07:57:55,646 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 256, 'model_id': 1, 'dropout': 0.2, 'sequence_model_layers': 2, 'sequence_length': 20, 'layer_2_size': 512, 'layer_1_size': 256, 'pretrained_model_name': 'vgg16', 'sequence_model': 'LSTM', 'architecture': 'video_lrcnn_frozen', 'pooling': 'max'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 07:57:55,928 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/max/\n",
      "2020-04-14 07:57:55,929 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10034, valid=1285, test=265\n"
     ]
    }
   ],
   "source": [
    "print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "print(experiment)\n",
    "\n",
    "architecture = Architecture(model_id = experiment['model_id'], \n",
    "                            architecture = experiment['architecture'], \n",
    "                            sequence_length = experiment['sequence_length'], \n",
    "                            pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                            pooling = experiment['pooling'],\n",
    "                            sequence_model = experiment['sequence_model'],\n",
    "                            sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                            layer_1_size = experiment['layer_1_size'],\n",
    "                            layer_2_size = experiment['layer_2_size'],\n",
    "                            layer_3_size = experiment['layer_3_size'],\n",
    "                            dropout = experiment['dropout'],\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:57:57.945725Z",
     "start_time": "2020-04-14T07:57:57.942410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/seals/models/1/model_best.h5\n"
     ]
    }
   ],
   "source": [
    "print(architecture.path_model + \"model_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:04.559173Z",
     "start_time": "2020-04-14T07:57:58.837978Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model weights\n",
    "architecture.model = load_model(architecture.path_model + \"model_best.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and predict on test frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:04.566169Z",
     "start_time": "2020-04-14T07:58:04.562121Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_length = experiment['sequence_length']\n",
    "pretrained_model_name = experiment['pretrained_model_name']\n",
    "pooling = experiment['pooling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.482540Z",
     "start_time": "2020-04-14T07:58:04.568812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 07:58:04,845 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/max/\n",
      "2020-04-14 07:58:04,845 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10034, valid=1285, test=265\n"
     ]
    }
   ],
   "source": [
    "# build feature cache if it doesn't already exist\n",
    "data = Data(sequence_length=sequence_length, \n",
    "            return_CNN_features=True,\n",
    "            pretrained_model_name = pretrained_model_name,\n",
    "            pooling=pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.489544Z",
     "start_time": "2020-04-14T07:58:05.485739Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.499171Z",
     "start_time": "2020-04-14T07:58:05.492471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noseal', 'seal']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get class names from data object\n",
    "class_names = []\n",
    "for k in sorted(data.label_map.keys()):\n",
    "    class_names.append(data.label_map[k])\n",
    "class_names = [c.replace(\"label_\",\"\") for c in class_names]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.506394Z",
     "start_time": "2020-04-14T07:58:05.501739Z"
    }
   },
   "outputs": [],
   "source": [
    "# get list of videos\n",
    "videos = list(labels['video'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.514037Z",
     "start_time": "2020-04-14T07:58:05.509037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/seals/cache/features/vgg16/max/s1-218.npy\n"
     ]
    }
   ],
   "source": [
    "def get_features_path(video):\n",
    "    return pwd + 'cache/features/' + experiment['pretrained_model_name'] + '/' + experiment['pooling'] + '/' + video + '.npy'\n",
    "print(get_features_path(videos[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRCN or video concat frame predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T08:04:08.362929Z",
     "start_time": "2020-04-14T07:58:05.516685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing frame predictions for video 1/46: s1-218\n",
      "Computing frame predictions for video 2/46: s10-6558\n",
      "Computing frame predictions for video 3/46: s11-7363\n",
      "Computing frame predictions for video 4/46: s12-3465\n",
      "Computing frame predictions for video 5/46: s13-14\n",
      "Computing frame predictions for video 6/46: s14-1705\n",
      "Computing frame predictions for video 7/46: s15-2589\n",
      "Computing frame predictions for video 8/46: s16-0\n",
      "Computing frame predictions for video 9/46: s17-2973\n",
      "Computing frame predictions for video 10/46: s18-630\n",
      "Computing frame predictions for video 11/46: s19-672\n",
      "Computing frame predictions for video 12/46: s2-1133\n",
      "Computing frame predictions for video 13/46: s20-842\n",
      "Computing frame predictions for video 14/46: s21-919\n",
      "Computing frame predictions for video 15/46: s22-3733\n",
      "Computing frame predictions for video 16/46: s23-4847\n",
      "Computing frame predictions for video 17/46: s24-5851\n",
      "Computing frame predictions for video 18/46: s25-5886\n",
      "Computing frame predictions for video 19/46: s26-8164\n",
      "Computing frame predictions for video 20/46: s27-8212\n",
      "Computing frame predictions for video 21/46: s28-20\n",
      "Computing frame predictions for video 22/46: s29-316\n",
      "Computing frame predictions for video 23/46: s3-1993\n",
      "Computing frame predictions for video 24/46: s30-516\n",
      "Computing frame predictions for video 25/46: s31-784\n",
      "Computing frame predictions for video 26/46: s32-3110\n",
      "Computing frame predictions for video 27/46: s33-3405\n",
      "Computing frame predictions for video 28/46: s34-3590\n",
      "Computing frame predictions for video 29/46: s35-3664\n",
      "Computing frame predictions for video 30/46: s36-3838\n",
      "Computing frame predictions for video 31/46: s37-3930\n",
      "Computing frame predictions for video 32/46: s38-4060\n",
      "Computing frame predictions for video 33/46: s39-4336\n",
      "Computing frame predictions for video 34/46: s4-6975\n",
      "Computing frame predictions for video 35/46: s40-4508\n",
      "Computing frame predictions for video 36/46: s41-4712\n",
      "Computing frame predictions for video 37/46: s42-4950\n",
      "Computing frame predictions for video 38/46: s43-5211\n",
      "Computing frame predictions for video 39/46: s44-5304\n",
      "Computing frame predictions for video 40/46: s45-6301\n",
      "Computing frame predictions for video 41/46: s46-8087\n",
      "Computing frame predictions for video 42/46: s5-1102\n",
      "Computing frame predictions for video 43/46: s6-1247\n",
      "Computing frame predictions for video 44/46: s7-2029\n",
      "Computing frame predictions for video 45/46: s8-2244\n",
      "Computing frame predictions for video 46/46: s9-5491\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### LRCN and video concat\n",
    "if experiment['architecture'] == 'video_lrcnn_frozen' or experiment['architecture'] == 'video_mlp_concat':\n",
    "    # collect predictions for each video\n",
    "    y_preds = []\n",
    "\n",
    "    for c, video in enumerate(videos):\n",
    "        print(\"Computing frame predictions for video {}/{}: {}\".format(c+1,len(videos),video))\n",
    "\n",
    "        # load features from disk\n",
    "        features = np.load(get_features_path(video))\n",
    "\n",
    "        dfs = []\n",
    "        for i in range(sequence_length-1, len(features)):\n",
    "\n",
    "            # get features for the clip\n",
    "            features_frames = features[i-sequence_length+1:i+1,]\n",
    "            features_frames = np.expand_dims(features_frames, axis=0)\n",
    "\n",
    "            # run through model\n",
    "            y_pred = architecture.model.predict(features_frames)\n",
    "\n",
    "            # create pred dataframe\n",
    "            df_pred = pd.DataFrame(y_pred[0]).T\n",
    "            df_pred.columns = class_names\n",
    "            df_pred.index = [i]\n",
    "            dfs.append(df_pred)\n",
    "\n",
    "        # join pred dataframe onto labels\n",
    "        y_pred = pd.concat(dfs)\n",
    "        y_pred['pred'] = y_pred.idxmax(axis=1)\n",
    "        # align labels index\n",
    "        y_labs = labels[labels['video']==video]\n",
    "        y_labs.reset_index(inplace=True,drop=True)\n",
    "        # join predictions on labels\n",
    "        y_pred = pd.merge(y_pred, y_labs, left_index=True,right_index=True,how='left')\n",
    "        y_pred['error'] = (y_pred['label'] != y_pred['pred']).astype(int)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    preds_all = pd.concat(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image_mlp_frozen frame predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T08:04:08.371797Z",
     "start_time": "2020-04-14T08:04:08.365157Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### image mlp frozen\n",
    "if experiment['architecture'] == 'image_mlp_frozen':\n",
    "    # collect predictions for each video\n",
    "    y_preds = []\n",
    "\n",
    "    for c, video in enumerate(videos):\n",
    "        print(\"Computing frame predictions for video {}/{}: {}\".format(c+1,len(videos),video))\n",
    "\n",
    "        # load features from disk\n",
    "        features = np.load(get_features_path(video))\n",
    "\n",
    "        dfs = []\n",
    "        for i in range(0, len(features)):\n",
    "\n",
    "            # get features for the clip\n",
    "            features_frames = features[i,]\n",
    "            features_frames = np.expand_dims(features_frames, axis=0)\n",
    "\n",
    "            # run through model\n",
    "            y_pred = architecture.model.predict(features_frames)\n",
    "\n",
    "            # create pred dataframe\n",
    "            df_pred = pd.DataFrame(y_pred[0]).T\n",
    "            df_pred.columns = class_names\n",
    "            df_pred.index = [i]\n",
    "            dfs.append(df_pred)\n",
    "\n",
    "        # join pred dataframe onto labels\n",
    "        y_pred = pd.concat(dfs)\n",
    "        y_pred['pred'] = y_pred.idxmax(axis=1)\n",
    "        # align labels index\n",
    "        y_labs = labels[labels['video']==video]\n",
    "        y_labs.reset_index(inplace=True,drop=True)\n",
    "        # join predictions on labels\n",
    "        y_pred = pd.merge(y_pred, y_labs, left_index=True,right_index=True,how='left')\n",
    "        y_pred['error'] = (y_pred['label'] != y_pred['pred']).astype(int)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    preds_all = pd.concat(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View frame predictions and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T08:04:08.392187Z",
     "start_time": "2020-04-14T08:04:08.374651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noseal</th>\n",
       "      <th>seal</th>\n",
       "      <th>pred</th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.962018</td>\n",
       "      <td>0.037982</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s1-218</td>\n",
       "      <td>s1-218-00020.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.961379</td>\n",
       "      <td>0.038621</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s1-218</td>\n",
       "      <td>s1-218-00021.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.960175</td>\n",
       "      <td>0.039825</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s1-218</td>\n",
       "      <td>s1-218-00022.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.961160</td>\n",
       "      <td>0.038840</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s1-218</td>\n",
       "      <td>s1-218-00023.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.961303</td>\n",
       "      <td>0.038697</td>\n",
       "      <td>noseal</td>\n",
       "      <td>s1-218</td>\n",
       "      <td>s1-218-00024.jpeg</td>\n",
       "      <td>noseal</td>\n",
       "      <td>valid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      noseal      seal    pred   video              frame   label  split  \\\n",
       "19  0.962018  0.037982  noseal  s1-218  s1-218-00020.jpeg  noseal  valid   \n",
       "20  0.961379  0.038621  noseal  s1-218  s1-218-00021.jpeg  noseal  valid   \n",
       "21  0.960175  0.039825  noseal  s1-218  s1-218-00022.jpeg  noseal  valid   \n",
       "22  0.961160  0.038840  noseal  s1-218  s1-218-00023.jpeg  noseal  valid   \n",
       "23  0.961303  0.038697  noseal  s1-218  s1-218-00024.jpeg  noseal  valid   \n",
       "\n",
       "    error  \n",
       "19      0  \n",
       "20      0  \n",
       "21      0  \n",
       "22      0  \n",
       "23      0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T08:04:08.400656Z",
     "start_time": "2020-04-14T08:04:08.394665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08787983425414364"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T08:04:08.414240Z",
     "start_time": "2020-04-14T08:04:08.403227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08481164042256328"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all[preds_all['split'] == 'train']['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T08:04:08.424445Z",
     "start_time": "2020-04-14T08:04:08.416733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.088715953307393"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all[preds_all['split'] == 'valid']['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T08:04:08.435105Z",
     "start_time": "2020-04-14T08:04:08.427337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all[preds_all['split'] == 'test']['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T08:04:08.510838Z",
     "start_time": "2020-04-14T08:04:08.437271Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_all.to_csv(pwd + \"models/\" + str(experiment['model_id']) + '/frame_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
