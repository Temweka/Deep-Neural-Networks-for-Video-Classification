{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:51:58.953507Z",
     "start_time": "2020-04-14T06:51:58.950801Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:01.107751Z",
     "start_time": "2020-04-14T06:52:00.501570Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "from shutil import rmtree\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:03.214666Z",
     "start_time": "2020-04-14T06:52:01.991546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:03.588456Z",
     "start_time": "2020-04-14T06:52:03.584465Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"notebooks\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:03.598821Z",
     "start_time": "2020-04-14T06:52:03.592099Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:05.766399Z",
     "start_time": "2020-04-14T06:52:03.601834Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.architectures import Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:52:05.772697Z",
     "start_time": "2020-04-14T06:52:05.769082Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepvideoclassification.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model weights from file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e.g. /models/123/model_best.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> enter your experiment parameters below - the trained model and associated parameter files must be in /models/model_id/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:57:51.853484Z",
     "start_time": "2020-04-14T07:57:51.849483Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment = {\n",
    "             'architecture': 'video_lrcnn_frozen',\n",
    "             'dropout': 0.2,\n",
    "             'layer_1_size': 256,\n",
    "             'layer_2_size': 512,\n",
    "             'layer_3_size': 256,\n",
    "             'model_id': 1,\n",
    "             'pooling': 'max',\n",
    "             'pretrained_model_name': 'vgg16',\n",
    "             'sequence_length': 20,\n",
    "             'sequence_model': \"LSTM\",\n",
    "             'sequence_model_layers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:19:53.789639Z",
     "start_time": "2020-04-14T07:19:53.785759Z"
    }
   },
   "outputs": [],
   "source": [
    "# experiment = {\n",
    "#              'architecture': 'image_mlp_frozen',\n",
    "#              'dropout': 0.2,\n",
    "#              'layer_1_size': 128,\n",
    "#              'layer_2_size': 0,\n",
    "#              'layer_3_size': 0,\n",
    "#              'model_id': 6,\n",
    "#              'pooling': 'max',\n",
    "#              'pretrained_model_name': 'resnet50',\n",
    "#              'sequence_length': 1,\n",
    "#              'sequence_model': \"\",\n",
    "#              'sequence_model_layers': \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:54:32.948367Z",
     "start_time": "2020-04-14T07:54:32.944477Z"
    }
   },
   "outputs": [],
   "source": [
    "# experiment = {\n",
    "#              'architecture': 'video_mlp_concat',\n",
    "#              'dropout': 0.2,\n",
    "#              'layer_1_size': 128,\n",
    "#              'layer_2_size': 128,\n",
    "#              'layer_3_size': 512,\n",
    "#              'model_id': 7,\n",
    "#              'pooling': 'max',\n",
    "#              'pretrained_model_name': 'resnet50',\n",
    "#              'sequence_length': 3,\n",
    "#              'sequence_model': \"\",\n",
    "#              'sequence_model_layers': \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:57:57.397975Z",
     "start_time": "2020-04-14T07:57:55.643260Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 07:57:55,646 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 256, 'model_id': 1, 'dropout': 0.2, 'sequence_model_layers': 2, 'sequence_length': 20, 'layer_2_size': 512, 'layer_1_size': 256, 'pretrained_model_name': 'vgg16', 'sequence_model': 'LSTM', 'architecture': 'video_lrcnn_frozen', 'pooling': 'max'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 07:57:55,928 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/max/\n",
      "2020-04-14 07:57:55,929 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10034, valid=1285, test=265\n"
     ]
    }
   ],
   "source": [
    "print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "print(experiment)\n",
    "\n",
    "architecture = Architecture(model_id = experiment['model_id'], \n",
    "                            architecture = experiment['architecture'], \n",
    "                            sequence_length = experiment['sequence_length'], \n",
    "                            pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                            pooling = experiment['pooling'],\n",
    "                            sequence_model = experiment['sequence_model'],\n",
    "                            sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                            layer_1_size = experiment['layer_1_size'],\n",
    "                            layer_2_size = experiment['layer_2_size'],\n",
    "                            layer_3_size = experiment['layer_3_size'],\n",
    "                            dropout = experiment['dropout'],\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:57:57.945725Z",
     "start_time": "2020-04-14T07:57:57.942410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/seals/models/1/model_best.h5\n"
     ]
    }
   ],
   "source": [
    "print(architecture.path_model + \"model_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:04.559173Z",
     "start_time": "2020-04-14T07:57:58.837978Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model weights\n",
    "architecture.model = load_model(architecture.path_model + \"model_best.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and predict on test frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:04.566169Z",
     "start_time": "2020-04-14T07:58:04.562121Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_length = experiment['sequence_length']\n",
    "pretrained_model_name = experiment['pretrained_model_name']\n",
    "pooling = experiment['pooling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.482540Z",
     "start_time": "2020-04-14T07:58:04.568812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-14 07:58:04,845 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/vgg16/max/\n",
      "2020-04-14 07:58:04,845 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=10034, valid=1285, test=265\n"
     ]
    }
   ],
   "source": [
    "# build feature cache if it doesn't already exist\n",
    "data = Data(sequence_length=sequence_length, \n",
    "            return_CNN_features=True,\n",
    "            pretrained_model_name = pretrained_model_name,\n",
    "            pooling=pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.489544Z",
     "start_time": "2020-04-14T07:58:05.485739Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.499171Z",
     "start_time": "2020-04-14T07:58:05.492471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noseal', 'seal']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get class names from data object\n",
    "class_names = []\n",
    "for k in sorted(data.label_map.keys()):\n",
    "    class_names.append(data.label_map[k])\n",
    "class_names = [c.replace(\"label_\",\"\") for c in class_names]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.506394Z",
     "start_time": "2020-04-14T07:58:05.501739Z"
    }
   },
   "outputs": [],
   "source": [
    "# get list of videos\n",
    "videos = list(labels['video'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T07:58:05.514037Z",
     "start_time": "2020-04-14T07:58:05.509037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/seals/cache/features/vgg16/max/s1-218.npy\n"
     ]
    }
   ],
   "source": [
    "def get_features_path(video):\n",
    "    return pwd + 'cache/features/' + experiment['pretrained_model_name'] + '/' + experiment['pooling'] + '/' + video + '.npy'\n",
    "print(get_features_path(videos[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRCN or video concat frame predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T07:58:05.277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing frame predictions for video 1/46: s1-218\n",
      "Computing frame predictions for video 2/46: s10-6558\n",
      "Computing frame predictions for video 3/46: s11-7363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### LRCN and video concat\n",
    "if experiment['architecture'] == 'video_lrcnn_frozen' or experiment['architecture'] == 'video_mlp_concat':\n",
    "    # collect predictions for each video\n",
    "    y_preds = []\n",
    "\n",
    "    for c, video in enumerate(videos):\n",
    "        print(\"Computing frame predictions for video {}/{}: {}\".format(c+1,len(videos),video))\n",
    "\n",
    "        # load features from disk\n",
    "        features = np.load(get_features_path(video))\n",
    "\n",
    "        dfs = []\n",
    "        for i in range(sequence_length-1, len(features)):\n",
    "\n",
    "            # get features for the clip\n",
    "            features_frames = features[i-sequence_length+1:i+1,]\n",
    "            features_frames = np.expand_dims(features_frames, axis=0)\n",
    "\n",
    "            # run through model\n",
    "            y_pred = architecture.model.predict(features_frames)\n",
    "\n",
    "            # create pred dataframe\n",
    "            df_pred = pd.DataFrame(y_pred[0]).T\n",
    "            df_pred.columns = class_names\n",
    "            df_pred.index = [i]\n",
    "            dfs.append(df_pred)\n",
    "\n",
    "        # join pred dataframe onto labels\n",
    "        y_pred = pd.concat(dfs)\n",
    "        y_pred['pred'] = y_pred.idxmax(axis=1)\n",
    "        # align labels index\n",
    "        y_labs = labels[labels['video']==video]\n",
    "        y_labs.reset_index(inplace=True,drop=True)\n",
    "        # join predictions on labels\n",
    "        y_pred = pd.merge(y_pred, y_labs, left_index=True,right_index=True,how='left')\n",
    "        y_pred['error'] = (y_pred['label'] != y_pred['pred']).astype(int)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    preds_all = pd.concat(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image_mlp_frozen frame predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T07:58:08.037Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### image mlp frozen\n",
    "if experiment['architecture'] == 'image_mlp_frozen':\n",
    "    # collect predictions for each video\n",
    "    y_preds = []\n",
    "\n",
    "    for c, video in enumerate(videos):\n",
    "        print(\"Computing frame predictions for video {}/{}: {}\".format(c+1,len(videos),video))\n",
    "\n",
    "        # load features from disk\n",
    "        features = np.load(get_features_path(video))\n",
    "\n",
    "        dfs = []\n",
    "        for i in range(0, len(features)):\n",
    "\n",
    "            # get features for the clip\n",
    "            features_frames = features[i,]\n",
    "            features_frames = np.expand_dims(features_frames, axis=0)\n",
    "\n",
    "            # run through model\n",
    "            y_pred = architecture.model.predict(features_frames)\n",
    "\n",
    "            # create pred dataframe\n",
    "            df_pred = pd.DataFrame(y_pred[0]).T\n",
    "            df_pred.columns = class_names\n",
    "            df_pred.index = [i]\n",
    "            dfs.append(df_pred)\n",
    "\n",
    "        # join pred dataframe onto labels\n",
    "        y_pred = pd.concat(dfs)\n",
    "        y_pred['pred'] = y_pred.idxmax(axis=1)\n",
    "        # align labels index\n",
    "        y_labs = labels[labels['video']==video]\n",
    "        y_labs.reset_index(inplace=True,drop=True)\n",
    "        # join predictions on labels\n",
    "        y_pred = pd.merge(y_pred, y_labs, left_index=True,right_index=True,how='left')\n",
    "        y_pred['error'] = (y_pred['label'] != y_pred['pred']).astype(int)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    preds_all = pd.concat(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View frame predictions and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T07:58:14.897Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T07:58:15.192Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_all['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T07:58:15.445Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_all[preds_all['split'] == 'train']['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T07:58:15.637Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_all[preds_all['split'] == 'valid']['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T07:58:15.849Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_all[preds_all['split'] == 'test']['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T07:58:16.241Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_all.to_csv(pwd + \"models/\" + str(experiment['model_id']) + '/frame_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
