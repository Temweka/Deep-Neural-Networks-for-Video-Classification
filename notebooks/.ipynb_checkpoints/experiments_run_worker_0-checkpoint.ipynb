{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:17.241225Z",
     "start_time": "2019-01-20T13:23:17.238340Z"
    }
   },
   "outputs": [],
   "source": [
    "WORKER_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:17.250191Z",
     "start_time": "2019-01-20T13:23:17.246715Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(WORKER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:17.256285Z",
     "start_time": "2019-01-20T13:23:17.252996Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:17.726723Z",
     "start_time": "2019-01-20T13:23:17.258760Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:17.732683Z",
     "start_time": "2019-01-20T13:23:17.729341Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"notebooks\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:17.740247Z",
     "start_time": "2019-01-20T13:23:17.734762Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:19.698604Z",
     "start_time": "2019-01-20T13:23:17.742415Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from deepvideoclassification.architectures import Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:19.704538Z",
     "start_time": "2019-01-20T13:23:19.701161Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_batch_name = 'experiment_batch_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:19.729932Z",
     "start_time": "2019-01-20T13:23:19.706979Z"
    }
   },
   "outputs": [],
   "source": [
    "# load list of experiments\n",
    "experiments = pd.read_csv(pwd + \"experiments/\" + experiment_batch_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:23:19.736356Z",
     "start_time": "2019-01-20T13:23:19.732638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5376, 12)\n"
     ]
    }
   ],
   "source": [
    "print(experiments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T14:52:00.022848Z",
     "start_time": "2019-01-20T13:23:19.739360Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:05:25,454 [MainThread  ] [INFO ]  Begin experiment for model_id=192 on GPU:0 \n",
      "2019-01-20 15:05:25,455 [MainThread  ] [INFO ]  Model folder exists but no results found - potential error in previous model training\n",
      "2019-01-20 15:05:25,456 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'pretrained_model_name': 'inception_resnet_v2', 'layer_3_size': 512, 'architecture': 'video_MLP_concat', 'pooling': 'max', 'layer_1_size': 512, 'model_id': 192, 'dropout': 0.2, 'sequence_length': 3, 'layer_2_size': 512, 'WORKER': 0, 'sequence_model_layers': nan, 'sequence_model': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:05:26,550 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:05:26,551 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 22s 365us/step - loss: 3.9961 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73238, saving model to /mnt/seals/models/192/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 18s 296us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.73238\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 18s 294us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.73238\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 18s 294us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73238\n",
      "H1 {'loss': [3.996050113182943, 4.000005363699462, 4.000005358856518, 4.000005361053561], 'val_acc': [0.7323767973792159, 0.7323767973792159, 0.7323767973792159, 0.7323767973792159], 'val_loss': [4.290063843902616, 4.290063843902616, 4.290063843902616, 4.290063843902616], 'acc': [0.7504995636878343, 0.7504712535024128, 0.7504712534216971, 0.7504712537544035]}\n",
      "stopped_epoch1 1\n",
      "4\n",
      "0.7323767973792159\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 19s 308us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73238, saving model to /mnt/seals/models/192/model_round_2.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 18s 296us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.73238\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 18s 296us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.73238\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 18s 301us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73238\n",
      "H2 {'loss': [4.000005359919603, 4.000005360998438, 4.000005359344749, 4.000005361179556], 'val_acc': [0.7323767973792159, 0.7323767973792159, 0.7323767973792159, 0.7323767973792159], 'val_loss': [4.290063843902616, 4.290063843902616, 4.290063843902616, 4.290063843902616], 'acc': [0.7504712532189234, 0.750471254177669, 0.7504712533941356, 0.7504712542583848]}\n",
      "stopped_epoch2 1\n",
      "4\n",
      "0.7323767973792159\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 19s 312us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73238, saving model to /mnt/seals/models/192/model_round_3.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 18s 299us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.73238\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 18s 301us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.73238\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 19s 319us/step - loss: 4.0000 - acc: 0.7505 - val_loss: 4.2901 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73238\n",
      "H3 {'loss': [4.000005361809533, 4.000005360423584, 4.0000053594156215, 4.000005362439509], 'val_acc': [0.7323767973792159, 0.7323767973792159, 0.7323767973792159, 0.7323767973792159], 'val_loss': [4.290063843902616, 4.290063843902616, 4.290063843902616, 4.290063843902616], 'acc': [0.7504712540693917, 0.7504712533764175, 0.7504712534079163, 0.7504712525889468]}\n",
      "stopped_epoch3 1\n",
      "4\n",
      "0.7323767973792159\n",
      "best fit round 1 0.7323767973792159\n",
      "3137/3137 [==============================] - 0s 109us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:09:21,321 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_mlp_concat\",\n",
      "    \"batch_size\": 32,\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 3137,\n",
      "    \"data_total_rows_train\": 60553,\n",
      "    \"data_total_rows_valid\": 6412,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 1,\n",
      "    \"fit_dt_test_duration_seconds\": \"0\",\n",
      "    \"fit_dt_test_end\": \"2019-01-20 15:09:19\",\n",
      "    \"fit_dt_test_start\": \"2019-01-20 15:09:19\",\n",
      "    \"fit_dt_train_duration_seconds\": \"228\",\n",
      "    \"fit_dt_train_end\": \"2019-01-20 15:09:18\",\n",
      "    \"fit_dt_train_start\": \"2019-01-20 15:05:29\",\n",
      "    \"fit_num_epochs\": 6,\n",
      "    \"fit_stopped_epoch1\": 1,\n",
      "    \"fit_stopped_epoch2\": 1,\n",
      "    \"fit_stopped_epoch3\": 1,\n",
      "    \"fit_test_acc\": 0.18425247051322924,\n",
      "    \"fit_train_acc\": 0.7504712535024128,\n",
      "    \"fit_train_loss\": 4.000005363699462,\n",
      "    \"fit_val_acc\": 0.7323767973792159,\n",
      "    \"fit_val_loss\": 4.290063843902616,\n",
      "    \"frame_size\": [\n",
      "        299,\n",
      "        299\n",
      "    ],\n",
      "    \"layer_1_size\": 512,\n",
      "    \"layer_2_size\": 512,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 192,\n",
      "    \"model_param_count\": 2888711,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 1536,\n",
      "    \"path_model\": \"/mnt/seals/models/192/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"inception_resnet_v2\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": NaN,\n",
      "    \"sequence_model_layers\": NaN,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2019-01-20 15:09:21,322 [MainThread  ] [INFO ]  model 192 test acc: 0.18425247051322924\n",
      "2019-01-20 15:09:25,131 [MainThread  ] [INFO ]  Begin experiment for model_id=200 on GPU:0 \n",
      "2019-01-20 15:09:25,134 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'pretrained_model_name': 'inception_resnet_v2', 'layer_3_size': 512, 'architecture': 'video_MLP_concat', 'pooling': 'max', 'layer_1_size': 512, 'model_id': 200, 'dropout': 0.2, 'sequence_length': 3, 'layer_2_size': 128, 'WORKER': 0, 'sequence_model_layers': nan, 'sequence_model': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:09:26,238 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:09:26,240 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 20s 334us/step - loss: 0.2077 - acc: 0.9206 - val_loss: 0.2225 - val_acc: 0.8886\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88862, saving model to /mnt/seals/models/200/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 19s 309us/step - loss: 0.1587 - acc: 0.9368 - val_loss: 0.2802 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88862 to 0.89130, saving model to /mnt/seals/models/200/model_round_1.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 19s 307us/step - loss: 0.1493 - acc: 0.9412 - val_loss: 0.1718 - val_acc: 0.9288\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89130 to 0.92879, saving model to /mnt/seals/models/200/model_round_1.h5\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 19s 310us/step - loss: 0.1472 - acc: 0.9421 - val_loss: 0.2012 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92879\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 19s 320us/step - loss: 0.1616 - acc: 0.9377 - val_loss: 0.2085 - val_acc: 0.8957\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92879\n",
      "Epoch 6/20\n",
      "60553/60553 [==============================] - 20s 322us/step - loss: 0.1682 - acc: 0.9336 - val_loss: 0.1738 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92879\n",
      "H1 {'loss': [0.20765446354778327, 0.15866202148249656, 0.14931247135290507, 0.1472340586318223, 0.16156191672718406, 0.16821509295968048], 'val_acc': [0.8886240217660415, 0.8912975822696817, 0.9287942435989808, 0.9080964443985552, 0.8956866761482438, 0.9239150018373729], 'val_loss': [0.22254126869881072, 0.28018461598207706, 0.17179465079848572, 0.20116780880497012, 0.20851315686238683, 0.17378999726964173], 'acc': [0.920626814583162, 0.9368251369896923, 0.941196749759146, 0.9420979684533907, 0.9376697346211039, 0.9335977415503978]}\n",
      "stopped_epoch1 3\n",
      "6\n",
      "0.9080964443985552\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 21s 341us/step - loss: 0.1499 - acc: 0.9414 - val_loss: 0.1869 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90850, saving model to /mnt/seals/models/200/model_round_2.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 19s 314us/step - loss: 0.1454 - acc: 0.9429 - val_loss: 0.1874 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90850\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 19s 320us/step - loss: 0.1429 - acc: 0.9439 - val_loss: 0.1911 - val_acc: 0.9066\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90850\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 19s 321us/step - loss: 0.1412 - acc: 0.9445 - val_loss: 0.1843 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90850\n",
      "H2 {'loss': [0.14987204728603065, 0.14542662033545534, 0.1428684339665769, 0.1411563106119424], 'val_acc': [0.9084974766446885, 0.9082969573610512, 0.9066259868057237, 0.9081632799456734], 'val_loss': [0.18693105483233594, 0.18742330101361068, 0.19111209285590178, 0.18431092959527143], 'acc': [0.9413713327293292, 0.9428835832525173, 0.9439169165568492, 0.9445161546835638]}\n",
      "stopped_epoch2 1\n",
      "4\n",
      "0.9082969573610512\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 21s 351us/step - loss: 0.1398 - acc: 0.9452 - val_loss: 0.1870 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90792, saving model to /mnt/seals/models/200/model_round_3.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 19s 313us/step - loss: 0.1383 - acc: 0.9453 - val_loss: 0.1888 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90792\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 19s 312us/step - loss: 0.1386 - acc: 0.9458 - val_loss: 0.1913 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90792\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 19s 312us/step - loss: 0.1391 - acc: 0.9455 - val_loss: 0.1898 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90792\n",
      "H3 {'loss': [0.13977990967718326, 0.13825631388239373, 0.13863455446029208, 0.13909673992028065], 'val_acc': [0.9079182070638713, 0.9076062919047945, 0.9061358331964675, 0.9067373833504604], 'val_loss': [0.18696536845571163, 0.18882266184778712, 0.19126804080034746, 0.1897982719237553], 'acc': [0.9452475116736918, 0.9452522289738589, 0.9457736146118715, 0.9455164605436491]}\n",
      "stopped_epoch3 1\n",
      "4\n",
      "0.9076062919047945\n",
      "best fit round 2 0.9082969573610512\n",
      "3137/3137 [==============================] - 0s 147us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:14:11,416 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_mlp_concat\",\n",
      "    \"batch_size\": 32,\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 3137,\n",
      "    \"data_total_rows_train\": 60553,\n",
      "    \"data_total_rows_valid\": 6412,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 2,\n",
      "    \"fit_dt_test_duration_seconds\": \"0\",\n",
      "    \"fit_dt_test_end\": \"2019-01-20 15:14:09\",\n",
      "    \"fit_dt_test_start\": \"2019-01-20 15:14:09\",\n",
      "    \"fit_dt_train_duration_seconds\": \"279\",\n",
      "    \"fit_dt_train_end\": \"2019-01-20 15:14:08\",\n",
      "    \"fit_dt_train_start\": \"2019-01-20 15:09:29\",\n",
      "    \"fit_num_epochs\": 8,\n",
      "    \"fit_stopped_epoch1\": 3,\n",
      "    \"fit_stopped_epoch2\": 1,\n",
      "    \"fit_stopped_epoch3\": 1,\n",
      "    \"fit_test_acc\": 0.5304430985017532,\n",
      "    \"fit_train_acc\": 0.9428835832525173,\n",
      "    \"fit_train_loss\": 0.14542662033545534,\n",
      "    \"fit_val_acc\": 0.9082969573610512,\n",
      "    \"fit_val_loss\": 0.18742330101361068,\n",
      "    \"frame_size\": [\n",
      "        299,\n",
      "        299\n",
      "    ],\n",
      "    \"layer_1_size\": 512,\n",
      "    \"layer_2_size\": 128,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 200,\n",
      "    \"model_param_count\": 2495111,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 1536,\n",
      "    \"path_model\": \"/mnt/seals/models/200/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"inception_resnet_v2\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": NaN,\n",
      "    \"sequence_model_layers\": NaN,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2019-01-20 15:14:11,418 [MainThread  ] [INFO ]  model 200 test acc: 0.5304430985017532\n",
      "2019-01-20 15:14:14,393 [MainThread  ] [INFO ]  Begin experiment for model_id=208 on GPU:0 \n",
      "2019-01-20 15:14:14,396 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'pretrained_model_name': 'inception_resnet_v2', 'layer_3_size': 512, 'architecture': 'video_MLP_concat', 'pooling': 'max', 'layer_1_size': 256, 'model_id': 208, 'dropout': 0.2, 'sequence_length': 3, 'layer_2_size': 512, 'WORKER': 0, 'sequence_model_layers': nan, 'sequence_model': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:14:15,530 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:14:15,532 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 18s 299us/step - loss: 0.2397 - acc: 0.9084 - val_loss: 0.2060 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91518, saving model to /mnt/seals/models/208/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 16s 272us/step - loss: 0.1884 - acc: 0.9203 - val_loss: 0.2245 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91518\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 17s 285us/step - loss: 0.1833 - acc: 0.9217 - val_loss: 0.1989 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91518\n",
      "Epoch 4/20\n",
      "34048/60553 [===============>..............] - ETA: 7s - loss: 0.1811 - acc: 0.9229"
     ]
    }
   ],
   "source": [
    "###################\n",
    "### Run experiments\n",
    "###################\n",
    "\n",
    "for row in experiments.values:\n",
    "    \n",
    "    # get experiment params from dataframe row\n",
    "    experiment = dict(zip(experiments.columns, row))\n",
    "    \n",
    "    # only run experiment if not already run\n",
    "    if not os.path.exists(pwd + 'models/' + str(experiment[\"model_id\"]) + '/results.json'):\n",
    "\n",
    "        # only run experiment if matches this worker id\n",
    "        if experiment['WORKER'] == WORKER_ID:\n",
    "            \n",
    "            print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "            logging.info(\"Begin experiment for model_id={} on GPU:{} \".format(experiment['model_id'], os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "            print(experiment)\n",
    "\n",
    "            architecture = Architecture(model_id = experiment['model_id'], \n",
    "                                        architecture = experiment['architecture'], \n",
    "                                        sequence_length = experiment['sequence_length'], \n",
    "                                        pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                                        pooling = experiment['pooling'],\n",
    "                                        sequence_model = experiment['sequence_model'],\n",
    "                                        sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                                        layer_1_size = experiment['layer_1_size'],\n",
    "                                        layer_2_size = experiment['layer_2_size'],\n",
    "                                        layer_3_size = experiment['layer_3_size'],\n",
    "                                        dropout = experiment['dropout'],\n",
    "                                        verbose=True)\n",
    "\n",
    "            architecture.train_model()\n",
    "            \n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
