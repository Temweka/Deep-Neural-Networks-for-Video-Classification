{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:35.603894Z",
     "start_time": "2019-01-20T13:22:35.600657Z"
    }
   },
   "outputs": [],
   "source": [
    "WORKER_ID = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:35.610261Z",
     "start_time": "2019-01-20T13:22:35.606251Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(WORKER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:35.615883Z",
     "start_time": "2019-01-20T13:22:35.612822Z"
    }
   },
   "outputs": [],
   "source": [
    "# whether to log each feature and sequence status\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:36.089739Z",
     "start_time": "2019-01-20T13:22:35.618612Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:36.095593Z",
     "start_time": "2019-01-20T13:22:36.092304Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup paths\n",
    "pwd = os.getcwd().replace(\"notebooks\",\"\")\n",
    "path_cache = pwd + 'cache/'\n",
    "path_data = pwd + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:36.103959Z",
     "start_time": "2019-01-20T13:22:36.098670Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# any explicit log messages or uncaught errors to stdout and file /logs.log\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(pwd, \"logs\")),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "# init logger\n",
    "logger = logging.getLogger()\n",
    "# make logger aware of any uncaught exceptions\n",
    "def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "    if issubclass(exc_type, KeyboardInterrupt):\n",
    "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "        return\n",
    "\n",
    "    logger.error(\"Uncaught exception\", exc_info=(exc_type, exc_value, exc_traceback))\n",
    "sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:38.115021Z",
     "start_time": "2019-01-20T13:22:36.106483Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from deepvideoclassification.architectures import Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:38.121380Z",
     "start_time": "2019-01-20T13:22:38.117807Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_batch_name = 'experiment_batch_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:38.141505Z",
     "start_time": "2019-01-20T13:22:38.123566Z"
    }
   },
   "outputs": [],
   "source": [
    "# load list of experiments\n",
    "experiments = pd.read_csv(pwd + \"experiments/\" + experiment_batch_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T13:22:38.148052Z",
     "start_time": "2019-01-20T13:22:38.144224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5376, 12)\n"
     ]
    }
   ],
   "source": [
    "print(experiments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T14:25:10.213593Z",
     "start_time": "2019-01-20T13:22:38.150239Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:05:17,470 [MainThread  ] [INFO ]  Begin experiment for model_id=196 on GPU:4 \n",
      "2019-01-20 15:05:17,471 [MainThread  ] [INFO ]  Model folder exists but no results found - potential error in previous model training\n",
      "2019-01-20 15:05:17,472 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 512, 'layer_1_size': 512, 'layer_2_size': 256, 'dropout': 0.2, 'architecture': 'video_MLP_concat', 'sequence_length': 3, 'WORKER': 4, 'sequence_model': nan, 'pooling': 'max', 'pretrained_model_name': 'inception_resnet_v2', 'model_id': 196, 'sequence_model_layers': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:05:18,530 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:05:18,532 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 31s 506us/step - loss: 0.2278 - acc: 0.9168 - val_loss: 0.2158 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89504, saving model to /mnt/seals/models/196/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 18s 302us/step - loss: 0.1755 - acc: 0.9307 - val_loss: 0.2069 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89504\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 18s 301us/step - loss: 0.1647 - acc: 0.9356 - val_loss: 0.2121 - val_acc: 0.9035\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89504 to 0.90353, saving model to /mnt/seals/models/196/model_round_1.h5\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 18s 300us/step - loss: 0.1599 - acc: 0.9373 - val_loss: 0.1846 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90353 to 0.91215, saving model to /mnt/seals/models/196/model_round_1.h5\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 18s 300us/step - loss: 0.1547 - acc: 0.9400 - val_loss: 0.1950 - val_acc: 0.9044\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91215\n",
      "Epoch 6/20\n",
      "60553/60553 [==============================] - 18s 300us/step - loss: 0.1521 - acc: 0.9411 - val_loss: 0.1784 - val_acc: 0.9152\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91215 to 0.91525, saving model to /mnt/seals/models/196/model_round_1.h5\n",
      "Epoch 7/20\n",
      "60553/60553 [==============================] - 18s 300us/step - loss: 0.1507 - acc: 0.9418 - val_loss: 0.1627 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91525 to 0.93082, saving model to /mnt/seals/models/196/model_round_1.h5\n",
      "Epoch 8/20\n",
      "60553/60553 [==============================] - 18s 305us/step - loss: 0.1545 - acc: 0.9406 - val_loss: 0.1781 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93082\n",
      "Epoch 9/20\n",
      "60553/60553 [==============================] - 18s 301us/step - loss: 0.1498 - acc: 0.9419 - val_loss: 0.2012 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93082\n",
      "Epoch 10/20\n",
      "60553/60553 [==============================] - 18s 299us/step - loss: 0.1474 - acc: 0.9430 - val_loss: 0.1894 - val_acc: 0.9112\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93082\n",
      "H1 {'val_acc': [0.8950405689008669, 0.8911193498431781, 0.9035291160484142, 0.9121513408344385, 0.9043757372994164, 0.9152482137483726, 0.9308216918726973, 0.915003142391081, 0.908341521444874, 0.9111933173868556], 'loss': [0.22779177709167023, 0.17553299928933838, 0.16466927942467915, 0.15986101753921012, 0.15470356256064538, 0.15212962558994447, 0.15074480821496203, 0.1545127650560353, 0.14981561022730244, 0.1474326493932894], 'val_loss': [0.21577810056865476, 0.20685803782397036, 0.21209381024352625, 0.1845933057074984, 0.19499093671553, 0.17837319475222735, 0.16273732561471682, 0.1781014260636667, 0.20119160798588026, 0.18943595869498037], 'acc': [0.9167860227027026, 0.9306982747205543, 0.9355959910896632, 0.937261590488624, 0.9399676036337036, 0.9411354107110464, 0.941772397612056, 0.9406258206966915, 0.9419163077906779, 0.9429543600518184]}\n",
      "stopped_epoch1 7\n",
      "10\n",
      "0.915003142391081\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 19s 315us/step - loss: 0.1287 - acc: 0.9502 - val_loss: 0.1741 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92242, saving model to /mnt/seals/models/196/model_round_2.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 19s 321us/step - loss: 0.1270 - acc: 0.9508 - val_loss: 0.1775 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92242\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 20s 327us/step - loss: 0.1255 - acc: 0.9512 - val_loss: 0.1852 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92242\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 19s 308us/step - loss: 0.1249 - acc: 0.9518 - val_loss: 0.1816 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92242\n",
      "H2 {'val_acc': [0.9224222621468552, 0.9173425025889372, 0.9126860537680699, 0.9150031397882582], 'loss': [0.12873146227524287, 0.127033423714268, 0.12551837172048239, 0.12487314355439234], 'val_loss': [0.1740527032727535, 0.17750049691533418, 0.18521887515755794, 0.18163743815939648], 'acc': [0.950168817885465, 0.95081760036879, 0.9512092294808042, 0.9517966714493654]}\n",
      "stopped_epoch2 1\n",
      "4\n",
      "0.9173425025889372\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 19s 320us/step - loss: 0.1220 - acc: 0.9527 - val_loss: 0.1786 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91674, saving model to /mnt/seals/models/196/model_round_3.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 19s 306us/step - loss: 0.1227 - acc: 0.9524 - val_loss: 0.1785 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91674 to 0.91679, saving model to /mnt/seals/models/196/model_round_3.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 19s 317us/step - loss: 0.1223 - acc: 0.9525 - val_loss: 0.1775 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91679 to 0.91835, saving model to /mnt/seals/models/196/model_round_3.h5\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 19s 320us/step - loss: 0.1217 - acc: 0.9529 - val_loss: 0.1796 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91835\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 19s 310us/step - loss: 0.1222 - acc: 0.9526 - val_loss: 0.1768 - val_acc: 0.9188\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91835 to 0.91879, saving model to /mnt/seals/models/196/model_round_3.h5\n",
      "Epoch 6/20\n",
      "60553/60553 [==============================] - 19s 318us/step - loss: 0.1210 - acc: 0.9536 - val_loss: 0.1759 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91879 to 0.92051, saving model to /mnt/seals/models/196/model_round_3.h5\n",
      "Epoch 7/20\n",
      "60553/60553 [==============================] - 18s 304us/step - loss: 0.1216 - acc: 0.9528 - val_loss: 0.1777 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92051\n",
      "Epoch 8/20\n",
      "60553/60553 [==============================] - 19s 314us/step - loss: 0.1217 - acc: 0.9531 - val_loss: 0.1775 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92051\n",
      "Epoch 9/20\n",
      "60553/60553 [==============================] - 19s 310us/step - loss: 0.1211 - acc: 0.9533 - val_loss: 0.1758 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92051\n",
      "H3 {'val_acc': [0.9167409514309983, 0.916785513655662, 0.9183450891535802, 0.9161839635016691, 0.9187906807240886, 0.9205062168877495, 0.9187461219946444, 0.9191248779436684, 0.9200160610103191], 'loss': [0.12197738259692627, 0.1227130884625137, 0.12228716296679479, 0.12169560368137589, 0.1222182685915702, 0.12097569228440684, 0.12163465699143464, 0.12170683394176801, 0.121110286167008], 'val_loss': [0.17862238351508966, 0.1785046272514317, 0.17751428663395974, 0.17961517547118389, 0.17682634523639215, 0.17589594441432918, 0.17769405312710676, 0.1775187382048097, 0.17578737206259742], 'acc': [0.9526884517673536, 0.9524360171353128, 0.952485560083335, 0.9528653937469038, 0.9525657726405521, 0.9535589996908839, 0.9527615873830915, 0.9530965953279329, 0.9532711756699324]}\n",
      "stopped_epoch3 6\n",
      "9\n",
      "0.9187461219946444\n",
      "best fit round 3 0.9187461219946444\n",
      "3137/3137 [==============================] - 0s 110us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:12:52,803 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_mlp_concat\",\n",
      "    \"batch_size\": 32,\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 3137,\n",
      "    \"data_total_rows_train\": 60553,\n",
      "    \"data_total_rows_valid\": 6412,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"0\",\n",
      "    \"fit_dt_test_end\": \"2019-01-20 15:12:51\",\n",
      "    \"fit_dt_test_start\": \"2019-01-20 15:12:50\",\n",
      "    \"fit_dt_train_duration_seconds\": \"448\",\n",
      "    \"fit_dt_train_end\": \"2019-01-20 15:12:50\",\n",
      "    \"fit_dt_train_start\": \"2019-01-20 15:05:21\",\n",
      "    \"fit_num_epochs\": 17,\n",
      "    \"fit_stopped_epoch1\": 7,\n",
      "    \"fit_stopped_epoch2\": 1,\n",
      "    \"fit_stopped_epoch3\": 6,\n",
      "    \"fit_test_acc\": 0.5916480714058017,\n",
      "    \"fit_train_acc\": 0.9527615873830915,\n",
      "    \"fit_train_loss\": 0.12163465699143464,\n",
      "    \"fit_val_acc\": 0.9187461219946444,\n",
      "    \"fit_val_loss\": 0.17769405312710676,\n",
      "    \"frame_size\": [\n",
      "        299,\n",
      "        299\n",
      "    ],\n",
      "    \"layer_1_size\": 512,\n",
      "    \"layer_2_size\": 256,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 196,\n",
      "    \"model_param_count\": 2626311,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 1536,\n",
      "    \"path_model\": \"/mnt/seals/models/196/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"inception_resnet_v2\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": NaN,\n",
      "    \"sequence_model_layers\": NaN,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2019-01-20 15:12:52,804 [MainThread  ] [INFO ]  model 196 test acc: 0.5916480714058017\n",
      "2019-01-20 15:12:55,830 [MainThread  ] [INFO ]  Begin experiment for model_id=204 on GPU:4 \n",
      "2019-01-20 15:12:55,833 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 512, 'layer_1_size': 512, 'layer_2_size': 0, 'dropout': 0.2, 'architecture': 'video_MLP_concat', 'sequence_length': 3, 'WORKER': 4, 'sequence_model': nan, 'pooling': 'max', 'pretrained_model_name': 'inception_resnet_v2', 'model_id': 204, 'sequence_model_layers': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:12:56,970 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:12:56,971 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 17s 280us/step - loss: 2.6768 - acc: 0.8325 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83673, saving model to /mnt/seals/models/204/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 16s 261us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.83673\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 16s 260us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.83673\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 16s 260us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.83673\n",
      "H1 {'val_acc': [0.8367346959120024, 0.8367346959120024, 0.8367346959120024, 0.8367346959120024], 'loss': [2.6767643465542283, 2.719011263321872, 2.7190112667119335, 2.7190112630383823], 'val_loss': [2.6171817950583662, 2.6171817950583662, 2.6171817950583662, 2.6171817950583662], 'acc': [0.8324985676468676, 0.830382356465039, 0.8303823560653976, 0.8303823559620421]}\n",
      "stopped_epoch1 1\n",
      "4\n",
      "0.8367346959120024\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 17s 281us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83673, saving model to /mnt/seals/models/204/model_round_2.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 16s 262us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.83673\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 16s 259us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.83673\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 16s 265us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.83673\n",
      "H2 {'val_acc': [0.8367346959120024, 0.8367346959120024, 0.8367346959120024, 0.8367346959120024], 'loss': [2.719011264759006, 2.7190112640660318, 2.7190112634163683, 2.7190112701295566], 'val_loss': [2.6171817950583662, 2.6171817950583662, 2.6171817950583662, 2.6171817950583662], 'acc': [0.8303823559709012, 0.8303823567898707, 0.8303823561195363, 0.8303823564483053]}\n",
      "stopped_epoch2 1\n",
      "4\n",
      "0.8367346959120024\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 17s 280us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83673, saving model to /mnt/seals/models/204/model_round_3.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 17s 272us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.83673\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 16s 264us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.83673\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 16s 264us/step - loss: 2.7190 - acc: 0.8304 - val_loss: 2.6172 - val_acc: 0.8367\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.83673\n",
      "H3 {'val_acc': [0.8367346959120024, 0.8367346959120024, 0.8367346959120024, 0.8367346959120024], 'loss': [2.719011261431942, 2.719011264136904, 2.7190112627982037, 2.7190112679010143], 'val_loss': [2.6171817950583662, 2.6171817950583662, 2.6171817950583662, 2.6171817950583662], 'acc': [0.830382357221011, 0.8303823560250397, 0.8303823567623092, 0.8303823562494689]}\n",
      "stopped_epoch3 1\n",
      "4\n",
      "0.8367346959120024\n",
      "best fit round 1 0.8367346959120024\n",
      "3137/3137 [==============================] - 0s 126us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:16:22,679 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_mlp_concat\",\n",
      "    \"batch_size\": 32,\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 3137,\n",
      "    \"data_total_rows_train\": 60553,\n",
      "    \"data_total_rows_valid\": 6412,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 1,\n",
      "    \"fit_dt_test_duration_seconds\": \"0\",\n",
      "    \"fit_dt_test_end\": \"2019-01-20 15:16:21\",\n",
      "    \"fit_dt_test_start\": \"2019-01-20 15:16:20\",\n",
      "    \"fit_dt_train_duration_seconds\": \"200\",\n",
      "    \"fit_dt_train_end\": \"2019-01-20 15:16:20\",\n",
      "    \"fit_dt_train_start\": \"2019-01-20 15:13:00\",\n",
      "    \"fit_num_epochs\": 6,\n",
      "    \"fit_stopped_epoch1\": 1,\n",
      "    \"fit_stopped_epoch2\": 1,\n",
      "    \"fit_stopped_epoch3\": 1,\n",
      "    \"fit_test_acc\": 0.17468919349697165,\n",
      "    \"fit_train_acc\": 0.830382356465039,\n",
      "    \"fit_train_loss\": 2.719011263321872,\n",
      "    \"fit_val_acc\": 0.8367346959120024,\n",
      "    \"fit_val_loss\": 2.6171817950583662,\n",
      "    \"frame_size\": [\n",
      "        299,\n",
      "        299\n",
      "    ],\n",
      "    \"layer_1_size\": 512,\n",
      "    \"layer_2_size\": 0,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 204,\n",
      "    \"model_param_count\": 2363399,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 1536,\n",
      "    \"path_model\": \"/mnt/seals/models/204/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"inception_resnet_v2\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": NaN,\n",
      "    \"sequence_model_layers\": NaN,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2019-01-20 15:16:22,681 [MainThread  ] [INFO ]  model 204 test acc: 0.17468919349697165\n",
      "2019-01-20 15:16:25,619 [MainThread  ] [INFO ]  Begin experiment for model_id=212 on GPU:4 \n",
      "2019-01-20 15:16:25,622 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 512, 'layer_1_size': 256, 'layer_2_size': 256, 'dropout': 0.2, 'architecture': 'video_MLP_concat', 'sequence_length': 3, 'WORKER': 4, 'sequence_model': nan, 'pooling': 'max', 'pretrained_model_name': 'inception_resnet_v2', 'model_id': 212, 'sequence_model_layers': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:16:26,751 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:16:26,753 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 18s 294us/step - loss: 0.2135 - acc: 0.9161 - val_loss: 0.1782 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91110, saving model to /mnt/seals/models/212/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 16s 269us/step - loss: 0.1756 - acc: 0.9290 - val_loss: 0.1905 - val_acc: 0.9122\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91110 to 0.91217, saving model to /mnt/seals/models/212/model_round_1.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 17s 275us/step - loss: 0.1684 - acc: 0.9330 - val_loss: 0.1861 - val_acc: 0.9096\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91217\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 17s 283us/step - loss: 0.1615 - acc: 0.9361 - val_loss: 0.1927 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91217\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 17s 284us/step - loss: 0.1585 - acc: 0.9372 - val_loss: 0.1858 - val_acc: 0.8999\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91217\n",
      "H1 {'val_acc': [0.9111042011178291, 0.9121736245310017, 0.9096337396579464, 0.9115943472904484, 0.8998975296802842], 'loss': [0.21346596092295278, 0.1755799830662195, 0.16835922410874463, 0.16153729858209326, 0.15854397839823284], 'val_loss': [0.1782159839971171, 0.19046016227098383, 0.18612699823236734, 0.19272783308459013, 0.18583114402448841], 'acc': [0.9160829803206286, 0.9289713334563174, 0.9329796282805639, 0.9361244525844142, 0.9372450761158532]}\n",
      "stopped_epoch1 2\n",
      "5\n",
      "0.9096337396579464\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 18s 298us/step - loss: 0.1388 - acc: 0.9453 - val_loss: 0.1884 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90504, saving model to /mnt/seals/models/212/model_round_2.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 18s 289us/step - loss: 0.1353 - acc: 0.9466 - val_loss: 0.1733 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90504 to 0.91398, saving model to /mnt/seals/models/212/model_round_2.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 16s 271us/step - loss: 0.1323 - acc: 0.9480 - val_loss: 0.1767 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91398\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 16s 272us/step - loss: 0.1310 - acc: 0.9482 - val_loss: 0.1799 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91398\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 16s 271us/step - loss: 0.1290 - acc: 0.9494 - val_loss: 0.1858 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91398\n",
      "H2 {'val_acc': [0.9050441309205458, 0.9139782727991724, 0.9113269939470202, 0.9098788203482173, 0.9080296056908663], 'loss': [0.13884972360125936, 0.13534063037324992, 0.1322857935204968, 0.1309805613690869, 0.12899239472983967], 'val_loss': [0.18836967663808085, 0.17331872195358658, 0.17671025066136273, 0.17992292166090873, 0.18575759514636422], 'acc': [0.9452640240846762, 0.9466276468810221, 0.947979474485835, 0.9481894430522727, 0.9493572502290338]}\n",
      "stopped_epoch2 2\n",
      "5\n",
      "0.9113269939470202\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 17s 288us/step - loss: 0.1272 - acc: 0.9501 - val_loss: 0.1809 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91081, saving model to /mnt/seals/models/212/model_round_3.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 18s 289us/step - loss: 0.1272 - acc: 0.9503 - val_loss: 0.1803 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91081 to 0.91175, saving model to /mnt/seals/models/212/model_round_3.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 17s 280us/step - loss: 0.1268 - acc: 0.9500 - val_loss: 0.1761 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91175 to 0.91413, saving model to /mnt/seals/models/212/model_round_3.h5\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 17s 287us/step - loss: 0.1264 - acc: 0.9503 - val_loss: 0.1744 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91413 to 0.91496, saving model to /mnt/seals/models/212/model_round_3.h5\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 18s 290us/step - loss: 0.1263 - acc: 0.9505 - val_loss: 0.1805 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91496\n",
      "Epoch 6/20\n",
      "60553/60553 [==============================] - 17s 273us/step - loss: 0.1266 - acc: 0.9501 - val_loss: 0.1836 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91496\n",
      "Epoch 7/20\n",
      "60553/60553 [==============================] - 17s 285us/step - loss: 0.1265 - acc: 0.9502 - val_loss: 0.1790 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91496\n",
      "H3 {'val_acc': [0.9108145622558618, 0.9117503089229538, 0.9141342306761763, 0.9149585803895166, 0.9114829531998019, 0.9091213099374967, 0.9122850200717924], 'loss': [0.1272124284848689, 0.1272022515699493, 0.1268375716378793, 0.1264214183710518, 0.12632202358013486, 0.1266440052554552, 0.12651029438680558], 'val_loss': [0.18088147993282608, 0.1803282486020366, 0.1761410807027567, 0.17441663970556098, 0.18053611672378225, 0.18360326826312137, 0.178986460072728], 'acc': [0.9501074782300286, 0.9503198081593867, 0.949982440259229, 0.9502679047481296, 0.9504542821578112, 0.9501027586658832, 0.9501806140938197]}\n",
      "stopped_epoch3 4\n",
      "7\n",
      "0.9114829531998019\n",
      "best fit round 3 0.9114829531998019\n",
      "3137/3137 [==============================] - 1s 182us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:21:32,463 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_mlp_concat\",\n",
      "    \"batch_size\": 32,\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 3137,\n",
      "    \"data_total_rows_train\": 60553,\n",
      "    \"data_total_rows_valid\": 6412,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"0\",\n",
      "    \"fit_dt_test_end\": \"2019-01-20 15:21:30\",\n",
      "    \"fit_dt_test_start\": \"2019-01-20 15:21:30\",\n",
      "    \"fit_dt_train_duration_seconds\": \"298\",\n",
      "    \"fit_dt_train_end\": \"2019-01-20 15:21:28\",\n",
      "    \"fit_dt_train_start\": \"2019-01-20 15:16:30\",\n",
      "    \"fit_num_epochs\": 11,\n",
      "    \"fit_stopped_epoch1\": 2,\n",
      "    \"fit_stopped_epoch2\": 2,\n",
      "    \"fit_stopped_epoch3\": 4,\n",
      "    \"fit_test_acc\": 0.5454255658272235,\n",
      "    \"fit_train_acc\": 0.9504542821578112,\n",
      "    \"fit_train_loss\": 0.12632202358013486,\n",
      "    \"fit_val_acc\": 0.9114829531998019,\n",
      "    \"fit_val_loss\": 0.18053611672378225,\n",
      "    \"frame_size\": [\n",
      "        299,\n",
      "        299\n",
      "    ],\n",
      "    \"layer_1_size\": 256,\n",
      "    \"layer_2_size\": 256,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 212,\n",
      "    \"model_param_count\": 1380871,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 1536,\n",
      "    \"path_model\": \"/mnt/seals/models/212/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"inception_resnet_v2\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": NaN,\n",
      "    \"sequence_model_layers\": NaN,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2019-01-20 15:21:32,464 [MainThread  ] [INFO ]  model 212 test acc: 0.5454255658272235\n",
      "2019-01-20 15:21:38,044 [MainThread  ] [INFO ]  Begin experiment for model_id=220 on GPU:4 \n",
      "2019-01-20 15:21:38,047 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 512, 'layer_1_size': 256, 'layer_2_size': 0, 'dropout': 0.2, 'architecture': 'video_MLP_concat', 'sequence_length': 3, 'WORKER': 4, 'sequence_model': nan, 'pooling': 'max', 'pretrained_model_name': 'inception_resnet_v2', 'model_id': 220, 'sequence_model_layers': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:21:39,172 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:21:39,174 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 15s 251us/step - loss: 0.4514 - acc: 0.9096 - val_loss: 0.2081 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91803, saving model to /mnt/seals/models/220/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 13s 220us/step - loss: 0.1856 - acc: 0.9236 - val_loss: 0.2008 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91803 to 0.91823, saving model to /mnt/seals/models/220/model_round_1.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 13s 218us/step - loss: 0.1823 - acc: 0.9235 - val_loss: 0.2030 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91823\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 13s 217us/step - loss: 0.1698 - acc: 0.9322 - val_loss: 0.1859 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91823\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 13s 219us/step - loss: 0.1647 - acc: 0.9346 - val_loss: 0.2235 - val_acc: 0.8895\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91823\n",
      "H1 {'val_acc': [0.9180331789026838, 0.9182337017559068, 0.8913644207542715, 0.9140228341314396, 0.8895374930284207], 'loss': [0.45141697335405245, 0.18560150959799906, 0.18233697685642491, 0.16984948407011893, 0.16470787996374886], 'val_loss': [0.2080963490878279, 0.2007611251609889, 0.2029918482340059, 0.18587282846588235, 0.2235004657964296], 'acc': [0.9095833627862221, 0.9236206546470853, 0.9235121302172905, 0.9321892929851232, 0.9345956847403616]}\n",
      "stopped_epoch1 2\n",
      "5\n",
      "0.8913644207542715\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 14s 237us/step - loss: 0.1538 - acc: 0.9397 - val_loss: 0.1905 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90803, saving model to /mnt/seals/models/220/model_round_2.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 14s 223us/step - loss: 0.1513 - acc: 0.9406 - val_loss: 0.1822 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90803 to 0.91759, saving model to /mnt/seals/models/220/model_round_2.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 14s 233us/step - loss: 0.1505 - acc: 0.9407 - val_loss: 0.1800 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91759\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 14s 229us/step - loss: 0.1495 - acc: 0.9414 - val_loss: 0.1889 - val_acc: 0.9090\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91759\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 13s 222us/step - loss: 0.1502 - acc: 0.9410 - val_loss: 0.1787 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91759\n",
      "H2 {'val_acc': [0.9080296041291726, 0.9175875796724392, 0.9152927726265496, 0.9090099088192284, 0.9173202198963201], 'loss': [0.15377254099536744, 0.15128049124386314, 0.1505348703064213, 0.14945692367141902, 0.1501802355779451], 'val_loss': [0.19048229860593882, 0.18222606446563788, 0.1800441051358665, 0.18893758709997366, 0.17867545354983544], 'acc': [0.9397175258927335, 0.9406093071783264, 0.9407296271185799, 0.9413548161555775, 0.9410150903652456]}\n",
      "stopped_epoch2 2\n",
      "5\n",
      "0.9152927726265496\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 15s 240us/step - loss: 0.1473 - acc: 0.9423 - val_loss: 0.1780 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91855, saving model to /mnt/seals/models/220/model_round_3.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 13s 220us/step - loss: 0.1472 - acc: 0.9421 - val_loss: 0.1758 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91855 to 0.91941, saving model to /mnt/seals/models/220/model_round_3.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 13s 220us/step - loss: 0.1478 - acc: 0.9422 - val_loss: 0.1772 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91941\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 13s 221us/step - loss: 0.1474 - acc: 0.9425 - val_loss: 0.1793 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91941\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 13s 221us/step - loss: 0.1475 - acc: 0.9423 - val_loss: 0.1774 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91941\n",
      "H3 {'val_acc': [0.91854560531383, 0.9194145110050589, 0.9191248772000047, 0.9173870626569761, 0.9185901659396166], 'loss': [0.14728940937466234, 0.14715149601878036, 0.14775517426137477, 0.14742048930885487, 0.1474762702173079], 'val_loss': [0.17799668098176485, 0.17580848574842875, 0.17722246636469813, 0.179349848369621, 0.17740266009263522], 'acc': [0.9422631118946571, 0.9421475105686624, 0.9422206460318278, 0.942482517446481, 0.942315015139561]}\n",
      "stopped_epoch3 2\n",
      "5\n",
      "0.9191248772000047\n",
      "best fit round 3 0.9191248772000047\n",
      "3137/3137 [==============================] - 1s 209us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:25:19,411 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_mlp_concat\",\n",
      "    \"batch_size\": 32,\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 3137,\n",
      "    \"data_total_rows_train\": 60553,\n",
      "    \"data_total_rows_valid\": 6412,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 3,\n",
      "    \"fit_dt_test_duration_seconds\": \"0\",\n",
      "    \"fit_dt_test_end\": \"2019-01-20 15:25:17\",\n",
      "    \"fit_dt_test_start\": \"2019-01-20 15:25:16\",\n",
      "    \"fit_dt_train_duration_seconds\": \"213\",\n",
      "    \"fit_dt_train_end\": \"2019-01-20 15:25:15\",\n",
      "    \"fit_dt_train_start\": \"2019-01-20 15:21:42\",\n",
      "    \"fit_num_epochs\": 9,\n",
      "    \"fit_stopped_epoch1\": 2,\n",
      "    \"fit_stopped_epoch2\": 2,\n",
      "    \"fit_stopped_epoch3\": 2,\n",
      "    \"fit_test_acc\": 0.5900541919030922,\n",
      "    \"fit_train_acc\": 0.9422206460318278,\n",
      "    \"fit_train_loss\": 0.14775517426137477,\n",
      "    \"fit_val_acc\": 0.9191248772000047,\n",
      "    \"fit_val_loss\": 0.17722246636469813,\n",
      "    \"frame_size\": [\n",
      "        299,\n",
      "        299\n",
      "    ],\n",
      "    \"layer_1_size\": 256,\n",
      "    \"layer_2_size\": 0,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 220,\n",
      "    \"model_param_count\": 1181703,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 1536,\n",
      "    \"path_model\": \"/mnt/seals/models/220/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"inception_resnet_v2\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": NaN,\n",
      "    \"sequence_model_layers\": NaN,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2019-01-20 15:25:19,412 [MainThread  ] [INFO ]  model 220 test acc: 0.5900541919030922\n",
      "2019-01-20 15:25:21,912 [MainThread  ] [INFO ]  Begin experiment for model_id=228 on GPU:4 \n",
      "2019-01-20 15:25:21,914 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 512, 'layer_1_size': 128, 'layer_2_size': 256, 'dropout': 0.2, 'architecture': 'video_MLP_concat', 'sequence_length': 3, 'WORKER': 4, 'sequence_model': nan, 'pooling': 'max', 'pretrained_model_name': 'inception_resnet_v2', 'model_id': 228, 'sequence_model_layers': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:25:23,176 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:25:23,178 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 17s 287us/step - loss: 0.2152 - acc: 0.9159 - val_loss: 0.2186 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89491, saving model to /mnt/seals/models/228/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 15s 252us/step - loss: 0.1808 - acc: 0.9292 - val_loss: 0.2047 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89491 to 0.91532, saving model to /mnt/seals/models/228/model_round_1.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 15s 252us/step - loss: 0.1759 - acc: 0.9308 - val_loss: 0.2068 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91532 to 0.91710, saving model to /mnt/seals/models/228/model_round_1.h5\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 16s 261us/step - loss: 0.1691 - acc: 0.9331 - val_loss: 0.1847 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91710 to 0.92663, saving model to /mnt/seals/models/228/model_round_1.h5\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 16s 265us/step - loss: 0.1791 - acc: 0.9289 - val_loss: 0.1913 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92663\n",
      "Epoch 6/20\n",
      "60553/60553 [==============================] - 15s 252us/step - loss: 0.1790 - acc: 0.9282 - val_loss: 0.1997 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92663\n",
      "Epoch 7/20\n",
      "60553/60553 [==============================] - 15s 254us/step - loss: 0.1771 - acc: 0.9286 - val_loss: 0.2046 - val_acc: 0.9178\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92663\n",
      "H1 {'val_acc': [0.894906886428576, 0.9153150549473349, 0.9170974302276997, 0.926633118579184, 0.9165404367952591, 0.914134234245762, 0.9178326580573526], 'loss': [0.2151519830089327, 0.18080595238872058, 0.17593226226404213, 0.1691279910242615, 0.17909495495870667, 0.17903539950968936, 0.17705429040285947], 'val_loss': [0.2186113273026567, 0.20474392785478665, 0.20675970581421166, 0.1846789653533262, 0.1912774351969854, 0.19971762323334896, 0.2046096200914734], 'acc': [0.9159060424802214, 0.9291742283797939, 0.9308351124403741, 0.9331188237192829, 0.9289265128404004, 0.928232905667966, 0.9286080185664966]}\n",
      "stopped_epoch1 4\n",
      "7\n",
      "0.9165404367952591\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 18s 291us/step - loss: 0.1598 - acc: 0.9351 - val_loss: 0.1881 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92287, saving model to /mnt/seals/models/228/model_round_2.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 16s 260us/step - loss: 0.1559 - acc: 0.9362 - val_loss: 0.1914 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92287 to 0.92487, saving model to /mnt/seals/models/228/model_round_2.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 16s 270us/step - loss: 0.1545 - acc: 0.9367 - val_loss: 0.2097 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92487\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 17s 273us/step - loss: 0.1522 - acc: 0.9375 - val_loss: 0.1851 - val_acc: 0.9292\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.92487 to 0.92920, saving model to /mnt/seals/models/228/model_round_2.h5\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 17s 273us/step - loss: 0.1517 - acc: 0.9376 - val_loss: 0.1865 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92920\n",
      "Epoch 6/20\n",
      "60553/60553 [==============================] - 17s 273us/step - loss: 0.1505 - acc: 0.9382 - val_loss: 0.1904 - val_acc: 0.9226\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92920\n",
      "Epoch 7/20\n",
      "60553/60553 [==============================] - 16s 260us/step - loss: 0.1485 - acc: 0.9393 - val_loss: 0.1966 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92920\n",
      "H2 {'val_acc': [0.9228678562086371, 0.9248730260658026, 0.9171865454927802, 0.9291952767746938, 0.9255859752558055, 0.9225782188339972, 0.9198823820332476], 'loss': [0.1598393434147621, 0.15586534138113894, 0.1545488155176515, 0.1522058492064911, 0.15174532825650758, 0.15047539719565234, 0.1484590432101441], 'val_loss': [0.18814564279221924, 0.19137889111480785, 0.20971487229196117, 0.18509677006018882, 0.18650885416207577, 0.1903698650547213, 0.19658839302886968], 'acc': [0.9351076355880626, 0.9361905117813564, 0.9366859466045666, 0.9375093101907847, 0.9376319882997802, 0.938219430840242, 0.9392716375139154]}\n",
      "stopped_epoch2 4\n",
      "7\n",
      "0.9255859752558055\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 18s 294us/step - loss: 0.1467 - acc: 0.9399 - val_loss: 0.1913 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92175, saving model to /mnt/seals/models/228/model_round_3.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 15s 256us/step - loss: 0.1457 - acc: 0.9405 - val_loss: 0.1938 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.92175\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 16s 267us/step - loss: 0.1460 - acc: 0.9401 - val_loss: 0.1930 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92175\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 16s 265us/step - loss: 0.1461 - acc: 0.9400 - val_loss: 0.1903 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92175\n",
      "H3 {'val_acc': [0.9217538750699663, 0.9210854832336297, 0.9207958488336445, 0.9214865172645559], 'loss': [0.1466884447567359, 0.1456502562136941, 0.1460261590622687, 0.14611271296313616], 'val_loss': [0.19126162209959977, 0.1937579806529204, 0.1929722140709906, 0.1903273793064053], 'acc': [0.9398590803555847, 0.9404583195768835, 0.9400761279424247, 0.939991195879138]}\n",
      "stopped_epoch3 1\n",
      "4\n",
      "0.9210854832336297\n",
      "best fit round 2 0.9255859752558055\n",
      "3137/3137 [==============================] - 1s 293us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:30:32,653 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_mlp_concat\",\n",
      "    \"batch_size\": 32,\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 3137,\n",
      "    \"data_total_rows_train\": 60553,\n",
      "    \"data_total_rows_valid\": 6412,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 2,\n",
      "    \"fit_dt_test_duration_seconds\": \"0\",\n",
      "    \"fit_dt_test_end\": \"2019-01-20 15:30:30\",\n",
      "    \"fit_dt_test_start\": \"2019-01-20 15:30:29\",\n",
      "    \"fit_dt_train_duration_seconds\": \"302\",\n",
      "    \"fit_dt_train_end\": \"2019-01-20 15:30:28\",\n",
      "    \"fit_dt_train_start\": \"2019-01-20 15:25:26\",\n",
      "    \"fit_num_epochs\": 12,\n",
      "    \"fit_stopped_epoch1\": 4,\n",
      "    \"fit_stopped_epoch2\": 4,\n",
      "    \"fit_stopped_epoch3\": 1,\n",
      "    \"fit_test_acc\": 0.5406439273190946,\n",
      "    \"fit_train_acc\": 0.9376319882997802,\n",
      "    \"fit_train_loss\": 0.15174532825650758,\n",
      "    \"fit_val_acc\": 0.9255859752558055,\n",
      "    \"fit_val_loss\": 0.18650885416207577,\n",
      "    \"frame_size\": [\n",
      "        299,\n",
      "        299\n",
      "    ],\n",
      "    \"layer_1_size\": 128,\n",
      "    \"layer_2_size\": 256,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 228,\n",
      "    \"model_param_count\": 758151,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 1536,\n",
      "    \"path_model\": \"/mnt/seals/models/228/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"inception_resnet_v2\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": NaN,\n",
      "    \"sequence_model_layers\": NaN,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2019-01-20 15:30:32,654 [MainThread  ] [INFO ]  model 228 test acc: 0.5406439273190946\n",
      "2019-01-20 15:30:35,232 [MainThread  ] [INFO ]  Begin experiment for model_id=236 on GPU:4 \n",
      "2019-01-20 15:30:35,234 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 512, 'layer_1_size': 128, 'layer_2_size': 0, 'dropout': 0.2, 'architecture': 'video_MLP_concat', 'sequence_length': 3, 'WORKER': 4, 'sequence_model': nan, 'pooling': 'max', 'pretrained_model_name': 'inception_resnet_v2', 'model_id': 236, 'sequence_model_layers': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:30:36,427 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:30:36,429 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 15s 247us/step - loss: 0.3422 - acc: 0.9120 - val_loss: 0.2113 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91422, saving model to /mnt/seals/models/236/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 13s 211us/step - loss: 0.1852 - acc: 0.9235 - val_loss: 0.1930 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91422\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 13s 211us/step - loss: 0.1783 - acc: 0.9272 - val_loss: 0.2136 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91422\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 13s 212us/step - loss: 0.1729 - acc: 0.9289 - val_loss: 0.2146 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91422\n",
      "H1 {'val_acc': [0.9142233619300262, 0.9131093784116315, 0.9090990321158768, 0.9099233816433012], 'loss': [0.34219875466910593, 0.1851799579397007, 0.17827880452142872, 0.17286274053570166], 'val_loss': [0.2112714262192352, 0.19300102468995994, 0.2135576185254997, 0.21459556654960157], 'acc': [0.912022786697735, 0.923500334873185, 0.9271924932940151, 0.9289029203971139]}\n",
      "stopped_epoch1 1\n",
      "4\n",
      "0.9131093784116315\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 15s 246us/step - loss: 0.1601 - acc: 0.9339 - val_loss: 0.2005 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90843, saving model to /mnt/seals/models/236/model_round_2.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 13s 214us/step - loss: 0.1594 - acc: 0.9343 - val_loss: 0.1958 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90843 to 0.90925, saving model to /mnt/seals/models/236/model_round_2.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 13s 213us/step - loss: 0.1581 - acc: 0.9347 - val_loss: 0.1997 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90925\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 13s 211us/step - loss: 0.1568 - acc: 0.9353 - val_loss: 0.1975 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90925\n",
      "Epoch 5/20\n",
      "60553/60553 [==============================] - 13s 211us/step - loss: 0.1561 - acc: 0.9353 - val_loss: 0.2088 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90925\n",
      "H2 {'val_acc': [0.9084306441465915, 0.909254993079085, 0.9082969641655739, 0.9084752025042039, 0.9067819457238567], 'loss': [0.16012795228639243, 0.1593741593908311, 0.1581083565710215, 0.1567503418388598, 0.15612627194568293], 'val_loss': [0.20047903599139683, 0.19575180516753135, 0.19966171192922075, 0.19754454421015435, 0.20881030587241267], 'acc': [0.933890284990797, 0.9343432539255851, 0.934697133988674, 0.9352562664785686, 0.9353459153921797]}\n",
      "stopped_epoch2 2\n",
      "5\n",
      "0.9082969641655739\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 15s 245us/step - loss: 0.1545 - acc: 0.9360 - val_loss: 0.2020 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90805, saving model to /mnt/seals/models/236/model_round_3.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 13s 211us/step - loss: 0.1543 - acc: 0.9362 - val_loss: 0.2044 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90805\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 13s 216us/step - loss: 0.1549 - acc: 0.9360 - val_loss: 0.2019 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90805\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 13s 218us/step - loss: 0.1551 - acc: 0.9356 - val_loss: 0.2068 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90805\n",
      "H3 {'val_acc': [0.9080518864499578, 0.9078959283498549, 0.9079850487090317, 0.907049303529267], 'loss': [0.15453202528815835, 0.1543239520654234, 0.15487591575500745, 0.15510220510843808], 'val_loss': [0.20195536548765614, 0.20438487772003086, 0.20190696143129805, 0.206807487833076], 'acc': [0.9360182904359274, 0.9361763582094484, 0.9359545927288853, 0.935584196496608]}\n",
      "stopped_epoch3 1\n",
      "4\n",
      "0.9078959283498549\n",
      "best fit round 1 0.9131093784116315\n",
      "3137/3137 [==============================] - 1s 245us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:33:51,308 [MainThread  ] [INFO ]  {\n",
      "    \"architecture\": \"video_mlp_concat\",\n",
      "    \"batch_size\": 32,\n",
      "    \"convolution_kernel_size\": 3,\n",
      "    \"data_total_rows_test\": 3137,\n",
      "    \"data_total_rows_train\": 60553,\n",
      "    \"data_total_rows_valid\": 6412,\n",
      "    \"dropout\": 0.2,\n",
      "    \"fit_best_round\": 1,\n",
      "    \"fit_dt_test_duration_seconds\": \"0\",\n",
      "    \"fit_dt_test_end\": \"2019-01-20 15:33:49\",\n",
      "    \"fit_dt_test_start\": \"2019-01-20 15:33:48\",\n",
      "    \"fit_dt_train_duration_seconds\": \"187\",\n",
      "    \"fit_dt_train_end\": \"2019-01-20 15:33:47\",\n",
      "    \"fit_dt_train_start\": \"2019-01-20 15:30:39\",\n",
      "    \"fit_num_epochs\": 7,\n",
      "    \"fit_stopped_epoch1\": 1,\n",
      "    \"fit_stopped_epoch2\": 2,\n",
      "    \"fit_stopped_epoch3\": 1,\n",
      "    \"fit_test_acc\": 0.5795345871852088,\n",
      "    \"fit_train_acc\": 0.923500334873185,\n",
      "    \"fit_train_loss\": 0.1851799579397007,\n",
      "    \"fit_val_acc\": 0.9131093784116315,\n",
      "    \"fit_val_loss\": 0.19300102468995994,\n",
      "    \"frame_size\": [\n",
      "        299,\n",
      "        299\n",
      "    ],\n",
      "    \"layer_1_size\": 128,\n",
      "    \"layer_2_size\": 0,\n",
      "    \"layer_3_size\": 512,\n",
      "    \"model_id\": 236,\n",
      "    \"model_param_count\": 590855,\n",
      "    \"model_weights_path\": null,\n",
      "    \"num_features\": 1536,\n",
      "    \"path_model\": \"/mnt/seals/models/236/\",\n",
      "    \"pooling\": \"max\",\n",
      "    \"pretrained_model_name\": \"inception_resnet_v2\",\n",
      "    \"sequence_length\": 3,\n",
      "    \"sequence_model\": NaN,\n",
      "    \"sequence_model_layers\": NaN,\n",
      "    \"verbose\": true\n",
      "}\n",
      "2019-01-20 15:33:51,309 [MainThread  ] [INFO ]  model 236 test acc: 0.5795345871852088\n",
      "2019-01-20 15:33:58,071 [MainThread  ] [INFO ]  Begin experiment for model_id=244 on GPU:4 \n",
      "2019-01-20 15:33:58,075 [MainThread  ] [INFO ]  Loading data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244   XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "{'layer_3_size': 512, 'layer_1_size': 0, 'layer_2_size': 256, 'dropout': 0.2, 'architecture': 'video_MLP_concat', 'sequence_length': 3, 'WORKER': 4, 'sequence_model': nan, 'pooling': 'max', 'pretrained_model_name': 'inception_resnet_v2', 'model_id': 244, 'sequence_model_layers': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 15:33:59,214 [MainThread  ] [INFO ]  Features already cached: /mnt/seals/cache/features/inception_resnet_v2/max/\n",
      "2019-01-20 15:33:59,220 [MainThread  ] [INFO ]  Loading features sequence data into memory [may take a few minutes]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing data with #samples: train=60553, valid=6412, test=3137\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 13s 208us/step - loss: 1.0804 - acc: 0.8719 - val_loss: 0.7321 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91480, saving model to /mnt/seals/models/244/model_round_1.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 10s 169us/step - loss: 1.0122 - acc: 0.8804 - val_loss: 0.7615 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91480\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 10s 169us/step - loss: 0.9505 - acc: 0.8869 - val_loss: 0.7574 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91480\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 10s 171us/step - loss: 0.9654 - acc: 0.8863 - val_loss: 1.4547 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91480\n",
      "H1 {'val_acc': [0.9148026259333657, 0.897313087936944, 0.9142901920112162, 0.8532216447781416], 'loss': [1.080422149521254, 1.0122335221225724, 0.9505273815804094, 0.9654416930946593], 'val_loss': [0.7321170912782475, 0.7615257152452071, 0.7574146340507607, 1.4546629925184673], 'acc': [0.8719020760498568, 0.8804353364911353, 0.8868618224288577, 0.8863215618278597]}\n",
      "stopped_epoch1 1\n",
      "4\n",
      "0.897313087936944\n",
      "Train on 60553 samples, validate on 6412 samples\n",
      "Epoch 1/20\n",
      "60553/60553 [==============================] - 13s 211us/step - loss: 0.8325 - acc: 0.9034 - val_loss: 0.6810 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89974, saving model to /mnt/seals/models/244/model_round_2.h5\n",
      "Epoch 2/20\n",
      "60553/60553 [==============================] - 10s 171us/step - loss: 0.8159 - acc: 0.9071 - val_loss: 0.6298 - val_acc: 0.9202\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89974 to 0.92022, saving model to /mnt/seals/models/244/model_round_2.h5\n",
      "Epoch 3/20\n",
      "60553/60553 [==============================] - 10s 170us/step - loss: 0.8116 - acc: 0.9085 - val_loss: 0.6598 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.92022\n",
      "Epoch 4/20\n",
      "60553/60553 [==============================] - 10s 170us/step - loss: 0.8081 - acc: 0.9098 - val_loss: 0.6189 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.92022\n",
      "Epoch 5/20\n",
      "15296/60553 [======>.......................] - ETA: 7s - loss: 0.8026 - acc: 0.9106"
     ]
    }
   ],
   "source": [
    "###################\n",
    "### Run experiments\n",
    "###################\n",
    "\n",
    "for row in experiments.values:\n",
    "    \n",
    "    # get experiment params from dataframe row\n",
    "    experiment = dict(zip(experiments.columns, row))\n",
    "    \n",
    "    # only run experiment if not already run\n",
    "    if not os.path.exists(pwd + 'models/' + str(experiment[\"model_id\"]) + '/results.json'):\n",
    "\n",
    "        # only run experiment if matches this worker id\n",
    "        if experiment['WORKER'] == WORKER_ID:\n",
    "            \n",
    "            print(str(experiment[\"model_id\"]) + \"   \" + \"X\"*60)\n",
    "            logging.info(\"Begin experiment for model_id={} on GPU:{} \".format(experiment['model_id'], os.environ[\"CUDA_VISIBLE_DEVICES\"]))\n",
    "            print(experiment)\n",
    "\n",
    "            architecture = Architecture(model_id = experiment['model_id'], \n",
    "                                        architecture = experiment['architecture'], \n",
    "                                        sequence_length = experiment['sequence_length'], \n",
    "                                        pretrained_model_name = experiment['pretrained_model_name'],\n",
    "                                        pooling = experiment['pooling'],\n",
    "                                        sequence_model = experiment['sequence_model'],\n",
    "                                        sequence_model_layers = experiment['sequence_model_layers'],\n",
    "                                        layer_1_size = experiment['layer_1_size'],\n",
    "                                        layer_2_size = experiment['layer_2_size'],\n",
    "                                        layer_3_size = experiment['layer_3_size'],\n",
    "                                        dropout = experiment['dropout'],\n",
    "                                        verbose=True)\n",
    "\n",
    "            architecture.train_model()\n",
    "            \n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
